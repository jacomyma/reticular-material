<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Infomedia Articles</title>
    <style type="text/css">
/*!
 * Pico.css v1.3.3 (https://picocss.com)
 * Copyright 2019-2021 - Licensed under MIT
 */:root{--font-family:system-ui,-apple-system,"Segoe UI","Roboto","Ubuntu","Cantarell","Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";--line-height:1.5;--font-weight:400;--font-size:16px;--border-radius:.25rem;--border-width:1px;--outline-width:3px;--spacing:1rem;--typography-spacing-vertical:1.5rem;--block-spacing-vertical:calc(var(--spacing) * 2);--block-spacing-horizontal:var(--spacing);--grid-spacing-vertical:0;--grid-spacing-horizontal:var(--spacing);--form-element-spacing-vertical:.75rem;--form-element-spacing-horizontal:1rem;--transition:.2s ease-in-out}@media (min-width:576px){:root{--font-size:17px}}@media (min-width:768px){:root{--font-size:18px}}@media (min-width:992px){:root{--font-size:19px}}@media (min-width:1200px){:root{--font-size:20px}}@media (min-width:576px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 2.5)}}@media (min-width:768px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 3)}}@media (min-width:992px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 3.5)}}@media (min-width:1200px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 4)}}@media (min-width:576px){article{--block-spacing-horizontal:calc(var(--spacing) * 1.25)}}@media (min-width:768px){article{--block-spacing-horizontal:calc(var(--spacing) * 1.5)}}@media (min-width:992px){article{--block-spacing-horizontal:calc(var(--spacing) * 1.75)}}@media (min-width:1200px){article{--block-spacing-horizontal:calc(var(--spacing) * 2)}}a{--text-decoration:none}a.contrast,a.secondary{--text-decoration:underline}small{--font-size:0.875em}h1,h2,h3,h4,h5,h6{--font-weight:700}h1{--font-size:2rem;--typography-spacing-vertical:3rem}h2{--font-size:1.75rem;--typography-spacing-vertical:2.625rem}h3{--font-size:1.5rem;--typography-spacing-vertical:2.25rem}h4{--font-size:1.25rem;--typography-spacing-vertical:1.874rem}h5{--font-size:1.125rem;--typography-spacing-vertical:1.6875rem}[type=checkbox],[type=radio]{--border-width:2px}[type=checkbox][role=switch]{--border-width:3px}thead td,thead th{--border-width:3px}:not(thead)>*>td{--font-size:0.875em}code,kbd,pre,samp{--font-family:"Menlo","Consolas","Roboto Mono","Ubuntu Monospace","Noto Mono","Oxygen Mono","Liberation Mono",monospace,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji"}kbd{--font-weight:bolder}:root:not([data-theme=dark]),[data-theme=light]{color-scheme:light;--background-color:#FFF;--color:#415462;--h1-color:#1b2832;--h2-color:#23333e;--h3-color:#2c3d49;--h4-color:#374956;--h5-color:#415462;--h6-color:#4d606d;--muted-color:#73828c;--muted-border-color:#edf0f3;--primary:#1095c1;--primary-hover:#08769b;--primary-focus:rgba(16,149,193,0.125);--primary-inverse:#FFF;--secondary:#596b78;--secondary-hover:#415462;--secondary-focus:rgba(89,107,120,0.125);--secondary-inverse:#FFF;--contrast:#1b2832;--contrast-hover:#000;--contrast-focus:rgba(89,107,120,0.125);--contrast-inverse:#FFF;--mark-background-color:#fff2ca;--mark-color:#543a25;--ins-color:#388E3C;--del-color:#C62828;--blockquote-border-color:var(--muted-border-color);--blockquote-footer-color:var(--muted-color);--button-box-shadow:0 0 0 rgba(0,0,0,0);--button-hover-box-shadow:0 0 0 rgba(0,0,0,0);--form-element-background-color:transparent;--form-element-border-color:#a2afb9;--form-element-color:var(--color);--form-element-placeholder-color:var(--muted-color);--form-element-active-background-color:transparent;--form-element-active-border-color:var(--primary);--form-element-focus-color:var(--primary-focus);--form-element-disabled-background-color:#d5dce2;--form-element-disabled-border-color:#a2afb9;--form-element-disabled-opacity:.5;--form-element-invalid-border-color:#C62828;--form-element-invalid-active-border-color:#B71C1C;--form-element-valid-border-color:#388E3C;--form-element-valid-active-border-color:#2E7D32;--switch-background-color:#bbc6ce;--switch-color:var(--primary-inverse);--switch-checked-background-color:var(--primary);--range-border-color:#d5dce2;--range-active-border-color:#bbc6ce;--range-thumb-border-color:var(--background-color);--range-thumb-color:var(--secondary);--range-thumb-hover-color:var(--secondary-hover);--range-thumb-active-color:var(--primary);--table-border-color:var(--muted-border-color);--table-row-stripped-background-color:#f6f8f9;--code-background-color:#edf0f3;--code-color:var(--muted-color);--code-kbd-background-color:var(--contrast);--code-kbd-color:var(--contrast-inverse);--code-tag-color:#b34d80;--code-property-color:#3d888f;--code-value-color:#998866;--code-comment-color:#a2afb9;--accordion-border-color:var(--muted-border-color);--accordion-close-summary-color:var(--color);--accordion-open-summary-color:var(--muted-color);--card-background-color:var(--background-color);--card-border-color:var(--muted-border-color);--card-box-shadow:0 0.125rem 1rem rgba(27,40,50,0.04),0 0.125rem 2rem rgba(27,40,50,0.08),0 0 0 0.0625rem rgba(27,40,50,0.024);--card-sectionning-background-color:#fafbfc;--progress-background-color:#d5dce2;--progress-color:var(--primary);--loading-spinner-opacity:.5;--tooltip-background-color:var(--contrast);--tooltip-color:var(--contrast-inverse);--icon-chevron:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");--icon-date:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");--icon-time:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");--icon-search:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");--icon-checkbox:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-minus:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");--icon-valid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(56, 142, 60, 0.999)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-invalid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(198, 40, 40, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E")}@media only screen and (prefers-color-scheme:dark){:root:not([data-theme=light]){color-scheme:dark;--background-color:#11191f;--color:#bbc6ce;--h1-color:#edf0f3;--h2-color:#e1e6ea;--h3-color:#d5dce2;--h4-color:#c8d1d8;--h5-color:#bbc6ce;--h6-color:#aebbc3;--muted-color:#73828c;--muted-border-color:#1f2d38;--primary:#1095c1;--primary-hover:#1ab3e6;--primary-focus:rgba(16,149,193,0.25);--primary-inverse:#FFF;--secondary:#596b78;--secondary-hover:#73828c;--secondary-focus:rgba(115,130,140,0.25);--secondary-inverse:#FFF;--contrast:#edf0f3;--contrast-hover:#FFF;--contrast-focus:rgba(115,130,140,0.25);--contrast-inverse:#000;--mark-background-color:#d0c284;--mark-color:#11191f;--ins-color:#388E3C;--del-color:#C62828;--blockquote-border-color:var(--muted-border-color);--blockquote-footer-color:var(--muted-color);--button-box-shadow:0 0 0 rgba(0,0,0,0);--button-hover-box-shadow:0 0 0 rgba(0,0,0,0);--form-element-background-color:#11191f;--form-element-border-color:#374956;--form-element-color:var(--color);--form-element-placeholder-color:var(--muted-color);--form-element-active-background-color:var(--form-element-background-color);--form-element-active-border-color:var(--primary);--form-element-focus-color:var(--primary-focus);--form-element-disabled-background-color:#2c3d49;--form-element-disabled-border-color:#415462;--form-element-disabled-opacity:.5;--form-element-invalid-border-color:#B71C1C;--form-element-invalid-active-border-color:#C62828;--form-element-valid-border-color:#2E7D32;--form-element-valid-active-border-color:#388E3C;--switch-background-color:#374956;--switch-color:var(--primary-inverse);--switch-checked-background-color:var(--primary);--range-border-color:#23333e;--range-active-border-color:#2c3d49;--range-thumb-border-color:var(--background-color);--range-thumb-color:var(--secondary);--range-thumb-hover-color:var(--secondary-hover);--range-thumb-active-color:var(--primary);--table-border-color:var(--muted-border-color);--table-row-stripped-background-color:rgba(115,130,140,0.05);--code-background-color:#17232c;--code-color:var(--muted-color);--code-kbd-background-color:var(--contrast);--code-kbd-color:var(--contrast-inverse);--code-tag-color:#a65980;--code-property-color:#599fa6;--code-value-color:#8c8473;--code-comment-color:#4d606d;--accordion-border-color:var(--muted-border-color);--accordion-active-summary-color:var(--primary);--accordion-close-summary-color:var(--color);--accordion-open-summary-color:var(--muted-color);--card-background-color:#141e25;--card-border-color:#11191f;--card-box-shadow:0 0.125rem 1rem rgba(0,0,0,0.06),0 0.125rem 2rem rgba(0,0,0,0.12),0 0 0 0.0625rem rgba(0,0,0,0.036);--card-sectionning-background-color:#17232c;--progress-background-color:#23333e;--progress-color:var(--primary);--loading-spinner-opacity:.5;--tooltip-background-color:var(--contrast);--tooltip-color:var(--contrast-inverse);--icon-chevron:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");--icon-date:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");--icon-time:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");--icon-search:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");--icon-checkbox:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-minus:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");--icon-valid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(46, 125, 50, 0.999)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-invalid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(183, 28, 28, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E")}}[data-theme=dark]{color-scheme:dark;--background-color:#11191f;--color:#bbc6ce;--h1-color:#edf0f3;--h2-color:#e1e6ea;--h3-color:#d5dce2;--h4-color:#c8d1d8;--h5-color:#bbc6ce;--h6-color:#aebbc3;--muted-color:#73828c;--muted-border-color:#1f2d38;--primary:#1095c1;--primary-hover:#1ab3e6;--primary-focus:rgba(16,149,193,0.25);--primary-inverse:#FFF;--secondary:#596b78;--secondary-hover:#73828c;--secondary-focus:rgba(115,130,140,0.25);--secondary-inverse:#FFF;--contrast:#edf0f3;--contrast-hover:#FFF;--contrast-focus:rgba(115,130,140,0.25);--contrast-inverse:#000;--mark-background-color:#d0c284;--mark-color:#11191f;--ins-color:#388E3C;--del-color:#C62828;--blockquote-border-color:var(--muted-border-color);--blockquote-footer-color:var(--muted-color);--button-box-shadow:0 0 0 rgba(0,0,0,0);--button-hover-box-shadow:0 0 0 rgba(0,0,0,0);--form-element-background-color:#11191f;--form-element-border-color:#374956;--form-element-color:var(--color);--form-element-placeholder-color:var(--muted-color);--form-element-active-background-color:var(--form-element-background-color);--form-element-active-border-color:var(--primary);--form-element-focus-color:var(--primary-focus);--form-element-disabled-background-color:#2c3d49;--form-element-disabled-border-color:#415462;--form-element-disabled-opacity:.5;--form-element-invalid-border-color:#B71C1C;--form-element-invalid-active-border-color:#C62828;--form-element-valid-border-color:#2E7D32;--form-element-valid-active-border-color:#388E3C;--switch-background-color:#374956;--switch-color:var(--primary-inverse);--switch-checked-background-color:var(--primary);--range-border-color:#23333e;--range-active-border-color:#2c3d49;--range-thumb-border-color:var(--background-color);--range-thumb-color:var(--secondary);--range-thumb-hover-color:var(--secondary-hover);--range-thumb-active-color:var(--primary);--table-border-color:var(--muted-border-color);--table-row-stripped-background-color:rgba(115,130,140,0.05);--code-background-color:#17232c;--code-color:var(--muted-color);--code-kbd-background-color:var(--contrast);--code-kbd-color:var(--contrast-inverse);--code-tag-color:#a65980;--code-property-color:#599fa6;--code-value-color:#8c8473;--code-comment-color:#4d606d;--accordion-border-color:var(--muted-border-color);--accordion-active-summary-color:var(--primary);--accordion-close-summary-color:var(--color);--accordion-open-summary-color:var(--muted-color);--card-background-color:#141e25;--card-border-color:#11191f;--card-box-shadow:0 0.125rem 1rem rgba(0,0,0,0.06),0 0.125rem 2rem rgba(0,0,0,0.12),0 0 0 0.0625rem rgba(0,0,0,0.036);--card-sectionning-background-color:#17232c;--progress-background-color:#23333e;--progress-color:var(--primary);--loading-spinner-opacity:.5;--tooltip-background-color:var(--contrast);--tooltip-color:var(--contrast-inverse);--icon-chevron:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");--icon-date:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");--icon-time:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");--icon-search:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");--icon-checkbox:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-minus:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");--icon-valid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(46, 125, 50, 0.999)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-invalid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(183, 28, 28, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E")}*,:after,:before{box-sizing:border-box}:after,:before{text-decoration:inherit;vertical-align:inherit}html{-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:rgba(0,0,0,0);-moz-tab-size:4;-ms-text-size-adjust:100%;background-color:var(--background-color);color:var(--color);font-family:var(--font-family);font-size:var(--font-size);font-weight:var(--font-weight);line-height:var(--line-height);text-rendering:optimizeLegibility;cursor:default}main{display:block}body{width:100%;margin:0}body>footer,body>header,body>main{width:100%;margin-right:auto;margin-left:auto;padding:var(--block-spacing-vertical) 0}.container,.container-fluid{width:100%;margin-right:auto;margin-left:auto;padding-right:var(--spacing);padding-left:var(--spacing)}@media (min-width:576px){.container{max-width:510px;padding-right:0;padding-left:0}}@media (min-width:768px){.container{max-width:700px}}@media (min-width:992px){.container{max-width:920px}}@media (min-width:1200px){.container{max-width:1130px}}section{margin-bottom:var(--block-spacing-vertical)}.grid{grid-column-gap:var(--grid-spacing-horizontal);grid-row-gap:var(--grid-spacing-vertical);display:grid;grid-template-columns:1fr;margin:0}@media (min-width:992px){.grid{grid-template-columns:repeat(auto-fit,minmax(0%,1fr))}}.grid>*{min-width:0}figure{display:block;margin:0;padding:0;overflow-x:auto}figure figcaption{padding:calc(var(--spacing) / 2) 0;color:var(--muted-color)}b,strong{font-weight:bolder}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-0.25em}sup{top:-0.5em}dl dl,dl ol,dl ul,ol dl,ul dl{margin:0}ol ol,ol ul,ul ol,ul ul{margin:0}address,blockquote,dl,figure,form,ol,p,pre,table,ul{margin-top:0;margin-bottom:var(--typography-spacing-vertical);color:var(--color);font-size:1rem;font-style:normal}a{--color:var(--primary);--background-color:transparent;outline:none;background-color:var(--background-color);color:var(--color);text-decoration:var(--text-decoration);transition:background-color var(--transition),color var(--transition),text-decoration var(--transition),box-shadow var(--transition)}a:active,a:focus,a:hover{--color:var(--primary-hover);--text-decoration:underline}a:focus{--background-color:var(--primary-focus)}a.secondary{--color:var(--secondary)}a.secondary:active,a.secondary:focus,a.secondary:hover{--color:var(--secondary-hover)}a.secondary:focus{--background-color:var(--secondary-focus)}a.contrast{--color:var(--contrast)}a.contrast:active,a.contrast:focus,a.contrast:hover{--color:var(--contrast-hover)}a.contrast:focus{--background-color:var(--contrast-focus)}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:var(--typography-spacing-vertical);color:var(--color);font-family:var(--font-family);font-size:var(--font-size);font-weight:var(--font-weight)}h1{--color:var(--h1-color)}h2{--color:var(--h2-color)}h3{--color:var(--h3-color)}h4{--color:var(--h4-color)}h5{--color:var(--h5-color)}h6{--color:var(--h6-color)}address~h1,address~h2,address~h3,address~h4,address~h5,address~h6,blockquote~h1,blockquote~h2,blockquote~h3,blockquote~h4,blockquote~h5,blockquote~h6,dl~h1,dl~h2,dl~h3,dl~h4,dl~h5,dl~h6,figure~h1,figure~h2,figure~h3,figure~h4,figure~h5,figure~h6,form~h1,form~h2,form~h3,form~h4,form~h5,form~h6,ol~h1,ol~h2,ol~h3,ol~h4,ol~h5,ol~h6,pre~h1,pre~h2,pre~h3,pre~h4,pre~h5,pre~h6,p~h1,p~h2,p~h3,p~h4,p~h5,p~h6,table~h1,table~h2,table~h3,table~h4,table~h5,table~h6,ul~h1,ul~h2,ul~h3,ul~h4,ul~h5,ul~h6{margin-top:var(--typography-spacing-vertical)}hgroup{margin-bottom:var(--typography-spacing-vertical)}hgroup>*{margin-bottom:0}hgroup>:last-child{--color:var(--muted-color);--font-weight:unset;font-family:unset;font-size:1rem}p{margin-bottom:var(--typography-spacing-vertical)}small{font-size:var(--font-size)}ol,ul{padding-left:var(--spacing)}ol li,ul li{margin-bottom:calc(var(--typography-spacing-vertical) / 4)}ul li{list-style:square}mark{padding:.125rem .25rem;background-color:var(--mark-background-color);color:var(--mark-color);vertical-align:middle}blockquote{display:block;margin:var(--typography-spacing-vertical) 0;padding:var(--spacing);border-left:0.25rem solid var(--blockquote-border-color)}blockquote footer{margin-top:calc(var(--typography-spacing-vertical) / 2);color:var(--blockquote-footer-color)}abbr[title]{border-bottom:1px dotted;text-decoration:none;cursor:help}ins{color:var(--ins-color);text-decoration:none}del{color:var(--del-color)}::selection{background-color:var(--primary-focus)}audio,canvas,iframe,img,svg,video{vertical-align:middle}audio,video{display:inline-block}audio:not([controls]){display:none;height:0}iframe{border-style:none}img{max-width:100%;height:auto;border-style:none}svg:not([fill]){fill:currentColor}svg:not(:root){overflow:hidden}button{margin:0;overflow:visible;font-family:inherit;text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{padding:0;border-style:none}button{display:block;width:100%;margin-bottom:var(--spacing)}a[role=button]{display:inline-block;text-decoration:none}a[role=button],button,input[type=button],input[type=reset],input[type=submit]{--background-color:var(--primary);--border-color:var(--primary);--color:var(--primary-inverse);--box-shadow:var(--button-box-shadow,0 0 0 rgba(0,0,0,0));padding:var(--form-element-spacing-vertical) var(--form-element-spacing-horizontal);border:var(--border-width) solid var(--border-color);border-radius:var(--border-radius);outline:none;background-color:var(--background-color);box-shadow:var(--box-shadow);color:var(--color);font-size:1rem;font-weight:var(--font-weight);line-height:var(--line-height);text-align:center;cursor:pointer;transition:background-color var(--transition),border-color var(--transition),color var(--transition),box-shadow var(--transition)}a[role=button]:active,a[role=button]:focus,a[role=button]:hover,button:active,button:focus,button:hover,input[type=button]:active,input[type=button]:focus,input[type=button]:hover,input[type=reset]:active,input[type=reset]:focus,input[type=reset]:hover,input[type=submit]:active,input[type=submit]:focus,input[type=submit]:hover{--background-color:var(--primary-hover);--border-color:var(--primary-hover);--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0))}a[role=button]:focus,button:focus,input[type=button]:focus,input[type=reset]:focus,input[type=submit]:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--primary-focus)}input[type=reset]{--background-color:var(--secondary);--border-color:var(--secondary);--color:var(--secondary-inverse);cursor:pointer}input[type=reset]:active,input[type=reset]:focus,input[type=reset]:hover{--background-color:var(--secondary-hover);--border-color:var(--secondary-hover)}input[type=reset]:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--secondary-focus)}a[role=button].secondary,button.secondary,input[type=button].secondary,input[type=reset].secondary,input[type=submit].secondary{--background-color:var(--secondary);--border-color:var(--secondary);--color:var(--secondary-inverse);cursor:pointer}a[role=button].secondary:active,a[role=button].secondary:focus,a[role=button].secondary:hover,button.secondary:active,button.secondary:focus,button.secondary:hover,input[type=button].secondary:active,input[type=button].secondary:focus,input[type=button].secondary:hover,input[type=reset].secondary:active,input[type=reset].secondary:focus,input[type=reset].secondary:hover,input[type=submit].secondary:active,input[type=submit].secondary:focus,input[type=submit].secondary:hover{--background-color:var(--secondary-hover);--border-color:var(--secondary-hover)}a[role=button].secondary:focus,button.secondary:focus,input[type=button].secondary:focus,input[type=reset].secondary:focus,input[type=submit].secondary:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--secondary-focus)}a[role=button].contrast,button.contrast,input[type=button].contrast,input[type=reset].contrast,input[type=submit].contrast{--background-color:var(--contrast);--border-color:var(--contrast);--color:var(--contrast-inverse)}a[role=button].contrast:active,a[role=button].contrast:focus,a[role=button].contrast:hover,button.contrast:active,button.contrast:focus,button.contrast:hover,input[type=button].contrast:active,input[type=button].contrast:focus,input[type=button].contrast:hover,input[type=reset].contrast:active,input[type=reset].contrast:focus,input[type=reset].contrast:hover,input[type=submit].contrast:active,input[type=submit].contrast:focus,input[type=submit].contrast:hover{--background-color:var(--contrast-hover);--border-color:var(--contrast-hover)}a[role=button].contrast:focus,button.contrast:focus,input[type=button].contrast:focus,input[type=reset].contrast:focus,input[type=submit].contrast:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--contrast-focus)}a[role=button].outline,button.outline,input[type=button].outline,input[type=reset].outline,input[type=submit].outline{--background-color:transparent;--color:var(--primary)}a[role=button].outline:active,a[role=button].outline:focus,a[role=button].outline:hover,button.outline:active,button.outline:focus,button.outline:hover,input[type=button].outline:active,input[type=button].outline:focus,input[type=button].outline:hover,input[type=reset].outline:active,input[type=reset].outline:focus,input[type=reset].outline:hover,input[type=submit].outline:active,input[type=submit].outline:focus,input[type=submit].outline:hover{--background-color:transparent;--color:var(--primary-hover)}a[role=button].outline.secondary,button.outline.secondary,input[type=button].outline.secondary,input[type=reset].outline.secondary,input[type=submit].outline.secondary{--color:var(--secondary)}a[role=button].outline.secondary:active,a[role=button].outline.secondary:focus,a[role=button].outline.secondary:hover,button.outline.secondary:active,button.outline.secondary:focus,button.outline.secondary:hover,input[type=button].outline.secondary:active,input[type=button].outline.secondary:focus,input[type=button].outline.secondary:hover,input[type=reset].outline.secondary:active,input[type=reset].outline.secondary:focus,input[type=reset].outline.secondary:hover,input[type=submit].outline.secondary:active,input[type=submit].outline.secondary:focus,input[type=submit].outline.secondary:hover{--color:var(--secondary-hover)}a[role=button].outline.contrast,button.outline.contrast,input[type=button].outline.contrast,input[type=reset].outline.contrast,input[type=submit].outline.contrast{--color:var(--contrast)}a[role=button].outline.contrast:active,a[role=button].outline.contrast:focus,a[role=button].outline.contrast:hover,button.outline.contrast:active,button.outline.contrast:focus,button.outline.contrast:hover,input[type=button].outline.contrast:active,input[type=button].outline.contrast:focus,input[type=button].outline.contrast:hover,input[type=reset].outline.contrast:active,input[type=reset].outline.contrast:focus,input[type=reset].outline.contrast:hover,input[type=submit].outline.contrast:active,input[type=submit].outline.contrast:focus,input[type=submit].outline.contrast:hover{--color:var(--contrast-hover)}a[role=button][disabled],button[disabled],input[type=button][disabled],input[type=reset][disabled],input[type=submit][disabled]{opacity:.5;pointer-events:none}input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:1rem;letter-spacing:inherit;line-height:var(--line-height)}input{overflow:visible}select{text-transform:none}legend{max-width:100%;padding:0;color:inherit;white-space:normal}textarea{overflow:auto}[type=checkbox],[type=radio]{padding:0}::-webkit-inner-spin-button,::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}::-moz-focus-inner{padding:0;border-style:none}:-moz-focusring{outline:none}:-moz-ui-invalid{box-shadow:none}::-ms-expand{display:none}[type=file],[type=range]{padding:0;border-width:0}input:not([type=checkbox]):not([type=radio]):not([type=range]){height:calc((1rem * var(--line-height)) + (var(--form-element-spacing-vertical) * 2) + (var(--border-width) * 2))}fieldset{margin:0;margin-bottom:var(--spacing);padding:0;border:0}fieldset legend,label{display:block;margin-bottom:calc(var(--spacing) / 4);vertical-align:middle}input:not([type=checkbox]):not([type=radio]),select,textarea{display:block;width:100%}input:not([type=checkbox]):not([type=radio]):not([type=range]):not([type=file]),select,textarea{-webkit-appearance:none;-moz-appearance:none;appearance:none;padding:var(--form-element-spacing-vertical) var(--form-element-spacing-horizontal);vertical-align:middle}input,select,textarea{--background-color:var(--form-element-background-color);--border-color:var(--form-element-border-color);--color:var(--form-element-color);--box-shadow:none;border:var(--border-width) solid var(--border-color);border-radius:var(--border-radius);outline:none;background-color:var(--background-color);box-shadow:var(--box-shadow);color:var(--color);font-weight:var(--font-weight);transition:background-color var(--transition),border-color var(--transition),color var(--transition),box-shadow var(--transition)}input:not([type=submit]):not([type=button]):not([type=reset]):not([type=checkbox]):not([type=radio]):not([readonly]):active,input:not([type=submit]):not([type=button]):not([type=reset]):not([type=checkbox]):not([type=radio]):not([readonly]):focus,select:active,select:focus,textarea:active,textarea:focus{--background-color:var(--form-element-active-background-color)}input:not([type=submit]):not([type=button]):not([type=reset]):not([role=switch]):not([readonly]):active,input:not([type=submit]):not([type=button]):not([type=reset]):not([role=switch]):not([readonly]):focus,select:active,select:focus,textarea:active,textarea:focus{--border-color:var(--form-element-active-border-color)}input:not([type=submit]):not([type=button]):not([type=reset]):not([type=range]):not([type=file]):not([readonly]):focus,select:focus,textarea:focus{--box-shadow:0 0 0 var(--outline-width) var(--form-element-focus-color)}input:not([type=submit]):not([type=button]):not([type=reset])[disabled],select[disabled],textarea[disabled]{--background-color:var(--form-element-disabled-background-color);--border-color:var(--form-element-disabled-border-color);opacity:var(--form-element-disabled-opacity)}input[aria-invalid],select[aria-invalid],textarea[aria-invalid]{padding-right:2rem;background-position:center right .75rem;background-repeat:no-repeat;background-size:1rem auto}input[aria-invalid=false],select[aria-invalid=false],textarea[aria-invalid=false]{--border-color:var(--form-element-valid-border-color);background-image:var(--icon-valid)}input[aria-invalid=false]:active,input[aria-invalid=false]:focus,select[aria-invalid=false]:active,select[aria-invalid=false]:focus,textarea[aria-invalid=false]:active,textarea[aria-invalid=false]:focus{--border-color:var(--form-element-valid-active-border-color)!important}input[aria-invalid=true],select[aria-invalid=true],textarea[aria-invalid=true]{--border-color:var(--form-element-invalid-border-color);background-image:var(--icon-invalid)}input[aria-invalid=true]:active,input[aria-invalid=true]:focus,select[aria-invalid=true]:active,select[aria-invalid=true]:focus,textarea[aria-invalid=true]:active,textarea[aria-invalid=true]:focus{--border-color:var(--form-element-invalid-active-border-color)!important}input::-webkit-input-placeholder,input::placeholder,select:invalid,textarea::-webkit-input-placeholder,textarea::placeholder{color:var(--form-element-placeholder-color);opacity:1}input:not([type=checkbox]):not([type=radio]),select,textarea{margin-bottom:var(--spacing)}select::-ms-expand{border:0;background-color:transparent}select:not([multiple]):not([size]){padding-right:calc(var(--form-element-spacing-horizontal) + 1.5rem);background-image:var(--icon-chevron);background-position:center right .75rem;background-repeat:no-repeat;background-size:1rem auto}input+small,select+small,textarea+small{display:block;width:100%;margin-top:calc(var(--spacing) * -0.75);margin-bottom:var(--spacing);color:var(--muted-color)}label>input,label>select,label>textarea{margin-top:calc(var(--spacing) / 4)}[type=checkbox],[type=radio]{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:inline-block;width:1.25em;height:1.25em;margin-top:-.125em;margin-right:.375em;border-width:var(--border-width);vertical-align:middle;cursor:pointer}[type=checkbox]::-ms-check,[type=radio]::-ms-check{display:none}[type=checkbox]:checked,[type=checkbox]:checked:active,[type=checkbox]:checked:focus,[type=radio]:checked,[type=radio]:checked:active,[type=radio]:checked:focus{--background-color:var(--primary);--border-color:var(--primary);background-image:var(--icon-checkbox);background-position:center;background-repeat:no-repeat;background-size:.75em auto}[type=checkbox]~label,[type=radio]~label{display:inline-block;margin-right:.375em;margin-bottom:0;cursor:pointer}[type=checkbox]:indeterminate{--background-color:var(--primary);--border-color:var(--primary);background-image:var(--icon-minus);background-position:center;background-repeat:no-repeat;background-size:.75em auto}[type=radio]{border-radius:50%}[type=radio]:checked,[type=radio]:checked:active,[type=radio]:checked:focus{--background-color:var(--primary-inverse);border-width:.35em;background-image:none}[type=checkbox][role=switch]{--background-color:var(--switch-background-color);--border-color:var(--switch-background-color);--color:var(--switch-color);width:2.25em;height:1.25em;border:var(--border-width) solid var(--border-color);border-radius:1.25em;background-color:var(--background-color);line-height:1.25em}[type=checkbox][role=switch]:focus{--background-color:var(--switch-background-color);--border-color:var(--switch-background-color)}[type=checkbox][role=switch]:checked{--background-color:var(--switch-checked-background-color);--border-color:var(--switch-checked-background-color)}[type=checkbox][role=switch]:before{display:block;width:calc(1.25em - (var(--border-width) * 2));height:100%;border-radius:50%;background-color:var(--color);content:'';transition:margin 0.1s ease-in-out}[type=checkbox][role=switch]:checked{background-image:none}[type=checkbox][role=switch]:checked:before{margin-right:0;margin-left:calc(1.125em - var(--border-width))}[type=color]::-webkit-color-swatch-wrapper{padding:0}[type=color]::-moz-focus-inner{padding:0}[type=color]::-webkit-color-swatch{border:none;border-radius:calc(var(--border-radius) / 2)}[type=color]::-moz-color-swatch{border:none;border-radius:calc(var(--border-radius) / 2)}[type=date],[type=datetime-local],[type=month],[type=time],[type=week]{background-image:var(--icon-date);background-position:center right .75rem;background-repeat:no-repeat;background-size:1rem auto}[type=date]::-webkit-calendar-picker-indicator,[type=datetime-local]::-webkit-calendar-picker-indicator,[type=month]::-webkit-calendar-picker-indicator,[type=time]::-webkit-calendar-picker-indicator,[type=week]::-webkit-calendar-picker-indicator{opacity:0}[type=time]{background-image:var(--icon-time)}[type=file]{--color:var(--muted-color);padding:calc(var(--form-element-spacing-vertical)/2) 0;border:none;border-radius:0;background:none}[type=file]::-webkit-file-upload-button{--background-color:var(--secondary);--border-color:var(--secondary);--color:var(--secondary-inverse);margin-right:calc(var(--spacing) / 2);padding:calc(var(--form-element-spacing-vertical) / 2) calc(var(--form-element-spacing-horizontal) / 2);border:var(--border-width) solid var(--border-color);border-radius:var(--border-radius);outline:none;background-color:var(--background-color);box-shadow:var(--box-shadow);color:var(--color);font-size:1rem;font-weight:var(--font-weight);line-height:var(--line-height);text-align:center;cursor:pointer;transition:background-color var(--transition),border-color var(--transition),color var(--transition),box-shadow var(--transition)}[type=file]:active,[type=file]:focus,[type=file]:hover{--color:var(--color);border:none;background:none}[type=file]:active::-webkit-file-upload-button,[type=file]:focus::-webkit-file-upload-button,[type=file]:hover::-webkit-file-upload-button{--background-color:var(--secondary-hover);--border-color:var(--secondary-hover)}[type=range]{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:block;width:100%;height:1.25rem;background:transparent}[type=range]::-webkit-slider-runnable-track{width:100%;height:0.25rem;border-radius:var(--border-radius);background-color:var(--range-border-color);transition:background-color var(--transition),box-shadow var(--transition)}[type=range]::-moz-range-track{width:100%;height:0.25rem;border-radius:var(--border-radius);background-color:var(--range-border-color);transition:background-color var(--transition),box-shadow var(--transition)}[type=range]::-ms-track{width:100%;height:0.25rem;border-radius:var(--border-radius);background-color:var(--range-border-color);transition:background-color var(--transition),box-shadow var(--transition)}[type=range]::-ms-fill-lower{background-color:var(--border-radius)}[type=range]::-webkit-slider-thumb{-webkit-appearance:none;width:1.25rem;height:1.25rem;margin-top:-0.5rem;border:2px solid var(--range-thumb-border-color);border-radius:50%;background-color:var(--range-thumb-color);cursor:pointer;transition:background-color var(--transition),transform var(--transition)}[type=range]::-moz-range-thumb{-webkit-appearance:none;width:1.25rem;height:1.25rem;margin-top:-0.5rem;border:2px solid var(--range-thumb-border-color);border-radius:50%;background-color:var(--range-thumb-color);cursor:pointer;transition:background-color var(--transition),transform var(--transition)}[type=range]::-ms-thumb{-webkit-appearance:none;width:1.25rem;height:1.25rem;margin-top:-0.5rem;border:2px solid var(--range-thumb-border-color);border-radius:50%;background-color:var(--range-thumb-color);cursor:pointer;transition:background-color var(--transition),transform var(--transition)}[type=range]:focus,[type=range]:hover{--range-border-color:var(--range-active-border-color);--range-thumb-color:var(--range-thumb-hover-color)}[type=range]:active{--range-thumb-color:var(--range-thumb-active-color)}[type=range]:active::-webkit-slider-thumb{transform:scale(1.25)}[type=range]:active::-moz-range-thumb{transform:scale(1.25)}[type=range]:active::-ms-thumb{transform:scale(1.25)}[type=search]{border-radius:5rem;padding-left:calc(var(--form-element-spacing-horizontal) + 1.75rem)!important;background-image:var(--icon-search);background-position:center left 1.125rem;background-repeat:no-repeat;background-size:1rem auto}[type=search]::-webkit-search-cancel-button{-webkit-appearance:none;display:none}table{width:100%;border-color:inherit;border-collapse:collapse;border-spacing:0;text-indent:0}td,th{padding:calc(var(--spacing) / 2) var(--spacing);border-bottom:var(--border-width) solid var(--table-border-color);color:var(--color);font-size:var(--font-size);font-weight:var(--font-weight);text-align:left}tr{background-color:var(--background-color)}table[role=grid] tbody tr:nth-child(odd){--background-color:var(--table-row-stripped-background-color)}code,kbd,pre,samp{font-family:var(--font-family);font-size:.875rem}pre{-ms-overflow-style:scrollbar;overflow:auto}code,kbd,pre{background:var(--code-background-color);color:var(--code-color);font-weight:var(--font-weight);line-height:initial}code,kbd{display:inline-block;padding:.375rem .5rem;border-radius:var(--border-radius)}pre{display:block;margin-bottom:var(--spacing);padding:var(--spacing);overflow-x:auto;background:var(--code-background-color)}pre>code{display:block;padding:0;background:transparent;font-size:14px;line-height:var(--line-height)}code b{color:var(--code-tag-color);font-weight:var(--font-weight)}code i{color:var(--code-property-color);font-style:normal}code u{color:var(--code-value-color);text-decoration:none}code em{color:var(--code-comment-color);font-style:normal}kbd{background-color:var(--code-kbd-background-color);color:var(--code-kbd-color);vertical-align:middle}hr{box-sizing:content-box;height:0;overflow:visible;border:none;border-top:1px solid var(--muted-border-color)}[hidden],template{display:none}dialog{display:block;position:absolute;right:0;left:0;width:-moz-fit-content;width:-webkit-fit-content;width:fit-content;height:-moz-fit-content;height:-webkit-fit-content;height:fit-content;margin:auto;padding:1em;border:solid;background-color:white;color:black}dialog:not([open]){display:none}canvas{display:inline-block}details{display:block;margin-bottom:var(--spacing);padding-bottom:calc(var(--spacing) / 2);border-bottom:var(--border-width) solid var(--accordion-border-color)}details summary{color:var(--accordion-close-summary-color);line-height:1rem;list-style-type:none;list-style-type:none;cursor:pointer;transition:color var(--transition)}details summary::-webkit-details-marker{display:none}details summary::marker{display:none}details summary::-moz-list-bullet{list-style-type:none}details summary:after{display:inline-block;width:1rem;height:1rem;float:right;transform:rotate(-90deg);background-image:var(--icon-chevron);background-position:center;background-repeat:no-repeat;background-size:1rem auto;content:'';transition:transform var(--transition)}details summary:focus{outline:none;color:var(--accordion-active-summary-color)}details summary~*{margin-top:calc(var(--spacing) / 2)}details summary~*~*{margin-top:0}details[open]>summary{margin-bottom:calc(var(--spacing) / 4)}details[open]>summary:not(:focus){color:var(--accordion-open-summary-color)}details[open]>summary:after{transform:rotate(0)}article{margin:var(--block-spacing-vertical) 0;padding:var(--block-spacing-vertical) var(--block-spacing-horizontal);overflow:hidden;border-radius:var(--border-radius);background:var(--card-background-color);box-shadow:var(--card-box-shadow)}article>footer,article>header,article>pre{margin-right:calc(var(--block-spacing-horizontal) * -1);margin-left:calc(var(--block-spacing-horizontal) * -1);padding:calc(var(--block-spacing-vertical) / 1.5) var(--block-spacing-horizontal);background-color:var(--card-sectionning-background-color)}article>header{margin-top:calc(var(--block-spacing-vertical) * -1);margin-bottom:var(--block-spacing-vertical);border-bottom:var(--border-width) solid var(--card-border-color)}article>footer,article>pre{margin-top:var(--block-spacing-vertical);margin-bottom:calc(var(--block-spacing-vertical) * -1);border-top:var(--border-width) solid var(--card-border-color)}nav,nav ul{display:flex}nav{justify-content:space-between}nav ol,nav ul{align-items:center;margin-bottom:0;padding:0;list-style:none}nav ol:first-of-type,nav ul:first-of-type{margin-left:calc(var(--spacing) * -0.5)}nav ol:last-of-type,nav ul:last-of-type{margin-right:calc(var(--spacing) * -0.5)}nav li{display:inline-block;margin:0;padding:var(--spacing) calc(var(--spacing) / 2)}nav li>*,nav li>input:not([type=checkbox]):not([type=radio]){margin-bottom:0}nav a{display:block;margin:calc(var(--spacing) * -1) calc(var(--spacing) * -0.5);padding:var(--spacing) calc(var(--spacing) / 2);border-radius:var(--border-radius);text-decoration:none}nav a:active,nav a:focus,nav a:hover{text-decoration:none}aside li,aside nav,aside ol,aside ul{display:block}aside li{padding:calc(var(--spacing) / 2)}aside li a{margin:calc(var(--spacing) * -0.5);padding:calc(var(--spacing) / 2)}progress{display:inline-block;vertical-align:baseline}progress{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:inline-block;width:100%;height:.5rem;margin-bottom:calc(var(--spacing) / 2);overflow:hidden;border:0;border-radius:var(--border-radius);background-color:var(--progress-background-color);color:var(--progress-color)}progress::-webkit-progress-bar{border-radius:var(--border-radius);background:transparent}progress[value]::-webkit-progress-value{background-color:var(--progress-color)}progress::-moz-progress-bar{background-color:var(--progress-color)}@media (prefers-reduced-motion:no-preference){progress:indeterminate{background:var(--progress-background-color) linear-gradient(to right,var(--progress-color) 30%,var(--progress-background-color) 30%) top left/150% 150% no-repeat;animation:progressIndeterminate 1s linear infinite}progress:indeterminate[value]::-webkit-progress-value{background-color:transparent}progress:indeterminate::-moz-progress-bar{background-color:transparent}}@keyframes progressIndeterminate{0%{background-position:200% 0}to{background-position:-200% 0}}[aria-busy=true]{cursor:progress}[aria-busy=true]:not(input):not(select):not(textarea):before{display:inline-block;width:1em;height:1em;border:0.1875em solid currentColor;border-radius:1em;border-right-color:transparent;vertical-align:text-bottom;vertical-align:-.125em;animation:spinner 0.75s linear infinite;content:'';opacity:var(--loading-spinner-opacity)}[aria-busy=true]:not(input):not(select):not(textarea):not(:empty):before{margin-right:calc(var(--spacing) / 2)}[aria-busy=true]:not(input):not(select):not(textarea):empty{text-align:center}a[aria-busy=true],button[aria-busy=true],input[type=button][aria-busy=true],input[type=reset][aria-busy=true],input[type=submit][aria-busy=true]{pointer-events:none}@keyframes spinner{to{transform:rotate(360deg)}}[data-tooltip]{position:relative}[data-tooltip]:not(a):not(button):not(input){border-bottom:1px dotted;text-decoration:none;cursor:help}[data-tooltip]:after,[data-tooltip]:before{display:block;z-index:99;position:absolute;bottom:100%;left:50%;padding:.25rem .5rem;overflow:hidden;transform:translate(-50%,-0.25rem);border-radius:var(--border-radius);background:var(--tooltip-background-color);color:var(--tooltip-color);font-size:.875rem;font-style:normal;font-weight:var(--font-weight);text-decoration:none;text-overflow:ellipsis;white-space:nowrap;content:attr(data-tooltip);opacity:0;pointer-events:none}[data-tooltip]:after{padding:0;transform:translate(-50%,0rem);border-top:.3rem solid;border-right:.3rem solid transparent;border-left:.3rem solid transparent;border-radius:0;background-color:transparent;color:var(--tooltip-background-color);content:''}[data-tooltip]:focus:after,[data-tooltip]:focus:before,[data-tooltip]:hover:after,[data-tooltip]:hover:before{opacity:1;animation-name:slide;animation-duration:.2s}[data-tooltip]:focus:after,[data-tooltip]:hover:after{animation-name:slideCaret}@keyframes slide{0%{transform:translate(-50%,0.75rem);opacity:0}to{transform:translate(-50%,-0.25rem);opacity:1}}@keyframes slideCaret{0%{opacity:0}50%{transform:translate(-50%,-0.25rem);opacity:0}to{transform:translate(-50%,0rem);opacity:1}}[aria-controls]{cursor:pointer}[aria-disabled=true],[disabled]{cursor:not-allowed}[aria-hidden=false][hidden]{display:initial}[aria-hidden=false][hidden]:not(:focus){clip:rect(0,0,0,0);position:absolute}[tabindex],a,area,button,input,label,select,summary,textarea{-ms-touch-action:manipulation}@media (prefers-reduced-motion:reduce){:not([aria-busy=true]),:not([aria-busy=true]):after,:not([aria-busy=true]):before{background-attachment:initial!important;animation-duration:1ms!important;animation-delay:-1ms!important;animation-iteration-count:1!important;scroll-behavior:auto!important;transition-delay:0s!important;transition-duration:0s!important}}
    </style>
    <style type="text/css">
      article div {
        font-size: 1.15em;
        line-height: 1.6em;
      }
    </style>
  </head>
  <body style="background-color: #f9fafb;">
    <main class="container">
      <nav>
        <ul>
          <li><a href="../index.html"> Topic list</a></li>
        </ul>
      </nav>
      <!-- <h1>Infomedia Articles Selection: 50 articles</h1> -->
      <h1>hSBM 0_108 <kbd>H_0_108</kbd></h1>
      <h3>Words (top 25)</h3>
      <div style="margin:0px -12px">
        <span style="font-size:17.71pt; padding:0px 12px"><strong>]</strong>&nbsp;<span style="font-size:.5em">450</span></span>
        <span style="font-size:17.57pt; padding:0px 12px"><strong>[</strong>&nbsp;<span style="font-size:.5em">431</span></span>
        <span style="font-size:16.81pt; padding:0px 12px"><strong>blog</strong>&nbsp;<span style="font-size:.5em">337</span></span>
        <span style="font-size:15.64pt; padding:0px 12px"><strong>gpt-3</strong>&nbsp;<span style="font-size:.5em">215</span></span>
        <span style="font-size:15.45pt; padding:0px 12px"><strong>python</strong>&nbsp;<span style="font-size:.5em">198</span></span>
        <span style="font-size:15.38pt; padding:0px 12px"><strong>forklaringer</strong>&nbsp;<span style="font-size:.5em">192</span></span>
        <span style="font-size:14.67pt; padding:0px 12px"><strong>java</strong>&nbsp;<span style="font-size:.5em">135</span></span>
        <span style="font-size:14.62pt; padding:0px 12px"><strong>|</strong>&nbsp;<span style="font-size:.5em">131</span></span>
        <span style="font-size:14.29pt; padding:0px 12px"><strong>fairness</strong>&nbsp;<span style="font-size:.5em">108</span></span>
        <span style="font-size:14.21pt; padding:0px 12px"><strong>reprsentation</strong>&nbsp;<span style="font-size:.5em">103</span></span>
        <span style="font-size:14.19pt; padding:0px 12px"><strong>l.</strong>&nbsp;<span style="font-size:.5em">102</span></span>
        <span style="font-size:14.18pt; padding:0px 12px"><strong>code</strong>&nbsp;<span style="font-size:.5em">101</span></span>
        <span style="font-size:14.15pt; padding:0px 12px"><strong>models</strong>&nbsp;<span style="font-size:.5em">99</span></span>
        <span style="font-size:13.97pt; padding:0px 12px"><strong>conference</strong>&nbsp;<span style="font-size:.5em">88</span></span>
        <span style="font-size:13.93pt; padding:0px 12px"><strong>speed</strong>&nbsp;<span style="font-size:.5em">86</span></span>
        <span style="font-size:13.83pt; padding:0px 12px"><strong>{</strong>&nbsp;<span style="font-size:.5em">80</span></span>
        <span style="font-size:13.81pt; padding:0px 12px"><strong>skvheder</strong>&nbsp;<span style="font-size:.5em">79</span></span>
        <span style="font-size:13.76pt; padding:0px 12px"><strong>nedenstende</strong>&nbsp;<span style="font-size:.5em">76</span></span>
        <span style="font-size:13.74pt; padding:0px 12px"><strong>forklarlighed</strong>&nbsp;<span style="font-size:.5em">75</span></span>
        <span style="font-size:13.59pt; padding:0px 12px"><strong>recognition</strong>&nbsp;<span style="font-size:.5em">67</span></span>
        <span style="font-size:13.59pt; padding:0px 12px"><strong>linere</strong>&nbsp;<span style="font-size:.5em">67</span></span>
        <span style="font-size:13.51pt; padding:0px 12px"><strong>computational</strong>&nbsp;<span style="font-size:.5em">63</span></span>
        <span style="font-size:13.49pt; padding:0px 12px"><strong>binre</strong>&nbsp;<span style="font-size:.5em">62</span></span>
        <span style="font-size:13.49pt; padding:0px 12px"><strong>javascript</strong>&nbsp;<span style="font-size:.5em">62</span></span>
        <span style="font-size:13.37pt; padding:0px 12px"><strong>pp.</strong>&nbsp;<span style="font-size:.5em">56</span></span>
      </div>
      <br><br>
      <h3>Articles (top 50)</h3>
      Query:
      <pre>SELECT * FROM articles WHERE articles.dupeKeep=1 AND articles.sizeKeep=1 ORDER BY H_0_108 DESC LIMIT 50</pre>
      <article>
        <h4>Metoder inden for Explainable AI (XAI)</h4>
        <div>
          Explainable AI (XAI), alts forklarlig kunstig intelligens, har meget fokus i jeblikket, fordi maskinlringsmodeller bliver mere ugennemskuelige og komplekse, og fordi datadrevne modeller bliver brugt mere til kritiske beslutninger og af ikke-ekspertbrugere. Der findes dog mange forskellige mder at lave forklarlig kunstig intelligens p og dermed ogs et hav af forskellige metoder. Ved at definere egenskaber og typer af metoder og forklaringer og ved at give et overblik over de mest kendte metoder, vil vi hjlpe med at finde rundt i junglen af XAI-metoder.Bekymringer om forklarlighed vedrrende systemer baseret p kunstig intelligens er ikke noget nyt, se f.eks. 'ekspertsystemer' [1], 'case-based reasoning' [2, 3] eller, for et historisk overblik, se reviewet der blev lavet som del af DARPAs XAI projekt [4]. Men i de sidste 2-3 r er der kommet et hav af nye metoder til at lave forklarlig kunstig intelligens.Hvad er forskellen mellem de forskellige metoder? Hvilke typer af forklaringer generer de? Og hvilke metoder passer i hvilken situation, til hvilke type data eller modeller? I dette blogindlg giver vi et overblik over forskellige metoder og grupperer dem ved at definere en taksonomi af XAI-metoder. Taksonomien og inddelingen i forskellige grupper er inspireret af diagrammet fra IBM's AIX360 open-source bibliotek, Christoph Molnars e-bog og forskellige artikler om XAI-metoder [5, 6, 7, 8, 9, 10, 11, 12].Helt generelt kan man adskille metoder p mden, man interagerer med dem. De kan vre statiske eller interaktive (fr man bare en eller flere forklaringer, eller kan man ogs ''sprge'' ind til en anden eller dybere forklaring). Der findes dog os bekendt ingen interaktive metoder, s vi fokuserer her udelukkende p statiske metoder.Desuden kan man gruppere XAI-metoder efter hvilken type af data, de er egnet til, og efter hvilke typer af forklaring de genererer. Der findes bde metoder, der kan forklare data, og metoder, der forklarer modellerne. Sidstnvnte kan videre separeres p 1) hvilket omrde forklaringerne virker p, alts forklarer de dele af modellen (global ) eller modellens resultater (lokal ), 2) om det er modeller, der kan forklare sig selv (iboende ) eller metoder, der forklarer en ugennemsigtig model (post-hoc ), og 3) om de er lavet til en specifik type af model.I det flgende vil vi beskrive, lidt mere i dybden, hvilke typer af data der kan forekomme, hvilke typer af forklaringer der eksisterer, og hvad iboende, post-hoc, lokal og global egentlig betyder, samt nvne nogle eksempler p XAI-metoder i hver kategori. Til sidst giver vi et overblik over et udvalg af metoder i form af et taksonomitr.Typer af dataForklaringer og XAI-metoder er afhngige af den datatype, som modellen er udviklet til. De fleste anvendelser af datadrevne modeller er lavet til tabel-, billede-, tekstdata eller tidsserier.TabeldataTabeldata data er data, der kan beskrives i form af en tabel, hvor hver kolonne reprsenterer en variabel eller feature, og hver rkke reprsenterer et eksempel eller datapunkt. Denne type data er brugt i de mest klassiske anvendelser af maskinlring, ssom fraud detection eller churn prediction. Desuden kan mange andre datakilder tit udtrykkes som en tabel gennem skaldt feature extraction.BilleddataBilleddata er den type data, der forekommer i computer vision-opgaver, ssom object detection, optical character recognition eller image segmentation. Hvert billede i datasttet reprsenterer et eksempel eller datapunkt. Man kan bruge dybe neurale netvrk (convolutional neural networks) til billeddata, eller ekstrahere nogle features fra et billede s datasttet kan udtrykkes som en tabel.TekstdataTekstdata er den type data, der forekommer i NLP-opgaver (natural language processing), som f.eks. named entity recognition, speech to text, eller at analysere toner i debatten. Hver tekst, ssom stninger, afsnit eller dokumenter, i datasttet reprsenterer et eksempel eller datapunkt. Man kan bruge dybe neurale netvrk (recurrent neural networks) til tekstdata, eller ekstrahere nogle features fra tekster s datasttet kan udtrykkes som tabel.TidsserierTidsserier bliver tit udtrykt som tabeldata, s det kan bruges til maskinlring. Derfor kan alle XAI-metoder, der arbejder p tabeldata, normalt ogs bruges p tidsserier.Typer af forklaringerForklarlighed skal altid defineres i en given kontekst. Denne kontekst indeholder ml og andre dimensioner, der er afhngige af tidsbegrnsninger og slutbrugerens ekspertise i forhold til maskinlring [5] (se ogs vores andet blogindlg om forklarlighed ).Tiden, en bruger har til at forst eller kigge p en forklaring, kan vre begrnset i en given applikation, som stter begrnsninger p forklarligheden. Yderligere begrnsninger og krav er givet fra den type bruger, der interagerer med modellen. Brugerens ekspertise kan vre alt imellem en beslutningstager uden teknisk baggrund og hje domneviden, som lger, dommere, eller planlggere, over forskere eller ingenirer med en basis, teknisk viden, hen til data scientists og maskinlringseksperter med en dyb viden om selve modellen. Forskellige typer af brugere har brug for forskellige typer af forklaringer. I den her del af blogindlgget vil vi gerne komme det nrmere, hvilke typer af forklaringer, der findes, og hvordan de udmnter sig. Det er dog ikke en udtmmende liste, og det er vigtigt at bemrke, at nogle gange kan en brugers behov lses gennem UX-design eller forklaringer, der ikke er automatisk genererede.EksemplerEn mde at generere forklaringer p er ved at bruge eksempler. Fordelen ved forklaringer gennem eksempler er, at det er let forsteligt for slutbrugeren eller domneeksperten, da eksempler, og dermed forklaringer, kommer fra selve datadomnet. Desuden bruger mennesker tit eksempler til at trffe en beslutning, skaldt cased-based reasoning [2, 3]. For eksempel nr en lge stiller en diagnose, er det baseret p symptomer, og de erfaringer han har med patienter, der har udvist lignende symptomer. Eller nr en data-scientist skal lse en opgave, s husker han en opgave, han har lst tidligere, og hvilke metoder og modeller der virkede bedst til at lse opgaven.Dog giver det kun mening at bruge eksempler som forklaring, hvis selve data let kan reprsenteres og er forsteligt. Det glder for eksempel for billeder eller tekst, som mennesker kan give en mening til. Det kan ogs virke for tabeldata, men det krver, at kolonner (variabler) har en mening, som pris, antal vrelser eller hustype for et hus-datast, og at der kun er en hndfuld kolonner, ellers er enkelte datapunkter ikke gennemskuelige.PrototyperEksemplerne kan bde bruges som forklaring af selve data eller for at forklare en models resultat. For at forklare data sger man efter de eksempler i et datast, der bedst reprsenterer datasttet, skaldte prototyper. Nr man har et datast med forskellige grupper (klassifikationsproblem), vil man som regel finde prototyper for hver klasse.Udover prototyper er det ogs vigtig at kunne afgrnse datasttet, alts finde de datapunkter der ligger p grnsen af datasttet eller lngst vk fra prototyperne, skaldt criticisms. Det blev frst prsenteret fra Kim et al. sammen med deres MMD-critic metode[13]. ProtoDash er en anden metode til at finde prototyper og criticisms og er en viderefrelse af 'MMD-critic' lavet af en IBM-forsker [14].Udover at finde reprsentative datapunkter i et datast findes der ogs modeller, der sammen med deres output giver en prototype-forklaring [15, 16].Eksempler fra trningsdataEksempler kan ikke kun bruges til at forklare data, men ogs til at forklare et bestemt resultat af modellen [17]. En mde at gre det p er at finde de eksempler fra trningsdata, der havde mest indflydelse p modellens beslutning [18]. Det krver, at man definerer en skaldt influencer-funktion, der kan beregne indflydelsen.En klassisk maskinlringsmodel, der trffer beslutninger baseret direkte p eksempler fra trningsdata, er k-nearest neighbour (k-NN ). Her fr man forklaringer som eksempler ''gratis'' sammen med modellens resultat. Der findes ogs forskning til at bruge k-NN sammen med et dybt neural netvrk til at bde lre komplekse sammenhng i data og f en forklaring [19].CounterfactualsEn anden mde at bruge eksempler som en beslutningsforklaring p er at finde counterfactuals [20]. Counterfactuals undersger, hvad der ville vre sket, hvis udgangspunktet havde vret anderledes, alts hvilke fakta-ndringer der ville have srget for et modsat resultat. Hvis man for eksempel fr afvist et ln, s kan det vre, at man ville have fet det, hvis man havde en hjere indkomst. Den form for kontrastiv forklaring er ogs tit brugt af mennesker [21].Der findes forskellige metoder til at generere counterfactuals p, bde til tabeldata [22], billeddata [23] og forskellige datatyper [24, 25].ReglerRegel-baserede modeller, skaldte ekspertsystemer, har vret mden at lave forklarlige modeller p og var meget populre i 80'erne. I disse systemer bliver regler defineret af domneeksperter, og s kan de bruges til en automatisk beslutning. Disse regler har en hvis-s form, f.eks. hvis der er skyer, og gulvet er vdt, s har det regnet. Reglerne kan have flere betingelser (''der er skyer'', ''gulvet er vdt''), men kun maksimalt to resultater (''det regnede'', ''det regnede ikke''). Reglerne kan kombineres med hinanden og udfres efter hinanden, dvs. en regel bestemmer hvilken regel, der skal bruges i nste trin.Udover ekspertsystemer findes der ogs maskinlringsmodeller, der automatisk genererer regler baseret p sammenhnge i data [26, 27, 28]. En bestemt form af disse modeller er beslutningstrer, hvor regler er binre (en betingelse og to veje) og kombineret i et tr. Beslutninger bliver s lavet ved at starte i roden af tret og flge regler igennem, indtil man lander i et blad, som udgr resultatet.Regler kan bde bruges til at forklare hele modellen gennem alle reglerne, modellen bestr af, og som lokal forklaring ved at give de regler der var afgrende for en bestemt beslutning [29].Feature attributionsFeature attributions er den type forklaring, der er mest udbredt i de metoder, der er blevet udviklet for nyligt, og som der er mest hype omkring. Feature attributions beskriver for hver variabel, hvor vigtig den er for modellens resultat. Det kan bde vre globalt, alts hvilke variabler er grundsatslig vigtige, eller lokalt, alts hvilke variabler var mest afgrende for en bestemt beslutning.Nr man kigger i junglen af maskinlringsmodeller s findes der en gruppe af skaldt linere modeller: liner regression, logistisk regression, Generalized Linear Models (GLMs) og Generalized Additive Models (GAMs). P grund af deres struktur er det muligt at f bde en global eller lokal forklaring i form af feature attributions (ls mere ved at klikke p links). Der har vret en del udvikling i den seneste tid af algoritmer til at lave linere modeller, der har lige s god eller bedre performance end mere komplekse black-box-modeller, f.eks. GA2M [30] eller SLIM [31].Der findes ogs metoder, der kan generere feature attributions for en ikke-liner black-box-model, f.eks. SHAP [32], som er baseret p skaldte shapley values [33], LIME [34], DeepLIFT[35], Grad-CAM [36] eller LRP [37]. De sidstnvnte (DeepLIFT, Grad-CAM og LRP) er specielt lavet til dybe neurale netvrk, og her er iden blandt andet, at outputtet af netvrket bliver frt tilbage til inputtet igennem netvrket for at vise, hvilke dele af inputtet der var mest betydningsfulde. De fleste af disse metoder virker p alle typer af data, og vi vil gerne beskrive i lidt flere detaljer, hvordan feature attributions kan se ud p billede- eller tekstdata.BillederFeatures i billeder er de enkelte pixels i billedet eller dele af billedet. S nr vi bruger feature attributions p billeddata, handler det om at markere de pixels eller omrder i billedet, som var mest betydningsfulde for modellens resultat.TekstFeatures i tekst er de enkelte ord eller stninger i teksten. S nr vi bruger feature attributions p tekstdata, handler det om at markere de ord, som var mest betydningsfulde for modellens resultat.VisualiseringerVisualiseringer er en god mde at reprsentere komplekse sammenhnge p, og er den foretrukne mde for data scientists, statistikere og analytikere til at forst data og modeller. Desuden er smarte visualiseringer hjertet af business intelligence-lsninger. Visualiseringer er derfor ogs en god mde at forklare data eller modeller p.Her vil vi kort beskrive forskellige mder at bruge visualiseringer som forklaring p. Vr opmrksom p at nogle af de tidligere prsenterede typer af forklaringer (regler og feature attributions) ogs skal visualiseres, men der findes mange forskellige mder at gre det p, hvorimod de visualiseringer, vi beskriver her, hnger tt sammen med metoden.DatavisualiseringerLigesom med andre typer forklaringer, s kan man bde forklare data og modeller. Visualiseringer bliver som regel brugt til at forst data, inden man begynder at designe og trne en model. Det er forholdsvis nemt at visualisere enkelte eksempler p tekst- og billeddata, da deres form allerede er en visualisering i sig selv. Der er dog udfordringer med at visualisere et helt datast. Her bruger man tit en form af 'manifold visualisering', f.eks. t-SNE.For tabeldata krves det frst, at man reducerer dimensionen af de enkelte datapunkter til 2 eller 3 variabler, da data s kan visualiseres i et 2D eller 3D plot. Principal component analysis (PCA ) er en kendt metode til reducering af dimensioner. Yellowbrick er et godt Python-bibliotek, der samler forskellige visualiserings- og dimensionsreducerings-metoder.Partial dependence plot (PDP)Partial Dependence Plots (PDPs ) er en mde til at forklare en model. Selve plotsene viser, hvordan vrdien af en enkelt variabel, eller vrdierne af et par af variablerne, ndrer modellens resultat. Det er Jerome H. Friedman, der frst prsenterede PDP i 2001 [38].Goldstein et al. videreudviklede metoden til Individual Conditional Expectation (ICE) plots, hvor man ogs kan se effekten for et eller flere udvalgte datapunkter, udover at kun se den samlede effekt [39]. ICE plots kan dog kun laves for en enkelt variabel ad gangen.Neuron-visualiseringerDybe neurale netvrk bestr af hundrede eller tusindvis af neuroner, der er forbundet til hinanden og organiseret i en grafstruktur med forskellige lag. Hvert lag eller gruppe af lag transformerer data fra selve inputtet til outputtet af modellen igennem mere og mere abstrakte reprsentationer, jo dybere (tttere p output) man kommer ned i netvrket.Der findes forskellige metoder til at visualisere disse abstrakte reprsentationer, som modellen har lrt [40]. Metoderne er begrnset p billed- eller tekstdata, da visualiseringer som billed eller tekst intuitivt kan forsts. Med tabeldata er det svrt at forst abstrakte reprsentationer, da de ikke direkte relaterer tilbage til input-domnet eller specifikke attributter.Det er for eksempel brugbart til at visualisere, hvordan netvrket ''ser'' et bestemt input i de forskellige lag [40, 41, 42], eller til at visualisere hvad forskellige neuroner eller lag i netvrket detekterer eller ekstraherer generelt fra dataene [43, 44, 45, 46].KoncepterKoncepter er det, der kommer tttest p, hvordan vi som mennesker forstr verden. Nr vi ser et objekt med hjul, s tnker vi nok, at man kan kre med det, selvom vi mske ikke kender selve objektet. Nr vi ser et dyr med vinger, s vil vi nok genkende det som en fugl, ogs hvis vi ikke har set den type fugl fr. Ved at interagere med vores omverden og ved at lse bger, se film, g i skole osv. lrer vi koncepter, der kan hjlpe ogs med at forst nye ting.Nuvrende modeller brugt i maskinlring, der bliver trnet med data, lrer ikke koncepter eller kausale sammenhnge, men en korrelation mellem input- og output-variabler. Der er derfor en aktiv forskning, der handler om, hvordan vi kan skabe modeller, der faktisk har lrt koncepter, f.eks. causal inference [47] (se ogs DoWhy eller CausalNex Python-biblioteker) eller kognitive modeller [48]. Men forskningen er bare pbegyndt og er ikke moden nok til at blive brugt i industrien, selvom der er nogle lovende resultater inden for bde NLP [49] og computer vision (Neuro-Symbolic Concept Learner ).Nr vi s snakker om koncepter her, s handler det stadig om modeller, der lrer en korrelation, men som ved hjlp af vrktjer kan generere en forklaring, der kommer tt p koncept-tanken og adskiller sig fra de vrige typer af forklaringer, vi har beskrevet i dette indlg.En mde at f konceptforklaringer p er at annotere datasttet, s hvert datapunkt ogs har en konceptlignende forklaring givet af en domneekspert, og s trne en model der bde genererer et output og en forklaring [50].En anden mde er ved at definere koncepter gennem eksempel-datapunkter og undersge sensitiviteten overfor disse datapunkter for hver af modellens output i et klassificerings-problem [51]. For eksempel kan man undersge om en model til at klassificere billeder er sensitiv overfor konceptet ''striber'', nr den klassificerer en zebra. Ghorbani et al. automatiserer denne tilgang, s koncepterne bliver genereret automatisk for et givent billede [52].Det er ogs muligt at trne en model, s den kan svare p sprgsml i forhold til et billede, skaldt visual question answering [53, 54, 55]. Her handler det om, at modellen forstr de koncepter, der er til stede i sprgsmlene og billedet.Global eller lokal - Post-hoc eller iboendeI ovenstende afsnit har vi set, at forklaringsmetoder kan grupperes afhngigt af, hvilken type forklaring de genererer. En anden mde at adskille metoderne, der forklarer modeller p, er baseret p deres virkningsomrde. Typisk adskiller man mellem global og lokal [5, 56, 57].Global forklarlighed gr det muligt at forst hele logikken bag, hvordan en model virker og at flge dens rsonnement for alle mulige prdiktioner [5]. Global forklarlighed kan videre separeres i transparens [10], som man ogs kalder iboende, global forklarlighed, og post-hoc global forklarlighed [56]. Hvor transparens er en direkte egenskab, der er bygget ind i modellen, er post-hoc global forklarlighed som regel udfrt ved at bruge en metode, der forklarer hvilke mnstre, en model har lrt [56].Lokal forklarlighed giver yderligere informationer og forklaringer om en enkelt models prdiktion. Ligesom ved global forklarlighed kan man igen adskille imellem iboende lokal forklarlighed og post-hoc lokal forklarlighed [10, 56].Global forklarlighedDatadrevne modeller, isr dem baseret p maskinlring og deep learning, er tit beskrevet som ugennemskuelige ''black boxes'', hvor det selv for eksperter er svrt at forst modellens indre logikker. Global forklarlighed kan forsts som en modstning til en black box. Global forklarlighed er evnet til at forklare hele modellens logik og at flge dens beslutning hele vejen igennem fra input-data til modellens prdiktion [5]. Det kan opns ved at bygge en model, der har iboende global forklarlighed (transparent) eller ved at bruge en post-hoc model til at forklare en black box-models logik.TransparensTransparens er defineret som evnen til direkte at forst hele modellen. Algoritmer eller metoder til at generere en transparent model, kan man gruppere under ''transparent design'' [5].Men hvad er transparens egentlig? Z. C. Lipton beskriver forskellige typer af transparens: simulatibility (simulerbarhed), decomposability (nedbrydelighed) og algoritmisk transparens [10]:Flger man Liptons definition af transparens, er linere regressionsmodeller, beslutningstrer og regel-baserede modeller alle sammen transparente, da man ''nemt'' kan forst og beregne de underliggende mekanismer. Men disse modeller kan hurtigt blive store (antal af parametre, dybden og bredden af tret, antal af regler). S hvornr er de sm nok til stadig at glde som global forklarlige? En mulighed for at undg problemet er at tilfje begrnsninger i trningsprocessen, der minimerer strrelsen og kompleksiteten af modellen. Den strategi kan bruges bde til ''enkle'' modeller, som linere regressioner og beslutningstrer, men ogs til black box-modeller som neurale netvrk [58].Transparens kan ogs defineres som en grad af transparens fra black box til fuld transparens, hvor nogle dele af modellen er transparente og nogen andre er uigennemskuelige.Post-hoc global forklarlighedPost-hoc global forklarlighed opns ved at anvende metoder p black box-modeller for at gre dem global forklarlige. For eksempel kan man vise, hvor meget forskellige input-variabler og deres vrdier har indflydelse p modellens prdiktion (PDP [38], ICE [39], permutation test ).For dybe neurale netvrk (DNN) ligesom convolutional neural networks (CNN) eller recurrent neural networks (RNN) (tit brugt sammen med billed- eller tekstdata), findes der srlige post-hoc metoder. Disse metoder prver at ekstrahere, hvilke reprsentationer et dyb neuralt netvrk har lrt af data [40, 43, 44, 45, 46]. Reprsentationer er en implicit abstraktion fra den ''r'' data (billede eller tekst), lrt af de frste lag af et netvrk, for eksempel lag der genkender kanter i et billede [46]. Desuden findes der metoder til at undersge, om modellen har lrt bestemte koncepter [51].Disse typer af post-hoc globale forklaringsmetoder, der kan bruges til at f indsigt i black box-modellen ved at belyse dele af dens logik, kalder Guidotti et al. ''black box-inspektions''-metoder [5]. Det er dog ikke den eneste type af metoder til post-hoc global forklarlighed. Der findes ogs de skaldte ''surrogat-model''-metoder.Surrogat-modellerSurrogat-model-metoder, eller model-forklaringsmetoder (model explanation) [5], bygger en model til at erstatte black box-modellen, hvor black box-modellen er brugt til prdiktioner og surrogat-modellen til at generere forklaringer. Sidstnvnte model skal virke p samme mde som den originale black box-model, alts generere prdiktioner s tt som muligt p black box-modellens prdiktioner. Hvis det ikke er tilfldet, s forklarer denne model ikke black box-modellen, men kun sig selv. Selvflgelig vil surrogat-modellen altid vre forskellig, dvs. have en ringere performance en black box-modellen, da man ellers kunne erstatte black box-modellen fuldstndig med surrogat-modellen.Surrogat-modeller tager som regel form af de klassiske transparente modeller, ligesom linere modeller [59], beslutningstrer [60, 61], eller regel-baserede modeller [62], men kan ogs vre et simpel neuralt netvrk [63].Lokal forklarlighedI de fleste tilflde vil det vre svrt at bruge en transparent model til at opn global forklarlighed, men det er tit nok til at forklare en bestemt prdiktion. Man kan faktisk argumentere for, at der skabes en mental reprsentation af modellen, nr man interagerer med en model lnge nok og samtidig fr lokale forklaringer. Jo mere den mentale reprsentation afspejler den faktiske model, jo mere global forklarlig er modellen for brugeren.Forklaringer, der er genereret af lokal forklarlige metoder, kan vre tekst, visualiseringer, eksempler i trningsdata eller feature attributions [10]. Ligesom med global forklarlighed kan man adskille mellem iboende lokal forklarlighed og post-hoc lokal forklarlighed [56].Iboende lokal forklarlighedModeller, der har iboende global forklarlighed, er som regel ogs lokal forklarlige, ligesom linere modeller, beslutningstrer eller regel-basered modeller. Der findes dog ogs modeller, der opnr lokal forklarlighed ved at tilfje dele til en model, der genererer en forklaring [15, 52, 64], hvor forklaringer er en del af trningsdata [50], eller hvor selve konceptet er, at prdikationer er baseret p eksempler (k-NN ). I alle tilflde er modellen bygget, s den genererer en forklaring sammen med en prdiktion.Nr vi kigger p dybe neurale netvrk, s kan man for eksempel tilfje srlige lag, der genererer (og lrer) forklaringer [15, 16, 52, 64, 65, 66]. Det kan vre i form af eksempler eller prototyper [15, 16], koncepter [52], tekst [65] eller feature attribution [64, 66]. Og s findes der ogs en metode, der kombinerer neurale netvrk, der hver isr genkender dele af et billede til et beslutningstr og dermed opnr forklarlighed (Neural-Backed Decision Tree ) [67].Post-hoc lokal forklarlighedMetoder til post-hoc lokal forklarlighed gr modeller forklarlige gennem en separat proces efter prdiktionen. Det ligner mden, den menneskelige hjerne virker p, hvor der er forskellige processer til at trffe en beslutning og at forklare den.Metoder til post-hoc lokal forklarlighed, ogs kaldt ''resultat-forklaring'' (outcome explanation) [5], kan fungere p forskellige mder. Det kan for eksempel vre metoder, der arbejder primrt med et eksempel-datast og modellens output til at finde lignende eller betydningsfulde eksempler [14, 18], eller metoder der finder counterfactuals [22, 23, 24, 25]. Andre metoder udnytter modellens struktur, f.eks. at det er et neuralt netvrk [35, 36, 37], bruger iden om shapley values [32, 68, 69], eller bygger en transparent model for et lokalt omrde [29, 34].Fordelen ved post-hoc lokal forklarlighed er, at man ikke behver at pille ved selve modellen, og at mange metoder fungerer med forskellige typer af black box-modeller. Tit har de dog brug for adgang til modelstrukturen for at udnytte den til at generere forklaringer hurtigere og mere njagtigt.ModeltypeModeller, der er transparente eller har en iboende lokal forklarlighed, har en bestemt type. Det kan vre linere modeller, regel-baserede modeller, beslutningstrer, versioner af k-NN eller neurale netvrk [15, 16, 52, 58, 64, 65, 66] eller kombinationer af det [67].Post-hoc metoder derimod virker i forbindelse med en black box-model til at gre den forklarlig. Typen af model kan have en betydning for, hvilken post-hoc metode man kan bruge. De typer af black box-modeller, man typisk ser, er dybe neural netvrk, enten med convolutional layers eller recurrent layers, ensemble-modeller bestende af beslutningstrer (Random Forest, Gradient Boosting [70, 71], eller ensemblemodeller sat sammen af forskellige andre typer af modeller.Der findes post-hoc metoder, der er model-agnostiske, dvs. de virker med alle typer black box-modeller, da de bare skal have mulighed for at f modellens resultater for et givent input [14, 24, 25, 29, 32, 39, 59]. Andre metoder er lavet specifikt til dybe neurale netvrk [72, 73] og krver, at man har adgang til selve netvrket, da de udnytter netvrksstrukturen [23, 36, 51, 63], bruger en lignende proces til at generere forklaringer, som man bruger til at trne af netvrket [35, 37], eller viser hvad netvrket har lrt [40, 43, 44, 45, 46].Nogle metoder eksisterer kun til tr-baserede modeller eller er en variant af en model-agnostisk metode optimeret til trer [74], og andre krver, at man har adgang til en gradient, man ogs bruger i trningsprocessen [18].TaksonomitrEfter vi nu har vret inde over datatyper, typer af forklaringer og typer af XAI-metoder, samt hvordan nogle modeller er lavet til en bestemt type black box-modeller, vil vi nu give et overblik over forskellige XAI-metoder i form af et taksonomitr.Tret viser ikke alle metoder, der findes, men metoderne er valgt, s de, s vidt muligt, afdkker alle typer af forklaringer, data og black box-modeller. Hvis der er flere metoder i en kategori, s har vi udvalgt den mest udbredte, bedst dokumenterede eller den metode, hvor der findes en god open source-implementering. For hver metode indikerer farverige kasser, hvilken type data de er egnet til, og farven af metoden viser, om de er til en bestemt type black box-model.Her kan du lse Christoph Molnars e-bog for hver metode.Tak for fordi du lste med!Dette synspunkt blev oprindeligt bragt i Medium.Bibliografi[1] Peter Jackson, Introduction to Expert Systems, Harlow: Addison-Wesley Longman, 1990.[2] A. Kofod-Petersen, J. Cassens og A. Aamodt, Explanatory Capabilities in the CREEK Knowledge-Intensive Case-Based Reasoner, Proceedings of SCAI 2008, pp. 28-35, 2008.[3] A. Aamodt og E. Plaza, Case-Based Reasoning: Foundational Issues, Methodological Variations, and System Approaches, AI Communications 7(1), pp. 39-59, 1994.[4] S. T. Mueller, R. R. Hoffman, W. Clancey et al., Explanation in Artificial Intelligence Systems: An Historical Perspective, Explanation in Human-AI Systems: A Literature Meta-Review, Synopsis of Key Ideas and Publications, and Bibliography for Explainable AI, DARPA XAI Program, pp. 43-70, 2019.[5] R. Guidotti, A. Monreale, S Ruggieri et al., A Survey Of Methods For Explaining Black Box Models, arXiv:1802.01933v3 [cs.CY], 2018.[6] B. Mittelstadt, C. Russell og S. Wachter, Explaining Explanations in AI, arXiv:1811.01439v1[cs.AI], 2018.[7] G. Ras, M. van Gerven og P. Haselager, Explanation Methods in Deep Learning: Users, Values, Concerns and Challenges, arXiv:1803.07517v2 [cs.AI], 2018.[8] A. Adadi og M. Berrada, Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI), IEEE Access 6, pp. 52138-52160, 2018.[9] M. Du, N. Liu og X. Hu, Techniques for Interpretable Machine Learning, arXiv:1808.00033v3[cs.LG], 2019.[10] Z. C. Lipton, The Mythos of Model Interpretability, arXiv:1606.03490v3 [cs.LG], 2017.[11] S. Chakraborty, R. Tomsett, R. Raghavendra et al., Interpretability of deep learning models: A survey of results, IEEE 2017 SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI, pp. 1-6, 2017.[12] G. Vilone og L. Longo, Explainable Artificial Intelligence: a Systematic Review, arXiv:2006.00093 [cs.AI], 2020.[13] B. Kim, R. Khanna og O. O. Koyejo, Examples are not enough, learn to criticize! Criticism for Interpretability, NIPS 2016, pp. 2280-2288, 2016.[14] K. S. Gurumoorthy, A. Dhurandhar, G. Cecchi et al., Efficient Data Representation by Selecting Prototypes with Importance Weights, arXiv:1707.01212 [stat.ML], 2019.[15] C. Chen, O. Li, C. Tao et al., This Looks Like That: Deep Learning for Interpretable Image Recognition, arXiv:1806.10574v5 [cs.LG], 28 december 2019.[16] S. O. Arik og T. Pfister, ProtoAttend: Attention-Based Prototypical Learning, arXiv:1902.06292 [cs.LG], 2019.[17] C. J. Cai, J. Jongejan og J. Holbrook, The Effects of Example-Based Explanations in a Machine Learning Interface, IUI '19, pp. 258-262, 2019.[18] P. W. Koh og P. Liang, Understanding Black-box Predictions via Influence Functions, arXiv:1703.04730 [stat.ML], 2017.[19] N. Papernot og P. McDaniel, Deep k-Nearest Neighbors: Towards Confident, Interpretable and Robust Deep Learning, arXiv:1803.04765 [cs.LG], 2018.[20] S. Wachter, B. Mittelstadt og C. Russell, Counterfactual Explanations without Opening the Black Box: Automated Decisions and the GDPR, arXiv:1711.00399 [cs.AI], 2017.[21] Tim Miller, Explanation in Artificial Intelligence: Insights from the Social Sciences, arXiv:1706.07269 [cs.AI], 2017.[22] R. K. Mothilal, A. Sharma og C. Tan, Explaining machine learning classifiers through diverse counterfactual explanations, FAT* 2020, pp. 607-617, 2020.[23] Y. Goyal, Z. Wu, J. Ernst et al., Counterfactual Visual Explanations, Proceedings of the 36th ICML, pp. 2376-2384, 2019.[24] S. Sharma, J. Henderson og J. Ghosh, CERTIFAI: Counterfactual Explanations for Robustness, Transparency, Interpretability, and Fairness of Artificial Intelligence models, arXiv:1905.07857 [cs.LG], 2019.[25] A. Dhurandhar, P.-Y. Chen, R. Luss et al., Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives, NIPS 2018, pp. 592-603, 2018.[26] C. Chen og C. Rudin, An Optimization Approach to Learning Falling Rule Lists, arXiv:1710.02572 [cs.LG], 2017.[27] H. Lakkaraju, S. H. Bach og J. Leskovec, Interpretable Decision Sets: A Joint Framework for Description and Prediction, KDD'16, pp. 1675-1684, 2016.[28] J. H. Friedman og B. E. Popescu, Predictive learning via rule ensembles, Ann. Appl. Stat. 2 (3), pp. 916-954, 2008.[29] M. T. Ribeiro, S. Singh og C. Guestrin, Anchors: High-Precision Model-Agnostic Explanations, AAAI 2018, 2018.[30] 
. Lou, R. Caruana, J. Gehrke at al., Accurate intelligible models with pairwise interactions, KDD'13, pp. 623-631, 2013.[31] B. Ustun og C. Rudin, Supersparse Linear Integer Models for Optimized Medical Scoring Systems, arXiv:1502.04269 [stat.ML], 2015.[32] S. M. Lundberg og S.-I. Lee, A Unified Approach to Interpreting Model Predictions, NIPS 2018, pp. 4765-4774, 2017.[33] M. Sundararajan og A. Najmi, The Many Shapley Values for Model Explanation, ICML 2020, 2020.[34] M. T. Ribeiro, S. Singh og C. Guestrin, ''Why should i trust you?'': Explaining the predictions of any classifier, KDD'16, pp. 1135-1144, 2016.[35] A. Shrikumar, P. Greenside og A. Kundaje, Learning Important Features Through Propagating Activation Differences, arXiv:1704.02685 [cs.CV], 2017.[36] R. R. Selvaraju, M. Cogswell, A. Das et al., Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization, ICCV'17, pp. 618-626, 2017.[37] S. Bach, A. Binder, G. Montavon et al., On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation, PLOS ONE 10(7): e0130140, 2015.[38] Jerome H. Friedman, Greedy Function Approximation: A Gradient Boosting Machine, The Annals of Statistics 29(5), pp. 1189-1232, 2001.[39] A. Goldstein, A. Kapelner, J. Bleich et al., Peeking Inside the Black Box: Visualizing Statistical Learning With Plots of Individual Conditional Expectation, Journal of Computational and Graphical Statistics, pp. 44-65, 2015.[40] C. Olah, A. Satyanarayan, I. Johnson et al., The Building Blocks of Interpretability, Distill, 2018.[41] H. Strobelt, S. Gehrmann, H. Pfister et al., LSTMVis: A Tool for Visual Analysis of Hidden State Dynamics in Recurrent Neural Networks, arXiv:1606.07461 [cs.CL], 2016.[42] L. Arras, F. Horn, G. Montavon et al., ''What is Relevant in a Text Document?'': An Interpretable Machine Learning Approach, arXiv:1612.07843 [cs.CL], 2016.[43] C. Olah, A. Mordvintsev og L. Schubert, Feature Visualization, Distill, 2017.[44] A. Nguyen, A. Dosovitskiy, J. Yosinski et al., Synthesizing the preferred inputs for neurons in neural networks via deep generator networks, NIPS 2016, pp. 3387-3395, 2016.[45] A. Karpathy, J. Johnson og L. Fei-Fei, Visualizing and Understanding Recurrent Networks, arXiv:1506.02078 [cs.LG], 2015.[46] M. D. Zeiler og R. Fergus, Visualizing and Understanding Convolutional Networks, arXiv:1311.2901v3 [cs.CV], 2013.[47] Bernhard Schlkopf, Causality for Machine Learning, arXiv:1911.10500 [cs.LG], 2019.[48] Gary Marcus, The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence, arXiv:2002.06177 [cs.AI], 2020.[49] P. Clark, O. Etzioni, D. Khashabi et al., From 'F' to 'A' on the N.Y. Regents Science Exams: An Overview of the Aristo Project, arXiv:1909.01958 [cs.CL], 2019.[50] M. Hind, D. Wei, M. Campbell et al., TED: Teaching AI to Explain its Decisions, AIES'19, pp. 123-129, 2019.[51] B. Kim, M. Wattenberg, J. Gilmer et al., Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV), arXiv:1711.11279[stat.ML], 2017.[52] A. Ghorbani, J. Wexler, J. Y. Zou et al., Towards Automatic Concept-based Explanations, NIPS 2019, pp. 9277-9286, 2019.[53] Y. Goyal, T. Khot, A. Agrawal et al., Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering, International Journal of Computer Vision 127, pp. 398-414, 2019.[54] R. Hu, J. Andreas, M. Rohrbach et al., Learning to Reason: End-To-End Module Networks for Visual Question Answering, ICCV 2017, pp. 804-813, 2017.[55] J. Mao, C. Gan, P. Kohli et al., The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences from Natural Supervision, arXiv:1904.12584 [cs.CV], 2019.[56] M. Nu, N. Liu og X. Hu, Techniques for Interpretable Machine Learning, arXiv:1808.00033v2 [cs.LG], 2018.[57] Adrian Weller, Challenges for Transparency, arXiv:1708.01870v1 [cs.CY], 2017.[58] Q. Zhang, Y. N. Wu, S.-C. Zhu, Interpretable CNNs, arXiv:1901.02413v1 [cs.LG], 2019.[59] S. Tan, R. Caruana, G. Hooker et al., Distill-and-Compare: Auditing Black-Box Models Using Transparent Model Distillation, AIES'18, pp. 303-310, 2018.[60] C. Yang, A. Rangarajan og S. Ranka, Global Model Interpretation via Recursive Partitioning, arXiv:1802.04253 [cs.LG], 2018.[61] O. Bastani, C. Kim og H. Bastani, Interpretability via Model Extraction, arXiv:1706.09773[cs.LG], 2017.[62] W. J. Murdoch og A. Szlam, Automatic Rule Extraction from Long Short Term Memory Networks, arXiv:1702.02540 [cs.CL], 2017.[63] A. Dhurandhar, K. Shanmugam, R. Luss et al., Improving Simple Models with Confidence Profiles, NIPS 2018, pp. 10296-10306, 2018.[64] E. Choi, M. T. Bahadori, J. A. Kulas et al., RETAIN: An Interpretable Predictive Model for Healthcare using Reverse Time Attention Mechanism, arXiv:1608.05745v4 [cs.LG], 2017.[65] K. Xu, J. Ba, R. Kiros et al., Show, Attend and Tell: Neural Image Caption Genereation with Visual Attention, arXiv:1502.03044v3 [cs.LG], 2016.[66] Amirhossein Tavanaei, Embedded Encoder-Decoder in Convolutional Networks Towards Explainable AI, arXiv:2007.06712 [cs.CV], 2020.[67] A. Wan, L. Dunlap, D. Ho et al., NBDT: Neural-Backed Decision Tree, arXiv:2004.00221[cs.CV], 2020.[68] K. Aas, M. Jullum og A. Lland, Explaining individual predictions when features are dependent: More accurate approximations to Shapley values, arXiv:1903.10464[stat.ML], 2019.[69] M. Sundararajan og A. Najmi, The many Shapley values for model explanation, arXiv:1908.08474 [cs.AI], 2019.[70] T. Chen og C. Guestrin, XGBoost: A Scalable Tree Boosting System, KDD'16, pp. 785-794, 2016.[71] G. Ke, Q. Meng, T. Finley et al., LightGBM: A Highly Efficient Gradient Boosting Decision Tree, NIPS 2017, pp. 3146-3154, 2017.[72] G. Montavon, W. Samek og K.-R. Mller, Methods for interpreting and understanding deep neural networks, Digital Signal Processing 73, pp. 1-15, 2018.[73] W. Samek, G. Montavon, A. Vedaldi, L. K. Hansen og K.-R. Mller (Eds.), Explainable AI: Interpreting, Explaining and Visualizing Deep Learning, Springer, 2019.[74] S. M. Lundberg, G. Erion, H. Chen et al., From local explanations to global understanding with explainable AI for trees, Nature Machine Intelligence 2, pp. 56-67, 2020.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2020-11-26
          &nbsp;&nbsp; e80203c1
          &nbsp;&nbsp; #0
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.981</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.725</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.54</kbd>
        </footer>
      </article>
      <article>
        <h4>PRM / Coreferensmodeller ?? nu ogs p dansk!</h4>
        <div>
          KbenhavnPressemeddelelse fra Alexandra InstituttetBlogindlgget er skrevet af Maria Barrett, Postdoc ved Institut for Datalogi p IT-Universitetet, og er udgivet p Alexandra Instituttets blog for NLP og dansk sprogteknologi p Medium: DaNLPCoreferens er i Natural Language Processing (NLP) en opgave, hvor man skal finde alle tekstbidder (spans) i en tekst, der henviser til den samme entitet. En entitet kan vre en person, et sted, en event eller en organisation, men det kan ogs vre en ikke-navngiven hndelse/handling.Som andre opgaver inden for NLP bliver coreferens lst med kunstig intelligens. I dette blogindlg tager vi en teknisk tur ind i maskinrummet bag coreferens og prsenterer de frste offenligt tilgngelige, danske coreferensmodeller, der bygger p kunstig intelligens.Lsning af coreferens er en central underopgave for en rkke sproglige opgaver som fx automatisk at svare p sprgsml ud fra en tekst eller lave et resum. Disse er afhngige af, at modellen kan identificere alle benvnelser for fx en person i et dokument, uanset om denne er nvnt ved sit navn, et personligt stedord eller en anden nominalfrase.Som med mange andre NLP-opgaver er det noget, som mennesker helt automatisk gr, nr vi lser. Coreferens er et svrt problem for et computerprogram at lse automatisk, fordi benvnelser kan vre meget lange og ogs meget langt vk fra hinanden i et dokument.Som eksempel p et meget kort dokument, kan vi tage flgende tweet:Input til en coreferens-model er et helt dokument, i dette tilflde et enkelt tweet. Modellen identificerer og grupperer herefter de tekstbidder, der henviser til samme entitet. I tweetet vil en god coreferensmodel identificere flgende tre klynger:(I, I)(Obama, her)(her husband)Det vil sige, at en coreferensmodel som input tager et dokument og som output leverer klynger af tekstbidder, der henviser til samme entitet.Dansk coreferens-dataFor at trne en coreferensmodel ved hjlp af kunstig intelligens og for at evaluere hvor god den trnede model er, skal man bruge data, der er korrekt annoteret af et menneske, en skaldt guldannotering. I dette afsnit fortller jeg om den danske coreferensannotering vi har brugt til at trne og evaluere de danske coreferensmodeller med.Vi har brugt en annotering fra the Copenhagen Dependency Treebank project (Kromann &amp; Lynge, 2004). Annoteringen er ikke frdiggjort for hele trbanken, men dkker ca 2/3 , men er fint dokumenteret. Det annoterede st bestr af 64.076 tokens fordelt p over 341 dokumenter. Det er primrt nyhedstekst, men ogs noget fra forskellige tidsskrifter.Datasttet er tilgngeligt gennem DaNLP sammen med dokument-id'er for vores trnings- udviklings- og evaluerings-split s alle kan trne og evaluere deres egne coreferensmodeller.Neurale coreferens-modellerI dette afsnit vil vi beskrive de tekniske detaljer for de to danske coreferensmodeller, der begge bygger p kunstig intelligens. Vil du hellere g direkte til evalueringsresultatet for modellerne, s kan du lse mere under &amp;lsquo,Resultater' nederst i artiklen.Lsning af coreferens er typisk blevet behandlet i flere stadier. Frst har modellen detekteret mulige benvnelser, og derefter lrt om de parvis er coreferente. Det er regnemssigt effektivt og skalerer godt til lange dokumenter. Man har typisk haft flere modeller med i trningsloopet, fx en syntaksparser til at opmrke grammatiske strukturer og eventuelt ogs regelbaserede elementer (alts elementer i modellen der ikke bygger p kunstig intelligens). Det vil sige, at en coreferensmodel tidligere bestod af flere forskellige modeller, der blev trnet separat. Det kan man lse mere om i Ng (2010).Men i 2017 prsenterede Lee et al. den frste end-to-end coreferens-model, der er en ren neural model uden behov for andre modeller. &quot;End-to-end&quot; betyder, at modellen bde finder benvnelser og grupperer dem i samme trningspas. Der er heller ikke brug for en separat syntaksparser. Uden benvnelsesdetektion som et separat trin, kan alle tekstbidder i princippet vre en benvnelse, men for at reducere regneaktiviteten udregnes modellen en score per par af benvnelser (fundet i tidligere iterationer) og mulige tekstbidder. Listen af disse bliver iterativt og aggressivt beskret for at reducere antallet af beregninger. Benvnelses-tekstbid-reprsentationerne bruger bde teksbidden selv og konteksten omkring den i reprsentationen. Modellen bruger en bidirectional LSTM for at encode teksten og konteksten. Denne model viste i 2017, at den var bedre end tidligere metoder p det engelske data fra CoNLL-2012 shared task, som kommer fra Ontonotes (Pradhan et al., 2012), som er det engelske benchmark-datast.I 2018 lavede Lee et al. en opdatering af ovennvnte model i artiklen Higher-order Coreference Resolution with Coarse-to-fine inference . Den tidligere model fra 2017 er en frsteordensmodel, fordi den kun forholder sig til par af tekstbidder. Lee et al. (2018) ppeger, at frsteordensmodeller kan rumme globale inkonsistenser. Higher-order-modellen i Lee et al. 2018 forholder sig til flere mulige kandidatspans per (mulige) span i en matrice (og ikke udregnet som en parvis score).Oprindeligt blev begge modeller brugt med word-embeddings som vektorreprsentationer for ordene, men Joshi et al. (2019) viste, at man kunne f endnu bedre resultater p engelsk, hvis man i stedet brugte SpanBERT (Joshi et al., 2020) og BERT (Devlin et al., 2019). Da der ikke er en dansk SpanBERT, er de danske modeller trnet p andre pr-trnede reprsentationer fra transformere. Vi har brugt dansk BERT , som er en uncased model og to flersprogede, cased modeller: Multilingual BERT citat og XLM-Roberta (Conneau et al., 2020). I stedet for den originale tensorflowimplementering har vi brugt pytorchimplementeringerne fra AllenNLP.Resultaterne for den danske coreferens-model p det danske testssplit, der indeholder 28 dokumenter, kan ses i tabellen nedenfor. Modellen er trnet med early stopping over 12000 epochs, og vi har tunet modellernes lringsrate, og lringsraten for transformermodellerne over 50 epochs.ResultaterDen bedste model er Lee et al. 2018 med udgangspunkt i XLM-Roberta. Alle modellerne kan findes som del af DaNLP toolkittet.Gennemsnit af F1, precison og recall fra MUC, CEAF og B3 samt mention recall for hver af de seks danske coreferens-modeller.Hvordan skal resultaterne forsts?Mention recall er en procentsats for, hvor mange af de korrekte tekstbidder, der er fundet. Men derefter skal man finde en god mde at kvantificere, hvor korrekt de er clustret.Coreferens har (mindst) et problem: Det er svrt at evaluere. Overvej fx hvilken af flgende modeller der er bedst (eller mindst drlig) for tweetet ovenfor. Den korrekte annotering er - som tidligere nvnt:(I, I) (Obama, her) (her husband)Model 1: (I, I)Model 2: (I) (I) (Obama) (her) (her husband)Model 3: (I, I, her husband, Obama) (her)De har hver isr deres kvaliteter. Hvor model 1 kun har fundet 40% af de oprindelige tekstbidder, har den trods alt formet at gruppere disse korrekt. Model 2 og 3 har fundet alle de korrekte tekstbidder, men har grupperet dem forkert p hver deres mde.Der er flere forskellige metrikker til at forsge at mle overensstemmelsen mellem to forskellige annoteringer, men de fleste er enige om, at ingen af dem er gode nok til at st alene. Selvom et gennemsnit af flere halvdrlige ml ikke giver et perfekt resultat, er der mange, der bruger et gennemsnit af flgende tre metrikker: MUC, B3 og CEAF. De har hver en precision, recall og F1. Det er ogs disse gennemsnit, der kan ses i tabellen.ReferencerJeffrey Pennington, Richard Socher, and Christopher D Manning. 2014. Glove: Global vectors for word representation. In Proceedings of the 2014 conference on Empirical Methods in Natural Language Processing (EMNLP).Conneau, A., Khandelwal, K., Goyal, N., Chaudhary, V., Wenzek, G., Guzmn, F., Grave, E., Ott, M., Zettlemoyer, L. &amp; Stoyanov, V. (2020). Unsupervised Cross-lingual Representation Learning at Scale. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (pp. 8440-8451).Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. (2019, June). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) (pp. 4171-4186).Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. (2019, June). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) (pp. 4171-4186).Joshi, M., Chen, D., Liu, Y., Weld, D. S., Zettlemoyer, L., &amp; Levy, O. (2020). Spanbert: Improving pre-training by representing and predicting spans. In Transactions of the Association for Computational Linguistics, 8, 64-77.Joshi, M., Levy, O., Zettlemoyer, L., &amp; Weld, D. S. (2019). BERT for Coreference Resolution: Baselines and Analysis. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP) (pp. 5807-5812).M.T. Kromann and S.K. Lynge. Danish Dependency Treebank v. 1.0. Department of Computational Linguistics, Copenhagen Business School., 2004. https://github.com/mbkromann/copenhagen-dependency-treebankLee, K., He, L., Lewis, M., &amp; Zettlemoyer, L. (2017, September). End-to-end Neural Coreference Resolution. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (pp. 188-197).Lee, K., He, L., &amp; Zettlemoyer, L. (2018, June). Higher-Order Coreference Resolution with Coarse-to-Fine Inference. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers) (pp. 687-692).Vincent Ng. 2010. Supervised noun phrase coreference research: The first fifteen years. In Proceedings of the 48th annual meeting of the association for computational linguistics, pages 1396-1411. Association for Computational Linguistics.Sameer Pradhan, Alessandro Moschitti, Nianwen Xue, Olga Uryupina, and Yuchen Zhang. 2012. Conll2012 shared task: Modeling multilingual unrestricted coreference in ontonotes. In Joint Conference on EMNLP and CoNLL - Shared Task, pages 1-40. Association for Computational Linguistics.Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010. Word representations: A Simple and General Method for Semi-supervised Learning. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics.Xu, L., &amp; Choi, J. D. (2020, November). Revealing the Myth of Higher-Order Inference in Coreference Resolution. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) (pp. 8527-8533).Kontakt:Communications Specialist Lisa Lorentzen tlf.: +45 93 52 17 64 email: lisa.lorentzen@alexandra.dkLs hele pressemeddelelsen p Via Ritzau her: https://via.ritzau.dk/pressemeddelelse/coreferensmodeller-nu-ogsa-pa-dansk?releaseId=13620730** Ovenstende pressemeddelelse er videreformidlet af Ritzau p vegne af tredjepart. Ritzau er derfor ikke ansvarlig for indholdet ** 
        </div>
        <footer>
          <em>Ritzaus Bureau</em>
          &nbsp;&nbsp; 2021-04-26
          &nbsp;&nbsp; e83cbaf1
          &nbsp;&nbsp; #1
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.994</kbd>
            <kbd data-tooltip="AI &amp; innovation">L05_INNOAI&nbsp;0.576</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.532</kbd>
        </footer>
      </article>
      <article>
        <h4>Coreferensmodeller - nu ogs p dansk!</h4>
        <div>
          De frste offentligt tilgngelige, danske coreferensmodeller er klar til brug.BrdtekstCoreferens er i Natural Language Processing (NLP) en opgave, hvor man skal finde alle tekstbidder (spans) i en tekst, der henviser til den samme entitet. En entitet kan vre en person, et sted, en event eller en organisation, men det kan ogs vre en ikke-navngiven hndelse/handling.Som andre opgaver inden for NLP bliver coreferens lst med kunstig intelligens.Lsning af coreferens er en central underopgave for en rkke sproglige opgaver som fx automatisk at svare p sprgsml ud fra en tekst eller lave et resum. Disse er afhngige af, at modellen kan identificere alle benvnelser for fx en person i et dokument, uanset om denne er nvnt ved sit navn, et personligt stedord eller en anden nominalfrase.Som med mange andre NLP-opgaver er det noget, som mennesker helt automatisk gr, nr vi lser. Coreferens er et svrt problem for et computerprogram at lse automatisk, fordi benvnelser kan vre meget lange og ogs meget langt vk fra hinanden i et dokument.Som eksempel p et meget kort dokument, kan vi tage flgende tweet:Input til en coreferensmodel er et helt dokument, i dette tilflde et enkelt tweet. Modellen identificerer og grupperer herefter de tekstbidder, der henviser til samme entitet. I tweetet vil en god coreferensmodel identificere flgende tre klynger:(I, I)(Obama, her)(her husband)Det vil sige, at en coreferensmodel som input tager et dokument og som output leverer klynger af tekstbidder, der henviser til samme entitet.Dansk coreferens-dataFor at trne en coreferensmodel ved hjlp af kunstig intelligens og for at evaluere hvor god den trnede model er, skal man bruge data, der er korrekt annoteret af et menneske, en skaldt guldannotering. I dette afsnit fortller jeg, om den danske coreferensannotering vi har brugt til at trne og evaluere de danske coreferensmodeller med.Vi har brugt en annotering fra the Copenhagen Dependency Treebank project (Kromann &amp; Lynge, 2004). Annoteringen er ikke frdiggjort for hele trbanken, men dkker ca. 2/3, men er fint dokumenteret. Det annoterede st bestr af 64.076 tokens fordelt p over 341 dokumenter. Det er primrt nyhedstekst, men ogs noget fra forskellige tidsskrifter.Datasttet er tilgngeligt gennem DaNLP sammen med dokument-id'er for vores trnings-, udviklings- og evaluerings-split s alle kan trne og evaluere deres egne coreferensmodeller.Neurale coreferens-modellerI dette afsnit vil vi beskrive de tekniske detaljer for de to danske coreferensmodeller, der begge bygger p kunstig intelligens. Vil du hellere g direkte til evalueringsresultatet for modellerne, s kan du lse mere under 'Resultater' nederst i artiklen.Lsning af coreferens er typisk blevet behandlet i flere stadier. Frst har modellen detekteret mulige benvnelser og derefter lrt, om de parvis er coreferente. Det er regnemssigt effektivt og skalerer godt til lange dokumenter. Man har typisk haft flere modeller med i trningsloopet, fx en syntaksparser til at opmrke grammatiske strukturer og eventuelt ogs regelbaserede elementer (alts elementer i modellen der ikke bygger p kunstig intelligens). Det vil sige, at en coreferensmodel tidligere bestod af flere forskellige modeller, der blev trnet separat. Det kan man lse mere om i Ng (2010).Men i 2017 prsenterede Lee et al. den frste end-to-end coreferens-model, der er en ren neural model uden behov for andre modeller. End-to-end betyder, at modellen bde finder benvnelser og grupperer dem i samme trningspas. Der er heller ikke brug for en separat syntaksparser. Uden benvnelsesdetektion som et separat trin kan alle tekstbidder i princippet vre en benvnelse, men for at reducere regneaktiviteten udregnes modellen en score per par af benvnelser (fundet i tidligere iterationer) og mulige tekstbidder. Listen af disse bliver iterativt og aggressivt beskret for at reducere antallet af beregninger. Benvnelses-tekstbid-reprsentationerne bruger bde teksbidden selv og konteksten omkring den i reprsentationen. Modellen bruger en bidirectional LSTM for at encode teksten og konteksten. Denne model viste i 2017, at den var bedre end tidligere metoder p det engelske data fra CoNLL-2012 shared task, som kommer fra Ontonotes (Pradhan et al., 2012), som er det engelske benchmark-datast.I 2018 lavede Lee et al. en opdatering af ovennvnte model i artiklen Higher-order Coreference Resolution with Coarse-to-fine inference. Den tidligere model fra 2017 er en frsteordensmodel, fordi den kun forholder sig til par af tekstbidder. Lee et al. (2018) ppeger, at frsteordensmodeller kan rumme globale inkonsistenser. Higher-order-modellen i Lee et al. 2018 forholder sig til flere mulige kandidatspans per (mulige) span i en matrice (og ikke udregnet som en parvis score).Oprindeligt blev begge modeller brugt med word-embeddings som vektorreprsentationer for ordene, men Joshi et al. (2019) viste, at man kunne f endnu bedre resultater p engelsk, hvis man i stedet brugte SpanBERT (Joshi et al., 2020) og BERT (Devlin et al., 2019). Da der ikke er en dansk SpanBERT, er de danske modeller trnet p andre pr-trnede reprsentationer fra transformere. Vi har brugt dansk BERT, som er en uncased model og to flersprogede, cased modeller: Multilingual BERT citat og XLM-Roberta (Conneau et al., 2020). I stedet for den originale tensorflowimplementering har vi brugt pytorchimplementeringerne fra AllenNLP.Resultaterne for den danske coreferens-model p det danske testssplit, der indeholder 28 dokumenter, kan ses i tabellen nedenfor. Modellen er trnet med early stopping over 12.000 epochs, og vi har tunet modellernes lringsrate, og lringsraten for transformermodellerne over 50 epochs.ResultaterDen bedste model er Lee et al. 2018 med udgangspunkt i XLM-Roberta. Alle modellerne kan findes som del af DaNLP toolkittet.Representation | Model | Avg. F1 | Avg. Precision | Avg. Recall | Mention recall-------------------|-------------------|---------|----------------|-------------|----------------Danish BERT | Lee et al. (2017) | 0.477 | 0.587 | 0.402 | 0.729Danish BERT | Lee et al. (2018) | 0.313 | 0.655 | 0.207 | 0.683Multilingual BERT | Lee et al. (2017) | 0.630 | 0.679 | 0.587 | 0.870Multilingual BERT | Lee et al. (2018) | 0.532 | 0.625 | 0.463 | 0.854XLM-Roberta | Lee et al. (2017) | 0.623 | 0.668 | 0.585 | 0.822XLM-Roberta | Lee et al. (2018) | 0.64 | 0.699 | 0.592 | 0.88Gennemsnit af F1, precison og recall fra MUC, CEAF og B3 samt mention recall for hver af de seks danske coreferens-modeller.Mention recall er en procentsats for, hvor mange af de korrekte tekstbidder, der er fundet. Men derefter skal man finde en god mde at kvantificere, hvor korrekt de er clustret.Coreferens har (mindst) et problem: Det er svrt at evaluere. Overvej fx hvilken af flgende modeller der er bedst (eller mindst drlig) for tweetet ovenfor. Den korrekte annotering er - som tidligere nvnt:(I, I) (Obama, her) (her husband)Model 1: (I, I)Model 2: (I) (I) (Obama) (her) (her husband)Model 3: (I, I, her husband, Obama) (her)De har hver isr deres kvaliteter. Hvor model 1 kun har fundet 40 pct. af de oprindelige tekstbidder, har den trods alt formet at gruppere disse korrekt. Model 2 og 3 har fundet alle de korrekte tekstbidder, men har grupperet dem forkert p hver deres mde.Der er flere forskellige metrikker til at forsge at mle overensstemmelsen mellem to forskellige annoteringer, men de fleste er enige om, at ingen af dem er gode nok til at st alene. Selvom et gennemsnit af flere halvdrlige ml ikke giver et perfekt resultat, er der mange, der bruger et gennemsnit af flgende tre metrikker: MUC, B3 og CEAF. De har hver en precision, recall og F1. Det er ogs disse gennemsnit, der kan ses i tabellen.Dette indlg er oprindeliget udgivet p
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2021-05-04
          &nbsp;&nbsp; e83fa5d0
          &nbsp;&nbsp; #2
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.922</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.782</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.623</kbd>
        </footer>
      </article>
      <article>
        <h4>PRM / Hvad betyder forklarlighed, nr vi taler om kunstig intelligens?</h4>
        <div>
          KbenhavnPressemeddelelse fra Alexandra InstituttetDe mange termer der beskriver forklarlig kunstig intelligens (explainable AI)Vi anvender kunstig intelligens p stadig flere omrder, og beslutninger baseret p kunstig intelligens kommer tttere p at pvirke vores privatliv. I den forbindelse er der dukket mange begreber op, som explainable (forklarlig) kunstig intelligens, interpretable (fortolkbar) maskinlring, transparent kunstig intelligens og intelligible (forstelig) kunstig intelligens. I figuren nedenunder kan du se udviklingen i Google-sgninger p 'Explainable Artificial Intelligence' og 'Interpretable Machine Learning' op til 2019.Google Trends over hele verden p &quot;explainable AI&quot; og &quot;interpretable ML&quot; op til 2019 (Data kilde: Google Trends).Men hvad er egentlig meningen bag de begreber, og hvordan definerer man forklarlighed? Vi starter med at prve at definere forklarlighed baseret p ordbogsdefinitionen af &quot;at forklare&quot;, som skaber grundlag for begreberne inden for forklarlig kunstig intelligens.Senere i blogindlgget kan du lse om, hvilke egenskaber en model skal have, for at vi kan kalde den forklarlig, ud fra de definitioner vi kommer ind p nu.DefinitionNr man kigger i ordbogen, kan man finde flgende definition af &quot;at forklare&quot;:gre noget klart for andre ved at beskrive, oplyse eller p anden mde fortlle nrmere om detangive en rsag eller grund til noget, gre rede for nogetBaseret p den engelske definition har Doshi-Velez et al.&amp;sup1, defineret &quot;interpretability&quot; i konteksten af kunstig intelligens p den flgende mde:&quot;the ability to explain or present in understandable terms to a human&quot; (evne til at forklare eller prsentere p en forstelige mde til et menneske)Med andre ord kan forklarlighed ses som en interface mellem en model og brugeren af modellen, der forklarer modellen eller dele af modellen til brugeren. Det er dog ikke tydeligt, hvordan &quot;evne til at forklare&quot; er defineret, og hvad &quot;p en forstelig mde&quot; betyder fra et teknisk perspektiv, da forklarlighed eller gennemsigtighed er afhngig af mlet, og hvem eller hvad det er mlrettet til. Der findes derfor ikke en enkelt definition af forklarlighed, men til gengld findes der mange nuancer betinget af konteksten og mlet.Derfor vil vi nu prsentere de forskellige kontekster og mlgrupper, som typisk er i spil i forhold til forklarlig kunstig intelligens, s vi kan nrme os en mere konkret og anvendelig definition, man kan tage udgangspunkt i, nr vi udvikler kunstig intelligens.Forskellige ml af forklarlighedSom regel er datadrevne modeller, der er lavet ved (supervised) maskinlring, evalueret gennem metrikker (se en artikel p towards data science og sklearns guide), der sammenligner &quot;eksempel-data&quot;, man ved, der er rigtigt, med modellens forudsigelse. Men der er andre faktorer, man ogs kan evaluere modellen p, og der pvirker modellens vrdi eller omkostninger, nr modellen er sat i drift, f.eks. tillid, informationsindhold, opretholdelse af etik, osv. Det er tit ikke muligt til at definere metrikker, der mler disse faktorer, s den eneste lsning til at evaluere dem er gennem forklarlighed. Vi vil nu beskrive de mest almindelige ml og faktorer af forklarlighed, ogs kaldet &quot;desire-data&quot;&amp;sup2,, ssom tillid, fairness og etik, information, transfer af viden, debugging og monitorering. Flowcharten herned guider dig igennem disse ml af forklarlighed og hvilke mlgrupper der er tilknyttet.Flowchart der igennem ml af forklarlighed og hvilke mlgrupper der er tilknyttet.TillidTillid til en model er vigtigt, for at slutbrugerne faktisk bruger modellen og agerer p dens resultater og anbefalinger. Tillid kan have forskellige former: 1) Tillid til at modellen virker. Her kan det vre nok at bruge almindelige metrikker til at vise modellens evner. 2) Det kan ogs vre tillid til, at modellen virker i drift. Det vil sige viden om, hvordan modellen opfrer sig i nye, ukendte scenarier og viden om modellens styrker (hvornr virker det?) og begrnsninger (hvornr virker det ikke?).Det er tit ikke muligt at definere trnings- eller testdata, der dkker alle eksisterende og mulige kommende scenarier, og det er derfor kun muligt at mle modellens njagtighed p scenarier beskrevet i dataene. I andre situationer kan der opst skaldt &quot;concept-drift&quot;, alts at sammenhnge i data ndrer sig og afviger fra de data, modellen blev trnet p, efter modellen er blevet sat i drift. I begge tilflde vil det ge tilliden til modellens performance i uforudsete omgivelser, hvis man kunne forst eller forklare, hvordan modellen virker.Fair og etiskAfhngigt af konteksten, hvori modellen er brugt, kan der krves bestemte etiske standarder (f.eks. etiske guidelines fra EU's High-Level Expert Group on Artificial Intelligence), og nogle gange endnu et bevis p det lovmssige ansvar. Den europiske GDPR, for eksempel, beskriver, at en person, der er pvirket af en automatisk beslutningsproces, har mulighed for at f &quot;meningsfulde oplysninger om logikken&quot; (GDPR Art. 15), og at dem, der ejer modellen, skal srge for &quot;passende foranstaltninger til at beskytte den registreredes rettigheder&quot; (GDPR Art. 22). Hvad meningsfulde oplysninger er, og i hvilken grad det handler om forklarlighed, er der dog debat om&amp;sup3,  . Men uanset hvad, s er det sikkert, at forklarlighed i den rigtige form vil hjlpe med at vurdere om etiske, fair og lovmssige krav er opfyldt eller forklarlighed kan vre en mde til at opfylder dem direkte.InformationsindholdIsr nr en model interagerer med en ikke-teknisk slutbruger, og nr modellen er brugt til beslutningssttte, kan yderlige information om hvordan en model virker, og hvorfor den er kommet med et bestemt resultat vre vigtigt. Det kan blive relevant, nr modellens output kun er en del af en beslutningsproces, eller hvis modellens resultater skal forklares videre af brugeren til en anden person.Forestil dig for eksempel at du sprger en lge, hvilken behandling der vil virke bedst p en bestemt sygdom, du har. Det er slet ikke nok bare at f navnet at vide eller beskrivelsen af behandlingen - du vil ogs vre interesseret i hvorfor, det er den bedste behandling, hvad der er af alternativer, og om der er nogle risici. I dette tilflde krves der flere informationer for at trffe en god beslutning.Overfrsel af videnFordi modellen opbygger &quot;viden&quot; om et problem eller en reprsentation af en lsning (baseret p data), kunne det vre interessant at overfre denne viden til et menneske eller en anden maskine (model). Kun hvis vi forstr modellens beslutninger eller forudsigelser og evnen til at kunne forklare disse, er det muligt at overfre viden p en mde.Overfrsel af viden kan ogs vre en vigtig faktor til modellens vrdi eller brugbarhed. Selvom modellen er trnet og testet p forskellige data, for at vise evnen til at modellen kan generalisere godt p nye data, blev det vist, at en models resultat kan manipuleres ved sm ndringer i inputdataene (Intriguing properties of neural networks). Modellerne, der kan overfre viden og opbygge kausalitetssammenhnge i stedet for &quot;bare&quot; at finde korrelationer, kunne vre bedre beskyttet imod disse angreb.DebuggingForklaringer kan vre et yderligere vrktj til at finde nye strategier til at forbedre og debugge en model, f.eks. til at finde ud af hvorfor modellen virker drligt p bestemte eksempler i dataene eller som hjlp til at fjerne undvendige inputvariabler.De kan ogs bruges til at verificere, at modellen &quot;kigger&quot; p de rigtige ting, og at den ikke har lrt mrkelige korrelationer i data, som for eksempel at finde skibe i et billede p grund af at der er vand, men ikke p grund af skibet, eller at genkende heste p grund af et vandmrke i stedet for hesten, eller at forudsige en lavere risiko til at d af lungebetndelse nr man har astma. Iflge en ny undersgelse er debugging eller et skaldt &quot;sanity check&quot; det mest brugte ml af forklarlighed i praksis i jeblikket.MonitoreringSom beskrevet tidligere er almindelige performance-metrikker ikke altid nok til at mle en models vrdi eller omkostning lbende i driftssituationen. Det er dog disse metrikker, der bliver brugt til at monitorere forskellige modeller og deres performance. Her kan forklaringer vre en yderlige &quot;performance&quot;-metrik til at identificere en model-&quot;drift&quot;&amp;sup1,.Egenskaber hos forklarlige modellerEfter at vi nu har etableret de forskellige ml af forklarlighed, er det nste sprgsml hvilke egenskaber en forklarlig model skal have. R. Guidotti et al. beskriver tre forskellige egenskaber: interpretability (forklarlighed), performance og fidelity (troskab)&amp;sup1,&amp;sup1,. Der findes andre egenskaber, ligesom fairness, sikkerhed og, brugbarhed, men disse er ikke ndvendigt specifikke for forklarlige modeller og kan ogs delvis adresseres af de andre tre egenskaber.ForklarlighedDet kommer ikke som nogen overraskelse, at forklarlige modeller skal vre forklarlige. Der kan vre forskellige former af forklarlighed (det kommer vi nrmere ind p i et senere blogindlg), men det er ikke klart defineret, hvordan man skal mle forklarlighed. Doshi-Velez et al. foreslr tre forskellige mder: applikationsbaseret, metrikbaseret p mennesker, tekniske metrikker&amp;sup1,.Den frste, den applikationsbaserede mde, er den mest ressource- og tidskrvende, men ogs den mest prcise. Her bliver forklarlighed mlt, mens modellen reelt bliver anvendt (i driftssituationen). Man mler selve gevinsten af modellen i form af forretningsmetrikker, eller om det er nemmere at identificere fejl, om man genererer ny viden, eller om der er mindre diskriminering. Som basis kan man sammenligne metrikker med menneskelig beslutningssttte.Den anden mde er uafhngig af selve konteksten eller applikationen og fokuserer udelukkende p, hvor godt et menneske forstr modellen. Det kan man mle gennem forskellige forsgsopstninger&amp;sup1,&amp;sup2, &amp;sup1,&amp;sup3, &amp;sup1,, for eksempel:Den sidste mde er den mindst ressourcekrvende og mest brugte i litteraturen&amp;sup1, &amp;sup1, &amp;sup1, &amp;sup1,. Her bruger man rent tekniske metrikker. Ideen er, at hvis man ndrer et input p de variabler, der bliver fremhvet af forklaringer, s burde modellens njagtighed ndres. Dette kan mles gennem almindelige performancemetrikker, men der er forskellige mder at &quot;ndre&quot; inputtet p&amp;sup1,.PerformanceDet vigtigste forml med modellen er stadig at lave en njagtig prdiktion. Derfor er performance ogs en vigtig egenskab. Performance mles som regel med forskellige metrikker (se en artikel p towards data science og sklearns guide), som f.eks. njagtighed. Tit kan der vre et trade-off mellem performance og forklarlighed, da simple modeller, som beslutningstrer eller linere modeller, er mere gennemskuelige men kan ikke modellere komplekse sammenhnge i data. S den endegyldige beslutning om, hvilken model der virker bedst, er afhngig af balancen mellem de to egenskaber.Man kan ogs mle performance i form af det overordnende ml, f.eks. get brugertilfredshed, bedre behandling af patienter, mere effektive og hurtigere processer, get omstning, osv. Forklarlighed kan have en positiv effekt p denne type af metrikker, hvor klassiske metrikker ikke er gode nok til at beskrive performance i forhold til det overordne ml&amp;sup1,.TroskabNogle forklarlighedsmetoder bygger en model til at erstatte black-box-modellen, hvor black-box-modellen er brugt til prdiktioner og den anden model, ogs kaldt 'surrogate model', til at generere forklaringer. Men sidstnvnte model skal virke p samme mde som den originale black-box-model, alts generere prdiktioner s tt som muligt til black-box modellens prdiktioner. Hvis det ikke er tilfldet, s forklarer denne model ikke black-box-modellen, men kun sig selv. Selvflgelig vil surrogate modellen altid vre forskellig, dvs. har en ringere performance en black-box modellen, da man ellers kunne erstatte black-box modellen fuldstndig med surrogate modellen. Troskab mler, hvor tt forklaringsmodellens resultater ligger p resultater fra black-box modellen.KonklusionBekymringer om forklarlighed vedrrende systemer baseret p kunstig intelligens er ikke nyt, se f.eks. ekspertsystemer&amp;sup2,, case-based reasoning&amp;sup2,&amp;sup1, (for et historisk overblik se afsnit &quot;Explanation in Artificial Intelligence Systems: An Historical Perspective&quot; i Explanation in Human-AI Systems: A Literature Meta-Review, Synopsis of Key Ideas and Publications, and Bibliography for Explainable AI). Men fordi modellerne er blevet mere komplekse (isr dybe neurale netvrk) og kunstig intelligens bliver brugt mere til kritiske beslutninger og af ikke-ekspert-brugere, er udfordringerne med forklarlighed mere aktuelt en nogensinde.Udfordringen ligger i at definere, hvad man egentlig mener med forklarlighed, og at det nu ogs er ndvendigt at mle modellens performance p mere beskrivende mder - ssom tillid eller fairness.I dette blogindlg er vi kommet ind p hvad forklarlighed betyder, hvad man kan opn med forklarlige modeller, og hvorfor forklarlighed er et vigtig yderlige performancekriterium.[1] F. Doshi-Velez og B. Kim, &quot;Towards a rigorous science of interpretable Machine Learning&quot;, arXiv:1702.08608 [stat.ML], 2017.[2] Z. C. Lipton, &quot;The Mythos of Model Interpretability&quot;, arXiv:1606.03490v3 [cs.LG], 2017.[3] G. Malgieri og G. Comand, &quot;Why a Right to Legibility of Automated Decision-Making Exists in the General Data Protection Regulation&quot;, International Data Privacy Law, pp. 243-265, 2017.[4] S. Wachter, B. Mittelstadt og L. Floridi, &quot;Why a Right to Explanation of Automated Decision-Making Does Not Exist in the General Data Protection Regulation&quot;, International Data Privacy Law, pp. 76-99, 2017.[5] A. Selbst og J. Powles, &quot;Meaningful information and the right to explanation&quot;, International Data Privacy Law, pp. 233-242, 2017.[6] B. Y. Lim og A. K. Dey, &quot;Assessing demand for intelligibility in context-aware applications&quot;, Proceedings of the UbiComp '09, pp. 195-204, 2009.[7] S. Lapuschkin, S. Wldchen, A. Binder, G. Montavon, W. Samek og K.-R. Mller, &quot;Unmasking Clever Hans predictors and assessing what machines really learn&quot;, Nature Communications, 10, 2019.[8] R. Caruana, Y. Lou, J. Gehrke, P. Koch, M. Sturm og N. Elhadad, &quot;Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission&quot;, Proceedings of KDD '15, pp. 1721-1730, 2015.[9] U. Bhatt, A. Xiang, S. Sharma, A. Weller, A. Taly, Y. Jia, J. Ghosh, R. Puri, J. M. F. Moura og P. Eckersley, &quot;Explainable machine learning in deployment&quot;, Proceedings of FAT* '20, pp. 648-657, 2020.[10] S. M. Lundberg, G. Erion, H. Chen, A. DeGrave, J. M. Prutkin, B. Nair, R. Katz, J. Himmelfarb, N. Bansal og S.-I. Lee, &quot;From local explanations to global understanding with explainable AI for trees&quot;, Nature Machine Intelligence, 2, pp. 56-67, 2020.[11] A. Weller, &quot;Challenges for Transparency&quot;, arXiv:1708.01870v1 [cs.CY], 2017.[12] J. Chang, S. Gerrish, C. Wang, J. L. Boyd-Graber og D. M. Blei, &quot;Reading Tea Leaves: How Humans Interpret Topic Models&quot;, Advances in Neural Information Processing Systems 22, 2009.[13] T. Kulesza, M. Burnett, W.-K. Wong og S. Stumpf, &quot;Principles of Explanatory Debugging to Personalize Interactive Machine Learning&quot;, Proceedings of the IUI'15, pp. 126-137, 2015.[14] F. Poursabzi-Sangdeh, D. G. Goldstein, J. M. Hofman, J. W. Vaughan og H. Wallach, &quot;Manipulating and Measuring Model Interpretability&quot;, arXiv:1802.07810v3 [cs.AI], 2019.[15] M. T. Ribeiro, S. Singh og C. Guestrin, &quot;Anchors: High-Precision Model-Agnostic Explanations&quot;, Thirty-Second AAAI Conference on Artificial Intelligence, 2018.[16] G. Montavon, W. Samek og K.-R. Mller, &quot;Methods for interpreting and understanding deep neural networks&quot;, Digital Signal Processing, pp. 1-15, 2018.[17] M. Ancona, E. Ceolini, C. ytireli og M. Gross, &quot;Towards better understanding of gradient-based attribution methods for Deep Neural Networks&quot;, arXiv:1711.06104v4 [cs.LG], 2018.[18] A. Shrikumar, P. Greenside og A. Kundaje, &quot;Learning Important Features Through Propagating Activation Differences&quot;, arXiv:1704.02685 [cs.CV], 2017.[19] L. Bernardi, T. Mavridis og P. Estevez, &quot;150 Successful Machine Learning Models: 6 Lessons Learned at Booking.com&quot;, Proceedings of KDD '19, pp. 1743-1751, 2019.[20] P. Jackson, &quot;Introduction to Expert Systems&quot;, Addison-Wesley Longman, Harlow, 1990.[21] A. Kofod-Petersen, J. Cassens og A. Aamodt, &quot;Explanatory Capabilities in the CREEK Knowledge-Intensive Case-Based Reasoner&quot;, Proceedings of SCAI 2008 , pp. 28-35, 2008.Kontakt:Communications Specialist Lisa Lorentzen tlf.: +45 93 52 17 64 email: lisa.lorentzen@alexandra.dkLs hele pressemeddelelsen p Via Ritzau her: https://via.ritzau.dk/pressemeddelelse/hvad-betyder-forklarlighed-nar-vi-taler-om-kunstig-intelligens?releaseId=13593240** Ovenstende pressemeddelelse er videreformidlet af Ritzau p vegne af tredjepart. Ritzau er derfor ikke ansvarlig for indholdet ** 
        </div>
        <footer>
          <em>Ritzaus Bureau</em>
          &nbsp;&nbsp; 2020-05-13
          &nbsp;&nbsp; e7b4bc10
          &nbsp;&nbsp; #3
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.964</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.765</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.548</kbd>
        </footer>
      </article>
      <article>
        <h4>Sdan migrerer du til Python 3</h4>
        <div>
          Nytrsdag gik solen ned over Python 2. S det er bare med at komme i gang med flytteriet, hvis man ikke lige fik det gjort. Ls her, hvordan du gr. rsskiftet betd, at det det slut med support for Python 2. S der er panik efter lukketid, hvis applikationer ikke er blevet flyttet endnu. I sin tid blev Python 2 brugt som et scripting-sprog. Det blev brugt til konfiguration og webapplikationer. Men s blev Pythons pakker til videnskabelig og numerisk brug meget populrt. Python 3 kom p gaden i 2008, men der har vret en del trghed i tilegnelsen af den nye version, som p mange punkter bryder kompatibiliteten med den forrige udgave. Og indtil nu har der ikke ndvendigvis vret gode grunde til at skifte. Virksomheder med applikationer, der krer en hvilken som helst version af Python 2, er ndt til at migrere - og jo fr, desto bedre,  siger Bart Copeland, der er administrerende direktr i softwarevirksomheden ActiveState, til mediet Techrepublic Bart Copeland ppeger, at populre data- og AI-biblioteker som NumPy og Tensorflow er skiftet til Python 3 fra den 1. januar. Migrering til en ny version af Python er en betydelig opgave, s det br ikke ske i hast. Migrering, som finder sted inden fristen udlber, vil hjlpe udviklerne med at give dem den tid, der er ndvendig for at gre det ordentligt og tage hjde for eventuelle uforudsete fejl i god tid.  Men nu har klokken alts slet 12. S det er alts bare med at komme i sving, hvis man ikke allerede er i gang. Sdan migrerer du koden Et sted at starte, eller mske en desperat ndlsning, kan vre programmet 2to3 , som automatisk overstter kode fra den gamle til den nye udgave. Derudover har organisationen bag sproget, Python Software Foundation, skabt en omfattende guide til, hvordan man flytter kode fra Python 2 til 3. Techrepublic har opsummeret disse rd. Det er langt nemmere at migrere fra Python 2.7 end tidligere versioner. Hvis organisationen bruger Python 2.6, skal man benytte biblioteket Six . Det byder p hjlpefunktioner der kan udjvne forskellene mellem Python-versionerne. Srg for, at din setup.py-fil korrekt angiver, hvilke versioner af Python din kode understtter, og at dine test har mindst 80 pct. kodedkning. Lr forskellene mellem Python 2 og Python 3 ved at lse Pythons egen What's New-dokumentation og den gratis Porting to Python 3 -bog. Brug bibliotekerne Futurize eller Modernize til at gre din Python 2-kode Python 3-kompatibel, og srg for at lse dokumentationen. Vr opmrksom p, hvordan division med heltal er forskellig i de to versioner. I Python 2 giver 9/2 = 4, og i Python 3 giver samme regnestykke vrdien 4.5. Hvis du har brugt __future__ import division i din kode og // operatoren til heltalsdivison, vil din kode allerede vre Python 3-kompatibel. Python 3 er ndret i forhold til, hvilke data der kan bruges med str-typen for klarere at skelne mellem tekst og binre data. For at sikre kompatibilitet skal en rkke skridt udfres, som gennemget i portabilitets-dokumentationen. Et vrktj til statisk type-tjek, som Mypy , kan ogs hjlpe med at finde problemet. Nr man afvikler kode, der opfrer sig forskelligt, baseret p hvilken version af Python, der krer, er det bedre at kontrollere, om en bestemt funktion, der understttes i Python 3, er i stand til at kre, i stedet for at tjekke, om sys.version_info [0] er lig med 3. Kontroller, hvilke softwareafhngigheder der spnder ben for Python 3 ved hjlp af vrktjerne leveret af projektet Caniusepython3 Denne artikel har tidligere vret bragt p DataTech
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2020-01-02
          &nbsp;&nbsp; e786662f
          &nbsp;&nbsp; #4
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.891</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.797</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.669</kbd>
        </footer>
      </article>
      <article>
        <h4>PRM / Computer, hvordan vil du lige forklare det? Og det gerne med subjektive eksempler og objektive facts til feature attribution metoder og fodbold!</h4>
        <div>
          KbenhavnPressemeddelelse fra Alexandra InstituttetEksempel p LimeOverstende er et eksempel p en forklaringsmodel, der kan anvendes til at forklare udfald fra en skaldt 'black-box'-klassifikationsmodel p bde tekst, tabel- eller billeddata - og det uden et egentligt kendskab til, hvordan selve modellen virker, da forklaringsmetoden anvendes efter selve modellen er udviklet ved at efterligne den komplekse model lokalt. To kendte frameworks til at lave disse model-uafhngige feature attribution forklaringer er LIME (Local Interpretable Model-agnostic Explanations, Ribeiro et. al 2016) og SHAP (SHapley Additive exPlanations , Lundberg et al. 2017), og denne blogpost giver en introduktion til, hvordan disse to metoder virker, men ogs en diskussion af hvornr de ikke gr. Mske synes du ligesom mig, at ovenstende forklaring giver fin mening, men denne blogpost handler i hj grad ogs om begrnsningerne ved metoderne, og den subjektive overskrift kunne have vret, hvorfor SHAP og LIME alligevel ikke redder kampen.Men bare rolig, tonen er ikke kun dyster, det hele bliver fremfrt i en blanding af positivt, negativt, objektivt og subjektivt tonede stninger.Vi starter lidt bredt, hvorefter vi dykker ned i teorien bag metoderne, skyder bolden over til det praktiske ved implementeringerne, laver en objektiv vurdering af den bedste fodboldspiller, ser p fordele og ulemper igennem eksempler, og til sidst kigger vi p, om vi kan snyde forklaringsmodellerne til ikke at opdage, at vi holder med AGF.Men inden vi gr i gang, skal det lige indskydes, at klassifikationsmodellen, vi vil bruge som eksempel igennem bloggen, er en spaCy-model, jeg har trnet p manuelt annoterede tweets for 'subjektivt' og 'objektivt', og i tillg er den trnet p stninger fra Wikipedia, som er antaget til at vre 'objektive'. Men mere om modellen senere.Og som et sidste indspark, hvis du vil lse mere generelt om forklarlig AI, kan jeg anbefale min kollegas blogpost.Den gngse tone.. eller den gngse opfattelse af, hvad disse &amp;lsquo,feature attribution'-metoder kan bruges til, tager vi fat p frst. Ribeiro et. al 2016 prsenterede et vrktj kaldet LIME, som kan adressere problemet med 'tillid' til maskinlringsmodeller igennem forklaring. Med det mener de, at forklaringer enten kan bruges til at skabe tillid til et enkelt udfald, eller til at skabe tillid til modellen. Vi vil i denne blog inddele anvendelsen i flgende tre grupper:Den grundlggende ide bag at give forklaringer af enkelte udfald til en bruger af systemet gr p, at hvis jeg som bruger finder forklaringen rimelig, s har jeg en strre tro p, at modellens udfald er korrekt i det specifikke tilflde, hvorimod hvis jeg finder forklaringen langt ude, s kan det vre, at jeg som bruger af modellen, skal vlge at forkaste modellens prdiktion p dette pgldende eksempel. Men hvilke forklaringer, en slutbruger egentlig har brug for, er stof til et helt andet og mere tvrfagligt blogindlg.Forklaringer kan ogs bruges i selve udviklingsprocessen til at f en indsigt i, hvilke ting modellen faktisk kigger p, og srligt kan det opdages, om modellen fitter p noget i data som er uhensigtsmssigt (se for eksempel Lapuschkin et al. 2019).Den sidste ide til anvendelse gr p, at man kan bruge disse metoder som en ekstern part, som ikke har fet indsigt i udviklingen af systemet, til at monitorere om et system er fair, fx i forhold til ikke at vre diskriminerende over for bestemte grupper ved for eksempel at undersge om modellen bruger skaldte &quot;beskyttede&quot; variabler til at komme frem til beslutningen. (Ls mere om Fairness i min tidligere blogpost om retfrdige superhelte).Af ovenstende tre anvendelsesmuligheder er det nok at benytte metoderne som udviklingsvrktj, der har strst potentiale. Men lad os lige se p den ovenstende stning engang,Eksempel p LimeJamen dog, modellen prdikterer, at det er en subjektiv holdning herfra - og forklaringen er, at &quot;er det nok&quot; ikke er et objektivt ordvalg. Men s lad os i stedet starte mere objektivt med teorien bag, fr vi begynder p diskussionen og tager fat p et fodboldeksempel.Den objektive matematik... er et godt sted at begynde og lad os begynde med at se nrmere p LIME fra 2016, hvorefter vi kigger ind i SHAP, der udkom ret efter. Ideen bag LIME er at trne en simpel, forklarlig model lokalt rundt om et enkelt data-eksempel, sledes at den simple model efterligner den egentlige klassifikationsmodel s godt som muligt i det lokale omrde. P formel bliver det i Ribeiro et. al 2016 , prsenteret sledes:Credit: Ribeiro et. al 2016Lad os bryde det lidt ned. Lad os forestille os, at vores egentlige klassifikationsmodel, hvilken er defineret som f i formlen, er trnet via deep learning til at lre de komplekse strukturer i dataene, og derfor ikke nemt lader sig forklare i sig selv. Ideen er nu i stedet at finde en simpel model, som vi nemt kan forklare. Men den simple model kan ikke bruges til at forst den komplekse struktur, som vores data har (hvis den kan det, behves den komplekse model jo slet ikke). Men det antages, at en simpel model godt kan bruges p et lille, specifikt omrde af data. Her er opstillingen, tag udgangspunkt i et enkelt datapoint, det er x, og find da skaldte naboer til dette datapoint, dvs. datapunkter der ligger tt p x, defineret her som omrdet &amp;pi,_x. P disse datapunkter findes en simpel forklarlig model, g, som kommer s tt p at lave de samme prdiktioner som f p de lokale nabo-datapunkter som muligt, mlt ved fx &amp;lsquo,mean squared error' ved termet L(f,g,&amp;pi,_x). Det sidste term &amp;Omega,(g) mler kompleksiteten p vores lokale approksimationsmodel g. Desuden skal g vre forklarlig, og det betyder, at g skal tage en forklarlig reprsentation af data som input. g kunne vre en liner model, og kompleksiteten for en sdan liner model kan mles p antallet af features. I praksis optimerer LIME kun p at minimere L, og selve modelkompleksiteten vlges p forhnd.To af de praktiske sprgsml, vi vil vende tilbage til senere, er, hvordan vi vlger vores 'forstelige' datareprsentationer, samt hvordan vi vlger vores 'nabo'-eksempler. Men nu vil vi lige blive i matematikken og se p teorien bag SHAP.En smukkere, objektiv matematik.. fs i SHAP-artiklen (Lundberg et al. 2017). Her fremlgges en generel og mere teoretisk funderet formulering af &amp;lsquo,additive feature attribution'-metoder, som LIME er et eksempel p. Artiklen viser, at LIME, og en rkke andre &amp;lsquo,feature attribution'-metoder kan beskrives p samme, flgende mde. Problemstillingen er den samme, vi vil gerne forklare enkelte udfald fra en kompleks model ved hjlp af en simpel forklaringsmodel. Denne simple forklaringsmodel, g, bliver prsenteret som en liner model p binre features z, alts hvorvidt en feature er til stede eller ej. Vi arbejder alts stadig med forklarlige reprsentationer af input-features. Det er nu vgtene ?, vi skal finde, da de udtrykker, hvor vigtig hver feature i er p g's prdiktion.Credit: Lundberg et al. 2017Problemet bestr i at finde vgtene ?, og det p en mde som gr, at vgtene overholder flgende tre kriterier: Lokal Accuracy, at g faktisk approksimerer f lokalt, Missingness, hvis en feature i ikke er til stede, br vgten vre nul, Consistency, selvom vi havde forskellige modeller, skal bidraget for hver feature gerne vre det samme. Lundberg et al. 2017 viser nu, at den eneste definition, som opfylder dette, er at finde vgtene ved hjlp af &amp;lsquo,Shapley Values'.Shapley values giver os nu (endelig) en anledning til at tale om fodbold, og s starter vi en ophedet, subjektiv diskussion om, hvilken fodboldspiller der gr det bedst.Den bedste fodboldspiller er... noget vi teoretisk kan udregne med shapley values. Det giver en metode til at udregne, hvor meget hver spiller bidrager til holdindsatsen. Eller i vores tilflde kan vi bruge shapley values til at udregne, hvor meget hver feature bidrager til udfaldet af modellen. Formlen ser sledes ud:credit: Lundberg et al. 2017Og mske kan den virke lidt skrmmende. Men princippet bag skal bare deles lidt op. ?_i er den pgldende spiller i's bidrag, som vi gerne vil undersge, og N er antallet af spillere p holdet. For at finde ud af hvor meget spiller i bidrager til sejren, summerer vi over alle mulige kombinationer af delmngder af holdet S og ekskluderer spiller i og udregner derp, hvad det marginale bidrage er af at tilfje den ene spiller i til holdet igen. Det marginale bidrag af at tilfje spiller i til delholdet bliver udregnet i termet (v((S&amp;cup, {i}-v(s)), hvor v er det payoff/den vrdi, teamet genererer. (Vi kunne fx mle det i antal ml.) Det sidste term er en faktor, vi ganger p det marginale bidrag for at justere for, hvordan delholdet er sammensat, alts vi vil gerne have det gennemstilige bidrag af spiller i, uanset hvilke andre spillere der er p delholdet. Til slut ganger vi ogs med 1 over antal spillere, da vi gerne vil have spiller i's bidrag uanset strrelsen p delholdet.Dette er det teoretiske fundament bag SHAP, men praktisk er det alt for omkostningstungt at udregne disse shapley values med alle de kombinationer, der skal opstilles, og derfor approksimeres disse vrdier (oftest) i praksis.Det praktiske i haven og problemer med at spille med naboen... er nogle af de ting, man skal overveje som 'kber' af LIME og SHAP. I praktisk er bde LIME og SHAP implementeret med open source GitHub og pip-pakker lige til at installere og med fine tutorials . Dog er der lidt ting, der skal tages hjde for. Der findes forskellige implementationer af SHAP, alt efter hvilken model man vil forklare - dog er kernel SHAP model-uafhngig og minder om LIME, men den er ogs langsom og den mest grove approksimation af Shapley values.I teorien virker metoderne bde p tekst, billede og tabeldata, men i praksis understtter SHAP-implementationerne ikke en direkte behandling af tekst fra alle typer modeller, da det ikke er defineret, hvordan teksten skal behandles som features.Der er generelt en udfordring med at vlge 'den forklarlige reprsentation', fordi der kan vre et gab mellem den, og det input som modellen rigtig fitter p. I tilfldet med tekstdata kan den simple linere model mske tage enkelte ord som input, selvom klassifikationsmodellen ikke ndvendigvis fitter p enkelte ord. Ved billedata kunne den forklarlige reprsentation vre et omrde i billedet i stedet for de egentlige pixels som input - vi snakker om segmentering eller superpixels. Der er alts en forskydning i, hvad modellen egentlig fitter p, og hvad den kan forklares med. Det vil i praksis sige, at vi ikke kan bruge LIME eller SHAP til noget, hvis ikke forklaringen af et udfald kan indfanges i den simple reprsentation, som vi lader LIME og SHAP fitte p. Lad os tage et eksempel med stningen &quot;denne blog handler om ansvarlig AI&quot;,Eksempel p LimeModellen afgr, at stningen er 'objektiv', men med forklaringen 'denne blog'. Men det er som om, at disse ord i sig selv ikke forklarer, hvorfor modellen siger 'objektiv', eller hvorfor vi selv vil sige 'objektiv'. Mske er forklaringen nrmere, at der ikke er noget, der gr stningen subjektiv, eller med andre ord, forklaringen kan ikke fanges ved at pege p enkelte ord.Med hensyn til at genere naboer, ligger der en udfordring med afst i SHAP i, at da modellen afprver kombinationer af, hvilke features der er med 'p holdet' eller ej, s skal vi have en mde at definere p, hvad det vil sige ikke at vre med, alts at vre bnket. Vi er ndt til at afklare, nr vi fjerner en feature, hvad er der s? Alts, hvis vi fjerner et omrde i et billede, hvad skal &quot;baggrunden&quot; s vre, skal de pixels i omrdet sttes til at vre hvide, eller sorte, eller hvad med en gennemsnitlig vrdi af hvad pixels &quot;normalt&quot; tager i det omrde? Det sidste krver, at vi har adgang til en lille smule trningsdata for at kunne udregne fx gennemsnitsvrdier. Ls mere om udfordringer med baggrundsdata i denne interaktive Distil-publikation.Det gode, subjektive eksempel... indledes p trningsbanen. Indledningsvis listede vi tre anvendelsesomrder for &amp;lsquo,feature attribution' metoder, og indtil videre har vi sparket lidt tvivl op om deres egentlige anvendelse til at forklare enkelte prdiktioner. Men lad os se p metodernes anvendelse som udviklingsvrktj. Subjektiv/objektiv-klassifikationsmodellen er trnet p manuelt annoterede tweets, hvor vi har gemt 400 til valideringssttet og 1716 eksempler til trning af modellen. Trningssttet fordeler sig mellem de to klasser sledes:Da dette ikke er srligt balanceret, er der tilfjet 1500 stninger fra Wikipedia, som vi bare uden videre har antaget er 'objektive'. P valideringsttet opns en accuracy p 87% og en macro-f1 p 73%. Men lad os lige se p et eksempel, hvor vi prver at forklare flgende stning med modellen:I modellens forklaring ser vi, at tilstedevrelse af &quot;#&quot; trkker prdiktionen mod at vre 'subjektiv'. Men vi synes mske egentlig ikke, at &quot;hasttags&quot; br tale for det ene eller det andet. Vi bliver opmrksomme p, at der netop er en skvhed i vores data, da langt de fleste subjektive eksempler kommer fra tweets, som netop bruger &quot;#&quot; i modstning til stninger fra Wikipedia. Vi renser nu data for &quot;#&quot; og &quot;@&quot; og trner modellen igen. Nu opns en hjre accuracy p valideringsttet p 88% (0.74 macro-f1). Og forklaringen p overstende stning bliver nu:Forklaringsmetoderne kan alts gre os opmrksomme p ting, modellen fitter p, som kan skyldes en skvhed i data. I LIME-artiklen (Ribeiro et. al 2016) vises denne anvendelse p en billedeklassificerings-task med &quot;husky hund eller ulv&quot;, hvor vi igennem forklaringen kan spotte, at modellen i tilflde af 'ulv' fitter p sne i billedet i stedet for p selve dyret. Dette datast er dog konstrueret, og skal tages som et legeeksempel. Andre eksempler findes i denne artikel Lapuschkin et al. 2019, hvor der i stedet bruges LRP-metoden.Hey dommer, de snyder...... forklaringsmodellerne til ikke at se, hvor unfair modellen virkelig er. Slack et al. 2020 viser i deres artikel, hvor nemt LIME og SHAP kan snydes. Med dette argumenterer de imod, at en tredjepart, uden adgang til informationer om selve udviklingen af modellen, kan bruge forklaringsmodellerne til at monitore fairness, hvilket var den tredje mulige anvendelse listet indledningsvis.Svagheden ved SHAP og LIME, viser Slack et al. 2020, er, at det er forholdsvist nemt at se forskel p de originale eksempler og de generede naboeksempler. Tricket er derfor at trne en model, der kan kende forskel mellem et original- og et naboeksempel, og ud fra dette kan det sorteres, s eksempler, der bliver brugt til at generere forklaringer af LIME og SHAP, bliver sendt til en anden klassifikationsmodel end den klassifikationsmodel, som anvendes ved originale eksempler.Lad os lege lidt med et eksempel. Legefortllingen er flgende: Den Nationale Boldunion Investeringsfond har lavet et udbud p et system, der kan mle p social medie-kommentarer, om fodboldspillere bliver omtalt positivt eller negativ med det forml at investere i de mest positivt omtalte klubber. Men de ved, at fans rundt om i landet vil gre alt for at levere et system, der fremstiller deres egen klub s positivt omtalt som muligt, og derfor vil de tjekke de indleverede systemer for, om de er favoriserende og diskriminerende.Vi er sdan en fan! Og vi holder meget af AGF og knap s meget af Brndby. Derfor har vi lavet et system, der hver gang, den ser navnet p en AGF-spiller, prdikterer positivt, og hver gang den ser en Brndby-spiller prdikterer negativt. Hvis ingen navne indgr, benytter systemet Afinn ordlistebaserede sentimentvrktj. S systemet er helt gennemskueligt og ikke nogen sort boks, men det leger vi, at Den Nationale Boldunion Investeringsfond jo ikke ved. De vil nu benytte SHAP og bruge et &quot;summary-plot&quot; til at opsummere hvilke features, der har vret mest betydende i et testst, som de har genereret for at teste modellens fairness. De har lavet teststtet til at undersge diskriminering/favorisering ved at skrive otte stninger,[&amp;lsquo,UNK er den bedste fodboldspiller', &amp;lsquo,Den var en sjovt at se UNK scorede et fantastisk ml', &amp;lsquo,unk er en succes', &amp;lsquo,Altid dejlig at se UNK spille', &amp;lsquo,Det var drligt sparket af UNK', &amp;lsquo,UNK er jo direkte en skndsel for holdet', &amp;lsquo,UNK har sammen med dommeren gjort kampen til en grim katastrofe', &amp;lsquo,Ringere spiller er ikke set end forfrdelige UNK']Samt en liste med spillernavne, som hver kan udskiftes p UNK-pladserne i de ovenstende stninger:AGF = [&amp;lsquo,Duncan', &amp;lsquo,Helenius', &amp;lsquo,Eskelinen', &amp;lsquo,Gersbach' ]Brndby= [&amp;lsquo,Gammelby', &amp;lsquo,Mensah', &amp;lsquo,Lindstrm', &amp;lsquo,Bruus']Hvis SHAP-modellen blev anvendt p ovenstende syntetiske 'testst' og med det ovenstende diskriminerende system, ville vi blive afslret i, at systemet har AGF-fodboldspillernes navne som features, der trkker modellens output mod 'positiv', og Brndbyspillernes mod 'negativ':SHAP summary plotDerfor vil vi nu, som de inkarnerede fans vi er, snyde dette tjek ved i stedet at levere et system, hvor det ikke bliver opdaget, at modellen holder med AGF.Ovenstende anvendelse af SHAP er et legeeksempel, hvor inputfeature-reprsentationen er en simpel &quot;countvector&quot;, og baggrundsdataene UNK er en token. I praksis ville vi nok fitte baggrundsdata p egentlig trningsdata (som vi i s fald br kende), og i tilflde af en countvector nok egentlig bare stte baggrundsvrdien til 0, men dette er blot for at vise ideen. S, med UNK som baggrundsdata, har vi gjort det nemt for os selv at kende forskel p originale eksempler og generede eksempler, s vi behver blot at indbygge i vores system, at hvis vi ser UNK, skal eksemplet sendes til en ikke-diskriminerede model, og nr vi ikke ser UNK, s kan vi anvende vores AGF-elskende model. Som vores ikke-diskriminerende model vil vi blot anvende Afinn-modellen. P den mde viser forklaringerne, hvordan Affin-modellen virker, og ikke hvordan modellen virker in real life. Lad os se hvad SHAP nu siger:SHAP summary plotDet ses, at SHAP nu tror, at de mest betydende features er hhv. positivt og negativt ladede ord, og ikke lngere fodboldspillernavnene som modellen rigtigt bruger.Positive og negative takter... eller i hvert fald en subjektiv opsummering over fordele og ulemper ved vrktjerne.Fordelene ved LIME er, at det er rigtig nemt at bruge, og at vrktjet virker bde for tabel-, billede- og tekstdata, og vrktjet kan endda bruges uanset typen af den originale model, og i tillg kan den originale model vre trnet p en ikke-fortolkelig reprsentation. Dette er dog ogs samtidig en af ulemperne, da der derved kan ske et skred imellem forklaringen, og hvad den originale model bruger af input. Af andre ulemper ved LIME kan nvnes problemet med at genere naboeksemplerne. LIME ignorer sammenhng mellem features, nr naboeksempler genereres, og det kan resultere i usandsynlige datapunkter. Der er i srdeleshed et problem med, hvordan tabeldata skal hndteres. Desuden er det uklart, i hvilket omrde forklaringerne holder, og om hvorvidt forklaringerne generaliser til andre eksempler, da det lokale omrder mske ikke kan beskrives linert. Til at adresse dette problem er forfatteren bag LIME kommet med en metode, der benytter 'if-then' regler (Ribeiro et. al. 2018). LIME kritiseres i Alvarez-Melis et. al 2018 for at vre ustabil i sine forklaringer.SHAP har den fordel, at den med sine shapley values er teoretisk velfunderet, og br derfor teoretisk anvendes over LIME. Ligeledes giver dens afst i shapely values en sammenhng mellem enkelte forklaringer og forklaringer for fx hele validerings-datasttet. SHAP Kernel implementation er ogs model-uafhngig, men desvrre meget langsomt, og beror p en approksimation af shapley values. Desuden ignoreres feature dependency ogs her, og udvlgelsen af baggrundsdata er ikke givet. Til gengld ses der lovende takter med Treebased SHAP, som kan bruges til at forklare &quot; tr baserede&quot;-modeller. Det er dog ikke noget, der er blevet plads til i dette indlg, men der kan lses mere om det i Lundberg et al. 2020.I den samlede subjektive vurdering af hvad disse feature attribution-metoder kan bruges til, vil jeg lgge vgt p, at metoderne kun er anvendelige, hvis man selv kan pege p, hvad det egentlig er, man forventer, modellerne fortller en. Forstet p den mde at man kun kan f en forklaring med den simple reprsentation, man nu engang har givet forklaringsmodellen at fitte p. Desuden skal man huske at sprge sig selv, om forklaringen egentlig er srlig forstelig for folk, der ikke kender til vrktjet, eller mske til maskinlring i det hele taget. Alt i alt er det subjektive lyspunkt nok, at modellen kan bruges til at spotte uhensigtsmssighed i selve udviklingsprocessen.Tak fordi du lste med, selvom det hele blev lidt langt./ Amalie Pauli ReferencerAlvarez-Melis, David, and Tommi S. Jaakkola. &quot;On the robustness of interpretability methods.&quot; arXiv preprint arXiv:1806.08049 (2018).Lapuschkin, Sebastian, et al. &quot;Unmasking clever hans predictors and assessing what machines really learn.&quot; Nature communications 10.1 (2019): 1-8.Lundberg, Scott M., and Su-In Lee. &quot;A unified approach to interpreting model predictions.&quot; Advances in neural information processing systems. 2017.Lundberg, Scott M., et al. &quot;From local explanations to global understanding with explainable AI for trees.&quot; Nature machine intelligence 2.1 (2020): 2522-5839.Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. &quot;&quot; Why should i trust you?&quot; Explaining the predictions of any classifier.&quot; Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. 2016.Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. &quot;Anchors: High-precision model-agnostic explanations.&quot; Thirty-Second AAAI Conference on Artificial Intelligence. 2018.Slack, Dylan, et al. &quot;Fooling lime and shap: Adversarial attacks on post hoc explanation methods.&quot; Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society. 2020.Kontakt:Communications Specialist Lisa Lorentzen tlf.: +45 93 52 17 64 email: lisa.lorentzen@alexandra.dkLs hele pressemeddelelsen p Via Ritzau her: https://via.ritzau.dk/pressemeddelelse/computer-hvordan-vil-du-lige-forklare-det-og-det-gerne-med-subjektive-eksempler-og-objektive-facts-til-feature-attribution-metoder-og-fodbold?releaseId=13594152** Ovenstende pressemeddelelse er videreformidlet af Ritzau p vegne af tredjepart. Ritzau er derfor ikke ansvarlig for indholdet ** 
        </div>
        <footer>
          <em>Ritzaus Bureau</em>
          &nbsp;&nbsp; 2020-05-28
          &nbsp;&nbsp; e7ba2803
          &nbsp;&nbsp; #5
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.99</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.879</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.621</kbd>
        </footer>
      </article>
      <article>
        <h4>Fredag 26 august</h4>
        <div>
          Dubstep Mania 2011 // Eddie K // AI // Torsdagsredaktionen // Denali ( Train): Dubstep and D'n'B All Night. ( Not for Pussies, Wimps or Fragile Ears).Bass Culture er igen i r get sammen med Present Aarhus og Heiniken om at presentere rets vildeste rave.Line-up: 23: 00 Denali Sound ( Aarhus) 24: 00 Eddie K ( UK) 01: 30 Torsdags Redaktionen ( Christiania Radio) 03: 00 Artificial Intelligence ( UK) 05: 00 Curfew Der er lagt op til en nat med fuld udblsning for musikken, og hoppestemning natten lang!.
        </div>
        <footer>
          <em>rhus Stiftstidende</em>
          &nbsp;&nbsp; 2011-08-25
          &nbsp;&nbsp; e2d64d07
          &nbsp;&nbsp; #6
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.943</kbd>
            <kbd data-tooltip="AI &amp; innovation">L05_INNOAI&nbsp;0.937</kbd>
        </footer>
      </article>
      <article>
        <h4>Her er nyhederne i Python 3.10: Match er en ren schweizerkniv</h4>
        <div>
          For anden gang udkommer Python efter en ny rlig udgivelsesplan. Den store nyhed for det hidtil switch-lse sprog er en ny match-stning, der kan lidt af hvert.Version2 : Med 30 r p bagen har programmeringssproget Python kronede dage. P lister over sprogs popularitet ligger Python enten i toppen eller tt p.Python er get fra at vre et scripting-sprog med lav indlringskurve, til at vre et af de foretrukne sprog til videnskabelig programmering, statistik, dataanalyse og kunstig intelligens.Ligesom i Javascript kan man i Python gre nsten, hvad man har lyst til p krselstidspunktet, ssom at udstyre objekter med nye felter og metoder. Det stter begrnsninger p afviklingshastigheden.Den danske ekspert i virtuelle maskiner Lars Bak vurderer, at sprog som Python og Javascript kan opn omkring halvdelen af den ydelse som typestrke sprog, der ogs afvikles i en virtuel maskine, ssom Java og C#, kan prstere.Men der er flere mder at gre tingene p. Det er nemt at kalde C-kode fra Python, og mange Python-biblioteker er implementeret i C, som gr dem lynhurtige.Nr det handler om kunstig intelligens, matricer og vektorer, kan biblioteker udnytte grafikkort, som er mange gange hurtigere, end nr tilsvarende operationer skal udfres p cpu-kerner, p grund af parallelisering af linere vektorberegninger.P den mde kan Python-koden blive et slags instrumenteringslag for de underliggende hjtydende biblioteker, med en nem syntaks, der tillader lidt af hvert og sjldent stiller sig i vejen for programmren.Match er en schweizerkniv-switchEn ny version er tt p af se dagens lys. Den har nummeret 3.10, og er den anden udgave efter en ny udsendelsesplan, hvor der kommer nye versioner n gang om ret.Blandt nyhederne er pattern matching, som ogs Java og PHP for nylig er blevet udstyret med. Pattern matching stammer fra de funktionelle sprog, og trenden blandt objektorienterede sprog er netop at lne ideer fra den funktionelle verden.Python har aldrig tidligere haft en switch-stning, s det er funklende nyt, og den nye konstruktion er en ren schweizerkniv, i forhold til hvilke mnstre stningen kan hndtere.P det overordnede plan ser det sledes ud, med eksempler taget fra dokumentationen:match subject:case :case :case :case _:P klassisk Python-maner kan en masse forskellige ting anvendes som argument i case-stningerne. Mnstrene kan best af sequences, mappings, primitive datatyper samt klasse-instanser.Et simpelt eksempel kan se sdan ud:def http_error(status):match status:case 400:return &quot;Bad request&quot;case 404:return &quot;Not found&quot;case 418:return &quot;I'm a teapot&quot;case _:return &quot;Something's wrong with the Internet&quot;Case-stninger kan ogs indeholde variable:# point is an (x, y) tuple match point:case (0, 0):print(&quot;Origin&quot;) case (0, y):print(f&quot;Y={y}&quot;) case (x, 0):print(f&quot;X={x}&quot;) case (x, y):print(f&quot;X={x}, Y={y}&quot;)Og med klasse-instanser:class Point:x: int y: int def location(point):match point:case Point(x=0, y=0):print(&quot;Origin is the point's location.&quot;) case Point(x=0, y=y):print(f&quot;Y={y} and the point is on the y-axis.&quot;) case Point(x=x, y=0):print(f&quot;X={x} and the point is on the x-axis.&quot;) case Point():print(&quot;The point is located somewhere else on the plane.&quot;) case _:print(&quot;Not a point&quot;)Lister kan ogs anvendes som argument til case-stningen:match points:case []:print(&quot;No points in the list.&quot;) case [Point(0, 0)]:print(&quot;The origin is the only point in the list.&quot;) case [Point(x, y)]:print(f&quot;A single point {x}, {y} is in the list.&quot;)Man kan ogs bruge underscore-wildcard'et p en mere kompleks facon:match test_variable:case ('warning', code, 40):print(&quot;A warning has been received.&quot;) case ('error', code, _):print(f&quot;An error {code} occurred.&quot;)Men der er mere, som de siger i TV-shoppen:Man kan ogs udstyre case-stningen med en 'guard', ogs kendt som en 'precondition', ved at stte en if-stning efter case-udtrykket:match point:case Point(x, y) if x == y:print(f&quot;The point is located on the diagonal Y=X at {x}.&quot;) case Point(x, y):Og der er endda flere muligheder med match-stningen, end hvad vi har vist her.Nemmere unionsPython er et sprog, hvor variabeltyper ikke gr det store vsen af sig. Men lidt type-information p en sidetallerken er nu heller ikke drligt. I Python 3.5 kom muligheden for at antyde typer.Ligesom i den nye PHP er der nu en nem mde at angive, at en variabel eller parameter kan antage n af to eller flere typer, i stedet for den gamle mde, Union[int, float], at gre det p:def square(number: int | float) -&gt; int | float:return number ** 2Context managers er en stningskonstruktion, hvor ressourcer som eksempelvis fil-handlers kan deallokeres p en robust facon, uden at programmren skal benytte try-finally eller andre tiltag. Det svarer til Java og C#'s try-with-resources og using, og nyheden er, at man kan have flere context managers i samme blok, som i:with (CtxManager1(), CtxManager2() ):Blandt andre nyheder er forbedrede fejlmeddelelser, som i dette eksempel:File &quot;example.py&quot;, line 1 expected = {9: 1, 18: 2, 19: 2, 27: 3, 28: 3, 29: 3, 36: 4, 37: 4, ^SyntaxError: '{'was never closed- hvor fortolkeren fr i tiden blot ville have sagt SyntaxError: invalid syntaxog peget p starten af den efterflgende stning.SyntaxError har i det hele taget fet en lang rkke specialiserede meddelelser, s det bliver nemmere at finde ud af, hvad der er galt.Der er flere nyheder i den nye version, som er frste beta af fire, fr den endelige udgave udsendes i starten af september i r. Beta-versionen kan testes p Windows og Mac, mens andre dyr selv m kompilere kildekoden. Links til det hele kan findes i udgivelsesnoterne.
        </div>
        <footer>
          <em>Pro.ing.dk/Gridtech</em>
          &nbsp;&nbsp; 2021-05-18
          &nbsp;&nbsp; e8453331
          &nbsp;&nbsp; #7
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.982</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.524</kbd>
        </footer>
      </article>
      <article>
        <h4>Forskere advarer: AI-forklaringsteknikker som Shap og Lime kan snydes</h4>
        <div>
          Et hold amerikanske forskere har demonstreret, at udbredte metoder til at bne black box-modeller rent faktisk kan snydes, s indbygget bias kan skjules. I arbejdet med at gre black box-machine learning til at forst bliver frameworks som Shap og Lime brugt mere og mere. Men teknikkerne er faktisk ikke plidelige, nr det handler om at afslre ellers skjult bias i ML-modellerne. Det mener et hold amerikanske forskere fra Harvard University og University of California. I en forskningsartikel , som blev offentliggjort i november, demonstrerer forskerne, at det er muligt at opbygge en klassifikationsmodel til at have en bias mod f.eks. race, men hvor forklaringer fra Lime og Shap ser uskyldige ud: In particular, our results show that the explanations of these classifiers generated using off-the-shelf implementations of Lime and Shap do not flag any of the relevant sensitive attributes (e.g., race) as important features of the classifier, thus demonstrating that the adversarial classifiers successfully fooled these explanation methods.  Forklaringsteknikker er ikke undersgt Shap og Lime er begge teknikker til at forklare et specifikt resultat fra en model, som ellers ikke er umiddelbart aflselig, som f.eks. en random forest. Modellen estimerer det bidrag, som den enkelte variabel giver til det endelige resultat. Det sker med en teknik, der kaldes 'input perturbations', hvilket grundlggende gr ud p at lave syntetisk data, som varierer inputtet for at se, hvad det betyder for resultatet, og p den mde afgr, hvilken del af inputtet er vigtigt for resultatet. Teknikkerne er blevet udbredt i takt med, at black box-modeller tages i brug til beslutningssttte. Med Shap kan en radiolog sledes f at vide, prcis hvilke dele af et billede der har fet deep learning-modellen til at mene, at patienten har en tumor. Eller en rekrutteringsalgoritme kan vise, hvilke dele af ansgerens CV der gr kandidaten interessant. Og i forlngelse deraf kan teknikken sledes ogs vise, om modellen fokuserer p noget, der ikke hensigtsmssigt. However, there has been little analysis of the reliability and robustness of these explanation techniques, especially in the adversarial setting, making their utility for critical applications unclear,  skriver forskerne. Med andre ord er sprgsmlet, hvor meget teknikkerne er vrd, hvis skaberne af modellen prver at snyde. Og her er svaret iflge de amerikanske forskere alts ikke oplftende. Klassifikation med stillads Forskerne forestiller sig at have et incitament til at bruge en model, der har en indbygget bias, men omvendt er underlagt regulatoriske krav om at lade modellen blive analyseret med teknikker som Shap og Lime. I artiklen prsenterer forskerne et framework, der som input har den diskriminerende klassifikationsmodel samt et sample af den data, som modellen skal bruges p. Med det input bygger frameworket, hvad forskerne kalder et stillads (scaffold) rundt om en klassifikationsmodel. Modellen med stilladset udnytter det faktum, at Lime og Shap bruger syntetisk data for at teste variablernes betydning. Distributionen i den syntetiske data er nemlig tilpas anderledes end den gte data, til at den ondsindede model kan skelne mellem, hvornr den bliver brugt, og hvornr den bliver testet. By being able to differentiate between data points coming from the input distribution and instances generated via perturbation, an adversary can create an adversarial classifier (scaffolding) that behaves like the original classifier (perhaps be extremely discriminatory) on the input data points, but behaves arbitrarily differently (looks unbiased and fair) on the perturbed instances, thus effectively fooling Lime or Shap into generating innocuous explanations,  skriver forskerne. Lime godkender kreditvurdering ud fra kn alene Artiklen giver to eksempler, hvor godt det virker i praksis. Forskerne bygger tre modeller: to, der p forskellige datast skal forudsige, om kriminelle vil beg ny kriminalitet alene baseret p race, og n model, der godkender ln alene baseret p kn. I alle tre tilflde kunne modellen snyde Lime til at lave forklaringer, der ikke afslrer modellernes bias. I Shap er forklaringen mere blandet. En af modellerne formede at snyde Shap i 100 procent af tilldene, mens Shap afslrer de andre to modellers bias i omkring 15 procent af tilfldene. Our findings suggest that existing post hoc explanation techniques are not sufficiently robust for ascertaining discriminatory behavior of classifiers in sensitive applications,  skriver forskerne, der foreslr, at man udvikler nye teknikker til at bne black box-modeller, som ikke kan narres. Professor: Drop black box-modeller De amerikanske forskere er ikke de eneste, der er skeptiske over for praksissen med at tilfje et forklaringslag til en black box-model. I en kommentar , der er udgivet i maj og senest opdateret i september, advokerer Cynthia Rudin, der er datalogiprofessor ved Duke University, for at bruge modeller, der i sig selv kan forsts og fortolkes, som f.eks. beslutningstrer. Rather than trying to create models that are inherently interpretable, there has been a recent explosion of work on 'Explainable ML', where a second (posthoc) model is created to explain the first black box model. This is problematic. Explanations are often not reliable, and can be misleading,  skriver hun. Selv hvis bde black box-modellen og den efterflgende model til forklaring gr deres arbejde efter hensigten, s er det alt for lidt information, der komme ud af det, argumenterer Rudin. Hun nvner som eksempel saliency maps, der kan bruges til at forst, hvad en computer vision-model egentlig ser p i et billede. Her demonstrerer Rudin, at et saliency map, der kategoriserer en hund som en fljte, essentielt ser ligedan ud, nr hunden kategorises korrekt. Fra Cynthia Rudins synsvinkel skal brugen af black box-modeller i kritiske miljer helt undgs. Trying to explain black box models, rather than creating models that are interpretable in the first place, is likely to perpetuate bad practices and can potentially cause catastrophic harm to society. 
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2019-12-10
          &nbsp;&nbsp; e77bda69
          &nbsp;&nbsp; #8
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.996</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.659</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.544</kbd>
        </footer>
      </article>
      <article>
        <h4>Google Cloud lgger over to millioner kroner i Python-udvikling</h4>
        <div>
          Krselsmilj, vrktjer og sikkerheden i pakkesystemet fr en kontant saltvandsindsprjtning fra it-kmpen.Google Cloud har doneret 350.000 USD, svarende til 2,16 millioner kroner, til Python Software Foundation, som str bag sproget af samme navn. Det skriver InfoworldMlet for donationen er sttte udviklingen af CPython, som er det officielle krselsmilj, samt forbedring af sprogets grundlggende vrktjer og styrke sikkerheden af Pythons Pypi-pakkesystem.Google benytter blandt andet Python og dets pakkesystem i forbindelse med firmaets Tensorflow-produkt til kunstig intelligens. I en meddelelse skriver Google Cloud, at Python er af kritisk vigtighed  for firmaet og dets kunder.Udover kunstig intelligens er Python ogs et populrt afviklingsmilj for mange af firmaets tjenester, ssom Google App Engine og Google Cloud Functions.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2021-02-18
          &nbsp;&nbsp; e821bd91
          &nbsp;&nbsp; #9
          <br>
          <br>
            <kbd data-tooltip="Tech industry &amp; regulation">L02_BIGTEC&nbsp;0.972</kbd>
            <kbd data-tooltip="AI &amp; innovation">L05_INNOAI&nbsp;0.631</kbd>
            <kbd data-tooltip="EU regulation of big tech">L10_EUREGU&nbsp;0.567</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.532</kbd>
        </footer>
      </article>
      <article>
        <h4>Transparens og prcision: SHAP-analyse forklarer, hvad der foregr i black-box-modeller</h4>
        <div>
          Et nyt vrktj til arbejdet med komplekse machine learning-modeller gr det muligt at bne den sorte kasse og forklare, hvordan modellen kom frem til en bestemt forudsigelse. SHAP-vrktjet - SHapley Additive exPlanation - bner for, at virksomheder ikke behver at ofre prcision for at kunne forsvare algoritmens forudsigelse.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2018-10-02
          &nbsp;&nbsp; e6eb61b6
          &nbsp;&nbsp; #10
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.899</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.837</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.608</kbd>
        </footer>
      </article>
      <article>
        <h4>Intelligenstest</h4>
        <div>
          Implementering af it-systemer, der rent faktisk virker efter hensigten, har vist sig at vre en udfordring for det offentlige, ikke mindst Skat. Er den s omdiskuterede Artificial Intelligence (AI) mon efterhnden menneskehedens eneste hb om en intelligent lsning af it-problematikker? &gt;&gt; Se flere p ing.dk/ satire. 
        </div>
        <footer>
          <em>Ingeniren</em>
          &nbsp;&nbsp; 2017-04-07
          &nbsp;&nbsp; e633e8e7
          &nbsp;&nbsp; #11
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.679</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.732</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.556</kbd>
        </footer>
      </article>
      <article>
        <h4>Googles Go-sprog fr endelig typeparametre</h4>
        <div>
          Efter flere rs udvikling er et forslag om typeparametre vedtaget. Faciliteten debuterer i Go 1.18, der skal udkomme i starten af nste r.Sproget Go flger nu efter de fleste andre moderne programmeringssprog og fr typeparametre, ogs kaldet 'generics.'Det skriver to af sprogets udviklere , Ian Lance Taylor og Robert Griesemer, der begge er ansat i Google. Sproget blev i sin tid udviklet for at lse de udfordringer, der er med server-programmering i stor skala hos Google.Udviklerne meddeler, at faciliteten forventes at blive tilfjet i version 1.18, som skulle udkomme i starten af 2022.Typeparametre gr det muligt at skrive kode, hvor funktioner benytter samme operationer for parametre og variable af forskellige typer, og kan p denne mde generalisere en algoritme.Det benyttes ofte i forbindelse med samlinger, hvor eksempelvis en liste-struktur kan udrustes med en elementtype, s metoder som tilfj(e) kun kan udfres med elementer af den specificerede type som parameter.Forslaget har vret en del r undervejs og et tidligere udkast, som byggede p kontrakter , er forkastet til fordel for en anden model.Et trivielt eksempel kan se sdan ud, iflge det vedtagede forslag:// Print prints the elements of a slice.// It should be possible to call this with any slice value.func Print(s []T) { // Just an example, not the suggested syntax.for _, v := range s {fmt.Println(v)}}I eksemplet her er []T et slice med elementtypen TTypeparametre er magen til almindelige funktionsparametre, og de anfres sammen med andre parametre.Typeparametrene kan udstyres med 'constraints', som begrnser udvalget af typer, der kan anvendes som parametre. En constraint er blot et almindeligt interface, som Stringer herunder:// Stringify calls the String method on each element of s,// and returns the results.func Stringify[T Stringer](s []T) (ret []string) {for _, v := range s {ret = append(ret, v.String())}return ret}Ingen ko- eller kontravariansSprogudviklerne har fravalgt muligheden for at angive kovarians og kontravarians for funktionsparametre, en facilitet der findes i sprog som Java og C#, og som gr det muligt at specificere, hvornr en subtype eller en supertype ogs accepteres som parameter givet ved et typeudtryk. Udeladelsen gr generics simplere, skrives der i forslaget.I modstning til Java benyttes der ikke 'type erasure', og det betyder, at en typeparameter i Go er kendt og kan anvendes i koden under afviklingen.Sammenlignet med C++ nvner sprogudviklerne, at dette sprogs template-implementering af typeparametre ikke benytter constraints, hvilket kan fre til fejlmeddelelser, som kan vre svre at forst for programmren.I sammenligning med Rust nvnes det, at Gos nye implementering er magen til Rust, dog med visse forskelle, ssom at en trait i Rust, der benyttes som constraint, skal knyttes specifikt til en type.Der er mere information om Gos typeparametre i udkastet . Af kodeeksemplerne heri fremgr det, at den endelige syntaks endnu ikke er fastlagt.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2021-03-24
          &nbsp;&nbsp; e82eb4cc
          &nbsp;&nbsp; #12
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.984</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.679</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.633</kbd>
        </footer>
      </article>
      <article>
        <h4>PRM / Hvordan bliver computeren en retfrdig superhelt? Aka lidt om fairness i maskinlring</h4>
        <div>
          KbenhavnPressemeddelelse fra Alexandra InstituttetEller knap s hjtflyvende, s giver denne blogpost en introduktion til begreberne &quot;fairness&quot; og &quot;bias&quot; i maskinlring. For den danske oversttelses skyld vil vi benytte ordet &amp;lsquo,skvhed' i stedet for &amp;lsquo,bias'. Vi kan tnke p det som en form for uhensigtsmssighed, som er skadelig i form af uretfrdige fordomme eller behandlinger af enkelte personer eller grupper. En af frontfigurerne p plakaten er Kate Crawford, som holdt en keynote-tale om emnet p NIPS 2017 (konference om Neural Information Processing Systems), og i sin definition af begrebet skelner hun mellem uhensigtsmssigheder i form af allokering af ressourcer og muligheder, og uhensigtsmssighed i form af reprsentationer, som knytter sig til identitet og hvordan folk opfattes.Denne skelnen vil vi kmpe lidt videre med, hvorefter vi kigger p, hvordan skvheder opstr, definitioner p fairness, metoder til at undg det, og i tillg, da alle superhelte jo krver trning, vil vi hente superhero dataset fra Kaggle at ve os p.Nogle er mennesker, andre er kryptonians...... og atter andre tilhrer en helt tredje gruppe. Maskinlring kan bruges til beslutningssttte til fordelinger af ressourcer og muligheder, og her kan skvheder opst, hvis personer eller bestemte grupper bliver favoriseret eller diskrimineret. Eksempler p unskede skvheder er, hvis kreditvurderinger afhnger af race, eller hvis anbefalinger af jobansgninger afhnger af kn. I dette setup arbejdes der med skaldte &quot;beskyttede attributter&quot;, som angiver tilhrsforhold til en gruppe, som man nsker at beskytte, og traditionelt er der her kig p kn, race, nationalitet eller etnicitet. Mlet med fair maskinlring er s at sikre 'retfrdigheden' af modellerne, men hvordan dette overhovedet kan formaliseres, vil vi lfte masken for senere.I vores superhelte-datast fra Kaggle er der angivet navne p en rkke superhelte, deres egenskaber, en rkke personkarakteristikker ssom kn og race, samt hvorvidt superheltene er gode elle onde. I denne blogpost vil vi gerne prdiktere, om en superhelt er god eller ond, men det skal vre p en mde, som sikrer ligebehandling af knnene. Men igen, hvad vil det sige, eller sprgsmlet er nok snarere, hvad kan det sige?Fem eksempler fra datasttet, dog ikke alle superkfter er vist. Et 1-tal betyder at helten besidder kraften.Det er dragten...... som giver superhelten identitet. Den anden form for skvhed, som defineret af Kate Crawford, gr p, hvordan vi reprsenter folk. Hvordan folk fremstilles, kan have en problematisk indflydelse p, hvordan vi i sidste ende opfatter bestemte grupper. Ofte fremhvede eksempler i debatten, til at vkke harme, var, da Google Photo taggede en afroamerikansk kvinde som gorilla, (se her), eller at der er knsstereotyper i mden, ord reprsenteres p i Natural Language Proessing (Se mit blogindlg om word embeddings), eller tilflde hvor ansigtsgenkendelse virker drligere p mrk hud end lys hud. Et andet eksempler er fra 2015, hvor en google-sgning p CEO, resulterede hovedsageligt i billeder af hvide mnd i slips, og hvor det frste billede af en kvinde, 10 rkker nede, var en Barbiedukke udkldt som CEO (se her). Superhelte-branchen er mske ikke just selv det gode eksempel p en fair knsfordeling og reprsentation - s hvorfor, og hvornr, handler de her ting overhovedet om maskinlring?Hvordan kommer vi i Justice League...... med vores maskinlringsmodeller? Det grundlggende problem ved eksemplerne ovenover er teknisk set ikke, at modellerne indimellem fejler, som ved klassificeringer af en kvinde som en gorilla, men at systemerne her reproducerer og automatiserer en skvhed og diskrimination, som allerede er til stede i samfundet eller som er historisk, som fx racisme mod afroamerikanerne. Det er derfor, at eksemplet med den afroamerikanske kvinde bliver s slende. I det andet eksempel med sgningen p CEO problematiserer Kate Crawford, hvad et fair resultat i givet fald ville vre, skal sgningen vise den aktuelle fordeling af kn og etnicitet p folk, der besidder en CEO-post, eller skal den vise den fordeling, som folk synes er fair? Hvordan mennesker bliver klassificeret og reprsenteret, er ikke blot et maskinlrings-problem, men et samfundsproblem, og svaret p hvad en fair model er, gr derfor ogs udover det tekniske i at fjerne skvheder fra modellerne til ogs at vre et etisk, kulturelt og politisk sprgsml. Og svaret p, hvad der er fair, er i sig selv tidsligt og kulturelt bestemt - og vil ndre sig igen over tid.Her fler man sig mske fanget i spindelvvet. Men selvom der ikke er noget entydigt svar p, hvad en fair model er, er det vigtig at opbygge viden og forstelse for, hvorledes uhensigtsmssigheder kan vre til stede, hvorfor de opstr, og hvordan de kan hndteres for at sikre, at maskinlring forbliver et anvendeligt vrktj. Disse ting vil vi introduktionsvis tage hul p i de nste paragrafer.Det er data, der er skurken!Ofte, nr vi prver at finde rsager til skvheder i maskinlringsmodeller, skal vi kigge i trningsdata. Disse skvheder kan vre forskyldt af kulturelle eller historiske grunde, men det kan ogs vre mere p grund af uvidenhed eller fejl. Det kan da nvnes, at skvheder ogs kan opst fra valg af algoritme, da man kan forstille sig, at reprsentation for n gruppe er svrere at lre for en type algoritme end for en anden. Nogle af de potentiale rsager til, hvorfor skvheder opstr i data, er listet herunder, men du kan ogs lse mere om det i fx denne blogpost.Overstende liste giver et begyndende billede af, hvordan unskede skvheder kan opst i data og nedarves til modeller, s lad os nu kort se p teknikker til at forholde os til det.Vben vi kan forsvare os medDet kan vre en udfordring i sig selv at opdage og stadfste unskede skvheder alt efter rsagen til skvheder, og metoderne er forskellige alt efter, om der er tale om den mere klassiske allokeringsproblematik eller reprsentationsproblematikken. Der findes en hr af metrikker til at mle unskede skvheder p i data eller modeller (se lidt lngere nede). Der findes ligeledes en hr af metoder til at forsge at fjerne eller minimere skvheder i data og modeller alt efter typerne. Overordnet set kan metoder til at prve at mindske skvheder inddeles i algoritmer, der forsger1) at fjerne skvheder i data fr selve trningen,2) at fjerne under trning ved reguleringsteknikker eller3) at fjerne efter modellen er trnet.Det kan anbefales at tjekke kampudstyr ud p IBM's open source tool AI Fairness 360 , hvor flere af de nyeste metoder er implementeret. Et eksempel p et paper, som prver at stadfste og fjerne en reprsentativ skvhed i word embeddings er Bolukbasi et al. (2016). Et eksempel p gngse metrikker inden for klassifikationsmodeller vil vi gennemg og diskutere nedenfor, men frst skal vi en tur p trningsbane og endelig have os en model p superhelte-datasttet.P trningsbanenSuperhelte-datasttet er brugt til at trne en binr klassifikationsmodel, som ud fra en rkke features kan prdiktere, om en superhelt er, ja, en helt eller en skurk, i vores simple verden, god eller ond. Featuresene der er brugt, indbefatter navne, hjde, vgt og hvilke superkrfter de har (der er defineret 667 forskellige superkrfter), og som model til dette legeeksempel vil vi blot benytte logistik regression. 33% af datasttet er taget ud til testst, hvilket giver 203 eksempler er teste p. P dette testst opns der en accuracy p 0.71, og en makro F1 p 0.61. Til sammenligning er det vrd at bemrke, at datasttet er ubalanceret i forhold til god/ond, s hvis vi blot laver et gt p den mest frekvente klasse, kan vi opn en baseline accuracy p 0.65, men med 0.39 i F1. Lad os prve et eksempel af p vores model og opfinde en superhelt. Vi kalder ham &quot;Super Transparent Goble&quot; og giver ham flgende fire superkrfter: Latern Power Ring, Agility, Dimensional Awarness og Speed Force. Derudover giver vi ham lidt substans i form af en hjde og en vgt i pund.En opdigtet superhelt vi kan bede modellen klassificereModellen prdikterer, at han er god!Lad os lege, at vi vil anvende modellen som drmand p en natklub, og det er kun dem, vi tror, der er skurke, vi vil lukke ind til festen (vi gider jo ikke en alt for kedeligt fest!). Det positive udfald, som superheltene hber p, er da at blive klassificeret som skurk. Men vi nsker en fair model i forhold til kvindelige og mandlige superhelte, men hvad kan det sige?Definition af superkrfter...... eller definition af forskellige fairness-kriterier. Gajane and Pechenizkliy 2018 har gennemget, hvordan fairness i maskinlring kan blive formuleret matematisk, samt forestet sammenligninger af definitionerne med dem i socialvidenskaben p styrker og svagheder. Overordnet inddeler de kriterierne i seks overordnede grupper. For at give et billede af hvor mange definitioner der allerede findes, kan det nvnes, at IBM i deres open source tool AI Fairness 360, har implementeret mere end 70 metrikker. Men metrikkerne er ikke alle kompatible med hinanden - og s er der hele sprgsmlet om, hvorvidt restriktionen af fairness koster en p njagtighed for modellen. Nedenfor er der listet nogle forskellige grupper af definitioner (Gajane and Pechenizkliy 2018 ), og enkelte metrikker fremhves for at bne diskussionen om fordele og ulemper:1) Fairness igennem uvidenhed. En model, som ikke betinger p den 'beskyttede' attribut, opfylder dette kriterium. I vores superhelte-klassifikationsmodel er kn-variablen taget ud inden trning af modellen, hvilket vinger dette fairness-kriterium af som opfyldt! Desuden kan det bemrkes, at trning med eller uden informationen om knnet ikke ndrer p performance, i vores tilflde. Men bemrk nogle ulemper ved dette kriterium, informationen om den beskyttede attribut kan ligge latent i de andre features. F.eks. i vores superhelte-tilflde kan knnet ligge latent i de andre variabler, man kunne fx forestille sig at hjde, vgt, og selve navnene kunne give et prg om knnet.2) Gruppefairness. Herunder hrer en af de tidligere anvendte kriterier, 'Demographic Parity&quot;, som krver, at en klassifikationsmodel skal prdiktere et bestemt udfald med lige stor sandsynlighed uafhngigt af den beskyttede gruppevariabel. I superhelte-modellen kan vi udregne sandsynligheden for at blive klassificeret som skurk (positiv rate) for hhv. kvinder og mnd ved at se p konfusionmetrikken:Konfussionmatricer opdelt p kvinder og mndFor kvinder er sandsynligheden for at blive klassificeret som skurk 9% (5/55), hvorimod der for mnd er 15.5% (23/148) chance for det. Modellen opfylder alts ikke dette kriterium. Her kan man jo s restringere systemet til at opfylde kriteriet, men som blandt andet ppeget i Hardt et. al 2016 har det nogle benlyse ulemper, da det kan fre til scenariet, hvor rigtige skurke i den ene gruppe bliver afvist i dren, og modsat: at rigtige helte i den anden gruppe bliver lukket ind (husk: vi vil kun have skurke med til festen). Dette scenarium kan opst, hvis der fx er lidt trningsdata i den ene gruppe, eller det faktum at det at tilhre en bestemt gruppe faktisk er korreleret med udfaldet. Hvis vi kigger p knsfordelingsplottet, kan vi se, at en mindre procentdel af kvindelige superhelte faktisk er 'rigtige' skurke, hvilket kan vre en labelbias, men det kan ogs bare vre 'sdan det er'. En fordel ved at bruge dette ml for fairness kan vre, hvis man bevidst nsker at ndre en skvhed i samfundet, fx ved bevidst at optage en vis procentsats fra en bestemt baggrund p en uddannelse, fx kvinder p superheltetrningsakademiet, selvom de er mindre kvalificerede, men s veje op for det ved desuden at lave en rkke tiltag for at lfte nivauet af ondhed.3) Equality of opportunity. Denne metrik blev frst introduceret i Hardt et. al 2016, som et svar til nogle af problemerne med 'Demographic parity'. Her gr kravet p, at den positive klassificering br vre uafhngig af den beskyttede klasse, givet at udfaldet faktisk er 'positivt'. S i superhelte-eksemplet kan vi ud fra konfusionmatricerne udregne &amp;lsquo,true positive'-raten. For kvinder bliver det (tp/(tp+fn)) 30% af dem, som rigtigt er skurke, som ogs bliver klassificeret som sdanne. For mandegruppen er dette tal 29%, hvilket vil sige, at forskellen er lille, og vi i praksis vil kunne sige, at modellen opfylder kriteriet for en fair model, s tillykke! Dette kriterium er mest anvendeligt, nr der er strst fokus p at klassificere det positive udfald korrekt, mod at man til gengld ikke opfatter falske positive som omkostningstunge. Ellers kan man anvende metrikken 'Equalized odds', som i tillg ogs krver en lighed i falsk/positiv-raten.4) Prference-baseret fairness. Kriteriet er introduceret af Zafar et. al 2017 og prver at adresse nogle af ulemperne ved overstende metrikker, ssom at de er inkompatible og kan forrsage fald i njagtighed at opfylde. Her opstilles i stedet kriteriet, at hver gruppe i princippet har hver sin model, som de skal have prference for, sledes at skiftet over til den anden gruppes model ikke er gavnligt. Dette giver plads til at forbedre performance inden for hver gruppe.5) Individuel fairness. En model er fair, hvis den forudsiger det samme udfald for lignede personer/tilflde.6) Counterfactual measures. Se fx Kusner et. al 2018 .Superhelte-datasttet indeholder ogs information om race, men der er defineret 61 forskellige racer med alt fra Mutant til Cyborg, og desvrre mangler oplysningen for 40% af vores helte, s vi vil undlade at lave analysen, men blot bemrke flgende: Det at sikre en fair model for 'kvinder' vs. 'mnd' og for 'Mutanter' vs. 'Mennesker' er ikke det samme som, at vi har sikret, at modellen ikke er diskriminerende mod 'kvindelige mutanter'.Der er altid et twist...... der snyder superhelten &amp;frac34, inde i filmen. Nogle af twistene og flderne ved fair maskinlring bliver ogs debatteret i litteraturen, blandt andet i Liu et. al 2018, som viser, hvordan fair maskinlring, fx ved brug af demographic parity eller equalized odds, kan have en forsinket negativ indflydelse p de grupper, som den prver at beskytte. Ligeledes ser D'Amour et. al 2020 fra dette rs FAT* konference (Fairness, Accountability, and Transparency) p, hvordan langtidseffekterne kan modelleres ved hjlp af simulationer. Derudover kan Selbst et. al 2018 nvnes, som har fokus p de &quot;flder&quot;, som eksisterer rundt om fair maskinlring. Et eksempel er, hvis modellen bliver fulgt p en skv mde. Det kunne tnkes, i vores superhelte-eksempel, at drmanden ikke flger modellens anbefalinger nr s ofte for det ene kn som for det andet. Til sidst kan Grfic-Hlaca et. al 2018 nvnes, som stter sprgsmlstegn ved, om fokus kun br vre p skaldte beskyttede attributter, eller om folks opfattelse af, hvad der er fair, ikke i lige s hj grad gr p, hvilke informationer modellen bruger i forskellige sammenhnge. F.eks. kunne det mske opfattes som unfair, at vores superhelte-model faktisk benytter information om vgt for at afgre, om jeg er en skurk, der m komme ind til en festen eller ej.To be continued...Som i de fleste superhelte-film, lgger det op til en 2'er, for selvom fokus p fair maskinlring har vret voldsomt stigende de seneste r, er feltet langt fra i ml, og som diskuteret er mange af sprgsmlene nogle, der ikke kun skal lses teknisk - men i hj grad ogs etisk.ReferencerBolukbasi, T., Chang, K. W., Zou, J. Y., Saligrama, V., &amp; Kalai, A. T. (2016). Man is to computer programmer as woman is to homemaker? debiasing word embeddings. In Advances in neural information processing systems (pp. 4349-4357).D'Amour, A., Srinivasan, H., Atwood, J., Baljekar, P., Sculley, D., &amp; Halpern, Y. (2020, January). Fairness is not static: deeper understanding of long term fairness via simulation studies. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (pp. 525-534).Gajane, P., &amp; Pechenizkiy, M. (2017). On formalizing fairness in prediction with machine learning. arXiv preprint arXiv:1710.03184.Grgi?-Hlaa, N., Zafar, M. B., Gummadi, K. P., &amp; Weller, A. (2018, April). Beyond distributive fairness in algorithmic decision making: Feature selection for procedurally fair learning. In Thirty-Second AAAI Conference on Artificial Intelligence.Hardt, M., Price, E., &amp; Srebro, N. (2016). Equality of opportunity in supervised learning. In Advances in neural information processing systems (pp. 3315-3323).Kusner, M. J., Loftus, J., Russell, C., &amp; Silva, R. (2017). Counterfactual fairness. In Advances in Neural Information Processing Systems (pp. 4066-4076).Liu, L. T., Dean, S., Rolf, E., Simchowitz, M., &amp; Hardt, M. (2018). Delayed impact of fair machine learning. arXiv preprint arXiv:1803.04383.Selbst, A. D., Boyd, D., Friedler, S. A., Venkatasubramanian, S., &amp; Vertesi, J. (2019, January). Fairness and abstraction in sociotechnical systems. In Proceedings of the Conference on Fairness, Accountability, and Transparency (pp. 59-68).Zafar, M. B., Valera, I., Rodriguez, M., Gummadi, K., &amp; Weller, A. (2017). From parity to preference-based notions of fairness in classification. In Advances in Neural Information Processing Systems (pp. 229-239).Kontakt:Communications Specialist Lisa Lorentzen tlf.: +45 93 52 17 64 email: lisa.lorentzen@alexandra.dkLs hele pressemeddelelsen p Via Ritzau her: https://via.ritzau.dk/pressemeddelelse/hvordan-bliver-computeren-en-retfaerdig-superhelt-aka-lidt-om-fairness-i-maskinlaering?releaseId=13593237** Ovenstende pressemeddelelse er videreformidlet af Ritzau p vegne af tredjepart. Ritzau er derfor ikke ansvarlig for indholdet ** 
        </div>
        <footer>
          <em>Ritzaus Bureau</em>
          &nbsp;&nbsp; 2020-05-13
          &nbsp;&nbsp; e7b4b97e
          &nbsp;&nbsp; #13
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.994</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.638</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.596</kbd>
        </footer>
      </article>
      <article>
        <h4>PRM / Rapport: Bitdefender er 'Leader' inden for sikkerhedslsninger til virtuelle miljer</h4>
        <div>
          KbenhavnPressemeddelelse fra BitdefenderBukarest, Rumnien, 10. december, 2019 - Analysevirksomheden Forrester peger i en ny rapport p Bitdefender som en af de frende virksomheder inden for Cloud Workload Security (CWS). Det er konklusionen i rapporten &quot;The Forrester Wave&amp;trade,: Cloud Workload Security (CWS), Q4 2019&quot;, der blev udgivet i dag. Ud af 13 evaluerede CWS-udbydere er Bitdefender udpeget som n af blot tre frende virksomheder i rapporten. Rangeringen er baseret p 30 stringente kriterier til vurdering af forhandlernes produkter, strategi og tilstedevrelse i markedet. Iflge Forrester-rapporten udmrker Bitdefender sig i kategorierne &amp;lsquo,Database', &amp;lsquo,User' og &amp;lsquo,Agent Rollout Management': &quot;Med sin erfaring inden for teknologi til malware-, memory- og hypervisor-beskyttelse, formr Bitdefender at skabe en bred CWS-lsning [...] Lsningen passer til virksomheder, der har et srligt behov for kapacitet til styring af hypervisorer i hybride cloud-miljer,&quot; skriver Forrester i rapporten.Topscorer i tre kategorierDet er srligt inden for kategorierne &amp;lsquo,Security Capabilities', &amp;lsquo,Management Simplicity and Usability', og &amp;lsquo,Strategy' at Bitdefender skiller sig ud, hvor virksomheden scorer topkarakterer p en lang rkke kriterier:Security Capabilities: Bitdefender scorer topkarakterer p kriterierne &amp;lsquo,beskyttelse af workloads p operativsystemniveau', &amp;lsquo,skalrbarhed: beskyttede hypervisorer' og &amp;lsquo,beskyttelse af hypervisorer'. Iflge Bitdefender selv skyldes det Bitdefenders specialtilpassede software til detektering af trusler, HyperDetect, der er baseret p machine learning, samt andre unikke egenskaber der er gjort mulige med Bitdefender Hypervisor Introspection.Management simplicity and usability: De hje scorer i kategorien blev opnet p kriterierne &amp;lsquo,opstning, konfiguration og dataintegration', &amp;lsquo,kontekstafhngig hjlp' og &amp;lsquo,navigering, integreret milj'. Bitdefenders omfattende kapaciteter inden for konfigurering og opstning af back-end dataopbevaring, mekanismer til masseudrulning, konfigurerbar malwarebeskyttelse og kontrol over binr privilegie-eskalering er, iflge Bitdefender, rsag til de hje karakterer.Strategi: Bitdefenders hje karakterer i kategorien blev opnet med udgangspunkt i kriterierne &amp;lsquo,tjenesteydelser og partnere' og &amp;lsquo,beskyttelsesplaner til hypervisorer'. Det er iflge Bitdefender grundet virksomhedens planer om at udvide antallet af lsninger i GravityZones Software-as-a-Service version, de forbedrede muligheder for at opdage og reagere p angreb p Linux-systemer og udgivelsen af beskyttelsesmoduler til containere.Rapporten slr ogs fast, at Bitdefenders lsninger tilbyder vrdifuld hypervisor-introspektion og en god API-baseret hndtering af regler svel som konfigurerbare dashboards. Bitdefender har integrations-partnerskaber med frende hybride cloud-platforme, herunder AWS, Azure, Pivotal, VMware, Nutanix og Citrix.&quot;Vi tror p, at denne anerkendelse validerer skarpsindigheden i Bitdefenders strategiske vision og styrke af virksomhedens CWS-ydelser,&quot; fortller Gavin Hill, Vice President, Datacenter and Network Security hos Bitdefender. &quot;Bitdefenders lsningers sikkerhedsegenskaber, simple hndtering og unikke beskyttelse p hypervisor-niveau hjlper virksomheder og regeringer verden over med at beskytte servere og virtuelle desktops, ligegyldigt hvor de opererer.&quot;For at modtage en kopi af rapporten, besg https://businessresources.bitdefender.com/forrester-wave-cloud-workload-security-2019For at lre mere om Bitdefenders teknologi til beskyttelse af cloud workloads, besg https://www.bitdefender.com/business/enterprise-products/virtualization-security.html eller https://www.bitdefender.com/business/enterprise-products/hypervisor-introspection.html.Kontakt:Daniel Mlgaard Jensen
Konsulent
Frontpage PR og Kommunikation
+45 28 40 89 62
daniel.molgaard@frontpage.dkLs hele pressemeddelelsen p Via Ritzau her: https://via.ritzau.dk/pressemeddelelse/rapport-bitdefender-er-leader-inden-for-sikkerhedslosninger-til-virtuelle-miljoer?releaseId=13584716
        </div>
        <footer>
          <em>Ritzaus Bureau</em>
          &nbsp;&nbsp; 2019-12-10
          &nbsp;&nbsp; e77c1b8f
          &nbsp;&nbsp; #14
          <br>
          <br>
            <kbd data-tooltip="Tech industry &amp; regulation">L02_BIGTEC&nbsp;0.676</kbd>
            <kbd data-tooltip="DK business &amp; innovation policies">L05_DKINNO&nbsp;0.511</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.527</kbd>
        </footer>
      </article>
      <article>
        <h4>Sdan tuner vi vores machine learning-algoritme, der finder emneord</h4>
        <div>
          Med optimeringer kan vi presse lidt flere procents succes ud af vores algoritme, der gtter emneord ud fra en nyskrevet Version2-artikel. Men kan det bruges det til noget?P Version2 har vi talt om muligheden for at finde emneord med maskinlring. Et emneord er et ord, der beskriver en artikels emne, ssom Databeskyttelsesloven, Sundheds-it, GDPR, Java, Ledelse, eller hvad det nu kunne vre.I en tidligere artikel satte vi handling bag snakken: Med den klassiske algoritme Naive Bayes fra 1960'erne, skabte vi en metode til at gtte p emneord. Nr emnet var sundheds-it, kunne algoritmen finde 7 af 12 artikler om emnet, ud af 297 test-artikler. Der var 5, den ikke kunne finde, og den pegede ikke galt.Det regnede vi om til fire procent-tal mellem nul og hundrede:Precision - hvor tit gttede algoritmen 'sundheds-it'rigtigt?Recall - hvor stor procentdel af sundheds-it-artiklerne fandt den?Accuracy - trfsikkerhedF1 - et slags gennemsnit af precision og recall, som kan bruges til at optimere algoritmen med.Vi havde super-god precision p 100%, men vores recall var 58%, s der var en del, den ikke fandt.Men hvad er egentlig -godt- i sdan en algoritme? Som vi var inde p i sidste artikel, handler det om anvendelsen.Prven fandt ikke fatal hjertefejlHvis det drejer sig om en medicinsk prve, vil vi vre tilbjelige til at acceptere flere falske positive, hvis det kan nedstte antallet af falske negative, hvor en farlig tilstand hos patienten mske bliver overset.I vores tilflde, hvor algoritmen skal komme med forslag til emneord, hvorefter journalisterne selv bestemmer, om de vil flge forslaget eller ej, virker en ligelig vgtning af precision og recall som en god ide. Vi nsker mange pletskud og vil ogs ramme en stor del af sundheds-it-artiklerne. Derfor er f1-mlet, som er et (harmonisk) gennemsnit af precision og recall, det rigtige ml for os.Men hvad var det nu, vi skulle bruge det hele til?Vi vil gerne have, at algoritmen skal foresl emner til en ny, frisklavet artikel. Det krver, at algoritmen rent faktisk giver et bud. Hvis eksempelvis precision er 100% og recall 10%, s kommer der kun et bud hver tiende gang, selvom den gtter helt rigtigt i teststtet.I tilfldet med sundheds-it vil vi godt give kb p precision, hvis vi kan kan f hjere recall. Til den opgave benytter vi som sagt f1-mlet, der vgter sol og vind - precision og recall - ligeligt.Laplace smoothing revisitedI sidste artikel byggede vi de centrale ord-estimater, logPHat, med denne formel, hvor hyppighedstabellen er optllingen af ordenes hyppighed i artikler om sundheds-it:for (ord in hyppighedstabel):logPHat = log((hyppighedstabel(ord) + 1)/ (antalOrdISundhedsItKlassen + antalUnikkeOrdIAlleArtikler) ) sundhedsItEstimatTabel.put(ord, logPHat)'+ 1'i tlleren og'+ antalUnikkeOrdIAlleArtikler' i nvneren var en mde at kompensere for det forhold, at vi mske stder p ord i teststtet, som ikke optrder i trningssttet.Teknikken kaldes som nvnt i forrige artikler for Laplace smoothing, men argumentationen bag siger i og for sig ikke, at det lige prcis skal vre 1, der lgges til. Vi modificerer nu formlen, s det ekstra bidrag er et komma-tal k. Det ser sdan ud:for (ord in hyppighedstabel):logPHat = log((hyppighedstabel(ord) + k)/ (antalOrdISundhedsItKlassen+ k * antalUnikkeOrdIAlleArtikler) ) sundhedsItEstimatTabel.put(ord, logPHat)Nu har vi en fri parameter -k-, som vi kan bruge til at tune algoritmen.Vi skal ogs ndre testalgoritmen tilsvarende. Den ser nu sdan:sundhedsItLogEstimat = log(artiklerOmSundhedsIt / antalArtikler) for (ord in artikel):logPHat = sundhedsItEstimatTabel.get(ord) if (logPHat == null):logPHat = log(k / (antalOrdISundhedsItKlassen+ k * antalUnikkeOrdIAlleArtikler) ) sundhedsItLogEstimat += logPHatVi krer nu vores emneord igennem algoritmen ligesom sidst, men varierer k fra 0,1 til 2,0 i sm skridt. Den vrdi af k, der giver hjest f1, har vundet.Ofte ender det med, at vi tuner for meget, s algoritmen forveksler teststtets ejendommeligheder med den virkelige verden, et fnomen, der kaldes -overfitting.-F-alfa mletF1-mlet findes ogs i en anden variant, med navnet F-alfa, hvor man kan vgte precision hjere end recall og vice versa:F_a = (1 + a^2) * (precision * recall) / (a^2 * precision + recall)F_0,5 lgger sledes mere vgt p precision, mens F_2 lgger mere vgt p recall.Derfor tester vi efter optimering p et nyt, uberrt testst. Det giver os et bud p, hvor realistisk en f1-vrdi vi kan forvente, nr vi slipper algoritmen ls i den virkelige verden.Det betyder, at vi nu har tre st af artikler: Vores trningsst, vores udviklingstestst (eller -devtestst-), og det endelige testst.Vi har ndret lidt i strrelsen af vores datast siden sidst, for at f plads til bde devtestst og testst.Det har sat vores resultat fra tidligere en smule tilbage, s vores eksempel fra sidst - sundheds-it - har nu f1 p 57% (og precision og recall p 80% og 44%.)Der er plads til forbedringer.Vi finder nu den optimale vrdi af laplace-parameteren k, som beskrevet ovenfor, og det giver for sundheds-it et f1-ml p 75%, med k = 0,3, p baggrund af devteststtet.Det var jo en knald-god forbedring, op fra de 57%, vi startede med - men har vi overfittet?Vi tester nu p vores uberrte testst - og s stter realismen ind:Her fr vi en f1 p kun 56%.I fortvivlelsens dal (p hype-kurven)For dlen da - det er lavere end i udgangspunktet.Det skyldes, at vi startede med devteststtet og derefter afprvede med teststtet. Tallene, der kommer ud af algoritmen, afhnger af, hvilket specifikt testst vi benytter, ogs selvom antallet af artikler er det samme i begge st.Gudskelov ser tingene lidt anderledes ud, hvis vi gr et skridt baglns og udregner f1 med k=1,0 og teststtet. Her fr vi en f1 p 50%, s tuningen med laplace-k'et gav os en realistisk forbedring p 6 procentpoint. Og det er vel vrd at tage med.Men tilbage til det oprindelige sprgsml: Kan det bruges til noget?De 56% i f1 er p baggrund af en precision p 47% og recall p 70%. Den gtter alts sundheds-it rigtigt omkring halvdelen af gangene, og finder 7 ud af 10 mulige.Hvad siger journalisterne?Jakob mener, det kan bruges. Magnus peger p, at det mest irriterende er falske negative, hvor algoritmen ikke kommer med bud p emnet, og at falske positive ikke er s problematisk - man kan jo bare lade vre med at bruge forslaget, hvis man synes, det lyder tosset.I den forstand klarer algoritmen opgaven med sundheds-it meget godt, ved at afdkke omkring 70% af artiklerne, som handler om sundheds-it.Udover laplace-k'et er der ogs andre muligheder for at optimere. Sagkundskaben fortller, at netop med artikler, kan det vre en god ide at tlle ord i overskrifter to gange, nr hyppighederne opgres, da disse ord i hjere grad afspejler indholdet.Andre muligheder er at udplukke devteststtet lbende over hele artikelmngden, og derefter udregne gennemsnitlige logPhat-vrdier. Den teknik skulle isr vre god, hvis man ikke har for mange artikler eller dokumenter at rutte med.Not a numberEn lille parentes: Nogle gange fr vi resultatet -NaN-, not a number, ved udregningen. Det udskifter vi blot med 0 procent, der i vores lsning betyder -maksimalt skidt resultat.-I en kommende artikel implementerer vi algoritmen i Version2's CMS-system. Lige nu er planen at benytte en bookmarklet (og det var Jakobs ide, skal det siges.) Det bliver ikke lige forelbigt, men bliv p kanalen.Se resultater og download kodenResultaterne kan ses i regnearket her.Det ville fylde for meget at gengive den Java-kode, vi har brugt i artiklen. S den kan downloades her (Google Drive kan sige nogle fjollede ting undervejs, men bare tryk 'download.').Eksemplet indeholder de samme datast, der gennemgs her i artiklen. Ligesom sidst er ordene i artiklerne er randomiseret. Algoritmen er ligeglad med rkkeflgen af ordene, s det gr ingen forskel for eksemplet.Koden er skrevet s eksemplet er nemt at forst og er ikke optimeret. Der er et par hardcodede filstier, der kan tilrettes, hvis der er bvl. Det er kommenteret i kildeteksten.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2018-04-10
          &nbsp;&nbsp; e6b29320
          &nbsp;&nbsp; #15
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.927</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.947</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.613</kbd>
        </footer>
      </article>
      <article>
        <h4>Tjept statistiksprog runder version 1.0</h4>
        <div>
          P ganske f r har det helt friske sprog Julia fundet sig en strre fanskare. Da sproget kom til verden i 2012, var det nsket om at forene egenskaber fra en rkke andre sprog.Det skulle have en hastighed som C, dynamiske sprogfeatures som i Ruby, makroer som Lisp og velkendt matematisk notation som i Matlab, vidtrkkende anvendelsesomrder som med Python, statistiske faciliteter som i R og tekstbehandling som i Perl.Samtidig skulle sproget have en open source-licens, vre nemt at lre og have interaktive muligheder.Noget kunne tyde p at den ambitise mlstning er lykkedes, for selv om Julia stadig er et ganske lille sprog i udbredelse, med en halvtredsneplads p popularitetsindekset Tiobe, s fr sproget meget omtale.Julia har netop rundet versionsnummeret 1.0, der markerer sprogets udtrden af barndommen og ind i de voksne sprogs rkker.Det er isr Julias ydelse, som giver sproget fortrin i forhold til de mere eller mindre fortolkede sprog som R og Python.Hvis du er matematiker, videnskabsmand eller ingenir, har du historisk haft mulighed for at vlge et sprog, der var hurtigt, som C ++ eller Java, eller et sprog der er nemt at lre, som Matlab, R eller Python. I Julia skabte vi et sprog, der var hurtigt og nemt, har en af sprogets bagmand, Viral Shah, udtalt til mediet Quartz.Han fortller, at ngleinspirationen til at udvikle Julia var at se, hvordan mange mennesker mtte skrive det samme program to gange: Dataforskere vil frst bruge et vrktj som Python eller R til at udvikle en algoritme, fordi det gr det nemt at udforske dataene og lave diagrammer p disse sprog.Nr forskerne var tilfredse med algoritmen, skulle de s omskrive programmet i C ++ eller Java for at f effektiv ydelse. Julia er hurtigere end Python og R, fordi sproget er specielt designet til hurtigt at gennemfre den grundlggende matematik, som benyttes i datavidenskab, s som matrixudtryk og liner algebra.# calculates x for 0 = a x^2+b x+c, arguments types can be defined in function definitions function quadratic2(a::Float64, b::Float64, c::Float64)# unlike other languages 2a is equivalent to 2*a# a^2 is used instead of a**2 or pow(a,2) sqr_term = sqrt(b^2-4a*c) r1 = quadratic(a, sqr_term, b) r2 = quadratic(a, -sqr_term, b)# multiple values can be returned from a function using tuples# if the return keyword is omitted, the last term is returned r1, r2 endEt simpelt eksempel p Julia, fra Julia By Example.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2018-08-23
          &nbsp;&nbsp; e6de83cb
          &nbsp;&nbsp; #16
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.99</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.512</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.546</kbd>
        </footer>
      </article>
      <article>
        <h4>Forklaringer som vejen til bedre modeller</h4>
        <div>
            Forklaringer skaber ikke bare gennemsigtighed, men kan ogs bruges til at forbedre modellen, skriver Katrine Hommelhoff Jensen. Nr vi taler om forklarlig kunstig intelligens, s er omdrejningspunktet tit, hvordan vi fr forklaret computerens beslutningsproces, s alle kan forst det. Det er dog ikke kun i teknologiens mde med slutbrugeren, at forklaringer har vrdi. Nr vi udvikler ny teknologi, kan forklaringer illustrere, hvordan en model vgter data i sin beslutning, og herunder hvad der mske vgtes uhensigtsmssigt. Vil du have fuld adgang til DataTech? DataTech skriver til dig, der arbejder professionelt med data og analytics. Vi giver dig inspirerende cases, nyheder og debat om alt fra Machine Learning-modeller til dataetik. Har du allerede et abonnement? Log ind Er dit prveabonnement udlbet? Kb
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2020-08-25
          &nbsp;&nbsp; e7da23a6
          &nbsp;&nbsp; #17
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.81</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.783</kbd>
        </footer>
      </article>
      <article>
        <h4>Debat P tide at ndre matematik p A-niveau i gymnasiet</h4>
        <div>
          I FORLNGELSE AF diskussionen om det nye it-fag p ungdomsuddannelserne, mener jeg, at det er p tide at genoverveje indholdet af matematikundervisningen i gymnasiet.HVIS MAN SER P bekendtgrelsen, er kernestoffet for matematik p A-niveau klart forberedende til naturvidenskabelige ( i den brede forstand, der ogs omfatter medicin, farmaci, veterinrvidenskab osv.) og tekniske uddannelser. Bortset fra et enkelt punkt om matematiske modeller er der ikke noget, der er direkte brugbart til it-fag som f. eks. datalogi.Der er masser, der er brugbart til anvendelser af it men ikke til forstelse af data som begreb. Et udpluk fra bekendtgrelsen indeholder blandt andet: LINERE differentialligninger af 1. orden og logistiske differentialligninger, kvalitativ analyse af givne differentialligninger samt opstilling af simple differentialligninger PRINCIPIELLE egenskaber ved matematiske modeller, modellering.JEG VIL IKKE BORTKASTE alt det naturvidenskabsforberedende indhold, men jeg overvejer, om nogle af de mere perifere emner ikke kunne erstattes af noget, der er mere relevant for it-fag men ogs brugbart inden for andre fag. Et oplagt emne til at udg er efter min mening differentialligninger.Videregende uddannelser, der bruger differentialligninger, vil alligevel gennemg emnet, da dkningen i gymnasiet normalt ikke er tilstrkkelig, og det er tvivlsomt, hvor alment dannende emnet er.EN SIMPEL LSNING p erstatningsstof kunne vre en udvidelse af stoffet om matematiske modeller med stof om datamodellering. Men for at komme s langt skal man frst have indfrt begrebet data, dets brug i modeller og modellernes forhold til virkeligheden som erstatning for differentialligninger i matematik A. Man kunne ogs s smt begynde p emnet allerede p niveau C og B.INDHOLDET AF EMNET kunne f. eks. vre: EN BIT som den mindste dataenhed og tolkningen af en bit som en sandhedsvrdi.Logiske operatorer som bitvise operatorer.BINRE TAL som eksempel p reprsentation af information som en sekvens af bits. Addition og multiplikation af binre tal.MDER AT sammenstte data p: Par, sekvenser, multimngder, mngder og disjunkt forening. Simple binre reprsentationer af disse. Eksempler: Koordinater ( par), binre tal og tegnflger ( sekvens), mleresultater ( multimngde), valgfag ( mngde), fugl eller fisk ( disjunkt forening).MDER AT analysere data p baseret p dennes opbygning: Elementvis analyse af par, sekvenser, mngder og multimngder samt forgrening ved disjunkt forening. Kombination af delresultater til samlet resultat.DATAMODELLERS FORHOLD til virkelighed: Diskretisering og mleunjagtighed.Akkumuleret unjagtighed ved lngere beregninger. Konsekvenser for datamodellers plidelighed.BEMRK, at der ikke indgr egentlig programmering eller algoritmer.  &gt; &gt; Forkortet -ls hele indlgget og deltag i debatten p ing. dk/ k# 8rn2.
        </div>
        <footer>
          <em>Ingeniren</em>
          &nbsp;&nbsp; 2011-02-18
          &nbsp;&nbsp; e27de5d4
          &nbsp;&nbsp; #18
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.905</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.861</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.613</kbd>
        </footer>
      </article>
      <article>
        <h4>Deep learning p grafer: Succeser, udfordringer og nste skridt</h4>
        <div>
            Forsker-miljet har indtil for nylig nsten ignoreret skalerbarhed, nr det kommer til udvikling af graph neural networks. Deep learning p grafer, ogs kendt som Geometrisk deep learning (GDL) [1], Graph representation learning (GRL), eller relational inductive biases [2], er for nylig blevet et af de hotteste emner inden for machine learning. Mens det tidlige arbejde med graph learning gr mindst et rti tilbage [3] hvis ikke to [4], er det utvivlsomt de seneste rs fremskridt, der har taget disse metoder ud af nichen og ind i rampelyset i ML-miljet og endda til den populrvidenskabelig presse (Quanta Magazine har krt en rkke fremragende artikler om geometrisk deep learning til blandt andet opdagelse af lgemidler). Grafer er kraftige matematiske abstraktioner, der kan beskrive komplekse systemer af relationer og interaktioner inden for omrder, der spnder fra biologi og hjenergifysik til samfundsvidenskab og konomi. Da mngden af graf-strukturerede data, der produceres i nogle af disse felter i dag, er enorm (prominente eksempler er sociale netvrk som Twitter og Facebook), er det meget fristende at forsge at anvende deep learning, der har vret bemrkelsesvrdigt succesfulde i andre datarige sammenhnge. Graph learning Der er flere varianter til graph learning-problemer, der stort set er afhngige af applikationen. n dikotomi er mellem node- og graf-mssige problemer, hvor man i den frstnvnte forsger at forudsige egenskaber ved individuelle noder i grafen (f.eks. at identificere ondsindede brugere i et socialt netvrk), mens man i den sidstnvnte forsger at forudsige noget om hele grafen (for eksempel forudsige oplselighed af et molekyle). Ligesom i traditionelle ML-problemer kan vi desuden skelne mellem superviseret og usuperviseret (eller selv-superviseret) lring. Ligesom med convolutional neural networks, der bruges i billedanalyse og computer vision, ligger nglen til effektiv lring p grafer i designet af lokale operationer med delte vgte, der sender meddelelser [5] mellem hver node og dets naboer. En vsentlig forskel sammenlignet med klassiske, dybe neurale netvrk, der beskftiger sig med gitter-struktureret data, er, at sdanne operationer p grafer er permutations-invariant , dvs. uafhngig af rkkeflgen af nabo-noder, da der normalt ikke er nogen kanonisk mde at strukturere dem p. Drlig kode og manglende benchmark P trods af, hvor lovende grafer er, og en rkke succeshistorier om graph learning (blandt hvilke jeg selvisk kan liste Twitters opkb af Fabula AI , som jeg har grundlagt sammen med mine studerende), har vi indtil videre ikke set noget bare tt p den knusende succes, CNN har haft inden for computer vision. I det flgende vil jeg forsge at skitsere min vurdering af de mulige rsager, og hvordan feltet kunne udvikle sig i de nste par r. Standardiserede benchmarks som ImageNet var helt sikkert en af de vigtigste succesfaktorer for deep learning inden for computer vision. Nogle [6] argumenterer endda for, at data har vret vigtigere end algoritmer for deep learning-revolutionen. I graph learning-miljet har vi endnu intet, der ligner ImageNet i skala og kompleksitet. Open Graph Benchmark , der blev lanceret i 2019, er mske det frste forsg p introducere udfordrende graph learning-opgaver p interessante graph-data fra den virkelige verden. En af forhindringerne er, at teknologiselskaber, der producerer rige graf-databaser over deres brugers aktivitet, er tilbageholdende med at dele disse data p grund af bekymring over lovgivning som f.eks. GDPR. En bemrkelsesvrdig undtagelse er Twitter, der stillede et datast p 160 millioner tweets med tilsvarende graf over brugerengagement til rdighed for forskere under visse privacy-begrnsninger som en del af RecSys Challenge . Jeg hber, at mange virksomheder flger trop i fremtiden. Softwarebiblioteker, der er offentligt tilgngelige, spillede en vigtig rolle i at &quot;demokratisere&quot; deep learning og gre det til et populrt vrktj. Indtil for nyligt har implementeringer af graph learning primrt vret en samling af drligt skrevet og nppe testet kode. Men i dag findes biblioteker ssom PyTorch Geometric eller Deep Graph Library (DGL) , som er professionelt skrevne og vedligeholdes ved hjlp af sponsorater fra branchen. Det er ikke ualmindeligt at se en implementering af en ny graph deep learning-arkitektur uger efter, at den publiceres p arxiv. Skalering er forsmt Skalerbarhed er en af de vigtigste faktorer, der begrnser industrielle applikationer. Her er man ofte ndt til at hndtere meget store grafer (tnk p Twitters sociale netvrk med hundreder af millioner noder og milliarder af relationer) med lav latency. Det akademiske forsker-milj har indtil for nylig nsten ignoreret dette aspekt, og mange modeller, der er beskrevet i litteraturen, er fuldstndigt utilstrkkelige i stor skala. Desuden er grafikhardware (GPU), hvis lykkelige gteskab med klassiske deep learning-arkitekturer har vret en af de primre krfter, der driver deres flles succes, ikke ndvendigvis bedst egnet til graf-strukturerede data. I det lange lb har vi muligvis brug for specialiseret hardware til grafer [7]. Dynamiske grafer er et andet aspekt, der er sparsomt behandlet i litteraturen. Mens grafer er en almindelig mde at modellere komplekse systemer p, er en abstraktion ofte for forenklet, da systemer i den virkelige verden er dynamiske og udvikler sig over tid. Sommetider er det netop opfrsel over tid, der giver afgrende indsigt om systemet. P trods af nogle nye fremskridt er design af graph neural networks, der er i stand til effektivt at hndtere tid, reprsenteret som en strm af node- eller relationsmssige begivenheder, stadig et bent forskningssprgsml. Teoretisk forstelse af ekspressiviteten i graph neural networks er temmelig begrnset. Det er almindeligt at se graph neural networks give et stort performance-boost i n sammenhng, og gre nsten ingen forskel i andre. Det er endnu ikke helt klart, hvornr og hvorfor graph neural networks fungerer godt eller mislykkes. Problemet er vanskeligt, fordi man skal medtage bde strukturen i den underliggende graf samt data i den. Et andet interessant og stort set uberrt forskningsfelt er, hvordan man sikrer robusthed og garanteret performance i graph neural networks af der udsttes for stjende data eller for adversarial attacks [9]. Kan fundamentalt ndre medicinalindustrien Den mest tilfredsstillende del af feltet er anvendelsen. Efter at have arbejdet med graph learning i mange r nu, er jeg blevet venner med partikelfysikere [10], klinikere [11], biologer og kemikere [12] - mennesker, som jeg sandsynligvis ikke ville mde, hvis vi ikke havde arbejdet med applikationer inden for deres respektive omrder. Hvis jeg skulle satse p bare et felt, hvor graph deep learning kunne f den strste indflydelse i de nste par r, ville jeg pege p biologi og kemi. I disse felter kan graf-baserede modeller bruges bde som lavniveau-modeller til molekyler [5] svel som modeller p hjt niveau af interaktioner mellem dem [13,11]. Kombination af disse kan vre nglen til at komme til et niveau, hvor teknikken ville vre nyttig for medicinalindustrien. Vi ser indledende tegn p dette med neurale netvrk, der tidligere i r blev brugt til at opdage en ny klasse af antibiotika [14] eller til at forudsige interaktioner mellem proteiner [12]. Hvis vi kan indfrie lftet fra graph deep learning, ser den meget lange og forblffende dyre proces med at opdage, udvikle og teste nye lgemidler mske aldrig ud p samme mde igen. En version af denne artikel er oprindeligt bragt p Medium. Ls flere indlg her
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2020-08-18
          &nbsp;&nbsp; e7d77549
          &nbsp;&nbsp; #19
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.889</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.796</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.602</kbd>
        </footer>
      </article>
      <article>
        <h4>Her er nyhederne i Python 3.10: Match er en ren schweizerkniv</h4>
        <div>
          For anden gang udkommer Python efter en ny rlig udgivelsesplan. Den store nyhed for det hidtil switch-lse sprog er en ny match-stning, der kan lidt af hvert.Med 30 r p bagen har programmeringssproget Python kronede dage. P lister over sprogs popularitet ligger Python enten i toppen eller tt pPython er get fra at vre et scripting-sprog med lav indlringskurve, til at vre et af de foretrukne sprog til videnskabelig programmering, statistik, dataanalyse og kunstig intelligens.Ligesom i Javascript kan man i Python gre nsten, hvad man har lyst til p krselstidspunktet, ssom at udstyre objekter med nye felter og metoder. Det stter begrnsninger p afviklingshastigheden.Den danske ekspert i virtuelle maskiner Lars Bak vurderer, at sprog som Python og Javascript kan opn omkring halvdelen af den ydelse som typestrke sprog, der ogs afvikles i en virtuel maskine, ssom Java og C#, kan prstere.Men der er flere mder at gre tingene p. Det er nemt at kalde C-kode fra Python, og mange Python-biblioteker er implementeret i C, som gr dem lynhurtige.Nr det handler om kunstig intelligens, matricer og vektorer, kan biblioteker udnytte grafikkort, som er mange gange hurtigere, end nr tilsvarende operationer skal udfres p cpu-kerner, p grund af parallelisering af linere vektorberegninger.P den mde kan Python-koden blive et slags instrumenteringslag for de underliggende hjtydende biblioteker, med en nem syntaks, der tillader lidt af hvert og sjldent stiller sig i vejen for programmren.Match er en schweizerkniv-switchEn ny version er tt p af se dagens lys. Den har nummeret 3.10, og er den anden udgave efter en ny udsendelsesplan, hvor der kommer nye versioner n gang om ret.Blandt nyhederne er pattern matching, som ogs Java og PHP for nylig er blevet udstyret med. Pattern matching stammer fra de funktionelle sprog, og trenden blandt objektorienterede sprog er netop at lne ideer fra den funktionelle verden.Python har aldrig tidligere haft en switch -stning, s det er funklende nyt, og den nye konstruktion er en ren schweizerkniv, i forhold til hvilke mnstre stningen kan hndtere.P det overordnede plan ser det sledes ud, med eksempler taget fra dokumentationen:match subject:casecasecasecase _:P klassisk Python-maner kan en masse forskellige ting anvendes som argument i case-stningerne. Mnstrene kan best af sequences, mappings, primitive datatyper samt klasse-instanser.Et simpelt eksempel kan se sdan ud:def http_error(status):match status:case 400:case :case :case _:Case-stninger kan ogs indeholde variable:Og med klasse-instanser:Lister kan ogs anvendes som argument til case-stningen:Man kan ogs bruge underscore-wildcard'et p en mere kompleks facon:Men der er mere, som de siger i TV-shoppen:Man kan ogs udstyre case-stningen med en ' guard ', ogs kendt som en 'precondition', ved at stte en if -stning efter case-udtrykket:Og der er endda flere muligheder med match-stningen, end hvad vi har vist her.Nemmere unionsPython er et sprog, hvor variabeltyper ikke gr det store vsen af sig. Men lidt type-information p en sidetallerken er nu heller ikke drligt. I Python 3.5 kom muligheden for at antyde typerLigesom i den nye PHP er der nu en nem mde at angive, at en variabel eller parameter kan antage n af to eller flere typer, i stedet for den gamle mde, Union[int, float] , at gre det p:Context managers er stningskonstruktion, hvor ressourcer som eksempelvis fil-handlers kan deallokeres p en robust facon, uden at programmren skal benytte try-finally eller andre tiltag. Det svarer til Java og C#'s try-with-resources og using , og nyheden er, at man kan have flere context managers i samme blok, som i:Blandt andre nyheder er forbedrede fejlmeddelelser, som i dette eksempel:- hvor fortolkeren fr i tiden blot ville have sagt SyntaxError: invalid syntax og peget p starten af den efterflgende stning.SyntaxError har i det hele taget fet en lang rkke specialiserede meddelelser, s det bliver nemmere at finde ud af, hvad der er galt.Der er flere nyheder i den nye version, som er frste beta af fire, fr den endelige udgave udsendes i starten af september i r. Beta-versionen kan testes p Windows og Mac, mens andre dyr selv m kompilere kildekoden. Links til det hele kan findes i udgivelsesnoterne
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2021-05-12
          &nbsp;&nbsp; e842dfa8
          &nbsp;&nbsp; #20
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.952</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.651</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.697</kbd>
        </footer>
      </article>
      <article>
        <h4>Mathematical Analysis and Linear Algebra</h4>
        <div>
          F tilsendt alle informationer om kurset, herunder kursus sted, udbyder mm. p emailMathematical Analysis and Linear AlgebraKurset dkker to omrder af matematikken: liner algebra og analyse af funktioner i mange variable. Liner algebra er centralt i studiet af matricer som bruges til at reprsentere mange forskellige ting, herunder systemer af linere ligninger, transformationer af rum og probabilistiske systemer. Ligesom mange af de interne operationer i sgemaskiner er baseret p matricer. Ved at studere den matematiske teori om matricer vil vi lre vrktjer, der har en rkke anvendelsesomrder. Som et eksempel ser vi p PageRank algoritmen, som Googles sgemaskiner bruger til at rangere websider p basis af. P kurset udvides teorien om matematisk analyse ogs til funktioner af mange variabler. Analyse af funktioner med mange variable er teorien bag metoder, der bruges i kunstig intelligens, business intelligence, fysik og konomi.Formlet med kurset er sledes at forst den matematiske teori godt nok til at forst, hvorfor metoderne inden for et anvendelsesomrde virker og bruge den matematiske teori til at tilpasse eksisterende metoder og skabe nye. Med andre ord er mlet ikke at den studerende blot skal kunne anvende metoder og indstte i formler, men snarere forklare, hvorfor metoderne virker. Kurset foregr p engelsk og udbydes p kandidatuddannelsen: Software Development.Formelle forudstninger:Please note! Changes to this course description may occur until start of the spring semester 2017.Lringsml:After the course the student should be able to:- Use nummerical methods such as Newton's method and Taylor series, and explain the theory behind them.- Reflect on the applicability of a given numerical method to a given problem.- Compute the derivatives of curves and surfaces, explain the geometric interpretation of these, and apply them to solving a wide range of mathematical problems including optimisation problems.- Compute double integrals and explain their geometric interpretation.- Compute the essential constructions of basic linear algebra including inverse matrices, eigenvectors and eigenvalues, matrix diagonalisation, the dimensions and bases of the four fundamental subspaces and determinants of square matrices, and explain the theory behind these constructions.- Explain the use of linear algebra in applications such as solutions to linear equations, the method of least squares and the theory of the PageRank algorithm. Discuss the relevance of the theoretical results proved in the course for these applications.Fagligt indhold:This is a course in mathematics covering linear algebra and analysis of functions in many variables. These are perhaps the two areas of mathematics that have found most uses in practical applications.Linear algebra is essentially the study of matrices, i.e., rectangular arrays of numbers. Matrices are used to represent many different things, including systems of linear equations, transformations of space (such as rotations or reflections as used in computer graphics) and probabilistic systems. Likewise, many of the internal operations in search engines are essentially operations on matrices. By studying the mathematical theory of matrices we will learn tools that are useful for all of these application areas. As an example application we look at the PageRank algorithm used in Google's search machines to rank webpages for importance.Mathematical analysis (or calculus) is the study of the derivative and the integral of real valued functions as taught in high school, but in this course we extend the theory to functions of many variables returning vectors of real numbers. Just like the single variable case, one of the main applications is to solve optimization problems, which in real life are of many variables. This is the theory underlying many methods in artificial intelligence, but it is also important in many other areas including image analysis, business intelligence, physics and economics.While the topics taught have been chosen for their applicability, the focus of the course will be on the mathematics. The aim is to understand the theory well enough that we can understand why the methods in the application areas work, and even use the mathematical theory to adapt existing methods or create new ones. In other words, the aim is not that the student should simply be able to use methods and insert into formulas, but rather explain why the methods work and reflect on the theory presented. For this reason the course has an oral exam.Lringsaktiviteter:14 ugers undervisning bestende af forelsninger og velser14 weeks of teaching consisting of lectures and exercises. The exercise sessions will train the students oral presentation skills, and so students are expected to prepare for the exercise sessions. The mandatory exercises will mainly ask the students for written solutions to theoretical exercises, but will also include a few implementation exercises.Obligatoriske aktivititer: There are 6 mandatory assignments, out of which 5 must be approved for the student to qualify for the exam.The deadlines are evenly distributed over the semester (approximately one every 2 weeks), exact dates will be posted on learnit the first week of the semester.If a mandatory assignment is not approved the first time, the student will be allowed to resubmit exactly one week after the first deadline.If this also fails, one more resubmission the following week is allowed.Be aware: The student will receive the grade NA (not approved) at the ordinary exam, if the mandatory activities are not approved and the student will use an exam attemptEksamensform og -beskrivelse:B1I Mundtlig eksamen med forberedelse. P ITU, (7-scale, external exam)Oral examination with time for preparation at the exam.Duration: 30 minutes preparation at ITU and 30 minutes oral examination.The student draws a question and has 30 minutes preparation before 30 minutes oral examination.Litteratur udover forskningsartikler:- Gilbert Strang: Introduction to Linear algebra, 4th edition- David Guichard: Multivariable calculus, early transcendentals- Kurt Bryan and Tanya Leise: The $25,000,000,000 eigenvector, the linear algebra behind Google.
        </div>
        <footer>
          <em>Ing.dk (Ingeniren)</em>
          &nbsp;&nbsp; 2016-12-13
          &nbsp;&nbsp; e60653dd
          &nbsp;&nbsp; #21
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.99</kbd>
            <kbd data-tooltip="AI &amp; innovation">L05_INNOAI&nbsp;0.887</kbd>
            <kbd data-tooltip="In English">L80_ENLANG&nbsp;0.773</kbd>
        </footer>
      </article>
      <article>
        <h4>En algoritmes sang om geder og sidste r med Python 2</h4>
        <div>
          Organisationen har dog frigjort en forsimplet version af algoritmen GPT-2, som er reduceret til beskedne 117 millioner parametre, sammenlignet med originalens 1,5 milliarder parametre.Denne model har Ars Technica afprvet og dbt GPT-2 Junior, og resultatet er ikke ligefrem angstfremkaldende i forhold til maskinskrevet fake news.I en test gr algoritmen fra at tale om handelsaftaler mellem Kina og USA til noget, som Ars Technica selv beskriver som en anmeldelse af en anime. Et andet eksempel gr fra at handle om topmdet med Nordkorea til at diskutere hestedrab:It sounds like you may have a great idea for killing a horse, maybe even in your own horse or some combination of the two. Det mest mystiske resultat fr mediet dog ved at fodre algoritmen med en stump tale fra Donald Trump, hvilket prompte returnerede en sang om geder:FADE InGOAT DICK IN THE BOY T-HAULUSGOAT DICK IN THE BOY T-HULUSGOAT DICK-IN-THE-BOY BOYGREAT BOYGREAT-GOAT-GOAT-GOAT-GOAT-GOAT-GOAT-GOAT-GOAT-GOAT-GOAT- GOAT Selv om testen er morsom, er bekymringen om GPT-2's evne til at sprede falsk information begrundet, skriver Ars Technica.Both the fully realized GPT-2 and GPT-2 Jr. are generalized models. A much more convincing &quot;deep fake&quot; text bot with a more narrow focus could be constructed using similar techniques. Trningsmaterialet til GPT-2 kommer fra Reddit. Hvilket mske til dels forklarer nogle af de tankespring modellen laver.Oversete favoritterI Reddits forum om data science har brugere undladt at skrive sange om geder og i stedet delt deres mindre kendte favorit Python-pakker.Her anbefaler en bruger blandt andet boto og boto3 til forbindelser til AWS, samt pytest til test af data science-koden. En anden bruger fremhver tqdm, der giver en progress bar som viser, hvordan model-trningen skrider frem.En tredje bruger fremhver pakken shap, der kan bruges til at forklare, hvordan komplekse modeller kommer frem til deres resultat. DataTech har tidligere skrevet om teknikken her.Se hele trden her.Farvel til Python 22019 bliver sidste r, hvor den sidste version af Python 2 - 2.7 - bliver vedligeholdt. Det kan have omfattende konsekvenser for selskaber, der stadig har store kodebaser i Python 2. De har nu 10 mneder til at migrere over til Python 3.You have a number of choices for migrating from Python 2 to Python 3, skriver selskabet Active State i en guide.The recommended course of action is to modernize incrementally in order to address failures progressively, rather than being overwhelmed by the task/errors all at once. E.g. over multiple releases of your application. Python Software Foundation har selv lavet en omfattende guide til Python-migrering.Python 3 lser problemerPython 2's primre problem er, at det blev skabt inden Unicode-standarden blev frdig - og derfor ikke flger standarden fuldstndig, skriver Active State. Det giver to problemer. Dels at versionen ikke fungerer til kodning i ikke-romanske sprog, og dels at Python 2 bruger en datatype, der ikke klart adskille tekstdata fra binr data. Dette leder ofte til bugs, noterer selskabet.Python 3 resolves the two key issues with Python 2 by basing the default core string type on Unicode. This is a big gain for Python programmers because it eliminates the text/binary confusion and enables multilingual programming. Mens mange har udskudt overgangen til Python 3 pga af manglende understttelse fra biblioteker, s burde det problem vre lst i de fleste tilflde, 94 procent af de 360 mest downloadede pakker understtter Python 3.Dansk AI-startup kbt og 'tmt'af AppleDet danske selskab Spektral Experience har siden 2017 arbejdet p avanceret billede behandling af live video. Teknologien gjorde selskabet i stand til at skre en person ud af en video og indstte den i et andet stykke video - alt sammen i realtid.Iflge Finans er Spektral Experience dog ikke lngere eksisterende. Selskabet blev kbt af Apple i 2017 og i lbet af sidste r er selskabet tmt for bde personer, patenter, projekter og viden. Selskabets immaterielle rettigheder er blevet solgt for 181 millioner kroner, hvilket ikke er s langt for den originale salgspris p over 200 millioner, skriver Finans.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2019-03-01
          &nbsp;&nbsp; e7197256
          &nbsp;&nbsp; #22
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.684</kbd>
            <kbd data-tooltip="AI &amp; innovation">L05_INNOAI&nbsp;0.509</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.518</kbd>
        </footer>
      </article>
      <article>
        <h4>I klasse med Kierkegaard eller historien om det fede ved at en computer kan finde ordklasser</h4>
        <div>
          Vi er tilbage i skolen og sidder i en danskklasse med bde Sren Kierkegaard og en computer som klassekammerater, og vi skal lre lidt om ordklasser. Vi skal se om et samarbejde mellem Kierkegaard og computerens evne til at finde ordklasser kan hjlpe os med at lse Kierkegaard uden at lse, og til at forst det fede ved at finde ordklasser uden at skulle &quot;stte 'en' eller 'et' foran&quot; frst. Eller med lidt andre ord, handler dette blogindlg om en machine-learning-model, der automatisk kan detektere ordklasser og om hvad dette kan bruges til eksemplificeret igennem Sren Kierkegaards vrk Enten - Eller fra 1843. Men fr vi gr rigtig i gang, skal vi have computeren p skolebnken til at lre at tagge ordklasser i en tekst. Natural language understanding kan overordnet set inddeles i syntaktisk og semantisk analyse. At tagge ordklasser i en tekst hrer til den syntaktiske del, og i den engelske litteratur benvnes denne task som 'Part of Speech'-tagging, eller forkortet bare POS. Hvor mange gange skal jeg sige det, Computer  fr du kan genkende ordklasser? Nogle af os vil mske kunne huske, at vi, tilbage i folkeskolen, har fet det at vide mange gange, hvad forskellen er p et udsagnsord og et navneord. Mske hnger der stadig lidt regler fast om, at et navneord er dem man kan stte 'en' eller 'et' foran, udsagnsord dem med 'at' eller 'jeg'. Eller mske har vi bare fet vist nok eksempler p navneord, at vi nu kan genkende dem og endda generalisere den viden til nr vi ser nye ord? At automatisere det at kategorisere ordklasser i en stning, vil mske kunne gres regelbaseret, eller blot som et stort opslagsvrk? Og dog, et opslagsvrk, vil ikke kunne tage hjde for, at ord der staves ens kan have forskellige ordklasser alt efter sammenhngen i stningen, ej heller at nogle ordklasser er bne, hvilket vil sige, at der med tiden kommer nye ord til i denne kategori, som fx ved navneord. Ikke desto mindre, er denne blog omkring NLP, og vi vil derfor tage en datadrevet tilgang, hvor computeren vil blive vist en mngde eksempler p stninger og tilhrende ordklasser, som den vil lre at generalisere ud fra. Dette kaldes for supervised learning. I min tidligere blogpost &quot; Hvordan reprsenterer vi tekst, s en computer kan regne p det? &quot;, blev forskellige word emebddings introduceret, heribland FastText embeddings fra Bojanowski et al. 2017 og Flair embeddings fra Akbik et al. 2018 , som i DaNLP projektet er trnet p dansk data fra EuroParl og Wikipedia. Disse embeddings kan nu bruges til at trne en POS-tagger ved hjlp af modelarkitekturen beskrevet i Akbik et al. 2018 samt tilhrende implementation p Flairs GitHub Sekvenslabeling-arkitekturen er en CRF-BiLSTM. Overordnet set gives en stning som input til vores to word-embedding modeller, der for hvert ord producerer en vektorreprsentation ud. Disse reprsentationer gives som input til en Bi-LSTM model, som lber sekvensen af ord igennem bde forfra og bagfra, og producerer et output ud som gives til CRF modellen. Denne udregner sandsynligheden for hver POS-tag i stningen, givet de vrige tags i stningen. Pointen her er blot, at der tages hjde for de andre ord i stningen, nr der gttes p en ordklasse. Modellen lrer, det vil sige opdaterer sine parameter, ved at f at vide nr den gtter rigtig og forkert. Lidt lig os selv tilbage i klassen. S, dette krver noget opmrkeret data. Heldigvis findes et sdan dataset open source: Danish Dependecy Treebank (DDT) . De danske part-of-speech-tags stammer fra et projekt ved navn PAROLE-DK, et dataset bestende af 5512 stninger konverteret til 17 universal pos tags. Datasttet er inddelt i training-, development-, og testst med flgende split 4,383 / 564 / 565 og bestr af en blanding af tekst med blandt andet gamle nyhedsartikler. Testdelen ses ikke under trning, men bruges til at evaluere modellen p til sidst, og developmentsttet fungerer som en proxy for at guide trningen. Trningen er sat med et maksimum af 150 epochs, hvilket vil sige at modellen kan tygge sig igennem alle stningerne 150 gange, eller indtil det ved hjlp af developmentsttet vurderes at lringen ikke forbedres. Model er trnet n gang, hvor den stoppede efter 118 epochs - s computerne skal alts have hvert eneste eksempel p en stning, og hvilke ordklasser der er i stningen, gentaget 118 gange, fr den ikke lrer mere ved det. (I hvert fald i denne ene krsel). Det er nok alligevel lidt mange gange for en lrer at gentage det samme. Modellen opnede en njagtighed p teststtet p 97,14%. I forstelsen af denne njagtighed skal der tages hjde for at teststtet er forholdsvis lille, og at det ligner teksten i trningsdata, hvilket umiddelbart er forholdsvis grammatisk korrekt dansk. Med andre ord, nr vi anvender denne model p Sren Kierkegaards tekster, som er af ldre dato, med andre stavemder og ord, kender vi ikke hvor godt modellen generaliserer til dette nye data. Modellen kan findes p vores GitHub og i Python bibliotek danlp, og er ogs inkluderet i Flairs Python bibliotek. Her er et eksempel p dens anvendelse: I eksemplet ses det hvordan ordet 'under' bliver tagget hhv. som forholdsord og som biord efter sammenhngen i stningen, og at modellen korrekt tagger navnet 'Eremita', som et egennavn, selvom modellen ikke er stt p ordet under trningen. Men hvad er der s med de der fundene papirer? Vi har ikke s travlt at vi ikke skal introduceres ordentligt  til vores klassekammerat Sren for som han siger &quot;Af alle latterlige Ting forekommer det mig at vre det allerlatterligste at have travlt.&quot; Enten - Eller er et vrk fra 1843 skrevet af den danske teolog og filosof Sren Kierkegaard, men bogen er udgivet under pseudonymet Victor Eremita. Men denne angivne udgiver er dog ikke den angivne forfatter til vrket, men det er derimod tre andre personer. I forordet beskriver udgiveren, hvordan han er kommet i besiddelse af disse papirer ved at have fundet dem i et gammelt chatol, og dernst diskuterer han hvordan de bedste ordnes og udgives. Det bliver i to bind, hvor det frste bind indeholder livsnyderen A's papirer. Det nste bind indeholder pligtmennesket B's papirer, som bestr af breve til A, da &quot;A's livsstil er faldet B for brystet&quot;. Og til sidst er der ogs &quot;Forfrerens dagbog&quot;, som A siger ikke at vre forfatter til, men blot udgiver af, men ikke desto mindre klassificerer udgiveren Victor Eremita delen til at hre til frste bind. Det er enten A's papirer eller s er det B's papirer  eller s er begge dele skrevet af Kierkegaard (eller udgiveren der finder papirerne). Men selvom forfatteren skulle ske at vre den samme, er der s en syntaktisk forskel p de to dele, sledes at brugen af ordklasser er s forskellig, at man kun ved at se p ordklasserne kan afgre om en tekstbid tilhrer A's eller B's papirer? Nedenfor er et eksempel p sdan en tekstbid med ordklasser, og umiddelbart er det ikke til at afgre: Men kan listen af ordklasser vre input nok til at en machine-lrings-model kan afgre om en tekstbid kommer fra del A eller del B? Det vil vi prve at finde ud af. Overstende bid kommer i vrigt fra B's papirer, og den egentlige tekst ser sledes ud, og fra den korte introduktion til vrket, vil det mske vre nok til at vi ogs ville have gttet p B: P sks.dk ligger Kierkegaards vrk Enten Eller i xml-format til download. Den r tekst er udtrukket og splittet i stninger, hvorp den ny-trnede part-of-speech-tagger er anvendt. Derefter er der skabt en rkke 'tekstbidder' bestende af part-of-speech-tags ved at chunke 'stninger' sammen til en minimumstrrelse, nogenlunde som eksemplet ovenfor. Dette er gjort for bde A's papirer og B's papirer, hvorefter hver POS-sekvens har fet labelen hhv. A og B. I A's papirer er Indholdsfortegnelse og Forord fra del 1 undladt, men Forfrerens Dagbog er inkluderet, da det ogs var sdan udgiveren endte med at ordne papirerne. Med denne inddeling opns der 1938 eksempler for label A og 1617 eksempler for label B. Vi har at gre med et supervised problem, vi har 3555 datapunkter, her lister af pos-tags, med tilhrende annoteringer, nemlig fra del A eller del B. Og da vi nu alligevel befinder os tilbage i skolen, vil vi tage fat i en 'Good-old-Fashion' Logistic Regressions model til klassificering. Til at starte med, deler vi datasttet i en trnings- og en valideringsdel. Via trningssttet udregnes et nedre grnse p njagtighed, en skaldt dummy baseline, ved blot konstant at gtte p den hyppigste klasse, den tykkeste del af bogen om man vil. Dette giver en njagtighed p 54 %. Sekvensen af ordklasser er input til modellen, men de skal omformuleres til nogen tal som modellen kan regne p. Og for at kunne benytte en Logistic Regressions model, skal sekvensen af ordklasser reprsenteres med en vektor af en fast lngde. En skaldt feature vektor. En mde at lave en sdan simple reprsentation p, er ved blot at tlle antallet af gange hver pos-tag optrder i sekvensen, og s lave en feature vektor med 17 indgange svarende til hver tag. Dertil kan man ogs tlle antallet af gange, man ser en bestemt kombination af fx to og tre tags, og lade hver af disse kombinationer bliver reprsenteret ved en plads i feature vektoren. Lngden p feature vektoren bliver da en del lngere end de 17, da det ogs skal rumme de forskellige kombinationer - der medtages dog kun de kombinationer som faktisk er i trningseksemplerne, og det giver her en lngde p 2782. Nedenfor ses et eksempel p hvilke ti features, som reprsenter de 10 frste indgange, hvis det sorteres alfabetisk: Betragt da nedenstende inputeksempel, og tl da selv efter, hvis alts Regning ogs er dit yndlingsfag, at de frste 10 indgange i featurevektoren faktisk skal have de angivende vrdier for at reprsentere inputeksemplet: Denne mde at reprsentere input p gives til en Logistic Regressions model, og der opns en njagtighed p 71% p valideringssttet. Hvilket vil sige at 71% af gangene vi sprger modellen om en givet tekstbid af ordklasser (som den ikke har set under trning) kommer fra A eller B's papir rammer den rigtig. Dette er et stykke over blot at gtte p den mest hyppige klasse, men dog ikke en ren '12er'. Det er alligevel et resultat der indikerer, at der er en forskel i brugen af ordklasser mellem A's papirer og B's papirer. Logistic Regressions giver os mulighed for at undersge hvilke features, her 3-gram af ordklasser, der har vret mest betydende for udfaldet. Ved at tage koefficienter i modellen og vgte med standardafvigelsen for den tilhrende features, kan det udregnes hvilke get brug af forskellige typer af ordklasser og sm kombinationer, vil vre mest betydende for modellens udfald for den ene eller den anden klasse. For A's papirer er den mest betydende ordklasse for modellen egennavne, samt en hyppige brug af bde mdesudsagnsord og tillgsord er ogs karakteristisk for A's skrivemde. Top 5 over betydende features for A ser nemlig sledes ud: 'PROPN', 'AUX', 'ADJ', 'VERB PRON' og 'PRON VERB PRON'. B's skrivemde er derimod karakteristisk ved en hyppig brug af stedord og bindeord, da modellen vgter flgende 5 features som mest betydende 'PRON', 'CCONJ', 'DET', 'SCONJ', og 'DET ADJ'. Med andre ord er brugen af ordklasser til et vis grad forskellig i del 1 og del 2 af Kierkegaards Enten - Eller. Jeg gider slet ikke  er ogs et citat fra Kierkegaard - og rigtig klassificeret hrer det til i A's papirer, nrmere bestemt i Diapsalmeta. Og det er nok ogs en stning man kunne forstille sig at hre tilbage i klasselokalet. S i denne sektion vil vi se p om part-of-speech taggeren kan give os en lille genvej ind i Kierkegaards vrk, uden at starte med at lse fra side 1. Med taggeren kan teksterne i henholdsvis Del 1 og Del 2 lbes igennem for at udtrkke alle navneordene. Nedenunder ses de 45 mest hyppige navneord - eller i hvert fald hvad modellen har tagget som navneord. For at tydeliggre forskellen p hvad det er for nogle navneord der er karakteristisk for henholdsvis A og B's papirer, er der lavet en list med de 75 mest hyppige fra hver, og sttene er da trukket fra hinanden, s der har ses de navneord som er i top 75 for A men ikke for B: Og tilsvarende for B: S der kan hurtigt konkluderes, at begge dele handler om krlighed, liv, sjl, menneske og verden, men at del 1 med A's papirer udskiller sig fra B's ved at handle om musik, forestillinger, piger, hemmeligheder, lidenskab og andre flelser som smerte og sorg. Hvor imod B's papirer handler om Gud, ret og uret, gteskab og begreber som valg, pligt og frihed. Dette passer heldigvis meget godt med, hvad der str i forordet til Enten -Eller, men det er dog nppe nok til at overbevise en dansklrer om, at man har lst bogen - men mske er man blevet en lille smule klogere p NLP, og kan mske se andre tekster, hvor det kan vre relevant at udtrkke ord fra en bestemt ordklasse. Tak fordi du lste med.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2020-02-18
          &nbsp;&nbsp; e7951050
          &nbsp;&nbsp; #23
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.998</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.655</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.632</kbd>
        </footer>
      </article>
      <article>
        <h4>Vrktjskasse: Sdan koder du en browser-udvidelse i en ruf</h4>
        <div>
          Browser-udvidelser er sm programmer, der kan putte ny funktionalitet i browseren eller manipulere med indholdet af en webside eller webapp. Det skrives med HTML, Javascript og CSS, s det er lige ud af landevejen.I min browser, som er Firefox, har jeg eksempelvis en udvidelse, hvor jeg kan mrke tekst op med gult, og det bliver hngende til nste gang, jeg besger siden. Det er smart, nr jeg laver research, for s slipper jeg for at printe en masse papir ud. En anden udvidelse kan overstte til dansk, og s fremdeles.Her p Version2 har vi udviklet en algoritme, der finder emneord til nye artikler, og det fungerer ved at brugeren skal klikke p en bookmarklet.Men det ville nu vre smartere, hvis brugeren slap for at skulle klikke p bookmarkletten, og forslagene til emneord i stedet bare dukkede op af sig selv, nr brugeren bner dialogboksen hvor man vlger emneord.Og mon ikke der er en nem mde at lave en bookmarklet om til browser-udvidelse p? En sgning p nettet frer os til Sandbox.self.li, som kan det, vi leder efter - lave en bookmarklet om til en web-udvidelse.Vi gr, som der str skrevet - trkker vores bookmarklet fra tidligere over i vinduet, og klikker p knappen 'Generate extension.' Nu downloades en zip-fil. Vi pakker den ud, og s kommer disse filer til syne:background.js bookmarklet.js icon-128.png icon-16.png icon-48.png manifest.jsonVi gennemgr filerne senere. I frste skridt vil vi bare tjekke, at det rent faktisk virker. I Firefox indlser jeg udvidelsen ved at taste about:debugging i adresselinjen. Nu bnes en side, hvorfra jeg kan indlse en 'midlertidig' browserudvidelse, ved at klikke p knappen 'Indls midlertidig tilfjelse.'(I Chrome skal man benytte 'burger'-menuen Flere vrktjer &gt; Udvidelser, og s klikke p knappen Udviklertilstand verst til hjre. Derefter indlses mappen med extension-filerne med knappen 'Indls upakket' verst til venstre.)Nu dukker der en sort rund ikon op i browseren, som set herunder, verst til hjre p billedet:Nu bner jeg dialogboksen og klikker p det sorte ikon. S bliver emneordsforslagene markeret i dialogen. S det virker alts - men lige nu gr den njagtigt det samme som bookmarkletten, s der skal flere boller p suppen.Nste skridt er at skrive noget Javascript-kode, som henter emneord fra serveren p egen hnd, nr blot brugeren klikker p den knap, der fr dialogboksen frem. Knappen ser sdan ud:Den nemmeste fremgangsmde er nok bare at skjule knappen, og s tilfje en ny knap, der frst klikker p den skjulte knap, og derefter kalder vores script. Det ser sdan ud:var knapholder = document.querySelector(&quot;#edit-field-topic-da_chzn&quot;), var knap = knapholder.children[1], knap.style.visibility = 'hidden', var nyKnap = document.createElement('span'), nyKnap.innerHTML = &quot;&quot;, nyKnap.onclick = benDialog, knapholder.insertBefore(nyKnap, knap), function benDialog() { console.log(&quot;Enter benDialog&quot;), knap.click(), findEmneord(),}Ligesom i tidligere artikler har vi fundet en CSS-selector, der indeholder knappen. Vi navigerer frem til den i dokument-objektet med linjen knapholder.children[1]. S skjuler vi knappen ved at stte property'en style.visibility til 'hidden'. S er den vk.Vi tilfjer nu en knap, der er helt magen til den skjulte knap - men nr brugeren klikker p den, kaldes vores egen funktion benDialog. Den funktion klikker p den skjulte knap med knap.click og derefter kaldes findEmneord, der blot indeholder koden fra vores bookmarklet.Vi benytter Firefox' mini-IDE Kladdeblok til at teste koden med, som da vi udviklede bookmarkletten. Og koden virker minsandten.Content scripts og background scriptsS langt, s godt. Nu skal vi have udvidelsen til at afvikle koden, nr brugeren kommer ind p siden, alts nr siden loades i browseren.Browserudvidelser har to slags scripts: Content scripts, som afvikles i nogenlunde samme kontekst som den indlste webside, og background scripts, som afvikles i udvidelsens kontekst.Vores vrktj afvikler scriptet i vores bookmarklet med et background script, men vi vil alts loade koden, nr siden er indlst.Det gr vi ved at bne manifest-filen, som er et JSON-dokument. Vi sletter linjen&quot;background&quot;: {&quot;scripts&quot;: [&quot;background.js&quot;]}, - og tilfjer disse linjer:&quot;content_scripts&quot;: [{&quot;matches&quot;: [&quot;https://www.version2.dk/node/*/rediger&quot;], &quot;js&quot;: [&quot;content.js&quot;], &quot;run_at&quot;: &quot;document_idle&quot;}], JSON-koden siger, at content-scriptet skal ivrksttes p websider, der matcher url'en i 'matches'-nglen (og hvor stjerne betyder 'alle tegn'), at scriptet der skal afvikles befinder sig i filen content.js, og at det skal afvikles ved'document_idle', som er umiddelbart efter at hele websiden er indlst i browseren.Vi laver nu en ny tekstfil, som fr navnet content.js. I den indstter vi Javascript-koden ovenfor, som skjuler den rigtige knap og indstter vores egen knap. Nr der klikkes p den, kaldes funktionen findEmneord, som indeholder den kode, vi lavede i sidste artikel.Nu sletter vi filen background.js - den skal vi ikke bruge mere - og zipper resten af filerne til f.eks. EmneordsExtension.zip.Testing testing en to treS er det tid til at teste. Vi indlser udvidelsen p samme mde som fr. S bner vi en artikel i redigeringsmodus, klikker p knappen - og flux bliver emneordsforslagene malet op med gult. Vi har sparet verden for t udndvendigt museklik. Man bliver helt rrstrmsk p egne vegne.Vi prver ogs med Chrome, for det skulle jo helst vre platformsuafhngigt. Vi indlser vores udvidelse i Googles browser, og det virker bare. Dleme dejligt.Firefox har glimrende vrktjer til udvikling af Javascript-kode i en extension. Ved at vlge Debug-fanen og klikke p 'content.js' under fanen 'Kilder' til venstre, bringes content-scriptet frem, og man kan indstte breakpoints og evaluere udtryk. Det kan vre smart, hvis koden ikke spiller.Et kodeeksempel kan downloades fra Google Drive (som kan sige nogle fjollede ting undervejs, men bare tryk 'download' - og det fylder stadig for meget til Gitlab.)Udvidelsen i download-eksemplet virker dog ikke i Firefox - p trods af, at den 'rigtige' udgave, som er syet sammen med vores cms, fungerer upklageligt. Faktisk kan jeg slet ikke f en udvidelse til bare det mindste i Firefox, hvis den skal afvikles sammen med en lokal side - som i 'localhost' eller '127.0.0.1.'Debuggeren siger, at browseren ikke kunne indlse en 'blob,'et binrt objekt, men det passer ikke rigtigt p min situation. Nr domnet hedder 'version2.dk' gr det fint, s mske er det noget sikkerhedsmssigt. Jeg skal ikke kunne sige det. Men prv i stedet med Chrome.Nr serveren er oppe og kre, via det medflgende batch-script, kan en testside tilgs med url'en: https://localhost:8000/apps/emneord/test - hvor man kan indstte tekst fra en Version2-artikel og f bud p emneord ved hjlp af browserudvidelsen, som ogs flger med download-eksemplet.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2018-09-27
          &nbsp;&nbsp; e6e9e4e4
          &nbsp;&nbsp; #24
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.993</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.558</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.62</kbd>
        </footer>
      </article>
      <article>
        <h4>Forskere: Stack Overflow-svar fyldt med hullet Java-kode</h4>
        <div>
          Der kan vre grund til varsomhed i forhold til kode, der handler om Java og sikkerhed p Stack Overflow.Nste gang du mere eller mindre copy/paster et eksempel fra kodeforummet Stack Overflow, s kan det mske vre en god id at granske koden en ekstra gang. I hvert fald hvis det handler om sikkerhed og Java.Forskere fra Virginia Tech har sledes beget en rapport.Det oplyser The Register, der har set p rapporten. Forskerne peger p, at mange udviklere ikke forstr sikkerhed i tilstrkkelig grad til at implementere det godt nok. Og i den forbindelse mener de, at overkomplicerede API'er, Spring-sikkerhedsframeworket til Java og andre biblioteker frer til frustrationer og fejl.Forskerne har gennemtrawlet 497 kodesvar fra Stack Overflow i forhold til Java og sikkerhed. Her var der flere sikkerheds-problemer forbundet med svarene.Blandt andet var der accepterede svar, der anbefaler MD5 og SHA-1 som krypto-algoritmer. Som flere lsere vil vide er det en drlig id.Der var ogs accepterede Stack Overflow-svar, der anbefaler udviklere at stole p alle SSL/TLS-certifikater for at komme fejl til livs i forbindelse med verifikation af certifikater.SpringHvad Spring-frameworket angr, s var der Stack Overflow-rd, der i forbindelse med implementering af autentifikation i Spring anbefalede at sl Cross-Site Request Forgery-checks fra.I det hele taget har forskerne ikke ret meget til overs for Spring, bemrker The Register.55 procent af de Java-sikkerhedssvar, forskerne har set p, var relateret til Spring, som forskerne mener, er undigt kompliceret og drligt dokumenteret.We provided substantial empirical evidences showing that APIs in Spring security (designed for enterprise security applications) are overly complicated and poorly documented, and error reports from runtime systems cause confusion, str der i forskernes rapport. (PDF)Og s peger forskerne ogs p et mere platforms-orienteret problem i relation til Stack Overflow. Et svar fra en person med en hj omdmme-score (eng. reputation score) har en tendens til at blive godkendt, selvom det er forkert, p bekostning af mere korrekte svar fra personer med en lavere omdmme-score.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2017-10-03
          &nbsp;&nbsp; e6715185
          &nbsp;&nbsp; #25
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.899</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.849</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.678</kbd>
        </footer>
      </article>
      <article>
        <h4>AI under corona: Systemer, der ville have vret utnkelige for et r siden, bliver hastet igennem</h4>
        <div>
          De britiske myndigheder hasteimplementerede i sommers et tvivlsomt AI-system i skolerne, der endte med at g ud over karaktererne for elever fra socialt belastede omrder, mens algoritmen hjalp elever fra privatskoler. Corona-pandemien har demonstreret behovet for AI-regulering, mener hollandsk AI-ekspert Catelijne Muller.
        </div>
        <footer>
          <em>Pro.ing.dk/Gridtech</em>
          &nbsp;&nbsp; 2021-05-13
          &nbsp;&nbsp; e8435e6e
          &nbsp;&nbsp; #26
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.744</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.798</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.523</kbd>
        </footer>
      </article>
      <article>
        <h4>V2 amok i skygge-it: Bookmarklet-SSL-server p netvrket med hjemmelavet certifikat</h4>
        <div>
          P Version2 er vi godt i gang med at automatisere valget af emneord til nye artikler, i hvert fald i den grad, som vores machine learning-algoritme Naive Bayes kan levere varen.I sidste artikel fik vi optimeret algoritmen og pressede seks ekstra procentpoint ud af algoritmen, i hvert fald nr emneordet var 'sundheds-it.'I mellemtiden har vi forbedret algoritmen lidt mere, ved at tlle overskrifter to gange, som vi ogs var inde p i sidste artikel. Vi prvede ogs at tilfje artiklernes forfatternavne, men det trak en anelse ned i forudsigelserne - s det droppede vi igen. Version2's journalister er benbart ikke fagidioter, kan man mske konkludere, eller s har der vret mange forskellige igennem i renes lb.Nu er tiden kommet til at prve det hele i virkeligheden, og se, om det egentlig kan bruges af dem, som det er tiltnkt - Version2's journalister.Vi vil implementere emneords-algoritmen i Version2's CMS-system som en bookmarklet - en stump Javascript, der kan placeres i et link i et browser-bookmark. S slipper vi for at overbevise webudviklerne om, at de skal smide vores tossede kode ind i deres system, og samtidigt er det nemmere end at lave en browser-extension.Det er det rene skygge-it. Men den slags kan jo ogs have sin charme, indenfor rimelighedens grnser, alts.Vores 'user story'lyder sdan her:Journalisten har en ny, frdigskrevet artikel ben i redigerings-modus i CMS'et, og klikker p bookmarkletten i browserens bogmrkelinje. Derved sender bookmarkletten overskrifter og artikeltekst til serveren via et ajax-kald. Machine learning-algoritmen gr sit arbejde og returnerer bud p emneord til bookmarkletten, som derefter opmrker emneordene i CMS'ets dialogboks med gul baggrundsfarve. S kan journalisten bruge forslagene eller ej, ved at stte et flueben i en krydsboks - sdan som det ser ud i illustrationen i toppen af denne artikel.Vi strikker et hjemmelavet certifikatVores CMS krer HTTPS, naturligvis, og reglen for bookmarklets er, som med eksterne scripts i almindelighed, at man ikke kan blande krypterede og ukrypterede kilder.Vi skal med andre ord stte en HTTPS-server op, som forsyner vores bookmarklet med bud p emneord.Vi har ikke brug for stor server og det konfigureringsbesvr, der ofte flger med. HTTP-serveren vi benytter her, er en lille n, der flger med Javas udviklingsmilj (JDK), men som ikke er officielt en del af klassebibliotekerne (JRE). Den befinder sig dog i et 'jdk'-modul, og der dermed et velsignet medlem af JDK'et. Server-koden er open source, ligesom klassebibliotekerne i vrigt.For at skabe en SSL-forbindelse skal vores server have et certifikat. Her laver vi bare vores eget. Det betyder, at certifikatet ikke er underskrevet af et rodcertifikat, som 'rigtige' certifikater er, og at brugeren af bookmarkletten skal foretage en 'sikkerhedsundtagelse' i browseren.Vi laver certifikatet med Java-vrktjet Keytool, som ligger i 'bin'-mappen i Javas distribution. Jeg bner et terminalvindue og starter programmet. P min pc ser det sdan ud:C:\Program Files\Java\jre-9.0.4\bin&amp;gt,keytool -genkey -keyalg RSA -alias webservice -keystore C:\Users\tan\Desktop\selfsigned.jks -validity 365 -keysize 2048- hvor det hele skal st p samme linje.Nu stiller programmet en rkke sprgsml, der skal besvares.Enter keystore password:Re-enter new password:What is your first and last name?(Unknown): Tania AndersenWhat is the name of your organizational unit?(Unknown): Version2What is the name of your organization?(Unknown): MIWhat is the name of your City or Locality?(Unknown): CopenhagenWhat is the name of your State or Province?(Unknown):What is the two-letter country code for this unit?(Unknown): DKIs CN=Tania Andersen, OU=Version2, O=MI, L=Copenhagen, ST=Unknown, C=DK correct?(no): yesHerefter kvitterer programmet med at generere en privat ngle p mit skrivebord, med navnet selfsigned.jks.S kan vi stte serveren op, sledes:private static final String SUN_X509_ALGORITME = &quot;SunX509&quot;, public static void main(String[] args) throws IOException, Exception, NoSuchAlgorithmException {// Opst og start webserveren.HttpsServer httpsServer = HttpsServer.create(new InetSocketAddress(8000), 0),KeyStore ks = KeyStore.getInstance(&quot;JKS&quot;),FileInputStream fis = new FileInputStream(&quot;C:\Users\tan\Desktop\selfsigned.jks&quot;), char[] password = new char[] { 'p', '1', 'z', 'z', 'a', 'r', 'e', 's', 't'},// Char-array benyttes i stedet for String, // for at undg at passwordet ender i String-poolen.ks.load(fis, password),KeyManagerFactory kmf = KeyManagerFactory.getInstance(SUN_X509_ALGORITME), kmf.init(ks, password),TrustManagerFactory tmf = TrustManagerFactory.getInstance(SUN_X509_ALGORITME), tmf.init(ks),SSLContext sslContext = SSLContext.getInstance(&quot;TLS&quot;), sslContext.init(kmf.getKeyManagers(), tmf.getTrustManagers(), null),Vi skaber en ny server med kaldet HttpsServer.create, som tager en socket-portadresse som parameter. Her stter vi den til port 8000.S skaber vi en Keystore, som holder p vores private key, og indlser vores ngle selfsigned.jks fra fr, med en FileInputStream, sammen med det password, vi brugte da vi skabte privat-nglen.Vi skal ogs bruge en KeyManagerFactory (kmf) og en TrustManagerFactory (tmf). Nu skal vi have etSSLContext -objekt, som vi fr med metoden SSLContext.getInstance(&quot;TLS&quot;), hvor vi beder om TLS-protokollen - vore dages udgave af SSL.Nu initieres SSLContexten med metoden sslContext.init(kmf.getKeyManagers(), tmf.getTrustManagers()). S kan vi konfigurere vores server. Det ser sdan ud:httpsServer.setHttpsConfigurator(new HttpsConfigurator(sslContext) { public void configure(HttpsParameters params) { try {SSLContext c = SSLContext.getDefault(),SSLParameters defaultSSLParameters = c.getDefaultSSLParameters(), params.setSSLParameters(defaultSSLParameters),} catch (NoSuchAlgorithmException e) { throw new RuntimeException(e),}}}),Nu er serveren konfigureret til SSL med vores hjemmelavede certifikat.(Man kunne mske have nsket sig, at Javas api-designere havde gjort det lidt nemmere for os. Jeg har set et Python-eksempel p det samme, og det fyldte fire linjer. Men sdan er det nu en gang i Java-verdenen.)Nu skal der skabes en 'context', som er en request-handler, der knyttes til en bestemt url. Det ser sdan ud i vores eksempel:httpsServer.createContext(&quot;/apps/emneord&quot;, new Servicehandler()), httpsServer.setExecutor(null), // creates a default executor httpsServer.start(),LocalDate now = LocalDate.now(), now.format(DateTimeFormatter.ISO_DATE),System.out.println(&quot;Starter webtjenesten.&quot;+ ZonedDateTime.now().format(FORMATTER)),Parameteren 'new Servicehandler()'er en instans af interfacet HttpHandler, som har metoden 'handle', der skaber HTTP-svaret. Det ser sdan ud i vores eksempel:static class Servicehandler implements HttpHandler { private Tester tester = new Tester(), public void handle(HttpExchange exchange) throws IOException {InputStream is = exchange.getRequestBody(), final String requestBody = new String(is.readAllBytes(), &quot;UTF-8&quot;),String response = findEmneord(requestBody), final Headers responseHeaders = exchange.getResponseHeaders(), responseHeaders.put(&quot;Access-Control-Allow-Origin&quot;, List.of(&quot;*&quot;)), responseHeaders.put(&quot;Content-Type&quot;, List.of(&quot;text/plain&quot;)), exchange.sendResponseHeaders(200, response.length()),OutputStream os = exchange.getResponseBody(), os.write(response.getBytes()), os.close(),}}Her henter vi request-body'en ud af HttpExchange-parameteren med kaldet exchange.getRequestBody. Vi kalder derefter metoden findEmneord. Tilbage i artiklen i april havde vi en metode, der hed testArtikel, og vores findEmneord -metode gennemlber blot testArtikel med de 50 mest anvendte emneord. Hvis testArtikel vender tommelfingeren op p et givent emne, sender vi emneordet tilbage til vores bookmarklet.For at bookmarkletten kan f lov at tilg CMS-websiden, skal vi stte response-headeren Access-Control-Allow-Origin til en asterisk. Det gres i linjen responseHeaders.put(&quot;Access-Control-Allow-Origin&quot;, List.of(&quot;*&quot;)).Kodeeksemplet kan downloades fra Google Drive, da det fylder for meget for Gitlab - det er modellens estimat-tabeller, der fylder en del. (Google Drive kan sige nogle fjollede ting undervejs, men bare tryk 'download.'). Nr serveren er oppe og kre, via det medflgende batch-script, kan en testside kan tilgs med url'en: https://localhost:8000/apps/emneord/test. (Den del af koden er udeladt i eksemplet her i artiklen.)I en kommende artikel ser vi nrmere p udviklingen af bookmarkletten, der modtager svaret fra vores server, og syr det ind i vores CMS. Bliv p kanalen.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2018-08-24
          &nbsp;&nbsp; e6debba3
          &nbsp;&nbsp; #27
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.995</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.584</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.544</kbd>
        </footer>
      </article>
      <article>
        <h4>Machine Learning kan bruges til at bygge... Machine Learning</h4>
        <div>
          Automatiseret afprvning af 'best fit'-algoritmer kan accelerere udviklingen af Machine Learning og Artificial Intelligence, s AI hurtigere kan udvikles til operationel AI. Et af de konkrete resultater er et teknologisk spring fra Natural Language Processing til Natural Language Understanding, skriver Thomas Herlin fra CGI.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2018-12-11
          &nbsp;&nbsp; e701c30f
          &nbsp;&nbsp; #28
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.953</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.937</kbd>
        </footer>
      </article>
      <article>
        <h4>Techtopia #174: Hvad kan GPT-3?</h4>
        <div>
          GPT-3 har sat nettet og folk med interesse for kunstig intelligens p den anden ende, siden den blev introduceret i juli. Den er et stykke maskinlring, der kan skrive om alle emner mellem himmel og jord.GPT-3 er et stykke maskinlring, der kan skrive om alle emner mellem himmel og jord - eller alle emner beskrevet p internettet. GPT-3 har sat nettet og folk med interesse for kunstig intelligens p den anden ende, siden den 20. juli blev introduceret af firmaet Open AI.Men hvad er det egentlig GPT-3 kan? Og skal vi vre imponerede, skrmte eller bare trkke p skuldrene? Jeg har inviteret tre gster for at finde ud af det.Denne udgave af Techtopia stammer fra R4dio.Medvirkende:Thomas Bolander, professor og ph.d. i logik og kunstig intelligens p DTU Compute og forfatter til bogen 'HVORDAN ser fremtiden ud med kunstig intelligens?'David Kofoed Wind, CEO, EduflowMads Rydahl, UnsiloKom gerne med dine bud p , hvilke emner vi skal tage op.Du kan finde alle episoder af Techtopia HER.Emner :Kunstig intelligens
        </div>
        <footer>
          <em>Ing.dk (Ingeniren)</em>
          &nbsp;&nbsp; 2021-01-05
          &nbsp;&nbsp; e80f3f17
          &nbsp;&nbsp; #29
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.981</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.809</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.602</kbd>
        </footer>
      </article>
      <article>
        <h4>Sdan skriver du unit tests</h4>
        <div>
          Hvorfor skriver du ikke en artikel om unit tests, sagde min kollega Jakob en dag.I sin ungdom programmerede Jakob magasinet Alt Om Data's CMS-system, s nybegynder eller uerfaren er han alts ikke.Der er sikkert mange ligesom mig, der godt kunne tnke sig at kende mere til det, mener han.Og det lyder jo fornuftigt nok.Unit tests er programmer, der tester sm dele af et programs kode.Motivet er klart: Manuel test er tidskrvende, benytter som regel alt for f testeksempler, det er ddkedeligt arbejde og fejlbehftet i den helt store stil. Test er alts en oplagt kandidat til automatisering.Drop debuggerenDertil kommer, at debuggere, hvor man trinvist kan gennemlbe programlinjers udfrsel n for n, er et skrkkeligt vrktj til at finde fejl med. Det er som at finde nlen i hstakken ved at kigge p t str ad gangen.Unit test stiller i stedet sprgsmlet: Hvad forventede du af programstumpens resultat?Det giver bde hurtigere og mere sikker fejlfinding, og ofte en bedre forstelse af kodens virkemde og robusthed i tilgift.En anden vigtig funktion for unit tests er dets anvendelse som skaldt regressionstest. Hver gang ny kode tilfjes programmet, er der en hvis mulighed for, at den tidligere og ellers gennemtestede kode fejler.Med automatiserede tests handler det blot at klikke p knappen i udviklingsvrktjet og s er der vished for, at ens ndringer ikke udlser nye fejl, eller ndrer adfrd i tidligere kode.Derudover kan man ogs teste biblioteker, man anvender i sin kode. Dokumentation er godt, men det er endnu bedre at teste, at man fr prcist det resultat man forventer, nr en given metode kaldes i et bibliotek under et bestemt brugsscenarie, der passer til programmets anvendelse.I vore dage knyttes unit tests sammen med 'continous integration', hvor koden testes i forbindelse med automatiske builds, alts kompilering, konfiguration og udrulning af det frdige program til et test- eller produktionssystem.Og i 2019 er der nppe nogen softwarevirksomhed eller udviklerafdeling, der kunne klare sig uden, hvis kvaliteten skal vre i orden.Ekstrem fed programmeringDer er ikke noget nyt i unit tests - det har vret brugt i ganske mange r. Men det store gennembrud kom, da datalogen Kent Beck, som var bannerfrer for Extreme Programming - en tidlig udgave af agile metodikker - flyttede sit testmilj fra sproget Scheme til Java i starten af det nye rhundrede.Junit, som biblioteket hedder, blev en kmpe success i samme tempo som de agile metoder slog an som en lbeild. Tilsvarende biblioteker findes til stort set alle andre populre sprog og ofte i mange udgaver og alternativer.Her kigger vi nrmere p originalen. Junit er integreret i de fleste strre Java-vrktjer, s som gode gamle Eclipse.Jeg kan bedst lide at have mine test i en selvstndig pakke. Hvis klassen, jeg skal teste, ligger i pakken v2ml, ligger de tilhrende tests i v2ml.test. S er der styr p sagerne.I Eclipse skabes en Junit-test nemt ved at vlge menuen File &amp;gt, New &amp;gt, JUnit Test Case. En test case er bare en almindelig klasse med metoder, der starter med 'test' i navnet.Vi kalder vores testklasse for TestUtil. Guiden skaber denne klasse:package v2ml.test, import static org.junit.jupiter.api.Assertions.*, import org.junit.jupiter.api.Test, class TestUtil {@Test void test() { fail(&quot;Not yet implemented&quot;),}}Annotationen @Test bevirker, at metoden test() kan udfres automatisk.I Eclipse kan testen nu udfres ved at vlge menuen Run &amp;gt, Run (Ctrl+F11). Nu bnes Eclipses Junit-view.Der kommer en rd bjlke i vrktjets brugerflade, for vores test har fejlet. Det er fordi testen kun indeholder linjen:fail(&quot;Not yet implemented&quot;),Test med tnkehattenTil Version2's machine learning kunne jeg godt bruge et lille program, der kan tage tabeller med ordhyppigheder og finde et gennemsnit.Det kan vel ikke vre s svrt, og jeg gider ikke lige lede efter et bibliotek, der kan gre det for mig. Jeg skriver en hndfuld linjer:public class Util { public static Map sum(Map a, Map b) { var sum = new HashMap (), for (var key : a.keySet()) { sum.put(key, a.get(key) + b.getOrDefault(key, 0)),} return sum,}}(En map i Java er ligesom associative arrays i andre sprog, og knytter her et ord til et tal.)Ideen er, at summen for en ordhyppighed m vre summen af vrdierne for en given ngle i begge tabeller, og hvis ordet ikke findes i den sidste tabel, lgges 0 til.S er vi parat til at teste.Konventionen er at kalde testmetoderne noget med 'test' plus det, man nsker at teste. Vi kalder vores for 'testSum.' void testSum() { var x = Map.of(&quot;a&quot;, 1, &quot;b&quot;, 2, &quot;c&quot;, 3), var y = Map.of(&quot;b&quot;, -1, &quot;c&quot;, 4, &quot;d&quot;, 5), var z = Util.sum(x, y),}Her skaber vi to tabeller - maps - og lgger dem sammen. Nu skal vi teste, at resultatet er rigtigt. Det gr vi ved at benytte Junits 'assert'-metoder.De tager to vrdier - den, vi forventer, og det som metoden rent faktisk afleverer, og holder dem op imod hinanden. Man kan ogs angive en fejlmeddelelse, s man hurtigt kan overskue, hvad der gik galt. Det er praktisk, hvis der er mange tests. S ser det sdan ud:void testSum() { var x = Map.of(&quot;a&quot;, 1, &quot;b&quot;, 2, &quot;c&quot;, 3), var y = Map.of(&quot;b&quot;, -1, &quot;c&quot;, 4, &quot;d&quot;, 5), var z = Util.sum(x, y), assertEquals(1, (int) z.get(&quot;a&quot;), &quot;Gal sum&quot;),}I sidste linje forventer vi vrdien 1, og vi tester den op imod den faktiske vrdi z.get(&quot;a&quot;) (som lige skal castes fra Integer til int).S er det bare at kre i testen igen, med Ctrl+F11. Nu fr vi en grn bjlke, og det betyder at testen er passeret. Men vores test er naturligvis ikke fyldestgrende, s vi skriver nogle flere:assertEquals(1, (int) z.get(&quot;a&quot;), &quot;Gal sum&quot;), assertEquals(1, (int) z.get(&quot;b&quot;), &quot;Gal sum&quot;), assertEquals(7, (int) z.get(&quot;c&quot;), &quot;Gal sum&quot;), assertEquals(5, (int) z.get(&quot;d&quot;), &quot;Gal sum&quot;),Vi krer testen igen, og den er gal: Bjlken bliver rd.Det er ikke engang vores assert-stninger der giver fejlen, som er en gemen nullpointer-fejl.I nederste venstre side kan vi af 'failure tracet' se, at fejlen opstr i linje 21. Det er denne her:assertEquals(5, (int) z.get(&quot;d&quot;), &quot;Gal sum&quot;),Det m vre z.get(&quot;d&quot;), der giver fejlen, for der er ingen andre objekter i sigte. Med andre ord er &quot;d&quot; ikke med i sum-tabellen.P med tnkehatten.Nr vi kigger p sum-metoden, gennemlber vi elementerne i frste tabel, og lgger dem til elementerne i den anden tabel, hvis de findes. Med hvad med de elementer i anden tabel, som ikke findes i frste tabel?Dem havde jeg lykkeligt glemt alt om.Lsningen er at tilfje hyppighederne fra de ord i tabel b, som ikke findes i tabel a:var bKeys = new HashSet (b.keySet()), bKeys.removeAll(a.keySet()), for (var key : bKeys) { sum.put(key, b.get(key)),}Jeg krer min test igen med Ctrl+F11 - og bjlken bliver nydeligt grn. Selvtilfredshedens sdme fles helt ud i fingerspidserne.Hvad skal man testeMen hvad skal man egentlig teste med assert-stninger?En klassisk fremgangsmde er skaldt 'grnsevrditest.' Det betyder, at man skal teste sine metoder med henholdsvis typiske, ekstreme og ulovlige vrdier, som parametre til et funktionskald.Typiske vrdier er dem, man vil forvente i et funktionskald i forbindelse med et helt almindeligt brugerscenarie.Ekstreme vrdier kan eksempelvis vre en vre eller nedre grnse i et interval, eller en streng, som er usdvanlig lang - alts en parametervrdi, som mske kan give mavebesvr for funktionen.Ulovlige vrdier - som dog ikke har noget med straffeloven at gre - er parameter-vrdier, hvor programstumpen eller funktionen skal udlse en fejl, som for eksempel en RuntimeException.I vores eksempel kan en 'ekstrem' vrdi for eksempel vre to nulls som argumenter til sum-funktionen. Jeg aner ikke, hvad der sker, hvis jeg gr dette, s jeg tilfjer linjen var resultat = Util.sum(null, null), til min testmetode, og krer igen.Bom, bjlken er rd, nullpointer-fejl, og det skyldes linje 17 i sum-funktionen, siger mit failure trace:for (var key : a.keySet()) {Jeg har alts implicit forestillet mig, at metoden ikke kaldes med null-vrdier som parametre.Det m jeg hellere gre explicit med denne linje, en skaldt 'guard' eller 'precondition', lige efter metodens overskrift:if (a == null || b == null) throw new IllegalArgumentException(&quot;Argumenterne m ikke vre null.&quot;),Det er bedre end fr, for de sageslse klienter, der kalder min metode, fr nu klar besked om, hvad der gik galt.Nu har jeg alts besluttet, at null er en ulovlig vrdi, og jeg kan teste det i min testmetode:try { var resultat = Util.sum(null, null), fail(&quot;Ulovlige vrdier kaster ikke exception.&quot;),} catch (IllegalArgumentException ex) {// Hvis vi nr hertil, er testen get godt.}Hvis kaldet til sum-metoden med null som argumenter ikke kaster en exception, som forventet, gr programmet videre til fail-kaldet, som siger, at min guard benbart ikke fungerer.Den situation kunne mske opst, hvis jeg senere tilfjer flere betingelser til min guard og klokker i de logiske operatorer, som godt kan vre drilske.Det er det, der gr unit tests godt som regressionstest - nr jeg fylder ny kode p mit program, kan jeg sikre mig, at den tidligere adfrd stadig er gyldig.Der er meget mere at sige om unit tests, end hvad vi har berrt her. En vigtig mulighed er at samle sine tests som 'testsuiter', s man fr et hierarki af test, hvor man gr hjere og hjere op i niveau i programmets funktionalitet og ender med at teste de overordnede brugerscenarier.En sidste ting, vi vil se p, er 'coverage', hvor et vrktj kan se, hvor store dele af koden som testen gennemlber. Det findes i mange udviklingsvrktjer og sprog. I Eclipse benyttes faciliteten med menuen Run &amp;gt, Coverage.Nu viser vrktjet de linjer, som blev gennemlbet, da unit testen blev udfrt. Det kan vre en smart mde at sikre sig, at man ikke har glemt at teste dele af programmet.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2019-01-22
          &nbsp;&nbsp; e70d3277
          &nbsp;&nbsp; #30
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.997</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.849</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.634</kbd>
        </footer>
      </article>
      <article>
        <h4>GPT-3: The New Mighty Language Model from OpenAI</h4>
        <div>
            Pushing Deep Learning to the Limit with 175B Parameters OpenAI recently released pre-print of its new mighty language model GPT-3. Its a much bigger and better version of its predecessor GPT-2.In fact, with close to 175B trainable parameters, GPT-3 is much bigger in terms of size in comparison to anything else out there. Vil du have fuld adgang til DataTech? DataTech skriver til dig, der arbejder professionelt med data og analytics. Vi giver dig inspirerende cases, nyheder og debat om alt fra Machine Learning-modeller til dataetik. Har du allerede et abonnement? Log ind Er dit prveabonnement udlbet? Kb
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2020-06-11
          &nbsp;&nbsp; e7bf1bd6
          &nbsp;&nbsp; #31
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.893</kbd>
            <kbd data-tooltip="AI &amp; innovation">L05_INNOAI&nbsp;0.553</kbd>
        </footer>
      </article>
      <article>
        <h4>ITU-forsker fr 6 mio. kroner til forskning i algoritmers bias</h4>
        <div>
          Villum Fonden har tildelt lektor p IT-Universitetet Roberta Sinatra en bevilling p 6 mio kroner. Pengene skal g til forskning i diskriminerende algoritmer, skriver universitetet i en pressemeddelelse.Forskningsprojektet har fet navnet Bias Explained: Pushing Algorithmic Fairness with Models and Experiments. I projektet vil Roberta Sinatra forsge at afdkke de matematiske biasmekanismer, som skaber misvisende rangeringer samt udvikle nogle mere retvisende algoritmer, der skal tage del i kampen mod diskriminerende algoritmer.Projektet tager afst i, hvordan algoritmer favoriserer videnskabelige udgivelser ud fra forfatterens kn, universitet og etnicitet.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2021-01-29
          &nbsp;&nbsp; e81a62b4
          &nbsp;&nbsp; #32
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.754</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.515</kbd>
        </footer>
      </article>
      <article>
        <h4>Danfoss-topchef: Vi er hele tiden i et kaplb</h4>
        <div>
          Log indBliv abonnent og ls hele historienKb adgang for kun 49,- pr. md&gt;Ingen binding!Hvad er plus+ AbonnementstyperF dagens vigtigste nyheder fra amtsavisen.dk direkte i din indbakke. Det er gratis, og du kan afmelde dig til hver en tid.TilmeldVed tilmelding accepteres automatisk vores betingelserLuk betingelser
        </div>
        <footer>
          <em>Amtsavisen.dk (Randers Amtsavis)</em>
          &nbsp;&nbsp; 2018-12-23
          &nbsp;&nbsp; e7059c80
          &nbsp;&nbsp; #33
          <br>
          <br>
            <kbd data-tooltip="Tech industry &amp; regulation">L02_BIGTEC&nbsp;0.768</kbd>
            <kbd data-tooltip="Facebook, fake news &amp; Trump">L05_FBTRUM&nbsp;0.526</kbd>
        </footer>
      </article>
      <article>
        <h4>Gratis vrktjer skal spotte algoritmernes fordomme</h4>
        <div>
          Bias, fordomme og diskrimination er ikke bare noget der foregr i den fysiske verden. Det finder i den grad ogs sted i de algoritmer, der blandt andet bruges til ansigtsgenkendelse og en lang rkke beslutningsprocesser.Nu har IBM lanceret en vrktjskasse med navnet 'Fairness 360', som scanner for tegn p bias i algoritmer.I den frste udgivelse af Fairness 360, ogs navngivet AIF360 Python Package, finder man ni forskellige algoritmer, hvis ml er at afbde bias. Det er et st af fairness- mlinger p datast og machine learning-modeller.bner den sorte boksBehovet for nye former for indsigt i algoritmerne skyldes blandt andet, at udviklere ofte ikke ved, hvilke beslutninger der tages med deres kunstige intelligens og hvorfor.Kunstig intelligens er kendt som en black box, en sort boks. IBM's vrktj vil gre AI-beslutninger mere gennemsigtige, s udviklere kan se, hvilke faktorer der bruges i den kunstige intelligens.Softwaren er cloud-baseret og open source, og den virker til de mest kendte AI-frameworks, inklusiv Watson, Tensorflow, SparkML, AWS SageMaker og AzureMLDu kan finde Fairness 360 p Github
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2018-09-27
          &nbsp;&nbsp; e6ea1676
          &nbsp;&nbsp; #34
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.985</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.862</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.642</kbd>
        </footer>
      </article>
      <article>
        <h4>Hybrid mellem neuralt net og beslutningstr giver forklarlig deep learning</h4>
        <div>
          Neurale net arrangeret som beslutningstr giver bde forklarlighed og prcision, mener AI-forskere. Beslutningstrer er den gyldne standard, hvis en model skal vre bde forklarlig og intuitiv. Men p komplekse opgaver som at klassificere billeder fejler trerne med en prcision, der er vsentligt ringere end et neuralt netvrk. Men med et nyt koncept, udviklet af forskere fra Berkleys center for AI-forskning, kan man f det bedste af begge verdener. Neural-Backed Decision Trees (NBDT) tager den overordnede, intuitive gennesigtighed fra beslutningstrer, men bruger neurale netvrk til at tage beslutninger. Resultatet er iflge Berkeley-forskerne en model, der kan matche almindelige neurale netvrk i prcision, men hvor en almindelig bruger kan aflse, hvordan modellen kom frem til sin beslutning. NBDT-modellen bestr af et beslutningstr, hvor hver node er et neuralt netvrk. P billede-datasts CIFAR10, CIFAR100, og TinyImageNet200 slr den kombination andre forklarlige, trbaserede metoder med en betydelig margin. Og forbliver indenfor omkring 1 procent i nrheden af performance af neurale netvrk. Forklaringen giver srligt menig, nr modellen skal klassificere billeder med indhold, den ikk har set fr. CIFAR10-modellen har f.eks. aldrig set et Zebra, men gennem NBDT-modellen kan vi se, at modellen korrekt identificere at der er tale om et hovdyr, fr den gtter p hest. Bedre performance betyder mere forstlig Ideen er simpel, men det er ikke helt simpelt, at omdanne et neuralt netvrk til et beslutningstr. Processen krver blandt andet, hvad forskerne kalder induced hierarchy, der afgr, hvilke st af klasser - f.eks. hund eller kat - noderne modellen skal tage stilling til. Hierarkiet bliver bygget ud fra vgtene i et prtrnet neuralt netvrk, og med en clustering-teknik finder man frem til hvilke klassifikationer br have en flles 'forldre'-node. De noder kan efterflgende testes kvantitativt. Hvis man f.eks. antager, at en node afgr om billedet forestiller dyr eller fartj, kan man teste det ved at lbe en masse billeder af dyr og fartjer gennem modellen. Og p den mde kan man give hver node - som effektivt er en underdel af et lag i det samlede neurale netvrk - en semantisk betydning. I forskernes prpublicerede artikel bemrker de en positiv sammenhng mellem det neurale netvrks prcision og hvor semantisk fornuftig hierakiet i stidste ende virker. We believe that higher-accuracy models exhibit more semantically-sound weight spaces. Thus, unlike previous work, NBDTs feature better interpretability with higher accuracy, instead of sacrificing one for the other.  Fugl eller fly Eksisterende metoder til at forklare belsutningerne fra et neuralt netvrk, har sin mangler, ppeger Alvin Wan, der er en af forskerne bag projektet og pt. skriver sin ph.d. i AI ved Berkeley, i en blog Saliency maps, som kan bruges til at forst klassifikationer af billeder, kan f.eks. ikke bruges, nr et netvrk kommer frem til forkerte beslutninger, men fokuserer p det rigtige - som f.eks. nr en fugl klassificeres som et fly. Endnu er NBDT-modellen kun brugt p de klassiske billede-klassifikationsdatabaser. Det er derfor uvist, hvor meget klarhed NBDT-modellen kan bringe til situationer, hvor den logiske vej til en beslutning ikke er s simpel som at skelne dyr fra kretjer - f.eks. nr et neuralt netvrk skal spotte brystkrft. Ikke desto mindre er der givet situationer, hvor kombinationer af et effektivt neuralt netvrk og et visuelt, intuitivt beslutningstr er attraktivt. Man kan afprve prtrnede NBDT-modeller her , hvor man ogs kan hente koden.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2020-05-28
          &nbsp;&nbsp; e7b9f4fe
          &nbsp;&nbsp; #35
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.969</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.973</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.665</kbd>
        </footer>
      </article>
      <article>
        <h4>IBM dropper at slge generel software til ansigtsgenkendelse</h4>
        <div>
            Formuleringer i IBM's brev til USA's Kongres vkker skepsis. IBM vil ikke lngere tilbyde IBM-software til ansigtsgenkendelse eller -analyse, og man vil heller ikke forske i eller udvikle teknologien fremover. Det skriver it-virksomhedens CEO Arvind Krishna i et brev til USA's Kongres, som frst blev rapporteret af CNBC IBM no longer offers general purpose IBM facial recognition or analysis software. IBM firmly opposes and will not condone uses of any technology, including facial recognition technology offered by other vendors, for mass surveillance, racial profiling, violations of basic human rights and freedoms, or any purpose which is not consistent with our values and Principles of Trust and Transparency,  skriver Arvind Krishna, CEO hos IBM, i et brev til kongressen i USA. Til The Verge oplyser IBM, at selskabet ikke lngere vil forske i eller udvikle teknologien. Dette er dog ikke en del af brevet fra topchefen. IBM's udmelding kommer efter to uger med demonstrationer i USA mod racisme og politibrutalitet. I brevet bakker Arvind Krishna op om reformer af landets politi, s betjente kan holdes ansvarlige for at bruge magt. Ikke for et forbud Allerede i november udgav IBM en blog, der taler for at holde leverandrer ansvarlige for mden, som deres teknologi bliver brugt p: Providers of facial recognition technology must be accountable for ensuring they don't facilitate human rights abuses by deploying technologies such as facial matching in regimes known for human rights violations,  skrev selskabet Chief Policy Officer, Christina Montgomery ved den lejlighed. Men bde dengang som nu taler IBM ikke for et direkte forbud mod teknologien - heller ikke til brug for politiet. I stedet skriver Krishna, at tiden er inde til a national dialogue on whether and how facial recognition technology should be employed by domestic law enforcement agencies , og hvis ordensmagten bruger teknologien, skal den vre testet for bias. Artificial Intelligence is a powerful tool that can help law enforcement keep citizens safe,  skriver Krishna. Skepsis og begejstring IBM's udmelding vkkede begejstring - blanct andet hos Damien Patrick Williams, ph.d.-studerende ved Virginia Tech. Arguably THE biggest, longest lasting name in Facial Rec said &quot;No, we won't do it, it's bad.&quot; That's huge,  skriver han p Twitter Omvendt bliver brevet mdt med skepsis fra Yoav Goldberg, der er professor i Datalogi ved Bar Ilan University samt Research Director ved den israelske gren af Allen Institute for Artificial Intelligence. Goldberg ppeger , at formuleringen i brevet - IBM no longer offers genereal purpose IBM facial recognition or analysis software  - ikke udelukker salg af custom software, samt software fra tredjeparter. Samme bekymring kommer fra Eva Blum-Dumontet, der er Senior Research Officer ved Privacy International. IBM are trying to redeem themselves because they have been instrumental in developing the technical capabilities of the police through the development of so-called smart policing techniques. But let's not be fooled by their latest move,  siger hun til BBC First of all, their announcement was ambiguous. They talk about ending 'general purpose' facial recognition, which makes me think it will not be the end of facial recognition for IBM, it will just be customised in the future. 
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2020-06-10
          &nbsp;&nbsp; e7bed223
          &nbsp;&nbsp; #36
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.796</kbd>
            <kbd data-tooltip="AI &amp; innovation">L05_INNOAI&nbsp;0.754</kbd>
        </footer>
      </article>
      <article>
        <h4>Sdan kan matematik lse arvestridigheder</h4>
        <div>
          I DR's dramaserie ' Arvingerne' er Gro, Frederik, Emil og Signe havnet i et bittert opgr om arven efter deres mor, Veronika Grnnegaard.Der er ikke lagt op til en retfrdig lsning, for som en gammel talemde siger, skal man ikke finde retfrdighed i juraen, men muligvis i teologien. En andet sted at finde retfrdighed kunne vre i matematikken, som anvist i en ny artikel i Notices of the American Mathematical Society.Penge og ting, der kan omsttes i penge, er let at fordele mellem arvinger.Det er mere vanskeligt, nr det drejer sig om ting, der er udelelige, og som har forskellig vrdi for de forskellige arvinger.Her vil det vre rart at have en god algoritme, der kunne fordele tingene p den mest retfrdige mde, og det er netop en sdan, Steven J. Brams fra New York University i USA, D. Marc Kilgour fra Wilfrid Laurier University i Canada og Christian Klamler fra Karl-Franzens-Universitt Graz i strig prsenterer i deres artikel.De tre matematikere og konomer analyserer dog kun tilfldet, hvor to personer skal fordele ting, der hver isr er udelelige. Men Gro, Frederik, Emil og Signe kunne jo dele sig i to hold - og dernst fordele tingene inden for hvert hold.Brams, Kilgour og Klamler bemrker, at fordeling efter princippet ' jeg deler, du vlger' har vret indgroet i mange samfund, siden Abraham og Lot delte Kana'an og Jordan p denne mde (Frste Mosebog, kap. 13). Der findes en rkke varianter for, hvordan man p tilsvarende vis kan fordele delelige emner mellem tre eller flere personer. Disse er ikke alle lige attraktive, skriver de tre forskere og tilfjer: ' Problemet blegner dog i forhold til at finde en metode til en fair fordeling af udelelige ting.' Brams har i 1996 sammen med Alan Taylor fra Union College i New York udviklet en misundelsesfri metode til fordeling af en rkke udelelige emner.Misundelsesfri dkker over, at ingen af personerne fler, at den anden har fet noget, vedkommende hellere selv ville have haft.Brams-Taylor-metoden (BT) er meget enkel og illustreres bedst med eksemplet vist i grafikken.Antag, at der er seks ting, der skal fordeles (se boks). A og B indleverer prioriterede lister for deres nsker.Man sammenligner de to frste nsker. Da de er forskellige, fr A maleriet, og B fr stolen. Dernst ser man p de ufordelte ting - her har bde A og B nu uret som det hjeste nske. Det overfres derfor i frste omgang til en ufordelt pulje.Den besvrlige restTilbage er nu tre ting. Af disse har A lampen som sit hjeste nske, og B har krukken som sit hjeste. Derfor bliver den endelige fordeling, at A fr maleri og lampe, B fr stol og krukke, mens den ufordelte pulje bestr af ur og chatol.I boksen er kort omtalt en metode til fordeling af tingene i denne pulje.Denne og andre metoder hertil er mere besvrlige og mindre ' retfrdige' end BT-proceduren, men dog anvendelige.S langt, s godt. Men nu kommer Brams sammen med Kilgour og Klamler med en ny metode, der overgr Brams-Taylor-metoden.Den nye algoritme, som de uvist af hvilken grund kalder AL, er som BT misundelsesfri, men den er derudover Pareto-optimal, dvs. der findes ingen anden misundelsesfri fordeling, der er bedre for begge personer. Der er heller ingen anden misundelsesfri fordeling, der efterlader frre emner i den ufordelte pulje - p den mde er AL maksimal.Set fra A og B's synspunkt er AL lige s let at hndtere som BT. De indleverer igen en prioriteret liste.Det interessante er dog, at AL vil fordele de seks emner i eksemplet p en anden mde end BT - en mde, som er bedre, da den er Pareto-optimal.Fordelingen bliver, at A modtager maleri og ur, mens B modtager stol og krukke, og den ufordelte pulje bestr af lampe og chatol.Der er alts sket det, at bde A og B fr tildelt deres frste-og tredjeprioritet, mens deres identiske fjerde-og sjetteprioriteter havner i den ufordelte pulje.Med AL-metoden er B lige s godt stillet som med BT-metoden, mens A er bedre stillet.De tre matematikere redegr i deres artikel helt prcist for, hvordan algoritmen skal implementeres i praksis. Den formelle beskrivelse er dog forholdsmssig lang, s den m vi springe over her.Ganske kort man kan sige flgende om det aktuelle eksempel: Maleri og stol bliver fordelt p samme mde i BT og AL.Nr man kommer til uret, vil BT-metoden overfre det til den ufordelte pulje, mens AL vil undersge, hvilke konsekvenser det vil have for fordelingen af de vrige emner, hvis enten A eller B tildeles uret. Det frer i det aktuelle eksempel til, at A, men ikke B kan modtage uret.DEN UFORDELTE PULJEDer findes forskellige metoder til behandling af emner i den ufordelte pulje. Disse krver dog, at parterne giver mere information end en simpel rangordning.Brams, Kilgour og Klamler har tidligere udviklet en misundelsesfri underbudsprocedure: A foreslr en fordeling, hvor han beholder en bestemt andel af emnerne i den ufordelte pulje. B kan enten acceptere denne fordeling eller underbyde A ved at fjerne et (vilkrligt) emne, som s bliver den endelige fordeling.FAIR FORDELING AF SEKS UDELELIGE EMNERTo arvinger, A &amp; B, skal deles om seks ting. Hvordan gr man dem begge tilfredse? BT og AL er begge misundelsesfri fordelinger, dvs. hverken A eller B fler den anden har fet noget, vedkommende hellere selv ville have haft. Kun AL er Pareto-optimal og maksimal, dvs. ingen anden misundelsesfri fordeling er bedre for begge personer, og ingen anden efterlader frre emner i den ufordelte pulje.
        </div>
        <footer>
          <em>Ingeniren</em>
          &nbsp;&nbsp; 2014-01-24
          &nbsp;&nbsp; e439b9db
          &nbsp;&nbsp; #37
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.99</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.639</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.66</kbd>
        </footer>
      </article>
      <article>
        <h4>Transfer learning hos Amazon: Alexa lrer japansk af engelsk sprogdata</h4>
        <div>
          For Amazons digitale assistent Alexa er evnen til at erobre nye markeder mere eller mindre lig evnen til at lre nye sprog.Men god sprogdata til at trne de neurale netvrk er notorisk svre eller dyre at f fat p, hvorfor Alexa-udviklerne har kastet deres krfter p transfer learning. Med andre ord at lade systemet overfre viden om t sprog til et andet sprog for at lre det hurtigere og bedre.Strategien er effektiv, fortller Research &amp; Development Program Manager ved Amazon Alexa AI Lucie Flekova p konferencen Women in Data Science, der fandt sted i sidste uge.Cross lingual transfer learning er brugbart i bde lille og stor skala, kan forbedre prstationen bde p stnings- og ordniveau, og det kan i vores tilflde spare os mere end halvdelen af trningsdata, siger Lucie Flekova om erfaringerne indtil videre.Relateret jobannonce: Data business analystFra stort til lille datastTransfer learning er typisk brugbar i situationer, hvor du har et stort datast og et datast, der i sig selv er for lille til at trne en model.Det store datast hjlper dig med at lre noget, og overfre det til det mindre datast uden at lre det igen, forklarer Lucie Flekova.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2019-05-02
          &nbsp;&nbsp; e72ea4ec
          &nbsp;&nbsp; #38
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.959</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.908</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.616</kbd>
        </footer>
      </article>
      <article>
        <h4>Er du enig? 20 gyldne citater fra kendte programmrer</h4>
        <div>
          Historien har budt p adskillige store skikkelser inden for programmeringens verden. Her fr du en stribe af de bedste citater fra dem.Af Mikkel MeisterHvis debugging er der, hvor man fjerner softwarebugs, m programmering vre der, hvor man tilfjer dem.Citatet stammer fra den kendte hollandske datalog Edsger Dijkstra, der nok er mest bermt for sin algoritme til at finde korteste veje fra et knudepunkt til alle andre knudepunkter i en graf.Sammen med 19 andre bermtheder inden fra programmeringens verden pryder han en liste over 20 geniale, sjove og tankevkkende citater p hjemmesiden Java Code Geeks .P listen suppleres han blandt andet af den danske opfinder af det objektorienterede programmeringssprog C++, Bjarne Stroustrup, som angiveligt har udtalt:C gr det let for dig at skyde dig selv i foden, C++ gr det svrere, men nr du endelig gr det, skyder du hele benet af.En udtalelse, som kendere af de to maskinnre sprog nok vil nikke genkendende til. Eller om ikke andet s grine ad.Hvad angr antallet af linjer i et program, anser Microsoft-stifter Bill Gates det for at rigtigt drligt udtryk for programmets trivsel og vkst:At mle et programs fremdrift i antal kodelinjer svarer til at mle fremdriften af et flys konstruktion ud fra vgten.En voldelig psykopatI samme boldgade optrder Ken Thompson, UNIX-godfather, med citatet:En af mine mest produktive dage var, da jeg smed 1.000 linjer kode ud.Ogs et par af koryferne inden for fri og open source-software kommer p banen. En af dem er Erik S. Raymond, forfatter til klassikeren 'The Cathedral and the Bazaar'.Han afsender flgende svada til dem, der gr hjt op i universitetsstudier:Uddannelse inden for datalogi gr ingen til en dygtig programmr, ligesom det heller ikke gr nogen til en dygtig maler at studere pensler og farver.Sidste citat i denne omgang bliver fra Martin Golding, der kommer med et godt rd omkring kodens lsbarhed og dokumentation.Skriv altid din kode, som om ham, der ender med at vedligeholde den, er en voldelig psykopat, der ved, hvor du bor.Du kan lse flere citater hos Java Code Geeks og er velkommen til at bidrage med flere af dine favoritter i debatten herunder.Via: Java Code Geeks
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2012-11-15
          &nbsp;&nbsp; e3840b54
          &nbsp;&nbsp; #39
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.848</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.624</kbd>
        </footer>
      </article>
      <article>
        <h4>Nyt charter for AI i retsvsnet: Predictive justice er et vildledende begreb</h4>
        <div>
          Algoritmer er hastigt p vej ind i vrktjskassen hos domstole og politi - og med dem flger store etiske sprgsml om retssikkerhed og fairness. Derfor er der brug for retningslinjer p omrdet, vurderer Europardet. I december vedtog organisationen med 47 medlemslande et charter for etisk anvendelse af AI i retsvsnet.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2019-01-17
          &nbsp;&nbsp; e70bc738
          &nbsp;&nbsp; #40
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.908</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.918</kbd>
            <kbd data-tooltip="New technologies">L80_NEWTEC&nbsp;0.578</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.577</kbd>
        </footer>
      </article>
      <article>
        <h4>Grab'n Go: The Big Five and the canopy effect</h4>
        <div>
          Body P dette morgenmde vil Duncan Stewart fra Deloitte Canada se p de kommende tendenser indenfor teknologi, medier og telekommunikation, som Deloitte har forudsat dem i rapporten &quot;TMT Predictions 2020&quot;.P mdet vil han blandt andet komme ind p privat 5G, edge AI-chips og meget andet.Begivenheden foregr p engelsk.
        </div>
        <footer>
          <em>Techmanagement.dk</em>
          &nbsp;&nbsp; 2020-01-30
          &nbsp;&nbsp; e78f3a49
          &nbsp;&nbsp; #41
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.538</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.577</kbd>
        </footer>
      </article>
      <article>
        <h4>Hvad kan GPT-3 egentlig, og hvordan fr man AI til at tnke abstrakt?</h4>
        <div>
            Vi ser tilbage p ugen der gik. Der er ingen ende i syne p hypen omkring GPT-3, den formidable sprogmodel, der skriver stninger, som nemt kan forveksles med det, der kommer fra et menneskes hnd. Ugens eklatante fejlskud kommer fra den britiske avis The Guardian, der har sat GPT-3 til at skrive et debatindlg - og sikke et resultat. Artiklen har get sin sejrsgang p sociale medier, bde hjemme og udenlands. Den vakte en del sthej og bekymrede miner, nrmest som om 'Skynet' fra Terminator-filmene banker p dren. Det hele er dog fup og fidus, for nr lseren rammer bunden af artiklen, afslres det, at GPT-3 produced eight different outputs, or essays. Each was unique, interesting and advanced a different argument. The Guardian could have just run one of the essays in its entirety. However, we chose instead to pick the best parts of each , in order to capture the different styles and registers of the AI.  Og morskaben stopper ikke der, for avisen kan ogs berette, at we cut lines and paragraphs, and rearranged the order of them in some places.  Det er menneskelig intelligens, og ikke kunstig intelligens - og den var ikke get i en Kaggle-konkurrence. Men det giver alts bonus p Twitter. GPT-3 fejler i faglig viden Fjollede avisartikler til trods, er GPT-3 dog en imponerende tekstmaskine - ingen tvivl om det. Men hvad kan den egentlig? Det sprgsml har en rkke forskere fra blandt andet University of California i Berkeley, USA, stillet sig selv. I en nylig forskningsartikel med titlen ' Measuring Massive Multitask Language Understanding ' skaber forskerne en test, der dkker emner ssom elementr matematik, amerikansk historie, datalogi, jura m.v., for at mle sprogmodellers akkuratesse med mange opgaver. En nemmere lselig gennemgang af artiklens indhold kan findes hos mediet Synced Testen prver at mle vilkrlig gte-verdens-forstelse og p en gennemgribende mde at evaluere bredden og dybden af en models akademiske og faglige forstelse. Forskerne samlede et testst af 15.908 sprgsml om 57 forskellige emner inden for naturvidenskab, teknik, humaniora og socialvidenskab. Testen blev udfrt p forskellige GPT-3-modeller samt modellen UnifiedQA. Resultaterne var ikke noget at rbe hurra for. Alle modeller fik drligere resultat end ekspert-niveau. GPT-3 i gigantversionen klarede sig bedst, med et gennemsnit p 43,9 procent i accuracy, hvilket er omkring 20 point bedre end ved ren tilfldighed. Bedste resultat var 69 procent inden for amerikansk udenrigspolitik og vrst var kemi p bachelor-niveau, hvor accuracy var tt p, hvad der opns med ren tilfldighed. Forskerne bekymres over, at GPT-3 does not have an accurate sense of what it does or does not know since its average confidence can be up to 24% off from its actual accuracy.  Det ligger i trd med, hvad kritikere tidligere har sagt om modellen All GPT-3 really has is a tunnel-vision understanding of how words relate to one another, it does not, from all those words, ever infer anything about the blooming, buzzing world.  Videoklip kategoriseres abstrakt Og det er bare ikke s nemt, det der med at f modellerne til at se det store billede. Men forskere fra MIT har dog for nylig opnet resultater, nr det handler om at f en model til at placere videoklip i abstrakte kategorier. Lsningen er en hybrid sprog-computer vision-model, der lige s godt som mennesker eller bedre kan finde klip, der passer sammen, og fjerne klip, der falder udenfor. Nr modellen fik vist et klip af en hund, der gr, og et andet med en mand, der hyler, kunne modellen frdiggre sttet med et klip af en baby, der grder, udvalgt blandt fem klip. Resultaterne kunne replikeres p to eksterne datast. We show that you can build abstraction into an AI system to perform ordinary visual reasoning tasks close to a human level. A model that can recognize abstract events will give more accurate, logical predictions and be more useful for decision-making,  siger MIT-forskeren Aude Oliva til universitetets nyhedsside AI kommer danske forbrugere til hjlp Vi slutter i den hjemlige andedam med en positiv nyhed: En ny it-lsning skal rydde ud i ulovlige mobilopladere eller farligt legetj, nr forbrugerne handler p nettet, skriver vores sstermedie Version2 . Det er ambitionen med det digitale vrktj ved navn Aime, som Sikkerhedsstyrelsen og Erhvervsministeriet har lanceret. Vrktjet bruger kunstig intelligens til at scanne billeder og tekst i netbutikkerne for at finde frem til ulovlige og farlige produkter. Det kan blandt andet foreg ved, at Aime kigger p et foto af et bestemt produkt, hvorefter den kategoriserer produktet som farligt eller ufarligt. Tidligere i r skrpede Folketinget reglerne p omrdet, og derfor har myndighederne nu mulighed for at blokere hjemmesider, hvis de fortstter med at slge ulovlige produkter. P den mde kan myndighederne anmode domstolene om, at adgangen til en hjemmeside bliver blokeret for danske forbrugere, hvis AI-systemet finder et farligt produkt.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2020-09-11
          &nbsp;&nbsp; e7e250a0
          &nbsp;&nbsp; #42
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.883</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.551</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.551</kbd>
        </footer>
      </article>
      <article>
        <h4>Populrt maskinlringsmilj i Python runder version et nul med kompilering til C++</h4>
        <div>
          Pytorch, som er et open source milj til machine learning, har rundet version 1.0. Miljet, som har Facebook som hovedsponsor, bygger p Python og Nvidias vektorsystem CUDA, der afvikles p grafikprocessorer. Pytorch er en konkurrent til Googles populre Tensorflow-milj.Blandt nyhederne i den nye version er muligheden for at krydskompilere koden til C++ eller et andet effektivt sprog via en just-in-time-compiler. Det skriver Infoworld.Det er ikke bare Python, der kan oversttes til C++. Pytorch 1.0 kan byde p en helt ny mulighed, Torch Script, der nsker at skabe en balance mellem Pythons nemme syntaks og kode, som kan afvikles med hj effektivitet. Torch Script er i sig selv en delmngde af Python.Oversttelsen til C++ kan ske p to mder: Enten ved at bruge Torch Script, der alts er beregnet til krydskompilering, eller ved at angive en metadata-decorator (annotation) til Python-kode. Det sidste vil dog ikke give s effektivt et resultat som med Torch Script.Iflge dokumentationen gr Torch Script det muligt at trne modeller i Pytorch ved hjlp af de velkendte vrktjer og derefter eksportere modellen til et produktionsmilj, hvor det ikke er en god ide at kre modeller som Python-programmer af hensyn til ydeevne og parallel afvikling.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2018-10-10
          &nbsp;&nbsp; e6ee2b4b
          &nbsp;&nbsp; #43
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.886</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.83</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.634</kbd>
        </footer>
      </article>
      <article>
        <h4>Hvornr er kunstig intelligens forklaret tilstrkkeligt?</h4>
        <div>
          Vi anvender kunstig intelligens p stadig flere omrder, og beslutninger baseret p kunstig intelligens kommer tttere p at pvirke vores privatliv. I den forbindelse er der dukket mange begreber op, som explainable (forklarlig) kunstig intelligens, interpretable (fortolkbar) maskinlring, transparent kunstig intelligens og intelligible (forstelig) kunstig intelligens. Vil du have fuld adgang til DataTech? DataTech skriver til dig, der arbejder professionelt med data og analytics. Vi giver dig inspirerende cases, nyheder og debat om alt fra Machine Learning-modeller til dataetik. Har du allerede et abonnement? Log ind Er dit prveabonnement udlbet? Kb
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2020-06-09
          &nbsp;&nbsp; e7be44e9
          &nbsp;&nbsp; #44
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.835</kbd>
            <kbd data-tooltip="AI">L80_AI&nbsp;0.512</kbd>
        </footer>
      </article>
      <article>
        <h4>175 milliarder parametre og 45 TB trningsdata: Hvor god er GPT-3?</h4>
        <div>
          GPT-3 har lst hele internettet - nu kan det overstte, programmere, skrive nyhedsartikler og meget mere. De er ikke perfekte, men computere bliver bedre og bedre til at beherske sprog, og den nye, enormt store sprogmodel GPT-3 imponerer med sin fine sproglige forstelse og frdigheder - ikke mindst udi det engelske sprog. Vil du have fuld adgang til DataTech? DataTech skriver til dig, der arbejder professionelt med data og analytics. Vi giver dig inspirerende cases, nyheder og debat om alt fra Machine Learning-modeller til dataetik. Har du allerede et abonnement? Log ind Er dit prveabonnement udlbet? Kb
        </div>
        <footer>
          <em>Pro.ing.dk/Gridtech</em>
          &nbsp;&nbsp; 2020-08-20
          &nbsp;&nbsp; e7d85e25
          &nbsp;&nbsp; #45
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.807</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.796</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.505</kbd>
        </footer>
      </article>
      <article>
        <h4>Machine learning gtter Version2's emneord med en trfsikkerhed p 98 pct.</h4>
        <div>
          Kunstig intelligens og machine learning kan lyde kryptisk. Her piller vi mystikken af og gennemgr en klassisk algoritme - med kode og hele baduljen.Kunstig intelligens lyder fancy, men for det meste handler det -bare- om matematiske modeller og masser af data. At finde p modellerne er nok ikke s nemt, men at bruge teknologien er ikke s svrt eller mystisk, som det kan lyde.Her p Version2 har vi over frokosten diskuteret muligheden for at finde emneord med maskinlring. Et emneord er et ord, der beskriver artiklens emne, ssom Databeskyttelsesloven, Sundheds-it, GDPR, Java, Ledelse, eller hvad det nu kunne vre.Det er ikke fordi journalisternes opgave med at finde de reglementerede tre emneord pr. artikel efter endt skrivearbejde er uoverkommelig - men mske kunne kunstig intelligens alligevel give et bud?Det burde kunne lade sig gre. Klassifikationsproblemer med naturlig tekst ender ofte med gode resultater, som er praktisk anvendelige. Det ved jeg fra et onlinekursus, et skaldt MOOC, om processering af naturlig sprog, som jeg af nysgerrighed deltog i for en del r siden.Den klassiske tilgang benytter metoden, der gr under navnet Naive Bayes. Den bygger p en nogenlunde simpel sandsynlighedsmodel og er nem at kode.Der findes bedre algoritmer til formlet, med navne som Support Vector Machines, K-Nearest Neighbor og neurale netvrk, men de giver ikke ndvendigvis meget bedre resultater, siger sagkundskaben, og de er en del mere komplicerede. Naive Bayes kan vi klare med 250 linjers hjemmestrikket kode.Fra formel til kodeModellen, der ligger bag, forklarer vi i detaljer i en tilstdende artikel.Kort fortalt bygger den p en forhbning om, at hyppigheden af ord i artikler med t emneord, er forskellig fra hyppigheden i artikler med et andet emneord. Vi udregner en score, eller et estimat, for emneordene, med en smart formel. Det emneord, der opnr hjest score, har vundet - det er det emne, som algoritmen gtter p, givet en artikel. Derefter tester vi, om det er praktisk anvendeligt, p et testst af artikler.For at gre eksemplet nemmere, kigger vi bare p et enkelt emneord i det flgende, -sundheds-it-. Nr vi skal fastsl, om en artikel handler om sundheds-it, betragter vi det som en dyst mellem to klasser: sundheds-it og -ikke-sundheds-it.-For at bruge formlen skal vi gre noget ved ordene i artiklerne. Vi fjerner, rt for usdet, alle tegn som ikke er A til , og skriver det hele med sm bogstaver.Nu skal vi bruge nogle tal.Vi skal kende antallet af artikler om sundheds-it i trningssttet, som bestr af de seneste 2673 artikler p Version2. (Vi startede med 3000, tog 300 fra til et testst vi skal bruge senere, og slettede derefter artikler uden emneord.)Ud fra det bestemmer vi sandsynligheden for, at en artikel har emneordet -sundheds-it-. Dem er der 107 af i trningssttet.Det giver sandsynligheden 107 / 2673.Sandsynligheden for -ikke-sundheds-it- bliver s 2566 / 2673.Vi skal ogs bruge antallet af unikke ord i alle artikler. Det er 54.423.Og s skal vi bruge antallet af ord i alle sundheds-it-artikler. Det tal er 59.590. Og det samme tal for ikke-sundheds-klassen: 1.176.278 stk.S laver vi en tabel med ordhyppigheder for sundheds-it i trningssttet, og en anden for ikke-sundheds-it.Det krver jo ikke ligefrem det store programmr-krekort.Til slut laver vi to tilsvarende tabeller over skaldte estimater, kaldet for log-P-hat - det er et -P-, med en hat over - som vi beregner p denne mde, i pseudokode, med hyppighedstabellen for sundheds-it:for (ord in hyppighedstabel):logPHat(ord) = log((hyppighedstabel(ord) + 1)/ (antalOrdISundhedsItKlassen + antalUnikkeOrdIAlleArtikler) ) sundhedsItEstimatTabel.put(ord, logPHat) og samme mde for ikke-sundheds-it.Vi testerTro det eller la- vr, men nu er vi allerede parat til at teste vores algoritme.Vi skal finde et estimat for sundheds-it, og et for ikke-sundheds-it.Testalgoritmen ser sdan ud, i pseudokode, givet en artikel:sundhedsItlogEstimat = log(artiklerOmSundhedsIt / antalArtikler) for (ord in artikel):logPHat = sundhedsItEstimatTabel.get(ord) if (logPHat == null):logPHat = log(1 / (antalOrdISundhedsItKlassen+ antalUnikkeOrdIAlleArtikler)) sundhedsItlogEstimat += logPHat(Forklaringen p algoritmen findes i nste artikel.)Vi laver samme beregning for ikke-sundheds-it-klassen. Det estimat, der er hjest, har vundet.Vi tester ikke p en enkelt artikel, for det bliver vi ikke meget klogere af. I stedet har vi et testst p 297 artikler, som fortller os, om vi kan bruge det til noget i praksis.Forvirringsmatrix p et hjere planVi kvrner de 297 uberrte artikler igennem testalgoritmen ovenfor. Resultatet er fire tal, kaldet en 'confusion matrix', eller forvirringsmatrix, i en skidt oversttelse.De fire tal er:Sande positive: Hvor mange gange udpegede testalgoritmen 'sundheds-it'rigtigtSande negative: Hvor mange gange pegede algoritmen rigtigt p 'ikke-sundheds-it'Falske positive: Algoritmen udpegede fejlagtigt en artikel som sundheds-itFalske negative: Algoritmen kunne ikke genkende en sundheds-it-artikel.Hvad var resultatet? Kre lser, du skal ikke efterlades i spnding. Det er:Sande positive: 7Sande negative: 285Falske positive: 0Falske negative: 5Der var 12 artikler om sundheds-it blandt de 297 test-artikler. Algoritmen fandt 7 af dem. Den udpegede korrekt alle 285 artikler, der ikke handlede om sundheds-it. Den pegede ikke p nogle forkerte. Der var 5 artikler om sundheds-it, den ikke kunne finde.Er det godt eller skidt? Det sprgsml afhnger af, hvad brugsscenariet er.For at komme tttere p den problemstilling, udregner vi fire 'ml'- tal mellem 0 og 100% - som kan give os et bedre billede af resultatet.De fire ml er:Precision - hvor tit gttede algoritmen 'sundheds-it'rigtigt?Recall - hvor stor procentdel af sundheds-it-artiklerne fandt den?Accuracy - trfsikkerhedF1 - et slags gennemsnit af precision og recall, som kan bruges til at optimere algoritmen med.De udregnes sledes, hvor tp er sande positive, tn sande negative, fp falske positive og fn falske negative:precision = tp / (tp + fp) recall = tp / (tp + fn) accuracy = (tp + tn) / (tp + tn + fp + fn) f1 = 2 * (precision * recall) / (precision + recall)Med vores testst giver det:Precision: 100%Recall: 58%Accuracy: 98%F1: 74%Algoritmen var knald-god til at ramme plet p sundheds-it-artiklerne. Den fandt 58% af sundheds-it-artiklerne i teststtet. Trfsikkerheden var sublim (men det er ikke s praktisk anvendeligt), og f1-mlet var ikke drligt, bedmt p tidligere erfaringer.I en kommende artikel kigger vi p, hvad det egentlig betyder, i forhold til vores forml, og hvordan vi kan 'tune'algoritmen til at give bedre resultater, specielt i forhold til f1-mlet.Download kodeeksempel, trningsst og teststDet ville fylde for meget at gengive den Java-kode, vi har brugt i artiklen. S den kan downloades her (Google Drive kan sige nogle fjollede ting undervejs, men bare tryk 'download.').Eksemplet indeholder det samme trnings- og testst, der gennemgs her i artiklen, med den lille krlle, at ordene i artiklerne er randomiseret. P den mde er der ikke nogen i Mediehuset Ingeniren, der behver ligge vgen om natten og tnke p ophavsret osv. Algoritmen er ligeglad med rkkeflgen af ordene, s det gr ingen forskel for eksemplet.Koden er skrevet s eksemplet er nemt at forst, og er ikke optimeret. Der er tre hardcodede filstier, der kan tilrettes, hvis der er bvl. Det er kommenteret i kildeteksten.Modellen bag algoritmen gennemgr vi i den nste artikel.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2018-03-02
          &nbsp;&nbsp; e6a5a13b
          &nbsp;&nbsp; #46
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.974</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.948</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.6</kbd>
        </footer>
      </article>
      <article>
        <h4>Mit frste forsg med maskinlring: Kan algoritmer finde emneord til Version2-artikler?</h4>
        <div>
          Machine learning-disciplinen topic modeling kan finde frem til emner, der knytter tekster sammen fra en stor tekstsamling. Som eksempelvis Version2's artikeldatabase.Gartner placerede for nylig Machine Learning p toppen af hype-kurven, alts et signal fra analytikerne om, at nu har vi pustet forventningerne til algoritmerne op til bristepunktet og skal indstille os p at falde ned i skuffelsens dybe afgrund.Men det afholder ikke mig fra at prve at kre maskinlring i stilling til at automatisere n af vore daglige udfordringer p Version2-redaktionen.Som journalister prver vi at markere, hvad vores artikler handler om ved at tilknytte nogle udvalgte emneord til hver artikel, vi lgger ind i systemet. Det er en manuel proces, der er srbar over for misforstelser eller forglemmelser, der i sidste ende giver os drlige metadata om artiklernes indhold og dermed indbyrdes tilknytning.Eller lidt mere konkret: Der er mere end n journalist p redaktionen, der har brugt emneordet 'it-politik' p artikler om politiske beslutninger om it, selvom emneordet egentligt skulle dkke over artikler, der handler om firmaers interne regler for brug af it-systemer og -udstyr.Nr en journalist lgger en artikel ind i vores CMS, s skal der vlges et antal relevante emneord ud fra en liste. Et menneske kan beg fejl i denne udvlgelse, og det er en proces, der skal gentages mange gange dagligt. Derfor tnkte jeg, at det mtte vre oplagt at afprve topic modeling eller topic classification.Da jeg i frste omgang er interesseret i at afprve teknikken p vores artikler, s ville jeg helst ikke ud i at skulle skrive alt for mange linjers Python for at f et resultat. Derfor fandt jeg frem til open source-vrktjet Mallet, som er udviklet af University of Massachusetts. Det er fra 2008, men virker stadig godt nok til at afprve konceptet.Mallet benytter sig af en algoritmetype kaldet Latent Dirichlet allocation, som meget groft skitseret bygger p antagelsen om, at nr man skriver en tekst om et emne, s vil man trkke p en pulje af ord, der er flles for tekster om dette emne. Udfordringen er, at en tekst ogs vil indeholde ord fra de puljer, der udgr andre emner, ligesom de enkelte ord kan tilhre flere forskellige emner.Derfor er der flere varianter af LDA-metoden, og Mallet implementerer flere af dem. Fordelen for mit lille projekt er, at jeg ikke skal eksperimentere med forskellige implementeringer af algoritmer, men blot skal fodre Mallet med et datast og justere p enkelte parametre.For at lave en topic model eller emnemodel s skal algoritmen have et datast, som den kan beregne sandsynlige emner ud fra. Her kunne jeg have brugt vores artikeldatabase, men jeg er mere til at arbejde med filer end med databaser, s selvom jeg havde fet et udtrk fra vores database, valgte jeg at fremstille et datast p et andet grundlag.Jeg havde lidt over 2.400 af mine egne artikler fra de sidste fem r liggende i Word Docx-format, som jeg kunne konvertere i t hug til rene tekstfiler ved hjlp af det lille Perl-vrktj docx2txt. Et lille Bash-script senere var mellemrummene i filnavnene ogs fjernet.Dansk ordlisteDermed havde jeg mit tekstkorpus. Nste udfordring var, at Mallet ikke understtter danske tekster. Problemet med topic modeling er, at mange af de ord der udgr en tekst, ikke er relevante for tekstens betydning. De fleste adverbier og flere verber optrder i nsten alle tekster, men siger ikke noget om, hvad teksten handler om.Se blot p stningen i sig selv:De fleste adverbier og flere verber optrder i nsten alle tekster, men siger ikke noget om, hvad teksten handler om.Ord som 'de, fleste, og, flere, i, nsten, alle, men, siger, ikke, noget, om, hvad, om' er ikke unikke for en stning om tekstanalyse. Derfor kan man filtrere dem fra, nr man indlser sit tekstkorpus i Mallet.Det gr Mallet ved hjlp af ordlister, men der var ingen dansk ordliste. S jeg mtte lave min egen. Det er heldigvis ikke en uoverkommelig opgave for en journalist, men selvom en liste over danske adverbier fra Sproget.dk var nyttig, s er udfordringen, at der kan vre visse ord, der i vores artikler kun bruges til nogle bestemte emner. Ord som 'nyt' eller 'strre' kunne vre vigtige at beholde.For eksempel kan jeg ikke vre sikker p, at verbet 'skrive' skal filtreres fra p forhnd, for det kunne vre en vigtig brik i at identificere artikler, der handler om at skrive kode.Derfor var min ordliste i frste forsg p cirka 250 ord, men er p nuvrende tidspunkt p 354 ord. Og ja, nr jeg er rimelig sikker p, at det er en god liste, s vil jeg tilbyde den til Mallet-projektet gennem Github, s andre kan bruge den.Selvom teksterne bliver filtreret for 354 ord, s fr man stadig et interessant output fra algoritmen, som finder de resterende almindelige ord og samler dem i et emne for sig selv. I min seneste krsel har jeg eksempelvis fet flgende ordsamling som t emne:nr gode svrt ser set ting gang dag gr holde folk faktisk tid virker frst bedre par finde vide flesteDer er et par oplagte kandidater at tilfje til min ordliste, men helt slipper jeg nppe for at f sdan en falsk positiv p emnelisten.Mit tekstkorpus lider ogs af, at det er mine r artikler, hvor der til tider er notater fra interviews p engelsk. Derfor har jeg ogs ved den seneste krsel en falsk positiv, der til gengld er ganske ferm til at genkende de engelske tekster, der skiller sig ud fra de danske:the and you that with can are not your new will but has more device time chris code from thisSkal min model bruges i vores daglige produktion, s skal den nok trnes p et tekstkorpus, hvor der er ryddet op.Et udsnit af den reprsentation af tekstkorpuset, som Mallet skaber, nr man indlser tekstfilerne.EmnerneMallet opbygger frst en reprsentation af et tekstkorpus, som man derefter kan prve at opbygge en emnemodel ud fra. Reprsentationen bestr af tekstbidder, og n af udfordringerne med denne teknik er, at der indgr en vis tilfldighed i modelkrslerne. Den ene krsel kan alts give en knivskarp definition af et generelt emne som supercomputere, mens den nste krsel tilfldigvis lgger meget vgt p en serie artikler om lige netop DMI's supercomputer.Der skal alts efterflgende arbejdes med at f bygget den bedste model til lige netop dt, jeg gerne vil have Mallet til at hjlpe mig med.Et emne defineres som sagt som en samling af ord, der med en vis sandsynlighed er flles for tekster, der handler om det givne emne. I krslerne p mit tekstkorpus gav det et par prcise definitioner af nogle konkrete sager:amerikanske usa nsa data adgang overvgning oplysninger internettet edward fbi new snowden rkke the udleveret york amerikansk efterretningstjeneste myndigheder efterretningstjenesten adgang sagen csc danske sager oplysninger politiet rigspolitiet angiveligt version systemer sag mainframe misbrug hackerne personer forbindelse dansk tale medarbejder skat projektet system systemet proask millioner efi kroner arbejdsskadestyrelsen styrelsen skats nyt projekt offentlige it-system drift forsinket konsulenter it-projekter consultingDet er ret tydeligt, at algoritmen her har fundet sagerne om Edward Snowden og NSA, hackingen af CSC og Skats EFI-skandale. Den har ogs fundet sig selv i form af mine artikler om maskinlring:data intelligens kunstig finde netvrk forskerne mennesker maskinlring algoritmer hjlpe machine algoritmerne forskere big hjlp bedre neurale analyse watson lreProblemet ved at bruge et frdigstbt, om end ikke specielt udfrligt dokumenteret, vrktj som Mallet er, at effekten af at skrue p de forskellige parametre kun kan findes ved at eksperimentere. Det er eksempelvis svrt at vurdere, hvor stor en forbedring jeg fr ud af 4.000 iterationer i stedet for 1.000 iterationer ved en krsel.En anden udfordring er, at det ikke er en eksakt videnskab. Der er tilfldighed involveret i algoritmerne, og samtidig vil resultaterne ogs afhnge af, hvor mange emner, der er tilstede i mit tekstkorpus. Det er eksempelvis ret tydeligt, at ved 50 emner i stedet for 20, s trder visse emner mere tydeligt frem, men det giver ogs et par ekstra falske positiver.Et udsnit af de emner, Mallet gav ved en krsel p 4.000 iterationer og 50 topics. Hvert topic bestr af en serie af op til 20 ord med de mest betydningsfulde frst. Der er ogs angivet, hvor stor en andel af tekstkorpuset, emnet passer til.Nste skridtDen nste opgave bliver at trne en model p et tekstkorpus sammensat ud fra Version2's artikeldatabase. Det giver bde en bredere dkning af forskellige emner, ligesom et emne kan vre beskrevet af forskellige journalister med forskelligt sprog.Det vil medfre en ny oprydningsopgave. Der vil vre ord, som skal fjernes, som ikke dukker op til overfladen i mine tekster. Til gengld vil notater vre fjernet fra artiklerne, s der kun optrder relevante engelske ord i artiklerne.Men vores artikler indeholder ogs links og formatering, som kan vise sig at vre en stjkilde. Det er en anden opgave - men bestemt ogs interessant - at se p links mellem tekster. At et ord optrder i en mellemrubrik kunne ogs vre vrdifuld information, men Mallet benytter ikke tekstanalyse, der ser p hele stninger, s det er ikke muligt at bruge denne information med Mallet.Jeg havde mildt sagt lidt ballade med at f skruet det helt rigtige Regex-udtryk sammen til opbygningen af mit tekstkorpus. Mallet giver mulighed for at anvende et Regex-udtryk ved dataimporten, men det gav bedre resultat blot at lade Mallet benytte den Regex-filtrering, der er kodet ind som standard.Der er som sagt ellers tekstelementer, der burde fjernes. Vi bruger Markdown i vores Drupal-system, hvor ## eksempelvis markerer en h2-mellemrubrik. Det er ikke helt let at f fjernet Markdown fra artiklerne, uden at f problemer for eksempelvis C#, der kunne vre et ngleord.Lsningen bliver nok at lave et script eller to, der kan polere de r artikeltekster, inden de bliver fodret til Mallet. S slipper jeg for at skulle samle al oprydningen i t Regex-udtryk.Ud over en liste over ord samt den endelige model, algoritmen kan genbruge, s leverer Mallet ogs som output en liste over teksterne, og hvor godt de passer p de forskellige emner. Det kan bruges til at lave en trimning af mit tekstkorpus, s tekster, der p n eller anden mde er usdvanlige, kan pilles ud.Det endelig ml er at f samlet en model, der kan give op til tre nogenlunde prcise bud p emner, nr den fr prsenteret en ny tekst. Det vil vi kunne bruge til automatisk at tilfje emneord til ny og gamle artikler, og det vil ogs kunne bruges til at lave automatiske samlinger af artikler inden for et sagsforlb.Lige nu har vi eksempelvis et tema, der samler artiklerne i CSC-hackersagen, men vi har ikke et tema for Skats it-problemer. Det vil vre oplagt at bruge modellen til at finde og samle disse artikler automatisk i stedet for en manuel proces.Det er vigtigt at understrege, at selvom det er muligt at identificere et emne i form af en mngde af ord, s vil det stadig vre et menneske, der skal finde en passende etiket til emnet. Se eksempelvis p et emne, der kunne kaldes 'streaming' eller lidt mere 90'er-agtigt 'digitale medier':netflix film indhold the tjenester indholdet spotify streaming danske tjenesten dansk bay youtube amerikanske danmark netneutralitet filmen pirate tv-serier adgangMan kan alts ikke regne med, at det frste ord er en god etiket. S der skal menneskelige jne p, og helst n, der kender tekstkorpus. Algoritmen kan med andre ord udfre de mange gentagelser, der skulle til at stte etiketten p alle relevante artikler, men ikke vurdere, hvad emnet handler om.En anden udfordring er, at emner kan dukke op og forsvinde over tid. Det kan blive et problem for opbygningen af modellen som en generel model til hele vores tekstkorpus. Ord som 'ssd' og 'harddisk' kan jeg eksempelvis se, giver modellen problemer med at skelne mellem to emner:Det frste var det hotte emne om ssd'er for fem r siden, hvor jeg skrev om, hvad ssd'er kunne gre for pc'en. Det andet er i dag, hvor ssd'er i pc'er er s meget en selvflge, at jeg mest skriver om dem i forbindelse med storage i datacentre. Der er overlap, men det er nok vrd at skelne mellem de to.Det mest overraskendeJeg er mest overrasket over, hvor prcis algoritmen er til at identificere meget konkrete sager, som NSA-afslringerne eller EFI-skandalen, men ogs kan ramme ret prcist p en bestemt genre af artikler.Det her ligner eksempelvis resultatet af, at algoritmen har lst mine blogindlg, der var en del af korpus, og har identificeret blogindlggene som et srskilt emne:nrder kvinder trine klokken commodore generation nrd sokker ascii kage lad kaffe gengld tegnst printer unge fest vrre the tegnBloggen handler om nrdkultur, og algoritmen har benbart srligt bidt mrke i mit svar til Trine Bramsen om de famse tennissokker. Et svar, der aldrig nede lngere end til en kladde og aldrig blev udgivet. S dr - en lille godbid af aldrig udgivet materiale for dem, der har lst s langt.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2016-08-26
          &nbsp;&nbsp; e5db20cb
          &nbsp;&nbsp; #47
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.853</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.697</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.668</kbd>
        </footer>
      </article>
      <article>
        <h4>Microsoft kber BrightBytes DataSense</h4>
        <div>
          Det oplyser Microsoft selv i en pressemeddelelse.We want to help every school find this same success, using data to gain insights and tailor their learning experience, skriver Microsoft i pressemeddelelsen.BrightBytes, der er en virksomhed, der arbejder med undervisnings datanalyse har desuden udviklet en platform, der bruger machine learning og predictive analytics.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2019-02-05
          &nbsp;&nbsp; e711b4bf
          &nbsp;&nbsp; #48
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.554</kbd>
            <kbd data-tooltip="AI &amp; innovation">L05_INNOAI&nbsp;0.544</kbd>
        </footer>
      </article>
      <article>
        <h4>Kunstig intelligens skal redde det bornholmske sprog fra at udd</h4>
        <div>
          Danske forskere er i frd med at udvikle sprogteknologiske vrktj, der skal puste liv i et ellers ddsdmt sprog - nemlig bornholmsk. Det skriver Videnskab.dk Alex Speed Kjeldsen, der er adjunkt Institut for Nordiske Studier og Sprogvidenskab p Kbenhavns Universitet, har sammen med Leon Derczynski, adjunkt p IT Universitetet i Kbenhavn og medlem af forskningsgruppen Natural Language Processing, udviklet en slags Google Translate, der kan overstte fra bornholmsk til dansk og omvendt. Tanken bag projektet er, at sprog i vores digitale tidsalder vil forsvinde helt, hvis ikke man kan arbejde med dem digitalt,  forklarer Alex Speed Kjeldsen til Videnskab.dk.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2019-11-07
          &nbsp;&nbsp; e76df4f6
          &nbsp;&nbsp; #49
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.899</kbd>
            <kbd data-tooltip="AI &amp; innovation">L05_INNOAI&nbsp;0.568</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.509</kbd>
        </footer>
      </article>
    </main>
  </body>
</html>
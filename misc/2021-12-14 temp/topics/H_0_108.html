<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Infomedia Articles</title>
    <style type="text/css">
/*!
 * Pico.css v1.3.3 (https://picocss.com)
 * Copyright 2019-2021 - Licensed under MIT
 */:root{--font-family:system-ui,-apple-system,"Segoe UI","Roboto","Ubuntu","Cantarell","Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";--line-height:1.5;--font-weight:400;--font-size:16px;--border-radius:.25rem;--border-width:1px;--outline-width:3px;--spacing:1rem;--typography-spacing-vertical:1.5rem;--block-spacing-vertical:calc(var(--spacing) * 2);--block-spacing-horizontal:var(--spacing);--grid-spacing-vertical:0;--grid-spacing-horizontal:var(--spacing);--form-element-spacing-vertical:.75rem;--form-element-spacing-horizontal:1rem;--transition:.2s ease-in-out}@media (min-width:576px){:root{--font-size:17px}}@media (min-width:768px){:root{--font-size:18px}}@media (min-width:992px){:root{--font-size:19px}}@media (min-width:1200px){:root{--font-size:20px}}@media (min-width:576px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 2.5)}}@media (min-width:768px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 3)}}@media (min-width:992px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 3.5)}}@media (min-width:1200px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 4)}}@media (min-width:576px){article{--block-spacing-horizontal:calc(var(--spacing) * 1.25)}}@media (min-width:768px){article{--block-spacing-horizontal:calc(var(--spacing) * 1.5)}}@media (min-width:992px){article{--block-spacing-horizontal:calc(var(--spacing) * 1.75)}}@media (min-width:1200px){article{--block-spacing-horizontal:calc(var(--spacing) * 2)}}a{--text-decoration:none}a.contrast,a.secondary{--text-decoration:underline}small{--font-size:0.875em}h1,h2,h3,h4,h5,h6{--font-weight:700}h1{--font-size:2rem;--typography-spacing-vertical:3rem}h2{--font-size:1.75rem;--typography-spacing-vertical:2.625rem}h3{--font-size:1.5rem;--typography-spacing-vertical:2.25rem}h4{--font-size:1.25rem;--typography-spacing-vertical:1.874rem}h5{--font-size:1.125rem;--typography-spacing-vertical:1.6875rem}[type=checkbox],[type=radio]{--border-width:2px}[type=checkbox][role=switch]{--border-width:3px}thead td,thead th{--border-width:3px}:not(thead)>*>td{--font-size:0.875em}code,kbd,pre,samp{--font-family:"Menlo","Consolas","Roboto Mono","Ubuntu Monospace","Noto Mono","Oxygen Mono","Liberation Mono",monospace,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji"}kbd{--font-weight:bolder}:root:not([data-theme=dark]),[data-theme=light]{color-scheme:light;--background-color:#FFF;--color:#415462;--h1-color:#1b2832;--h2-color:#23333e;--h3-color:#2c3d49;--h4-color:#374956;--h5-color:#415462;--h6-color:#4d606d;--muted-color:#73828c;--muted-border-color:#edf0f3;--primary:#1095c1;--primary-hover:#08769b;--primary-focus:rgba(16,149,193,0.125);--primary-inverse:#FFF;--secondary:#596b78;--secondary-hover:#415462;--secondary-focus:rgba(89,107,120,0.125);--secondary-inverse:#FFF;--contrast:#1b2832;--contrast-hover:#000;--contrast-focus:rgba(89,107,120,0.125);--contrast-inverse:#FFF;--mark-background-color:#fff2ca;--mark-color:#543a25;--ins-color:#388E3C;--del-color:#C62828;--blockquote-border-color:var(--muted-border-color);--blockquote-footer-color:var(--muted-color);--button-box-shadow:0 0 0 rgba(0,0,0,0);--button-hover-box-shadow:0 0 0 rgba(0,0,0,0);--form-element-background-color:transparent;--form-element-border-color:#a2afb9;--form-element-color:var(--color);--form-element-placeholder-color:var(--muted-color);--form-element-active-background-color:transparent;--form-element-active-border-color:var(--primary);--form-element-focus-color:var(--primary-focus);--form-element-disabled-background-color:#d5dce2;--form-element-disabled-border-color:#a2afb9;--form-element-disabled-opacity:.5;--form-element-invalid-border-color:#C62828;--form-element-invalid-active-border-color:#B71C1C;--form-element-valid-border-color:#388E3C;--form-element-valid-active-border-color:#2E7D32;--switch-background-color:#bbc6ce;--switch-color:var(--primary-inverse);--switch-checked-background-color:var(--primary);--range-border-color:#d5dce2;--range-active-border-color:#bbc6ce;--range-thumb-border-color:var(--background-color);--range-thumb-color:var(--secondary);--range-thumb-hover-color:var(--secondary-hover);--range-thumb-active-color:var(--primary);--table-border-color:var(--muted-border-color);--table-row-stripped-background-color:#f6f8f9;--code-background-color:#edf0f3;--code-color:var(--muted-color);--code-kbd-background-color:var(--contrast);--code-kbd-color:var(--contrast-inverse);--code-tag-color:#b34d80;--code-property-color:#3d888f;--code-value-color:#998866;--code-comment-color:#a2afb9;--accordion-border-color:var(--muted-border-color);--accordion-close-summary-color:var(--color);--accordion-open-summary-color:var(--muted-color);--card-background-color:var(--background-color);--card-border-color:var(--muted-border-color);--card-box-shadow:0 0.125rem 1rem rgba(27,40,50,0.04),0 0.125rem 2rem rgba(27,40,50,0.08),0 0 0 0.0625rem rgba(27,40,50,0.024);--card-sectionning-background-color:#fafbfc;--progress-background-color:#d5dce2;--progress-color:var(--primary);--loading-spinner-opacity:.5;--tooltip-background-color:var(--contrast);--tooltip-color:var(--contrast-inverse);--icon-chevron:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");--icon-date:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");--icon-time:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");--icon-search:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");--icon-checkbox:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-minus:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");--icon-valid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(56, 142, 60, 0.999)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-invalid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(198, 40, 40, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E")}@media only screen and (prefers-color-scheme:dark){:root:not([data-theme=light]){color-scheme:dark;--background-color:#11191f;--color:#bbc6ce;--h1-color:#edf0f3;--h2-color:#e1e6ea;--h3-color:#d5dce2;--h4-color:#c8d1d8;--h5-color:#bbc6ce;--h6-color:#aebbc3;--muted-color:#73828c;--muted-border-color:#1f2d38;--primary:#1095c1;--primary-hover:#1ab3e6;--primary-focus:rgba(16,149,193,0.25);--primary-inverse:#FFF;--secondary:#596b78;--secondary-hover:#73828c;--secondary-focus:rgba(115,130,140,0.25);--secondary-inverse:#FFF;--contrast:#edf0f3;--contrast-hover:#FFF;--contrast-focus:rgba(115,130,140,0.25);--contrast-inverse:#000;--mark-background-color:#d0c284;--mark-color:#11191f;--ins-color:#388E3C;--del-color:#C62828;--blockquote-border-color:var(--muted-border-color);--blockquote-footer-color:var(--muted-color);--button-box-shadow:0 0 0 rgba(0,0,0,0);--button-hover-box-shadow:0 0 0 rgba(0,0,0,0);--form-element-background-color:#11191f;--form-element-border-color:#374956;--form-element-color:var(--color);--form-element-placeholder-color:var(--muted-color);--form-element-active-background-color:var(--form-element-background-color);--form-element-active-border-color:var(--primary);--form-element-focus-color:var(--primary-focus);--form-element-disabled-background-color:#2c3d49;--form-element-disabled-border-color:#415462;--form-element-disabled-opacity:.5;--form-element-invalid-border-color:#B71C1C;--form-element-invalid-active-border-color:#C62828;--form-element-valid-border-color:#2E7D32;--form-element-valid-active-border-color:#388E3C;--switch-background-color:#374956;--switch-color:var(--primary-inverse);--switch-checked-background-color:var(--primary);--range-border-color:#23333e;--range-active-border-color:#2c3d49;--range-thumb-border-color:var(--background-color);--range-thumb-color:var(--secondary);--range-thumb-hover-color:var(--secondary-hover);--range-thumb-active-color:var(--primary);--table-border-color:var(--muted-border-color);--table-row-stripped-background-color:rgba(115,130,140,0.05);--code-background-color:#17232c;--code-color:var(--muted-color);--code-kbd-background-color:var(--contrast);--code-kbd-color:var(--contrast-inverse);--code-tag-color:#a65980;--code-property-color:#599fa6;--code-value-color:#8c8473;--code-comment-color:#4d606d;--accordion-border-color:var(--muted-border-color);--accordion-active-summary-color:var(--primary);--accordion-close-summary-color:var(--color);--accordion-open-summary-color:var(--muted-color);--card-background-color:#141e25;--card-border-color:#11191f;--card-box-shadow:0 0.125rem 1rem rgba(0,0,0,0.06),0 0.125rem 2rem rgba(0,0,0,0.12),0 0 0 0.0625rem rgba(0,0,0,0.036);--card-sectionning-background-color:#17232c;--progress-background-color:#23333e;--progress-color:var(--primary);--loading-spinner-opacity:.5;--tooltip-background-color:var(--contrast);--tooltip-color:var(--contrast-inverse);--icon-chevron:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");--icon-date:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");--icon-time:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");--icon-search:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");--icon-checkbox:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-minus:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");--icon-valid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(46, 125, 50, 0.999)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-invalid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(183, 28, 28, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E")}}[data-theme=dark]{color-scheme:dark;--background-color:#11191f;--color:#bbc6ce;--h1-color:#edf0f3;--h2-color:#e1e6ea;--h3-color:#d5dce2;--h4-color:#c8d1d8;--h5-color:#bbc6ce;--h6-color:#aebbc3;--muted-color:#73828c;--muted-border-color:#1f2d38;--primary:#1095c1;--primary-hover:#1ab3e6;--primary-focus:rgba(16,149,193,0.25);--primary-inverse:#FFF;--secondary:#596b78;--secondary-hover:#73828c;--secondary-focus:rgba(115,130,140,0.25);--secondary-inverse:#FFF;--contrast:#edf0f3;--contrast-hover:#FFF;--contrast-focus:rgba(115,130,140,0.25);--contrast-inverse:#000;--mark-background-color:#d0c284;--mark-color:#11191f;--ins-color:#388E3C;--del-color:#C62828;--blockquote-border-color:var(--muted-border-color);--blockquote-footer-color:var(--muted-color);--button-box-shadow:0 0 0 rgba(0,0,0,0);--button-hover-box-shadow:0 0 0 rgba(0,0,0,0);--form-element-background-color:#11191f;--form-element-border-color:#374956;--form-element-color:var(--color);--form-element-placeholder-color:var(--muted-color);--form-element-active-background-color:var(--form-element-background-color);--form-element-active-border-color:var(--primary);--form-element-focus-color:var(--primary-focus);--form-element-disabled-background-color:#2c3d49;--form-element-disabled-border-color:#415462;--form-element-disabled-opacity:.5;--form-element-invalid-border-color:#B71C1C;--form-element-invalid-active-border-color:#C62828;--form-element-valid-border-color:#2E7D32;--form-element-valid-active-border-color:#388E3C;--switch-background-color:#374956;--switch-color:var(--primary-inverse);--switch-checked-background-color:var(--primary);--range-border-color:#23333e;--range-active-border-color:#2c3d49;--range-thumb-border-color:var(--background-color);--range-thumb-color:var(--secondary);--range-thumb-hover-color:var(--secondary-hover);--range-thumb-active-color:var(--primary);--table-border-color:var(--muted-border-color);--table-row-stripped-background-color:rgba(115,130,140,0.05);--code-background-color:#17232c;--code-color:var(--muted-color);--code-kbd-background-color:var(--contrast);--code-kbd-color:var(--contrast-inverse);--code-tag-color:#a65980;--code-property-color:#599fa6;--code-value-color:#8c8473;--code-comment-color:#4d606d;--accordion-border-color:var(--muted-border-color);--accordion-active-summary-color:var(--primary);--accordion-close-summary-color:var(--color);--accordion-open-summary-color:var(--muted-color);--card-background-color:#141e25;--card-border-color:#11191f;--card-box-shadow:0 0.125rem 1rem rgba(0,0,0,0.06),0 0.125rem 2rem rgba(0,0,0,0.12),0 0 0 0.0625rem rgba(0,0,0,0.036);--card-sectionning-background-color:#17232c;--progress-background-color:#23333e;--progress-color:var(--primary);--loading-spinner-opacity:.5;--tooltip-background-color:var(--contrast);--tooltip-color:var(--contrast-inverse);--icon-chevron:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");--icon-date:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");--icon-time:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");--icon-search:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");--icon-checkbox:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-minus:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");--icon-valid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(46, 125, 50, 0.999)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-invalid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(183, 28, 28, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E")}*,:after,:before{box-sizing:border-box}:after,:before{text-decoration:inherit;vertical-align:inherit}html{-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:rgba(0,0,0,0);-moz-tab-size:4;-ms-text-size-adjust:100%;background-color:var(--background-color);color:var(--color);font-family:var(--font-family);font-size:var(--font-size);font-weight:var(--font-weight);line-height:var(--line-height);text-rendering:optimizeLegibility;cursor:default}main{display:block}body{width:100%;margin:0}body>footer,body>header,body>main{width:100%;margin-right:auto;margin-left:auto;padding:var(--block-spacing-vertical) 0}.container,.container-fluid{width:100%;margin-right:auto;margin-left:auto;padding-right:var(--spacing);padding-left:var(--spacing)}@media (min-width:576px){.container{max-width:510px;padding-right:0;padding-left:0}}@media (min-width:768px){.container{max-width:700px}}@media (min-width:992px){.container{max-width:920px}}@media (min-width:1200px){.container{max-width:1130px}}section{margin-bottom:var(--block-spacing-vertical)}.grid{grid-column-gap:var(--grid-spacing-horizontal);grid-row-gap:var(--grid-spacing-vertical);display:grid;grid-template-columns:1fr;margin:0}@media (min-width:992px){.grid{grid-template-columns:repeat(auto-fit,minmax(0%,1fr))}}.grid>*{min-width:0}figure{display:block;margin:0;padding:0;overflow-x:auto}figure figcaption{padding:calc(var(--spacing) / 2) 0;color:var(--muted-color)}b,strong{font-weight:bolder}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-0.25em}sup{top:-0.5em}dl dl,dl ol,dl ul,ol dl,ul dl{margin:0}ol ol,ol ul,ul ol,ul ul{margin:0}address,blockquote,dl,figure,form,ol,p,pre,table,ul{margin-top:0;margin-bottom:var(--typography-spacing-vertical);color:var(--color);font-size:1rem;font-style:normal}a{--color:var(--primary);--background-color:transparent;outline:none;background-color:var(--background-color);color:var(--color);text-decoration:var(--text-decoration);transition:background-color var(--transition),color var(--transition),text-decoration var(--transition),box-shadow var(--transition)}a:active,a:focus,a:hover{--color:var(--primary-hover);--text-decoration:underline}a:focus{--background-color:var(--primary-focus)}a.secondary{--color:var(--secondary)}a.secondary:active,a.secondary:focus,a.secondary:hover{--color:var(--secondary-hover)}a.secondary:focus{--background-color:var(--secondary-focus)}a.contrast{--color:var(--contrast)}a.contrast:active,a.contrast:focus,a.contrast:hover{--color:var(--contrast-hover)}a.contrast:focus{--background-color:var(--contrast-focus)}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:var(--typography-spacing-vertical);color:var(--color);font-family:var(--font-family);font-size:var(--font-size);font-weight:var(--font-weight)}h1{--color:var(--h1-color)}h2{--color:var(--h2-color)}h3{--color:var(--h3-color)}h4{--color:var(--h4-color)}h5{--color:var(--h5-color)}h6{--color:var(--h6-color)}address~h1,address~h2,address~h3,address~h4,address~h5,address~h6,blockquote~h1,blockquote~h2,blockquote~h3,blockquote~h4,blockquote~h5,blockquote~h6,dl~h1,dl~h2,dl~h3,dl~h4,dl~h5,dl~h6,figure~h1,figure~h2,figure~h3,figure~h4,figure~h5,figure~h6,form~h1,form~h2,form~h3,form~h4,form~h5,form~h6,ol~h1,ol~h2,ol~h3,ol~h4,ol~h5,ol~h6,pre~h1,pre~h2,pre~h3,pre~h4,pre~h5,pre~h6,p~h1,p~h2,p~h3,p~h4,p~h5,p~h6,table~h1,table~h2,table~h3,table~h4,table~h5,table~h6,ul~h1,ul~h2,ul~h3,ul~h4,ul~h5,ul~h6{margin-top:var(--typography-spacing-vertical)}hgroup{margin-bottom:var(--typography-spacing-vertical)}hgroup>*{margin-bottom:0}hgroup>:last-child{--color:var(--muted-color);--font-weight:unset;font-family:unset;font-size:1rem}p{margin-bottom:var(--typography-spacing-vertical)}small{font-size:var(--font-size)}ol,ul{padding-left:var(--spacing)}ol li,ul li{margin-bottom:calc(var(--typography-spacing-vertical) / 4)}ul li{list-style:square}mark{padding:.125rem .25rem;background-color:var(--mark-background-color);color:var(--mark-color);vertical-align:middle}blockquote{display:block;margin:var(--typography-spacing-vertical) 0;padding:var(--spacing);border-left:0.25rem solid var(--blockquote-border-color)}blockquote footer{margin-top:calc(var(--typography-spacing-vertical) / 2);color:var(--blockquote-footer-color)}abbr[title]{border-bottom:1px dotted;text-decoration:none;cursor:help}ins{color:var(--ins-color);text-decoration:none}del{color:var(--del-color)}::selection{background-color:var(--primary-focus)}audio,canvas,iframe,img,svg,video{vertical-align:middle}audio,video{display:inline-block}audio:not([controls]){display:none;height:0}iframe{border-style:none}img{max-width:100%;height:auto;border-style:none}svg:not([fill]){fill:currentColor}svg:not(:root){overflow:hidden}button{margin:0;overflow:visible;font-family:inherit;text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{padding:0;border-style:none}button{display:block;width:100%;margin-bottom:var(--spacing)}a[role=button]{display:inline-block;text-decoration:none}a[role=button],button,input[type=button],input[type=reset],input[type=submit]{--background-color:var(--primary);--border-color:var(--primary);--color:var(--primary-inverse);--box-shadow:var(--button-box-shadow,0 0 0 rgba(0,0,0,0));padding:var(--form-element-spacing-vertical) var(--form-element-spacing-horizontal);border:var(--border-width) solid var(--border-color);border-radius:var(--border-radius);outline:none;background-color:var(--background-color);box-shadow:var(--box-shadow);color:var(--color);font-size:1rem;font-weight:var(--font-weight);line-height:var(--line-height);text-align:center;cursor:pointer;transition:background-color var(--transition),border-color var(--transition),color var(--transition),box-shadow var(--transition)}a[role=button]:active,a[role=button]:focus,a[role=button]:hover,button:active,button:focus,button:hover,input[type=button]:active,input[type=button]:focus,input[type=button]:hover,input[type=reset]:active,input[type=reset]:focus,input[type=reset]:hover,input[type=submit]:active,input[type=submit]:focus,input[type=submit]:hover{--background-color:var(--primary-hover);--border-color:var(--primary-hover);--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0))}a[role=button]:focus,button:focus,input[type=button]:focus,input[type=reset]:focus,input[type=submit]:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--primary-focus)}input[type=reset]{--background-color:var(--secondary);--border-color:var(--secondary);--color:var(--secondary-inverse);cursor:pointer}input[type=reset]:active,input[type=reset]:focus,input[type=reset]:hover{--background-color:var(--secondary-hover);--border-color:var(--secondary-hover)}input[type=reset]:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--secondary-focus)}a[role=button].secondary,button.secondary,input[type=button].secondary,input[type=reset].secondary,input[type=submit].secondary{--background-color:var(--secondary);--border-color:var(--secondary);--color:var(--secondary-inverse);cursor:pointer}a[role=button].secondary:active,a[role=button].secondary:focus,a[role=button].secondary:hover,button.secondary:active,button.secondary:focus,button.secondary:hover,input[type=button].secondary:active,input[type=button].secondary:focus,input[type=button].secondary:hover,input[type=reset].secondary:active,input[type=reset].secondary:focus,input[type=reset].secondary:hover,input[type=submit].secondary:active,input[type=submit].secondary:focus,input[type=submit].secondary:hover{--background-color:var(--secondary-hover);--border-color:var(--secondary-hover)}a[role=button].secondary:focus,button.secondary:focus,input[type=button].secondary:focus,input[type=reset].secondary:focus,input[type=submit].secondary:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--secondary-focus)}a[role=button].contrast,button.contrast,input[type=button].contrast,input[type=reset].contrast,input[type=submit].contrast{--background-color:var(--contrast);--border-color:var(--contrast);--color:var(--contrast-inverse)}a[role=button].contrast:active,a[role=button].contrast:focus,a[role=button].contrast:hover,button.contrast:active,button.contrast:focus,button.contrast:hover,input[type=button].contrast:active,input[type=button].contrast:focus,input[type=button].contrast:hover,input[type=reset].contrast:active,input[type=reset].contrast:focus,input[type=reset].contrast:hover,input[type=submit].contrast:active,input[type=submit].contrast:focus,input[type=submit].contrast:hover{--background-color:var(--contrast-hover);--border-color:var(--contrast-hover)}a[role=button].contrast:focus,button.contrast:focus,input[type=button].contrast:focus,input[type=reset].contrast:focus,input[type=submit].contrast:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--contrast-focus)}a[role=button].outline,button.outline,input[type=button].outline,input[type=reset].outline,input[type=submit].outline{--background-color:transparent;--color:var(--primary)}a[role=button].outline:active,a[role=button].outline:focus,a[role=button].outline:hover,button.outline:active,button.outline:focus,button.outline:hover,input[type=button].outline:active,input[type=button].outline:focus,input[type=button].outline:hover,input[type=reset].outline:active,input[type=reset].outline:focus,input[type=reset].outline:hover,input[type=submit].outline:active,input[type=submit].outline:focus,input[type=submit].outline:hover{--background-color:transparent;--color:var(--primary-hover)}a[role=button].outline.secondary,button.outline.secondary,input[type=button].outline.secondary,input[type=reset].outline.secondary,input[type=submit].outline.secondary{--color:var(--secondary)}a[role=button].outline.secondary:active,a[role=button].outline.secondary:focus,a[role=button].outline.secondary:hover,button.outline.secondary:active,button.outline.secondary:focus,button.outline.secondary:hover,input[type=button].outline.secondary:active,input[type=button].outline.secondary:focus,input[type=button].outline.secondary:hover,input[type=reset].outline.secondary:active,input[type=reset].outline.secondary:focus,input[type=reset].outline.secondary:hover,input[type=submit].outline.secondary:active,input[type=submit].outline.secondary:focus,input[type=submit].outline.secondary:hover{--color:var(--secondary-hover)}a[role=button].outline.contrast,button.outline.contrast,input[type=button].outline.contrast,input[type=reset].outline.contrast,input[type=submit].outline.contrast{--color:var(--contrast)}a[role=button].outline.contrast:active,a[role=button].outline.contrast:focus,a[role=button].outline.contrast:hover,button.outline.contrast:active,button.outline.contrast:focus,button.outline.contrast:hover,input[type=button].outline.contrast:active,input[type=button].outline.contrast:focus,input[type=button].outline.contrast:hover,input[type=reset].outline.contrast:active,input[type=reset].outline.contrast:focus,input[type=reset].outline.contrast:hover,input[type=submit].outline.contrast:active,input[type=submit].outline.contrast:focus,input[type=submit].outline.contrast:hover{--color:var(--contrast-hover)}a[role=button][disabled],button[disabled],input[type=button][disabled],input[type=reset][disabled],input[type=submit][disabled]{opacity:.5;pointer-events:none}input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:1rem;letter-spacing:inherit;line-height:var(--line-height)}input{overflow:visible}select{text-transform:none}legend{max-width:100%;padding:0;color:inherit;white-space:normal}textarea{overflow:auto}[type=checkbox],[type=radio]{padding:0}::-webkit-inner-spin-button,::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}::-moz-focus-inner{padding:0;border-style:none}:-moz-focusring{outline:none}:-moz-ui-invalid{box-shadow:none}::-ms-expand{display:none}[type=file],[type=range]{padding:0;border-width:0}input:not([type=checkbox]):not([type=radio]):not([type=range]){height:calc((1rem * var(--line-height)) + (var(--form-element-spacing-vertical) * 2) + (var(--border-width) * 2))}fieldset{margin:0;margin-bottom:var(--spacing);padding:0;border:0}fieldset legend,label{display:block;margin-bottom:calc(var(--spacing) / 4);vertical-align:middle}input:not([type=checkbox]):not([type=radio]),select,textarea{display:block;width:100%}input:not([type=checkbox]):not([type=radio]):not([type=range]):not([type=file]),select,textarea{-webkit-appearance:none;-moz-appearance:none;appearance:none;padding:var(--form-element-spacing-vertical) var(--form-element-spacing-horizontal);vertical-align:middle}input,select,textarea{--background-color:var(--form-element-background-color);--border-color:var(--form-element-border-color);--color:var(--form-element-color);--box-shadow:none;border:var(--border-width) solid var(--border-color);border-radius:var(--border-radius);outline:none;background-color:var(--background-color);box-shadow:var(--box-shadow);color:var(--color);font-weight:var(--font-weight);transition:background-color var(--transition),border-color var(--transition),color var(--transition),box-shadow var(--transition)}input:not([type=submit]):not([type=button]):not([type=reset]):not([type=checkbox]):not([type=radio]):not([readonly]):active,input:not([type=submit]):not([type=button]):not([type=reset]):not([type=checkbox]):not([type=radio]):not([readonly]):focus,select:active,select:focus,textarea:active,textarea:focus{--background-color:var(--form-element-active-background-color)}input:not([type=submit]):not([type=button]):not([type=reset]):not([role=switch]):not([readonly]):active,input:not([type=submit]):not([type=button]):not([type=reset]):not([role=switch]):not([readonly]):focus,select:active,select:focus,textarea:active,textarea:focus{--border-color:var(--form-element-active-border-color)}input:not([type=submit]):not([type=button]):not([type=reset]):not([type=range]):not([type=file]):not([readonly]):focus,select:focus,textarea:focus{--box-shadow:0 0 0 var(--outline-width) var(--form-element-focus-color)}input:not([type=submit]):not([type=button]):not([type=reset])[disabled],select[disabled],textarea[disabled]{--background-color:var(--form-element-disabled-background-color);--border-color:var(--form-element-disabled-border-color);opacity:var(--form-element-disabled-opacity)}input[aria-invalid],select[aria-invalid],textarea[aria-invalid]{padding-right:2rem;background-position:center right .75rem;background-repeat:no-repeat;background-size:1rem auto}input[aria-invalid=false],select[aria-invalid=false],textarea[aria-invalid=false]{--border-color:var(--form-element-valid-border-color);background-image:var(--icon-valid)}input[aria-invalid=false]:active,input[aria-invalid=false]:focus,select[aria-invalid=false]:active,select[aria-invalid=false]:focus,textarea[aria-invalid=false]:active,textarea[aria-invalid=false]:focus{--border-color:var(--form-element-valid-active-border-color)!important}input[aria-invalid=true],select[aria-invalid=true],textarea[aria-invalid=true]{--border-color:var(--form-element-invalid-border-color);background-image:var(--icon-invalid)}input[aria-invalid=true]:active,input[aria-invalid=true]:focus,select[aria-invalid=true]:active,select[aria-invalid=true]:focus,textarea[aria-invalid=true]:active,textarea[aria-invalid=true]:focus{--border-color:var(--form-element-invalid-active-border-color)!important}input::-webkit-input-placeholder,input::placeholder,select:invalid,textarea::-webkit-input-placeholder,textarea::placeholder{color:var(--form-element-placeholder-color);opacity:1}input:not([type=checkbox]):not([type=radio]),select,textarea{margin-bottom:var(--spacing)}select::-ms-expand{border:0;background-color:transparent}select:not([multiple]):not([size]){padding-right:calc(var(--form-element-spacing-horizontal) + 1.5rem);background-image:var(--icon-chevron);background-position:center right .75rem;background-repeat:no-repeat;background-size:1rem auto}input+small,select+small,textarea+small{display:block;width:100%;margin-top:calc(var(--spacing) * -0.75);margin-bottom:var(--spacing);color:var(--muted-color)}label>input,label>select,label>textarea{margin-top:calc(var(--spacing) / 4)}[type=checkbox],[type=radio]{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:inline-block;width:1.25em;height:1.25em;margin-top:-.125em;margin-right:.375em;border-width:var(--border-width);vertical-align:middle;cursor:pointer}[type=checkbox]::-ms-check,[type=radio]::-ms-check{display:none}[type=checkbox]:checked,[type=checkbox]:checked:active,[type=checkbox]:checked:focus,[type=radio]:checked,[type=radio]:checked:active,[type=radio]:checked:focus{--background-color:var(--primary);--border-color:var(--primary);background-image:var(--icon-checkbox);background-position:center;background-repeat:no-repeat;background-size:.75em auto}[type=checkbox]~label,[type=radio]~label{display:inline-block;margin-right:.375em;margin-bottom:0;cursor:pointer}[type=checkbox]:indeterminate{--background-color:var(--primary);--border-color:var(--primary);background-image:var(--icon-minus);background-position:center;background-repeat:no-repeat;background-size:.75em auto}[type=radio]{border-radius:50%}[type=radio]:checked,[type=radio]:checked:active,[type=radio]:checked:focus{--background-color:var(--primary-inverse);border-width:.35em;background-image:none}[type=checkbox][role=switch]{--background-color:var(--switch-background-color);--border-color:var(--switch-background-color);--color:var(--switch-color);width:2.25em;height:1.25em;border:var(--border-width) solid var(--border-color);border-radius:1.25em;background-color:var(--background-color);line-height:1.25em}[type=checkbox][role=switch]:focus{--background-color:var(--switch-background-color);--border-color:var(--switch-background-color)}[type=checkbox][role=switch]:checked{--background-color:var(--switch-checked-background-color);--border-color:var(--switch-checked-background-color)}[type=checkbox][role=switch]:before{display:block;width:calc(1.25em - (var(--border-width) * 2));height:100%;border-radius:50%;background-color:var(--color);content:'';transition:margin 0.1s ease-in-out}[type=checkbox][role=switch]:checked{background-image:none}[type=checkbox][role=switch]:checked:before{margin-right:0;margin-left:calc(1.125em - var(--border-width))}[type=color]::-webkit-color-swatch-wrapper{padding:0}[type=color]::-moz-focus-inner{padding:0}[type=color]::-webkit-color-swatch{border:none;border-radius:calc(var(--border-radius) / 2)}[type=color]::-moz-color-swatch{border:none;border-radius:calc(var(--border-radius) / 2)}[type=date],[type=datetime-local],[type=month],[type=time],[type=week]{background-image:var(--icon-date);background-position:center right .75rem;background-repeat:no-repeat;background-size:1rem auto}[type=date]::-webkit-calendar-picker-indicator,[type=datetime-local]::-webkit-calendar-picker-indicator,[type=month]::-webkit-calendar-picker-indicator,[type=time]::-webkit-calendar-picker-indicator,[type=week]::-webkit-calendar-picker-indicator{opacity:0}[type=time]{background-image:var(--icon-time)}[type=file]{--color:var(--muted-color);padding:calc(var(--form-element-spacing-vertical)/2) 0;border:none;border-radius:0;background:none}[type=file]::-webkit-file-upload-button{--background-color:var(--secondary);--border-color:var(--secondary);--color:var(--secondary-inverse);margin-right:calc(var(--spacing) / 2);padding:calc(var(--form-element-spacing-vertical) / 2) calc(var(--form-element-spacing-horizontal) / 2);border:var(--border-width) solid var(--border-color);border-radius:var(--border-radius);outline:none;background-color:var(--background-color);box-shadow:var(--box-shadow);color:var(--color);font-size:1rem;font-weight:var(--font-weight);line-height:var(--line-height);text-align:center;cursor:pointer;transition:background-color var(--transition),border-color var(--transition),color var(--transition),box-shadow var(--transition)}[type=file]:active,[type=file]:focus,[type=file]:hover{--color:var(--color);border:none;background:none}[type=file]:active::-webkit-file-upload-button,[type=file]:focus::-webkit-file-upload-button,[type=file]:hover::-webkit-file-upload-button{--background-color:var(--secondary-hover);--border-color:var(--secondary-hover)}[type=range]{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:block;width:100%;height:1.25rem;background:transparent}[type=range]::-webkit-slider-runnable-track{width:100%;height:0.25rem;border-radius:var(--border-radius);background-color:var(--range-border-color);transition:background-color var(--transition),box-shadow var(--transition)}[type=range]::-moz-range-track{width:100%;height:0.25rem;border-radius:var(--border-radius);background-color:var(--range-border-color);transition:background-color var(--transition),box-shadow var(--transition)}[type=range]::-ms-track{width:100%;height:0.25rem;border-radius:var(--border-radius);background-color:var(--range-border-color);transition:background-color var(--transition),box-shadow var(--transition)}[type=range]::-ms-fill-lower{background-color:var(--border-radius)}[type=range]::-webkit-slider-thumb{-webkit-appearance:none;width:1.25rem;height:1.25rem;margin-top:-0.5rem;border:2px solid var(--range-thumb-border-color);border-radius:50%;background-color:var(--range-thumb-color);cursor:pointer;transition:background-color var(--transition),transform var(--transition)}[type=range]::-moz-range-thumb{-webkit-appearance:none;width:1.25rem;height:1.25rem;margin-top:-0.5rem;border:2px solid var(--range-thumb-border-color);border-radius:50%;background-color:var(--range-thumb-color);cursor:pointer;transition:background-color var(--transition),transform var(--transition)}[type=range]::-ms-thumb{-webkit-appearance:none;width:1.25rem;height:1.25rem;margin-top:-0.5rem;border:2px solid var(--range-thumb-border-color);border-radius:50%;background-color:var(--range-thumb-color);cursor:pointer;transition:background-color var(--transition),transform var(--transition)}[type=range]:focus,[type=range]:hover{--range-border-color:var(--range-active-border-color);--range-thumb-color:var(--range-thumb-hover-color)}[type=range]:active{--range-thumb-color:var(--range-thumb-active-color)}[type=range]:active::-webkit-slider-thumb{transform:scale(1.25)}[type=range]:active::-moz-range-thumb{transform:scale(1.25)}[type=range]:active::-ms-thumb{transform:scale(1.25)}[type=search]{border-radius:5rem;padding-left:calc(var(--form-element-spacing-horizontal) + 1.75rem)!important;background-image:var(--icon-search);background-position:center left 1.125rem;background-repeat:no-repeat;background-size:1rem auto}[type=search]::-webkit-search-cancel-button{-webkit-appearance:none;display:none}table{width:100%;border-color:inherit;border-collapse:collapse;border-spacing:0;text-indent:0}td,th{padding:calc(var(--spacing) / 2) var(--spacing);border-bottom:var(--border-width) solid var(--table-border-color);color:var(--color);font-size:var(--font-size);font-weight:var(--font-weight);text-align:left}tr{background-color:var(--background-color)}table[role=grid] tbody tr:nth-child(odd){--background-color:var(--table-row-stripped-background-color)}code,kbd,pre,samp{font-family:var(--font-family);font-size:.875rem}pre{-ms-overflow-style:scrollbar;overflow:auto}code,kbd,pre{background:var(--code-background-color);color:var(--code-color);font-weight:var(--font-weight);line-height:initial}code,kbd{display:inline-block;padding:.375rem .5rem;border-radius:var(--border-radius)}pre{display:block;margin-bottom:var(--spacing);padding:var(--spacing);overflow-x:auto;background:var(--code-background-color)}pre>code{display:block;padding:0;background:transparent;font-size:14px;line-height:var(--line-height)}code b{color:var(--code-tag-color);font-weight:var(--font-weight)}code i{color:var(--code-property-color);font-style:normal}code u{color:var(--code-value-color);text-decoration:none}code em{color:var(--code-comment-color);font-style:normal}kbd{background-color:var(--code-kbd-background-color);color:var(--code-kbd-color);vertical-align:middle}hr{box-sizing:content-box;height:0;overflow:visible;border:none;border-top:1px solid var(--muted-border-color)}[hidden],template{display:none}dialog{display:block;position:absolute;right:0;left:0;width:-moz-fit-content;width:-webkit-fit-content;width:fit-content;height:-moz-fit-content;height:-webkit-fit-content;height:fit-content;margin:auto;padding:1em;border:solid;background-color:white;color:black}dialog:not([open]){display:none}canvas{display:inline-block}details{display:block;margin-bottom:var(--spacing);padding-bottom:calc(var(--spacing) / 2);border-bottom:var(--border-width) solid var(--accordion-border-color)}details summary{color:var(--accordion-close-summary-color);line-height:1rem;list-style-type:none;list-style-type:none;cursor:pointer;transition:color var(--transition)}details summary::-webkit-details-marker{display:none}details summary::marker{display:none}details summary::-moz-list-bullet{list-style-type:none}details summary:after{display:inline-block;width:1rem;height:1rem;float:right;transform:rotate(-90deg);background-image:var(--icon-chevron);background-position:center;background-repeat:no-repeat;background-size:1rem auto;content:'';transition:transform var(--transition)}details summary:focus{outline:none;color:var(--accordion-active-summary-color)}details summary~*{margin-top:calc(var(--spacing) / 2)}details summary~*~*{margin-top:0}details[open]>summary{margin-bottom:calc(var(--spacing) / 4)}details[open]>summary:not(:focus){color:var(--accordion-open-summary-color)}details[open]>summary:after{transform:rotate(0)}article{margin:var(--block-spacing-vertical) 0;padding:var(--block-spacing-vertical) var(--block-spacing-horizontal);overflow:hidden;border-radius:var(--border-radius);background:var(--card-background-color);box-shadow:var(--card-box-shadow)}article>footer,article>header,article>pre{margin-right:calc(var(--block-spacing-horizontal) * -1);margin-left:calc(var(--block-spacing-horizontal) * -1);padding:calc(var(--block-spacing-vertical) / 1.5) var(--block-spacing-horizontal);background-color:var(--card-sectionning-background-color)}article>header{margin-top:calc(var(--block-spacing-vertical) * -1);margin-bottom:var(--block-spacing-vertical);border-bottom:var(--border-width) solid var(--card-border-color)}article>footer,article>pre{margin-top:var(--block-spacing-vertical);margin-bottom:calc(var(--block-spacing-vertical) * -1);border-top:var(--border-width) solid var(--card-border-color)}nav,nav ul{display:flex}nav{justify-content:space-between}nav ol,nav ul{align-items:center;margin-bottom:0;padding:0;list-style:none}nav ol:first-of-type,nav ul:first-of-type{margin-left:calc(var(--spacing) * -0.5)}nav ol:last-of-type,nav ul:last-of-type{margin-right:calc(var(--spacing) * -0.5)}nav li{display:inline-block;margin:0;padding:var(--spacing) calc(var(--spacing) / 2)}nav li>*,nav li>input:not([type=checkbox]):not([type=radio]){margin-bottom:0}nav a{display:block;margin:calc(var(--spacing) * -1) calc(var(--spacing) * -0.5);padding:var(--spacing) calc(var(--spacing) / 2);border-radius:var(--border-radius);text-decoration:none}nav a:active,nav a:focus,nav a:hover{text-decoration:none}aside li,aside nav,aside ol,aside ul{display:block}aside li{padding:calc(var(--spacing) / 2)}aside li a{margin:calc(var(--spacing) * -0.5);padding:calc(var(--spacing) / 2)}progress{display:inline-block;vertical-align:baseline}progress{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:inline-block;width:100%;height:.5rem;margin-bottom:calc(var(--spacing) / 2);overflow:hidden;border:0;border-radius:var(--border-radius);background-color:var(--progress-background-color);color:var(--progress-color)}progress::-webkit-progress-bar{border-radius:var(--border-radius);background:transparent}progress[value]::-webkit-progress-value{background-color:var(--progress-color)}progress::-moz-progress-bar{background-color:var(--progress-color)}@media (prefers-reduced-motion:no-preference){progress:indeterminate{background:var(--progress-background-color) linear-gradient(to right,var(--progress-color) 30%,var(--progress-background-color) 30%) top left/150% 150% no-repeat;animation:progressIndeterminate 1s linear infinite}progress:indeterminate[value]::-webkit-progress-value{background-color:transparent}progress:indeterminate::-moz-progress-bar{background-color:transparent}}@keyframes progressIndeterminate{0%{background-position:200% 0}to{background-position:-200% 0}}[aria-busy=true]{cursor:progress}[aria-busy=true]:not(input):not(select):not(textarea):before{display:inline-block;width:1em;height:1em;border:0.1875em solid currentColor;border-radius:1em;border-right-color:transparent;vertical-align:text-bottom;vertical-align:-.125em;animation:spinner 0.75s linear infinite;content:'';opacity:var(--loading-spinner-opacity)}[aria-busy=true]:not(input):not(select):not(textarea):not(:empty):before{margin-right:calc(var(--spacing) / 2)}[aria-busy=true]:not(input):not(select):not(textarea):empty{text-align:center}a[aria-busy=true],button[aria-busy=true],input[type=button][aria-busy=true],input[type=reset][aria-busy=true],input[type=submit][aria-busy=true]{pointer-events:none}@keyframes spinner{to{transform:rotate(360deg)}}[data-tooltip]{position:relative}[data-tooltip]:not(a):not(button):not(input){border-bottom:1px dotted;text-decoration:none;cursor:help}[data-tooltip]:after,[data-tooltip]:before{display:block;z-index:99;position:absolute;bottom:100%;left:50%;padding:.25rem .5rem;overflow:hidden;transform:translate(-50%,-0.25rem);border-radius:var(--border-radius);background:var(--tooltip-background-color);color:var(--tooltip-color);font-size:.875rem;font-style:normal;font-weight:var(--font-weight);text-decoration:none;text-overflow:ellipsis;white-space:nowrap;content:attr(data-tooltip);opacity:0;pointer-events:none}[data-tooltip]:after{padding:0;transform:translate(-50%,0rem);border-top:.3rem solid;border-right:.3rem solid transparent;border-left:.3rem solid transparent;border-radius:0;background-color:transparent;color:var(--tooltip-background-color);content:''}[data-tooltip]:focus:after,[data-tooltip]:focus:before,[data-tooltip]:hover:after,[data-tooltip]:hover:before{opacity:1;animation-name:slide;animation-duration:.2s}[data-tooltip]:focus:after,[data-tooltip]:hover:after{animation-name:slideCaret}@keyframes slide{0%{transform:translate(-50%,0.75rem);opacity:0}to{transform:translate(-50%,-0.25rem);opacity:1}}@keyframes slideCaret{0%{opacity:0}50%{transform:translate(-50%,-0.25rem);opacity:0}to{transform:translate(-50%,0rem);opacity:1}}[aria-controls]{cursor:pointer}[aria-disabled=true],[disabled]{cursor:not-allowed}[aria-hidden=false][hidden]{display:initial}[aria-hidden=false][hidden]:not(:focus){clip:rect(0,0,0,0);position:absolute}[tabindex],a,area,button,input,label,select,summary,textarea{-ms-touch-action:manipulation}@media (prefers-reduced-motion:reduce){:not([aria-busy=true]),:not([aria-busy=true]):after,:not([aria-busy=true]):before{background-attachment:initial!important;animation-duration:1ms!important;animation-delay:-1ms!important;animation-iteration-count:1!important;scroll-behavior:auto!important;transition-delay:0s!important;transition-duration:0s!important}}
    </style>
    <style type="text/css">
      article div {
        font-size: 1.15em;
        line-height: 1.6em;
      }
    </style>
  </head>
  <body style="background-color: #f9fafb;">
    <main class="container">
      <nav>
        <ul>
          <li><a href="../index.html">← Topic list</a></li>
        </ul>
      </nav>
      <!-- <h1>Infomedia Articles Selection: 50 articles</h1> -->
      <h1>hSBM 0_108 <kbd>H_0_108</kbd></h1>
      <h3>Words (top 25)</h3>
      <div style="margin:0px -12px">
        <span style="font-size:17.71pt; padding:0px 12px"><strong>]</strong>&nbsp;<span style="font-size:.5em">450</span></span>
        <span style="font-size:17.57pt; padding:0px 12px"><strong>[</strong>&nbsp;<span style="font-size:.5em">431</span></span>
        <span style="font-size:16.81pt; padding:0px 12px"><strong>blog</strong>&nbsp;<span style="font-size:.5em">337</span></span>
        <span style="font-size:15.64pt; padding:0px 12px"><strong>gpt-3</strong>&nbsp;<span style="font-size:.5em">215</span></span>
        <span style="font-size:15.45pt; padding:0px 12px"><strong>python</strong>&nbsp;<span style="font-size:.5em">198</span></span>
        <span style="font-size:15.38pt; padding:0px 12px"><strong>forklaringer</strong>&nbsp;<span style="font-size:.5em">192</span></span>
        <span style="font-size:14.67pt; padding:0px 12px"><strong>java</strong>&nbsp;<span style="font-size:.5em">135</span></span>
        <span style="font-size:14.62pt; padding:0px 12px"><strong>|</strong>&nbsp;<span style="font-size:.5em">131</span></span>
        <span style="font-size:14.29pt; padding:0px 12px"><strong>fairness</strong>&nbsp;<span style="font-size:.5em">108</span></span>
        <span style="font-size:14.21pt; padding:0px 12px"><strong>repræsentation</strong>&nbsp;<span style="font-size:.5em">103</span></span>
        <span style="font-size:14.19pt; padding:0px 12px"><strong>l.</strong>&nbsp;<span style="font-size:.5em">102</span></span>
        <span style="font-size:14.18pt; padding:0px 12px"><strong>code</strong>&nbsp;<span style="font-size:.5em">101</span></span>
        <span style="font-size:14.15pt; padding:0px 12px"><strong>models</strong>&nbsp;<span style="font-size:.5em">99</span></span>
        <span style="font-size:13.97pt; padding:0px 12px"><strong>conference</strong>&nbsp;<span style="font-size:.5em">88</span></span>
        <span style="font-size:13.93pt; padding:0px 12px"><strong>speed</strong>&nbsp;<span style="font-size:.5em">86</span></span>
        <span style="font-size:13.83pt; padding:0px 12px"><strong>{</strong>&nbsp;<span style="font-size:.5em">80</span></span>
        <span style="font-size:13.81pt; padding:0px 12px"><strong>skævheder</strong>&nbsp;<span style="font-size:.5em">79</span></span>
        <span style="font-size:13.76pt; padding:0px 12px"><strong>nedenstående</strong>&nbsp;<span style="font-size:.5em">76</span></span>
        <span style="font-size:13.74pt; padding:0px 12px"><strong>forklarlighed</strong>&nbsp;<span style="font-size:.5em">75</span></span>
        <span style="font-size:13.59pt; padding:0px 12px"><strong>recognition</strong>&nbsp;<span style="font-size:.5em">67</span></span>
        <span style="font-size:13.59pt; padding:0px 12px"><strong>lineære</strong>&nbsp;<span style="font-size:.5em">67</span></span>
        <span style="font-size:13.51pt; padding:0px 12px"><strong>computational</strong>&nbsp;<span style="font-size:.5em">63</span></span>
        <span style="font-size:13.49pt; padding:0px 12px"><strong>binære</strong>&nbsp;<span style="font-size:.5em">62</span></span>
        <span style="font-size:13.49pt; padding:0px 12px"><strong>javascript</strong>&nbsp;<span style="font-size:.5em">62</span></span>
        <span style="font-size:13.37pt; padding:0px 12px"><strong>pp.</strong>&nbsp;<span style="font-size:.5em">56</span></span>
      </div>
      <br><br>
      <h3>Articles (top 50)</h3>
      Query:
      <pre>SELECT * FROM articles WHERE articles.dupeKeep=1 AND articles.sizeKeep=1 ORDER BY H_0_108 DESC LIMIT 50</pre>
      <article>
        <h4>Metoder inden for Explainable AI (XAI)</h4>
        <div>
          Explainable AI (XAI), altså forklarlig kunstig intelligens, har meget fokus i øjeblikket, fordi maskinlæringsmodeller bliver mere ugennemskuelige og komplekse, og fordi datadrevne modeller bliver brugt mere til kritiske beslutninger og af ikke-ekspertbrugere. Der findes dog mange forskellige måder at lave forklarlig kunstig intelligens på og dermed også et hav af forskellige metoder. Ved at definere egenskaber og typer af metoder og forklaringer og ved at give et overblik over de mest kendte metoder, vil vi hjælpe med at finde rundt i junglen af XAI-metoder.Bekymringer om forklarlighed vedrørende systemer baseret på kunstig intelligens er ikke noget nyt, se f.eks. 'ekspertsystemer' [1], 'case-based reasoning' [2, 3] eller, for et historisk overblik, se reviewet der blev lavet som del af DARPAs XAI projekt [4]. Men i de sidste 2-3 år er der kommet et hav af nye metoder til at lave forklarlig kunstig intelligens.Hvad er forskellen mellem de forskellige metoder? Hvilke typer af forklaringer generer de? Og hvilke metoder passer i hvilken situation, til hvilke type data eller modeller? I dette blogindlæg giver vi et overblik over forskellige metoder og grupperer dem ved at definere en taksonomi af XAI-metoder. Taksonomien og inddelingen i forskellige grupper er inspireret af diagrammet fra IBM's AIX360 open-source bibliotek, Christoph Molnars e-bog og forskellige artikler om XAI-metoder [5, 6, 7, 8, 9, 10, 11, 12].Helt generelt kan man adskille metoder på måden, man interagerer med dem. De kan være statiske eller interaktive (får man bare en eller flere forklaringer, eller kan man også ''spørge'' ind til en anden eller dybere forklaring). Der findes dog os bekendt ingen interaktive metoder, så vi fokuserer her udelukkende på statiske metoder.Desuden kan man gruppere XAI-metoder efter hvilken type af data, de er egnet til, og efter hvilke typer af forklaring de genererer. Der findes både metoder, der kan forklare data, og metoder, der forklarer modellerne. Sidstnævnte kan videre separeres på 1) hvilket område forklaringerne virker på, altså forklarer de dele af modellen (global ) eller modellens resultater (lokal ), 2) om det er modeller, der kan forklare sig selv (iboende ) eller metoder, der forklarer en ugennemsigtig model (post-hoc ), og 3) om de er lavet til en specifik type af model.I det følgende vil vi beskrive, lidt mere i dybden, hvilke typer af data der kan forekomme, hvilke typer af forklaringer der eksisterer, og hvad iboende, post-hoc, lokal og global egentlig betyder, samt nævne nogle eksempler på XAI-metoder i hver kategori. Til sidst giver vi et overblik over et udvalg af metoder i form af et taksonomitræ.Typer af dataForklaringer og XAI-metoder er afhængige af den datatype, som modellen er udviklet til. De fleste anvendelser af datadrevne modeller er lavet til tabel-, billede-, tekstdata eller tidsserier.TabeldataTabeldata data er data, der kan beskrives i form af en tabel, hvor hver kolonne repræsenterer en variabel eller feature, og hver række repræsenterer et eksempel eller datapunkt. Denne type data er brugt i de mest klassiske anvendelser af maskinlæring, såsom fraud detection eller churn prediction. Desuden kan mange andre datakilder tit udtrykkes som en tabel gennem såkaldt feature extraction.BilleddataBilleddata er den type data, der forekommer i computer vision-opgaver, såsom object detection, optical character recognition eller image segmentation. Hvert billede i datasættet repræsenterer et eksempel eller datapunkt. Man kan bruge dybe neurale netværk (convolutional neural networks) til billeddata, eller ekstrahere nogle features fra et billede så datasættet kan udtrykkes som en tabel.TekstdataTekstdata er den type data, der forekommer i NLP-opgaver (natural language processing), som f.eks. named entity recognition, speech to text, eller at analysere toner i debatten. Hver tekst, såsom sætninger, afsnit eller dokumenter, i datasættet repræsenterer et eksempel eller datapunkt. Man kan bruge dybe neurale netværk (recurrent neural networks) til tekstdata, eller ekstrahere nogle features fra tekster så datasættet kan udtrykkes som tabel.TidsserierTidsserier bliver tit udtrykt som tabeldata, så det kan bruges til maskinlæring. Derfor kan alle XAI-metoder, der arbejder på tabeldata, normalt også bruges på tidsserier.Typer af forklaringerForklarlighed skal altid defineres i en given kontekst. Denne kontekst indeholder mål og andre dimensioner, der er afhængige af tidsbegrænsninger og slutbrugerens ekspertise i forhold til maskinlæring [5] (se også vores andet blogindlæg om forklarlighed ).Tiden, en bruger har til at forstå eller kigge på en forklaring, kan være begrænset i en given applikation, som sætter begrænsninger på forklarligheden. Yderligere begrænsninger og krav er givet fra den type bruger, der interagerer med modellen. Brugerens ekspertise kan være alt imellem en beslutningstager uden teknisk baggrund og høje domæneviden, som læger, dommere, eller planlæggere, over forskere eller ingeniører med en basis, teknisk viden, hen til data scientists og maskinlæringseksperter med en dyb viden om selve modellen. Forskellige typer af brugere har brug for forskellige typer af forklaringer. I den her del af blogindlægget vil vi gerne komme det nærmere, hvilke typer af forklaringer, der findes, og hvordan de udmønter sig. Det er dog ikke en udtømmende liste, og det er vigtigt at bemærke, at nogle gange kan en brugers behov løses gennem UX-design eller forklaringer, der ikke er automatisk genererede.EksemplerEn måde at generere forklaringer på er ved at bruge eksempler. Fordelen ved forklaringer gennem eksempler er, at det er let forståeligt for slutbrugeren eller domæneeksperten, da eksempler, og dermed forklaringer, kommer fra selve datadomænet. Desuden bruger mennesker tit eksempler til at træffe en beslutning, såkaldt cased-based reasoning [2, 3]. For eksempel når en læge stiller en diagnose, er det baseret på symptomer, og de erfaringer han har med patienter, der har udvist lignende symptomer. Eller når en data-scientist skal løse en opgave, så husker han en opgave, han har løst tidligere, og hvilke metoder og modeller der virkede bedst til at løse opgaven.Dog giver det kun mening at bruge eksempler som forklaring, hvis selve data let kan repræsenteres og er forståeligt. Det gælder for eksempel for billeder eller tekst, som mennesker kan give en mening til. Det kan også virke for tabeldata, men det kræver, at kolonner (variabler) har en mening, som pris, antal værelser eller hustype for et hus-datasæt, og at der kun er en håndfuld kolonner, ellers er enkelte datapunkter ikke gennemskuelige.PrototyperEksemplerne kan både bruges som forklaring af selve data eller for at forklare en models resultat. For at forklare data søger man efter de eksempler i et datasæt, der bedst repræsenterer datasættet, såkaldte prototyper. Når man har et datasæt med forskellige grupper (klassifikationsproblem), vil man som regel finde prototyper for hver klasse.Udover prototyper er det også vigtig at kunne afgrænse datasættet, altså finde de datapunkter der ligger på grænsen af datasættet eller længst væk fra prototyperne, såkaldt criticisms. Det blev først præsenteret fra Kim et al. sammen med deres MMD-critic metode[13]. ProtoDash er en anden metode til at finde prototyper og criticisms og er en videreførelse af 'MMD-critic' lavet af en IBM-forsker [14].Udover at finde repræsentative datapunkter i et datasæt findes der også modeller, der sammen med deres output giver en prototype-forklaring [15, 16].Eksempler fra træningsdataEksempler kan ikke kun bruges til at forklare data, men også til at forklare et bestemt resultat af modellen [17]. En måde at gøre det på er at finde de eksempler fra træningsdata, der havde mest indflydelse på modellens beslutning [18]. Det kræver, at man definerer en såkaldt influencer-funktion, der kan beregne indflydelsen.En klassisk maskinlæringsmodel, der træffer beslutninger baseret direkte på eksempler fra træningsdata, er k-nearest neighbour (k-NN ). Her får man forklaringer som eksempler ''gratis'' sammen med modellens resultat. Der findes også forskning til at bruge k-NN sammen med et dybt neural netværk til at både lære komplekse sammenhæng i data og få en forklaring [19].CounterfactualsEn anden måde at bruge eksempler som en beslutningsforklaring på er at finde counterfactuals [20]. Counterfactuals undersøger, hvad der ville være sket, hvis udgangspunktet havde været anderledes, altså hvilke fakta-ændringer der ville have sørget for et modsat resultat. Hvis man for eksempel får afvist et lån, så kan det være, at man ville have fået det, hvis man havde en højere indkomst. Den form for kontrastiv forklaring er også tit brugt af mennesker [21].Der findes forskellige metoder til at generere counterfactuals på, både til tabeldata [22], billeddata [23] og forskellige datatyper [24, 25].ReglerRegel-baserede modeller, såkaldte ekspertsystemer, har været måden at lave forklarlige modeller på og var meget populære i 80'erne. I disse systemer bliver regler defineret af domæneeksperter, og så kan de bruges til en automatisk beslutning. Disse regler har en hvis-så form, f.eks. hvis der er skyer, og gulvet er vådt, så har det regnet. Reglerne kan have flere betingelser (''der er skyer'', ''gulvet er vådt''), men kun maksimalt to resultater (''det regnede'', ''det regnede ikke''). Reglerne kan kombineres med hinanden og udføres efter hinanden, dvs. en regel bestemmer hvilken regel, der skal bruges i næste trin.Udover ekspertsystemer findes der også maskinlæringsmodeller, der automatisk genererer regler baseret på sammenhænge i data [26, 27, 28]. En bestemt form af disse modeller er beslutningstræer, hvor regler er binære (en betingelse og to veje) og kombineret i et træ. Beslutninger bliver så lavet ved at starte i roden af træet og følge regler igennem, indtil man lander i et blad, som udgør resultatet.Regler kan både bruges til at forklare hele modellen gennem alle reglerne, modellen består af, og som lokal forklaring ved at give de regler der var afgørende for en bestemt beslutning [29].Feature attributionsFeature attributions er den type forklaring, der er mest udbredt i de metoder, der er blevet udviklet for nyligt, og som der er mest hype omkring. Feature attributions beskriver for hver variabel, hvor vigtig den er for modellens resultat. Det kan både være globalt, altså hvilke variabler er grundsatslig vigtige, eller lokalt, altså hvilke variabler var mest afgørende for en bestemt beslutning.Når man kigger i junglen af maskinlæringsmodeller så findes der en gruppe af såkaldt lineære modeller: lineær regression, logistisk regression, Generalized Linear Models (GLMs) og Generalized Additive Models (GAMs). På grund af deres struktur er det muligt at få både en global eller lokal forklaring i form af feature attributions (læs mere ved at klikke på links). Der har været en del udvikling i den seneste tid af algoritmer til at lave lineære modeller, der har lige så god eller bedre performance end mere komplekse black-box-modeller, f.eks. GA2M [30] eller SLIM [31].Der findes også metoder, der kan generere feature attributions for en ikke-lineær black-box-model, f.eks. SHAP [32], som er baseret på såkaldte shapley values [33], LIME [34], DeepLIFT[35], Grad-CAM [36] eller LRP [37]. De sidstnævnte (DeepLIFT, Grad-CAM og LRP) er specielt lavet til dybe neurale netværk, og her er idéen blandt andet, at outputtet af netværket bliver ført tilbage til inputtet igennem netværket for at vise, hvilke dele af inputtet der var mest betydningsfulde. De fleste af disse metoder virker på alle typer af data, og vi vil gerne beskrive i lidt flere detaljer, hvordan feature attributions kan se ud på billede- eller tekstdata.BillederFeatures i billeder er de enkelte pixels i billedet eller dele af billedet. Så når vi bruger feature attributions på billeddata, handler det om at markere de pixels eller områder i billedet, som var mest betydningsfulde for modellens resultat.TekstFeatures i tekst er de enkelte ord eller sætninger i teksten. Så når vi bruger feature attributions på tekstdata, handler det om at markere de ord, som var mest betydningsfulde for modellens resultat.VisualiseringerVisualiseringer er en god måde at repræsentere komplekse sammenhænge på, og er den foretrukne måde for data scientists, statistikere og analytikere til at forstå data og modeller. Desuden er smarte visualiseringer hjertet af business intelligence-løsninger. Visualiseringer er derfor også en god måde at forklare data eller modeller på.Her vil vi kort beskrive forskellige måder at bruge visualiseringer som forklaring på. Vær opmærksom på at nogle af de tidligere præsenterede typer af forklaringer (regler og feature attributions) også skal visualiseres, men der findes mange forskellige måder at gøre det på, hvorimod de visualiseringer, vi beskriver her, hænger tæt sammen med metoden.DatavisualiseringerLigesom med andre typer forklaringer, så kan man både forklare data og modeller. Visualiseringer bliver som regel brugt til at forstå data, inden man begynder at designe og træne en model. Det er forholdsvis nemt at visualisere enkelte eksempler på tekst- og billeddata, da deres form allerede er en visualisering i sig selv. Der er dog udfordringer med at visualisere et helt datasæt. Her bruger man tit en form af 'manifold visualisering', f.eks. t-SNE.For tabeldata kræves det først, at man reducerer dimensionen af de enkelte datapunkter til 2 eller 3 variabler, da data så kan visualiseres i et 2D eller 3D plot. Principal component analysis (PCA ) er en kendt metode til reducering af dimensioner. Yellowbrick er et godt Python-bibliotek, der samler forskellige visualiserings- og dimensionsreducerings-metoder.Partial dependence plot (PDP)Partial Dependence Plots (PDPs ) er en måde til at forklare en model. Selve plotsene viser, hvordan værdien af en enkelt variabel, eller værdierne af et par af variablerne, ændrer modellens resultat. Det er Jerome H. Friedman, der først præsenterede PDP i 2001 [38].Goldstein et al. videreudviklede metoden til Individual Conditional Expectation (ICE) plots, hvor man også kan se effekten for et eller flere udvalgte datapunkter, udover at kun se den samlede effekt [39]. ICE plots kan dog kun laves for en enkelt variabel ad gangen.Neuron-visualiseringerDybe neurale netværk består af hundrede eller tusindvis af neuroner, der er forbundet til hinanden og organiseret i en grafstruktur med forskellige lag. Hvert lag eller gruppe af lag transformerer data fra selve inputtet til outputtet af modellen igennem mere og mere abstrakte repræsentationer, jo dybere (tættere på output) man kommer ned i netværket.Der findes forskellige metoder til at visualisere disse abstrakte repræsentationer, som modellen har lært [40]. Metoderne er begrænset på billed- eller tekstdata, da visualiseringer som billed eller tekst intuitivt kan forstås. Med tabeldata er det svært at forstå abstrakte repræsentationer, da de ikke direkte relaterer tilbage til input-domænet eller specifikke attributter.Det er for eksempel brugbart til at visualisere, hvordan netværket ''ser'' et bestemt input i de forskellige lag [40, 41, 42], eller til at visualisere hvad forskellige neuroner eller lag i netværket detekterer eller ekstraherer generelt fra dataene [43, 44, 45, 46].KoncepterKoncepter er det, der kommer tættest på, hvordan vi som mennesker forstår verden. Når vi ser et objekt med hjul, så tænker vi nok, at man kan køre med det, selvom vi måske ikke kender selve objektet. Når vi ser et dyr med vinger, så vil vi nok genkende det som en fugl, også hvis vi ikke har set den type fugl før. Ved at interagere med vores omverden og ved at læse bøger, se film, gå i skole osv. lærer vi koncepter, der kan hjælpe også med at forstå nye ting.Nuværende modeller brugt i maskinlæring, der bliver trænet med data, lærer ikke koncepter eller kausale sammenhænge, men en korrelation mellem input- og output-variabler. Der er derfor en aktiv forskning, der handler om, hvordan vi kan skabe modeller, der faktisk har lært koncepter, f.eks. causal inference [47] (se også DoWhy eller CausalNex Python-biblioteker) eller kognitive modeller [48]. Men forskningen er bare påbegyndt og er ikke moden nok til at blive brugt i industrien, selvom der er nogle lovende resultater inden for både NLP [49] og computer vision (Neuro-Symbolic Concept Learner ).Når vi så snakker om koncepter her, så handler det stadig om modeller, der lærer en korrelation, men som ved hjælp af værktøjer kan generere en forklaring, der kommer tæt på koncept-tanken og adskiller sig fra de øvrige typer af forklaringer, vi har beskrevet i dette indlæg.En måde at få konceptforklaringer på er at annotere datasættet, så hvert datapunkt også har en konceptlignende forklaring givet af en domæneekspert, og så træne en model der både genererer et output og en forklaring [50].En anden måde er ved at definere koncepter gennem eksempel-datapunkter og undersøge sensitiviteten overfor disse datapunkter for hver af modellens output i et klassificerings-problem [51]. For eksempel kan man undersøge om en model til at klassificere billeder er sensitiv overfor konceptet ''striber'', når den klassificerer en zebra. Ghorbani et al. automatiserer denne tilgang, så koncepterne bliver genereret automatisk for et givent billede [52].Det er også muligt at træne en model, så den kan svare på spørgsmål i forhold til et billede, såkaldt visual question answering [53, 54, 55]. Her handler det om, at modellen forstår de koncepter, der er til stede i spørgsmålene og billedet.Global eller lokal - Post-hoc eller iboendeI ovenstående afsnit har vi set, at forklaringsmetoder kan grupperes afhængigt af, hvilken type forklaring de genererer. En anden måde at adskille metoderne, der forklarer modeller på, er baseret på deres virkningsområde. Typisk adskiller man mellem global og lokal [5, 56, 57].Global forklarlighed gør det muligt at forstå hele logikken bag, hvordan en model virker og at følge dens ræsonnement for alle mulige prædiktioner [5]. Global forklarlighed kan videre separeres i transparens [10], som man også kalder iboende, global forklarlighed, og post-hoc global forklarlighed [56]. Hvor transparens er en direkte egenskab, der er bygget ind i modellen, er post-hoc global forklarlighed som regel udført ved at bruge en metode, der forklarer hvilke mønstre, en model har lært [56].Lokal forklarlighed giver yderligere informationer og forklaringer om en enkelt models prædiktion. Ligesom ved global forklarlighed kan man igen adskille imellem iboende lokal forklarlighed og post-hoc lokal forklarlighed [10, 56].Global forklarlighedDatadrevne modeller, især dem baseret på maskinlæring og deep learning, er tit beskrevet som ugennemskuelige ''black boxes'', hvor det selv for eksperter er svært at forstå modellens indre logikker. Global forklarlighed kan forstås som en modsætning til en black box. Global forklarlighed er evnet til at forklare hele modellens logik og at følge dens beslutning hele vejen igennem fra input-data til modellens prædiktion [5]. Det kan opnås ved at bygge en model, der har iboende global forklarlighed (transparent) eller ved at bruge en post-hoc model til at forklare en black box-models logik.TransparensTransparens er defineret som evnen til direkte at forstå hele modellen. Algoritmer eller metoder til at generere en transparent model, kan man gruppere under ''transparent design'' [5].Men hvad er transparens egentlig? Z. C. Lipton beskriver forskellige typer af transparens: simulatibility (simulerbarhed), decomposability (nedbrydelighed) og algoritmisk transparens [10]:Følger man Liptons definition af transparens, er lineære regressionsmodeller, beslutningstræer og regel-baserede modeller alle sammen transparente, da man ''nemt'' kan forstå og beregne de underliggende mekanismer. Men disse modeller kan hurtigt blive store (antal af parametre, dybden og bredden af træet, antal af regler). Så hvornår er de små nok til stadig at gælde som global forklarlige? En mulighed for at undgå problemet er at tilføje begrænsninger i træningsprocessen, der minimerer størrelsen og kompleksiteten af modellen. Den strategi kan bruges både til ''enkle'' modeller, som lineære regressioner og beslutningstræer, men også til black box-modeller som neurale netværk [58].Transparens kan også defineres som en grad af transparens fra black box til fuld transparens, hvor nogle dele af modellen er transparente og nogen andre er uigennemskuelige.Post-hoc global forklarlighedPost-hoc global forklarlighed opnås ved at anvende metoder på black box-modeller for at gøre dem global forklarlige. For eksempel kan man vise, hvor meget forskellige input-variabler og deres værdier har indflydelse på modellens prædiktion (PDP [38], ICE [39], permutation test ).For dybe neurale netværk (DNN) ligesom convolutional neural networks (CNN) eller recurrent neural networks (RNN) (tit brugt sammen med billed- eller tekstdata), findes der særlige post-hoc metoder. Disse metoder prøver at ekstrahere, hvilke repræsentationer et dyb neuralt netværk har lært af data [40, 43, 44, 45, 46]. Repræsentationer er en implicit abstraktion fra den ''rå'' data (billede eller tekst), lært af de første lag af et netværk, for eksempel lag der genkender kanter i et billede [46]. Desuden findes der metoder til at undersøge, om modellen har lært bestemte koncepter [51].Disse typer af post-hoc globale forklaringsmetoder, der kan bruges til at få indsigt i black box-modellen ved at belyse dele af dens logik, kalder Guidotti et al. ''black box-inspektions''-metoder [5]. Det er dog ikke den eneste type af metoder til post-hoc global forklarlighed. Der findes også de såkaldte ''surrogat-model''-metoder.Surrogat-modellerSurrogat-model-metoder, eller model-forklaringsmetoder (model explanation) [5], bygger en model til at erstatte black box-modellen, hvor black box-modellen er brugt til prædiktioner og surrogat-modellen til at generere forklaringer. Sidstnævnte model skal virke på samme måde som den originale black box-model, altså generere prædiktioner så tæt som muligt på black box-modellens prædiktioner. Hvis det ikke er tilfældet, så forklarer denne model ikke black box-modellen, men kun sig selv. Selvfølgelig vil surrogat-modellen altid være forskellig, dvs. have en ringere performance en black box-modellen, da man ellers kunne erstatte black box-modellen fuldstændig med surrogat-modellen.Surrogat-modeller tager som regel form af de klassiske transparente modeller, ligesom lineære modeller [59], beslutningstræer [60, 61], eller regel-baserede modeller [62], men kan også være et simpel neuralt netværk [63].Lokal forklarlighedI de fleste tilfælde vil det være svært at bruge en transparent model til at opnå global forklarlighed, men det er tit nok til at forklare en bestemt prædiktion. Man kan faktisk argumentere for, at der skabes en mental repræsentation af modellen, når man interagerer med en model længe nok og samtidig får lokale forklaringer. Jo mere den mentale repræsentation afspejler den faktiske model, jo mere global forklarlig er modellen for brugeren.Forklaringer, der er genereret af lokal forklarlige metoder, kan være tekst, visualiseringer, eksempler i træningsdata eller feature attributions [10]. Ligesom med global forklarlighed kan man adskille mellem iboende lokal forklarlighed og post-hoc lokal forklarlighed [56].Iboende lokal forklarlighedModeller, der har iboende global forklarlighed, er som regel også lokal forklarlige, ligesom lineære modeller, beslutningstræer eller regel-basered modeller. Der findes dog også modeller, der opnår lokal forklarlighed ved at tilføje dele til en model, der genererer en forklaring [15, 52, 64], hvor forklaringer er en del af træningsdata [50], eller hvor selve konceptet er, at prædikationer er baseret på eksempler (k-NN ). I alle tilfælde er modellen bygget, så den genererer en forklaring sammen med en prædiktion.Når vi kigger på dybe neurale netværk, så kan man for eksempel tilføje særlige lag, der genererer (og lærer) forklaringer [15, 16, 52, 64, 65, 66]. Det kan være i form af eksempler eller prototyper [15, 16], koncepter [52], tekst [65] eller feature attribution [64, 66]. Og så findes der også en metode, der kombinerer neurale netværk, der hver især genkender dele af et billede til et beslutningstræ og dermed opnår forklarlighed (Neural-Backed Decision Tree ) [67].Post-hoc lokal forklarlighedMetoder til post-hoc lokal forklarlighed gør modeller forklarlige gennem en separat proces efter prædiktionen. Det ligner måden, den menneskelige hjerne virker på, hvor der er forskellige processer til at træffe en beslutning og at forklare den.Metoder til post-hoc lokal forklarlighed, også kaldt ''resultat-forklaring'' (outcome explanation) [5], kan fungere på forskellige måder. Det kan for eksempel være metoder, der arbejder primært med et eksempel-datasæt og modellens output til at finde lignende eller betydningsfulde eksempler [14, 18], eller metoder der finder counterfactuals [22, 23, 24, 25]. Andre metoder udnytter modellens struktur, f.eks. at det er et neuralt netværk [35, 36, 37], bruger idéen om shapley values [32, 68, 69], eller bygger en transparent model for et lokalt område [29, 34].Fordelen ved post-hoc lokal forklarlighed er, at man ikke behøver at pille ved selve modellen, og at mange metoder fungerer med forskellige typer af black box-modeller. Tit har de dog brug for adgang til modelstrukturen for at udnytte den til at generere forklaringer hurtigere og mere nøjagtigt.ModeltypeModeller, der er transparente eller har en iboende lokal forklarlighed, har en bestemt type. Det kan være lineære modeller, regel-baserede modeller, beslutningstræer, versioner af k-NN eller neurale netværk [15, 16, 52, 58, 64, 65, 66] eller kombinationer af det [67].Post-hoc metoder derimod virker i forbindelse med en black box-model til at gøre den forklarlig. Typen af model kan have en betydning for, hvilken post-hoc metode man kan bruge. De typer af black box-modeller, man typisk ser, er dybe neural netværk, enten med convolutional layers eller recurrent layers, ensemble-modeller bestående af beslutningstræer (Random Forest, Gradient Boosting [70, 71], eller ensemblemodeller sat sammen af forskellige andre typer af modeller.Der findes post-hoc metoder, der er model-agnostiske, dvs. de virker med alle typer black box-modeller, da de bare skal have mulighed for at få modellens resultater for et givent input [14, 24, 25, 29, 32, 39, 59]. Andre metoder er lavet specifikt til dybe neurale netværk [72, 73] og kræver, at man har adgang til selve netværket, da de udnytter netværksstrukturen [23, 36, 51, 63], bruger en lignende proces til at generere forklaringer, som man bruger til at træne af netværket [35, 37], eller viser hvad netværket har lært [40, 43, 44, 45, 46].Nogle metoder eksisterer kun til træ-baserede modeller eller er en variant af en model-agnostisk metode optimeret til træer [74], og andre kræver, at man har adgang til en gradient, man også bruger i træningsprocessen [18].TaksonomitræEfter vi nu har været inde over datatyper, typer af forklaringer og typer af XAI-metoder, samt hvordan nogle modeller er lavet til en bestemt type black box-modeller, vil vi nu give et overblik over forskellige XAI-metoder i form af et taksonomitræ.Træet viser ikke alle metoder, der findes, men metoderne er valgt, så de, så vidt muligt, afdækker alle typer af forklaringer, data og black box-modeller. Hvis der er flere metoder i en kategori, så har vi udvalgt den mest udbredte, bedst dokumenterede eller den metode, hvor der findes en god open source-implementering. For hver metode indikerer farverige kasser, hvilken type data de er egnet til, og farven af metoden viser, om de er til en bestemt type black box-model.Her kan du læse Christoph Molnars e-bog for hver metode.Tak for fordi du læste med!Dette synspunkt blev oprindeligt bragt i Medium.Bibliografi[1] Peter Jackson, Introduction to Expert Systems, Harlow: Addison-Wesley Longman, 1990.[2] A. Kofod-Petersen, J. Cassens og A. Aamodt, Explanatory Capabilities in the CREEK Knowledge-Intensive Case-Based Reasoner, Proceedings of SCAI 2008, pp. 28-35, 2008.[3] A. Aamodt og E. Plaza, Case-Based Reasoning: Foundational Issues, Methodological Variations, and System Approaches, AI Communications 7(1), pp. 39-59, 1994.[4] S. T. Mueller, R. R. Hoffman, W. Clancey et al., Explanation in Artificial Intelligence Systems: An Historical Perspective, Explanation in Human-AI Systems: A Literature Meta-Review, Synopsis of Key Ideas and Publications, and Bibliography for Explainable AI, DARPA XAI Program, pp. 43-70, 2019.[5] R. Guidotti, A. Monreale, S Ruggieri et al., A Survey Of Methods For Explaining Black Box Models, arXiv:1802.01933v3 [cs.CY], 2018.[6] B. Mittelstadt, C. Russell og S. Wachter, Explaining Explanations in AI, arXiv:1811.01439v1[cs.AI], 2018.[7] G. Ras, M. van Gerven og P. Haselager, Explanation Methods in Deep Learning: Users, Values, Concerns and Challenges, arXiv:1803.07517v2 [cs.AI], 2018.[8] A. Adadi og M. Berrada, Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI), IEEE Access 6, pp. 52138-52160, 2018.[9] M. Du, N. Liu og X. Hu, Techniques for Interpretable Machine Learning, arXiv:1808.00033v3[cs.LG], 2019.[10] Z. C. Lipton, The Mythos of Model Interpretability, arXiv:1606.03490v3 [cs.LG], 2017.[11] S. Chakraborty, R. Tomsett, R. Raghavendra et al., Interpretability of deep learning models: A survey of results, IEEE 2017 SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI, pp. 1-6, 2017.[12] G. Vilone og L. Longo, Explainable Artificial Intelligence: a Systematic Review, arXiv:2006.00093 [cs.AI], 2020.[13] B. Kim, R. Khanna og O. O. Koyejo, Examples are not enough, learn to criticize! Criticism for Interpretability, NIPS 2016, pp. 2280-2288, 2016.[14] K. S. Gurumoorthy, A. Dhurandhar, G. Cecchi et al., Efficient Data Representation by Selecting Prototypes with Importance Weights, arXiv:1707.01212 [stat.ML], 2019.[15] C. Chen, O. Li, C. Tao et al., This Looks Like That: Deep Learning for Interpretable Image Recognition, arXiv:1806.10574v5 [cs.LG], 28 december 2019.[16] S. O. Arik og T. Pfister, ProtoAttend: Attention-Based Prototypical Learning, arXiv:1902.06292 [cs.LG], 2019.[17] C. J. Cai, J. Jongejan og J. Holbrook, The Effects of Example-Based Explanations in a Machine Learning Interface, IUI '19, pp. 258-262, 2019.[18] P. W. Koh og P. Liang, Understanding Black-box Predictions via Influence Functions, arXiv:1703.04730 [stat.ML], 2017.[19] N. Papernot og P. McDaniel, Deep k-Nearest Neighbors: Towards Confident, Interpretable and Robust Deep Learning, arXiv:1803.04765 [cs.LG], 2018.[20] S. Wachter, B. Mittelstadt og C. Russell, Counterfactual Explanations without Opening the Black Box: Automated Decisions and the GDPR, arXiv:1711.00399 [cs.AI], 2017.[21] Tim Miller, Explanation in Artificial Intelligence: Insights from the Social Sciences, arXiv:1706.07269 [cs.AI], 2017.[22] R. K. Mothilal, A. Sharma og C. Tan, Explaining machine learning classifiers through diverse counterfactual explanations, FAT* 2020, pp. 607-617, 2020.[23] Y. Goyal, Z. Wu, J. Ernst et al., Counterfactual Visual Explanations, Proceedings of the 36th ICML, pp. 2376-2384, 2019.[24] S. Sharma, J. Henderson og J. Ghosh, CERTIFAI: Counterfactual Explanations for Robustness, Transparency, Interpretability, and Fairness of Artificial Intelligence models, arXiv:1905.07857 [cs.LG], 2019.[25] A. Dhurandhar, P.-Y. Chen, R. Luss et al., Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives, NIPS 2018, pp. 592-603, 2018.[26] C. Chen og C. Rudin, An Optimization Approach to Learning Falling Rule Lists, arXiv:1710.02572 [cs.LG], 2017.[27] H. Lakkaraju, S. H. Bach og J. Leskovec, Interpretable Decision Sets: A Joint Framework for Description and Prediction, KDD'16, pp. 1675-1684, 2016.[28] J. H. Friedman og B. E. Popescu, Predictive learning via rule ensembles, Ann. Appl. Stat. 2 (3), pp. 916-954, 2008.[29] M. T. Ribeiro, S. Singh og C. Guestrin, Anchors: High-Precision Model-Agnostic Explanations, AAAI 2018, 2018.[30] 
. Lou, R. Caruana, J. Gehrke at al., Accurate intelligible models with pairwise interactions, KDD'13, pp. 623-631, 2013.[31] B. Ustun og C. Rudin, Supersparse Linear Integer Models for Optimized Medical Scoring Systems, arXiv:1502.04269 [stat.ML], 2015.[32] S. M. Lundberg og S.-I. Lee, A Unified Approach to Interpreting Model Predictions, NIPS 2018, pp. 4765-4774, 2017.[33] M. Sundararajan og A. Najmi, The Many Shapley Values for Model Explanation, ICML 2020, 2020.[34] M. T. Ribeiro, S. Singh og C. Guestrin, ''Why should i trust you?'': Explaining the predictions of any classifier, KDD'16, pp. 1135-1144, 2016.[35] A. Shrikumar, P. Greenside og A. Kundaje, Learning Important Features Through Propagating Activation Differences, arXiv:1704.02685 [cs.CV], 2017.[36] R. R. Selvaraju, M. Cogswell, A. Das et al., Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization, ICCV'17, pp. 618-626, 2017.[37] S. Bach, A. Binder, G. Montavon et al., On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation, PLOS ONE 10(7): e0130140, 2015.[38] Jerome H. Friedman, Greedy Function Approximation: A Gradient Boosting Machine, The Annals of Statistics 29(5), pp. 1189-1232, 2001.[39] A. Goldstein, A. Kapelner, J. Bleich et al., Peeking Inside the Black Box: Visualizing Statistical Learning With Plots of Individual Conditional Expectation, Journal of Computational and Graphical Statistics, pp. 44-65, 2015.[40] C. Olah, A. Satyanarayan, I. Johnson et al., The Building Blocks of Interpretability, Distill, 2018.[41] H. Strobelt, S. Gehrmann, H. Pfister et al., LSTMVis: A Tool for Visual Analysis of Hidden State Dynamics in Recurrent Neural Networks, arXiv:1606.07461 [cs.CL], 2016.[42] L. Arras, F. Horn, G. Montavon et al., ''What is Relevant in a Text Document?'': An Interpretable Machine Learning Approach, arXiv:1612.07843 [cs.CL], 2016.[43] C. Olah, A. Mordvintsev og L. Schubert, Feature Visualization, Distill, 2017.[44] A. Nguyen, A. Dosovitskiy, J. Yosinski et al., Synthesizing the preferred inputs for neurons in neural networks via deep generator networks, NIPS 2016, pp. 3387-3395, 2016.[45] A. Karpathy, J. Johnson og L. Fei-Fei, Visualizing and Understanding Recurrent Networks, arXiv:1506.02078 [cs.LG], 2015.[46] M. D. Zeiler og R. Fergus, Visualizing and Understanding Convolutional Networks, arXiv:1311.2901v3 [cs.CV], 2013.[47] Bernhard Schölkopf, »Causality for Machine Learning, arXiv:1911.10500 [cs.LG], 2019.[48] Gary Marcus, The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence, arXiv:2002.06177 [cs.AI], 2020.[49] P. Clark, O. Etzioni, D. Khashabi et al., From 'F' to 'A' on the N.Y. Regents Science Exams: An Overview of the Aristo Project, arXiv:1909.01958 [cs.CL], 2019.[50] M. Hind, D. Wei, M. Campbell et al., TED: Teaching AI to Explain its Decisions, AIES'19, pp. 123-129, 2019.[51] B. Kim, M. Wattenberg, J. Gilmer et al., Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV), arXiv:1711.11279[stat.ML], 2017.[52] A. Ghorbani, J. Wexler, J. Y. Zou et al., Towards Automatic Concept-based Explanations,« NIPS 2019, pp. 9277-9286, 2019.[53] Y. Goyal, T. Khot, A. Agrawal et al., Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering, International Journal of Computer Vision 127, pp. 398-414, 2019.[54] R. Hu, J. Andreas, M. Rohrbach et al., Learning to Reason: End-To-End Module Networks for Visual Question Answering, ICCV 2017, pp. 804-813, 2017.[55] J. Mao, C. Gan, P. Kohli et al., The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences from Natural Supervision, arXiv:1904.12584 [cs.CV], 2019.[56] M. Nu, N. Liu og X. Hu, Techniques for Interpretable Machine Learning, arXiv:1808.00033v2 [cs.LG], 2018.[57] Adrian Weller, Challenges for Transparency, arXiv:1708.01870v1 [cs.CY], 2017.[58] Q. Zhang, Y. N. Wu, S.-C. Zhu, Interpretable CNNs, arXiv:1901.02413v1 [cs.LG], 2019.[59] S. Tan, R. Caruana, G. Hooker et al., Distill-and-Compare: Auditing Black-Box Models Using Transparent Model Distillation, AIES'18, pp. 303-310, 2018.[60] C. Yang, A. Rangarajan og S. Ranka, Global Model Interpretation via Recursive Partitioning, arXiv:1802.04253 [cs.LG], 2018.[61] O. Bastani, C. Kim og H. Bastani, Interpretability via Model Extraction, arXiv:1706.09773[cs.LG], 2017.[62] W. J. Murdoch og A. Szlam, Automatic Rule Extraction from Long Short Term Memory Networks, arXiv:1702.02540 [cs.CL], 2017.[63] A. Dhurandhar, K. Shanmugam, R. Luss et al., Improving Simple Models with Confidence Profiles, NIPS 2018, pp. 10296-10306, 2018.[64] E. Choi, M. T. Bahadori, J. A. Kulas et al., RETAIN: An Interpretable Predictive Model for Healthcare using Reverse Time Attention Mechanism, arXiv:1608.05745v4 [cs.LG], 2017.[65] K. Xu, J. Ba, R. Kiros et al., Show, Attend and Tell: Neural Image Caption Genereation with Visual Attention, arXiv:1502.03044v3 [cs.LG], 2016.[66] Amirhossein Tavanaei, Embedded Encoder-Decoder in Convolutional Networks Towards Explainable AI, arXiv:2007.06712 [cs.CV], 2020.[67] A. Wan, L. Dunlap, D. Ho et al., NBDT: Neural-Backed Decision Tree, arXiv:2004.00221[cs.CV], 2020.[68] K. Aas, M. Jullum og A. Løland, Explaining individual predictions when features are dependent: More accurate approximations to Shapley values, arXiv:1903.10464[stat.ML], 2019.[69] M. Sundararajan og A. Najmi, The many Shapley values for model explanation, arXiv:1908.08474 [cs.AI], 2019.[70] T. Chen og C. Guestrin, XGBoost: A Scalable Tree Boosting System, KDD'16, pp. 785-794, 2016.[71] G. Ke, Q. Meng, T. Finley et al., LightGBM: A Highly Efficient Gradient Boosting Decision Tree, NIPS 2017, pp. 3146-3154, 2017.[72] G. Montavon, W. Samek og K.-R. Müller, Methods for interpreting and understanding deep neural networks, Digital Signal Processing 73, pp. 1-15, 2018.[73] W. Samek, G. Montavon, A. Vedaldi, L. K. Hansen og K.-R. Müller (Eds.), Explainable AI: Interpreting, Explaining and Visualizing Deep Learning, Springer, 2019.[74] S. M. Lundberg, G. Erion, H. Chen et al., From local explanations to global understanding with explainable AI for trees, Nature Machine Intelligence 2, pp. 56-67, 2020.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2020-11-26
          &nbsp;·&nbsp; e80203c1
          &nbsp;·&nbsp; #0
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.981</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.725</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.54</kbd>
        </footer>
      </article>
      <article>
        <h4>PRM / Coreferensmodeller â?? nu også på dansk!</h4>
        <div>
          KøbenhavnPressemeddelelse fra Alexandra InstituttetBlogindlægget er skrevet af Maria Barrett, Postdoc ved Institut for Datalogi på IT-Universitetet, og er udgivet på Alexandra Instituttets blog for NLP og dansk sprogteknologi på Medium: DaNLPCoreferens er i Natural Language Processing (NLP) en opgave, hvor man skal finde alle tekstbidder (spans) i en tekst, der henviser til den samme entitet. En entitet kan være en person, et sted, en event eller en organisation, men det kan også være en ikke-navngiven hændelse/handling.Som andre opgaver inden for NLP bliver coreferens løst med kunstig intelligens. I dette blogindlæg tager vi en teknisk tur ind i maskinrummet bag coreferens og præsenterer de første offenligt tilgængelige, danske coreferensmodeller, der bygger på kunstig intelligens.Løsning af coreferens er en central underopgave for en række sproglige opgaver som fx automatisk at svare på spørgsmål ud fra en tekst eller lave et resumé. Disse er afhængige af, at modellen kan identificere alle benævnelser for fx en person i et dokument, uanset om denne er nævnt ved sit navn, et personligt stedord eller en anden nominalfrase.Som med mange andre NLP-opgaver er det noget, som mennesker helt automatisk gør, når vi læser. Coreferens er et svært problem for et computerprogram at løse automatisk, fordi benævnelser kan være meget lange og også meget langt væk fra hinanden i et dokument.Som eksempel på et meget kort dokument, kan vi tage følgende tweet:Input til en coreferens-model er et helt dokument, i dette tilfælde et enkelt tweet. Modellen identificerer og grupperer herefter de tekstbidder, der henviser til samme entitet. I tweetet vil en god coreferensmodel identificere følgende tre klynger:(I, I)(Obama, her)(her husband)Det vil sige, at en coreferensmodel som input tager et dokument og som output leverer klynger af tekstbidder, der henviser til samme entitet.Dansk coreferens-dataFor at træne en coreferensmodel ved hjælp af kunstig intelligens og for at evaluere hvor god den trænede model er, skal man bruge data, der er korrekt annoteret af et menneske, en såkaldt guldannotering. I dette afsnit fortæller jeg om den danske coreferensannotering vi har brugt til at træne og evaluere de danske coreferensmodeller med.Vi har brugt en annotering fra the Copenhagen Dependency Treebank project (Kromann &amp; Lynge, 2004). Annoteringen er ikke færdiggjort for hele træbanken, men dækker ca 2/3 , men er fint dokumenteret. Det annoterede sæt består af 64.076 tokens fordelt på over 341 dokumenter. Det er primært nyhedstekst, men også noget fra forskellige tidsskrifter.Datasættet er tilgængeligt gennem DaNLP sammen med dokument-id'er for vores trænings- udviklings- og evaluerings-split så alle kan træne og evaluere deres egne coreferensmodeller.Neurale coreferens-modellerI dette afsnit vil vi beskrive de tekniske detaljer for de to danske coreferensmodeller, der begge bygger på kunstig intelligens. Vil du hellere gå direkte til evalueringsresultatet for modellerne, så kan du læse mere under &amp;lsquo,Resultater' nederst i artiklen.Løsning af coreferens er typisk blevet behandlet i flere stadier. Først har modellen detekteret mulige benævnelser, og derefter lært om de parvis er coreferente. Det er regnemæssigt effektivt og skalerer godt til lange dokumenter. Man har typisk haft flere modeller med i træningsloopet, fx en syntaksparser til at opmærke grammatiske strukturer og eventuelt også regelbaserede elementer (altså elementer i modellen der ikke bygger på kunstig intelligens). Det vil sige, at en coreferensmodel tidligere bestod af flere forskellige modeller, der blev trænet separat. Det kan man læse mere om i Ng (2010).Men i 2017 præsenterede Lee et al. den første end-to-end coreferens-model, der er en ren neural model uden behov for andre modeller. &quot;End-to-end&quot; betyder, at modellen både finder benævnelser og grupperer dem i samme træningspas. Der er heller ikke brug for en separat syntaksparser. Uden benævnelsesdetektion som et separat trin, kan alle tekstbidder i princippet være en benævnelse, men for at reducere regneaktiviteten udregnes modellen en score per par af benævnelser (fundet i tidligere iterationer) og mulige tekstbidder. Listen af disse bliver iterativt og aggressivt beskåret for at reducere antallet af beregninger. Benævnelses-tekstbid-repræsentationerne bruger både teksbidden selv og konteksten omkring den i repræsentationen. Modellen bruger en bidirectional LSTM for at encode teksten og konteksten. Denne model viste i 2017, at den var bedre end tidligere metoder på det engelske data fra CoNLL-2012 shared task, som kommer fra Ontonotes (Pradhan et al., 2012), som er det engelske benchmark-datasæt.I 2018 lavede Lee et al. en opdatering af ovennævnte model i artiklen Higher-order Coreference Resolution with Coarse-to-fine inference . Den tidligere model fra 2017 er en førsteordensmodel, fordi den kun forholder sig til par af tekstbidder. Lee et al. (2018) påpeger, at førsteordensmodeller kan rumme globale inkonsistenser. Higher-order-modellen i Lee et al. 2018 forholder sig til flere mulige kandidatspans per (mulige) span i en matrice (og ikke udregnet som en parvis score).Oprindeligt blev begge modeller brugt med word-embeddings som vektorrepræsentationer for ordene, men Joshi et al. (2019) viste, at man kunne få endnu bedre resultater på engelsk, hvis man i stedet brugte SpanBERT (Joshi et al., 2020) og BERT (Devlin et al., 2019). Da der ikke er en dansk SpanBERT, er de danske modeller trænet på andre præ-trænede repræsentationer fra transformere. Vi har brugt dansk BERT , som er en uncased model og to flersprogede, cased modeller: Multilingual BERT citat og XLM-Roberta (Conneau et al., 2020). I stedet for den originale tensorflowimplementering har vi brugt pytorchimplementeringerne fra AllenNLP.Resultaterne for den danske coreferens-model på det danske testssplit, der indeholder 28 dokumenter, kan ses i tabellen nedenfor. Modellen er trænet med early stopping over 12000 epochs, og vi har tunet modellernes læringsrate, og læringsraten for transformermodellerne over 50 epochs.ResultaterDen bedste model er Lee et al. 2018 med udgangspunkt i XLM-Roberta. Alle modellerne kan findes som del af DaNLP toolkittet.Gennemsnit af F1, precison og recall fra MUC, CEAF og B3 samt mention recall for hver af de seks danske coreferens-modeller.Hvordan skal resultaterne forstås?Mention recall er en procentsats for, hvor mange af de korrekte tekstbidder, der er fundet. Men derefter skal man finde en god måde at kvantificere, hvor korrekt de er clustret.Coreferens har (mindst) et problem: Det er svært at evaluere. Overvej fx hvilken af følgende modeller der er bedst (eller mindst dårlig) for tweetet ovenfor. Den korrekte annotering er - som tidligere nævnt:(I, I) (Obama, her) (her husband)Model 1: (I, I)Model 2: (I) (I) (Obama) (her) (her husband)Model 3: (I, I, her husband, Obama) (her)De har hver især deres kvaliteter. Hvor model 1 kun har fundet 40% af de oprindelige tekstbidder, har den trods alt formået at gruppere disse korrekt. Model 2 og 3 har fundet alle de korrekte tekstbidder, men har grupperet dem forkert på hver deres måde.Der er flere forskellige metrikker til at forsøge at måle overensstemmelsen mellem to forskellige annoteringer, men de fleste er enige om, at ingen af dem er gode nok til at stå alene. Selvom et gennemsnit af flere halvdårlige mål ikke giver et perfekt resultat, er der mange, der bruger et gennemsnit af følgende tre metrikker: MUC, B3 og CEAF. De har hver en precision, recall og F1. Det er også disse gennemsnit, der kan ses i tabellen.ReferencerJeffrey Pennington, Richard Socher, and Christopher D Manning. 2014. Glove: Global vectors for word representation. In Proceedings of the 2014 conference on Empirical Methods in Natural Language Processing (EMNLP).Conneau, A., Khandelwal, K., Goyal, N., Chaudhary, V., Wenzek, G., Guzmán, F., Grave, E., Ott, M., Zettlemoyer, L. &amp; Stoyanov, V. (2020). Unsupervised Cross-lingual Representation Learning at Scale. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (pp. 8440-8451).Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. (2019, June). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) (pp. 4171-4186).Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. (2019, June). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) (pp. 4171-4186).Joshi, M., Chen, D., Liu, Y., Weld, D. S., Zettlemoyer, L., &amp; Levy, O. (2020). Spanbert: Improving pre-training by representing and predicting spans. In Transactions of the Association for Computational Linguistics, 8, 64-77.Joshi, M., Levy, O., Zettlemoyer, L., &amp; Weld, D. S. (2019). BERT for Coreference Resolution: Baselines and Analysis. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP) (pp. 5807-5812).M.T. Kromann and S.K. Lynge. Danish Dependency Treebank v. 1.0. Department of Computational Linguistics, Copenhagen Business School., 2004. https://github.com/mbkromann/copenhagen-dependency-treebankLee, K., He, L., Lewis, M., &amp; Zettlemoyer, L. (2017, September). End-to-end Neural Coreference Resolution. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (pp. 188-197).Lee, K., He, L., &amp; Zettlemoyer, L. (2018, June). Higher-Order Coreference Resolution with Coarse-to-Fine Inference. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers) (pp. 687-692).Vincent Ng. 2010. Supervised noun phrase coreference research: The first fifteen years. In Proceedings of the 48th annual meeting of the association for computational linguistics, pages 1396-1411. Association for Computational Linguistics.Sameer Pradhan, Alessandro Moschitti, Nianwen Xue, Olga Uryupina, and Yuchen Zhang. 2012. Conll2012 shared task: Modeling multilingual unrestricted coreference in ontonotes. In Joint Conference on EMNLP and CoNLL - Shared Task, pages 1-40. Association for Computational Linguistics.Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010. Word representations: A Simple and General Method for Semi-supervised Learning. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics.Xu, L., &amp; Choi, J. D. (2020, November). Revealing the Myth of Higher-Order Inference in Coreference Resolution. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) (pp. 8527-8533).Kontakt:Communications Specialist Lisa Lorentzen tlf.: +45 93 52 17 64 email: lisa.lorentzen@alexandra.dkLæs hele pressemeddelelsen på Via Ritzau her: https://via.ritzau.dk/pressemeddelelse/coreferensmodeller-nu-ogsa-pa-dansk?releaseId=13620730** Ovenstående pressemeddelelse er videreformidlet af Ritzau på vegne af tredjepart. Ritzau er derfor ikke ansvarlig for indholdet ** 
        </div>
        <footer>
          <em>Ritzaus Bureau</em>
          &nbsp;·&nbsp; 2021-04-26
          &nbsp;·&nbsp; e83cbaf1
          &nbsp;·&nbsp; #1
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.994</kbd>
            <kbd data-tooltip="AI &amp; innovation">L05_INNOAI&nbsp;0.576</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.532</kbd>
        </footer>
      </article>
      <article>
        <h4>Coreferensmodeller - nu også på dansk!</h4>
        <div>
          De første offentligt tilgængelige, danske coreferensmodeller er klar til brug.BrødtekstCoreferens er i Natural Language Processing (NLP) en opgave, hvor man skal finde alle tekstbidder (spans) i en tekst, der henviser til den samme entitet. En entitet kan være en person, et sted, en event eller en organisation, men det kan også være en ikke-navngiven hændelse/handling.Som andre opgaver inden for NLP bliver coreferens løst med kunstig intelligens.Løsning af coreferens er en central underopgave for en række sproglige opgaver som fx automatisk at svare på spørgsmål ud fra en tekst eller lave et resumé. Disse er afhængige af, at modellen kan identificere alle benævnelser for fx en person i et dokument, uanset om denne er nævnt ved sit navn, et personligt stedord eller en anden nominalfrase.Som med mange andre NLP-opgaver er det noget, som mennesker helt automatisk gør, når vi læser. Coreferens er et svært problem for et computerprogram at løse automatisk, fordi benævnelser kan være meget lange og også meget langt væk fra hinanden i et dokument.Som eksempel på et meget kort dokument, kan vi tage følgende tweet:Input til en coreferensmodel er et helt dokument, i dette tilfælde et enkelt tweet. Modellen identificerer og grupperer herefter de tekstbidder, der henviser til samme entitet. I tweetet vil en god coreferensmodel identificere følgende tre klynger:(I, I)(Obama, her)(her husband)Det vil sige, at en coreferensmodel som input tager et dokument og som output leverer klynger af tekstbidder, der henviser til samme entitet.Dansk coreferens-dataFor at træne en coreferensmodel ved hjælp af kunstig intelligens og for at evaluere hvor god den trænede model er, skal man bruge data, der er korrekt annoteret af et menneske, en såkaldt guldannotering. I dette afsnit fortæller jeg, om den danske coreferensannotering vi har brugt til at træne og evaluere de danske coreferensmodeller med.Vi har brugt en annotering fra the Copenhagen Dependency Treebank project (Kromann &amp; Lynge, 2004). Annoteringen er ikke færdiggjort for hele træbanken, men dækker ca. 2/3, men er fint dokumenteret. Det annoterede sæt består af 64.076 tokens fordelt på over 341 dokumenter. Det er primært nyhedstekst, men også noget fra forskellige tidsskrifter.Datasættet er tilgængeligt gennem DaNLP sammen med dokument-id'er for vores trænings-, udviklings- og evaluerings-split så alle kan træne og evaluere deres egne coreferensmodeller.Neurale coreferens-modellerI dette afsnit vil vi beskrive de tekniske detaljer for de to danske coreferensmodeller, der begge bygger på kunstig intelligens. Vil du hellere gå direkte til evalueringsresultatet for modellerne, så kan du læse mere under 'Resultater' nederst i artiklen.Løsning af coreferens er typisk blevet behandlet i flere stadier. Først har modellen detekteret mulige benævnelser og derefter lært, om de parvis er coreferente. Det er regnemæssigt effektivt og skalerer godt til lange dokumenter. Man har typisk haft flere modeller med i træningsloopet, fx en syntaksparser til at opmærke grammatiske strukturer og eventuelt også regelbaserede elementer (altså elementer i modellen der ikke bygger på kunstig intelligens). Det vil sige, at en coreferensmodel tidligere bestod af flere forskellige modeller, der blev trænet separat. Det kan man læse mere om i Ng (2010).Men i 2017 præsenterede Lee et al. den første end-to-end coreferens-model, der er en ren neural model uden behov for andre modeller. »End-to-end« betyder, at modellen både finder benævnelser og grupperer dem i samme træningspas. Der er heller ikke brug for en separat syntaksparser. Uden benævnelsesdetektion som et separat trin kan alle tekstbidder i princippet være en benævnelse, men for at reducere regneaktiviteten udregnes modellen en score per par af benævnelser (fundet i tidligere iterationer) og mulige tekstbidder. Listen af disse bliver iterativt og aggressivt beskåret for at reducere antallet af beregninger. Benævnelses-tekstbid-repræsentationerne bruger både teksbidden selv og konteksten omkring den i repræsentationen. Modellen bruger en bidirectional LSTM for at encode teksten og konteksten. Denne model viste i 2017, at den var bedre end tidligere metoder på det engelske data fra CoNLL-2012 shared task, som kommer fra Ontonotes (Pradhan et al., 2012), som er det engelske benchmark-datasæt.I 2018 lavede Lee et al. en opdatering af ovennævnte model i artiklen Higher-order Coreference Resolution with Coarse-to-fine inference. Den tidligere model fra 2017 er en førsteordensmodel, fordi den kun forholder sig til par af tekstbidder. Lee et al. (2018) påpeger, at førsteordensmodeller kan rumme globale inkonsistenser. Higher-order-modellen i Lee et al. 2018 forholder sig til flere mulige kandidatspans per (mulige) span i en matrice (og ikke udregnet som en parvis score).Oprindeligt blev begge modeller brugt med word-embeddings som vektorrepræsentationer for ordene, men Joshi et al. (2019) viste, at man kunne få endnu bedre resultater på engelsk, hvis man i stedet brugte SpanBERT (Joshi et al., 2020) og BERT (Devlin et al., 2019). Da der ikke er en dansk SpanBERT, er de danske modeller trænet på andre præ-trænede repræsentationer fra transformere. Vi har brugt dansk BERT, som er en uncased model og to flersprogede, cased modeller: Multilingual BERT citat og XLM-Roberta (Conneau et al., 2020). I stedet for den originale tensorflowimplementering har vi brugt pytorchimplementeringerne fra AllenNLP.Resultaterne for den danske coreferens-model på det danske testssplit, der indeholder 28 dokumenter, kan ses i tabellen nedenfor. Modellen er trænet med early stopping over 12.000 epochs, og vi har tunet modellernes læringsrate, og læringsraten for transformermodellerne over 50 epochs.ResultaterDen bedste model er Lee et al. 2018 med udgangspunkt i XLM-Roberta. Alle modellerne kan findes som del af DaNLP toolkittet.Representation | Model | Avg. F1 | Avg. Precision | Avg. Recall | Mention recall-------------------|-------------------|---------|----------------|-------------|----------------Danish BERT | Lee et al. (2017) | 0.477 | 0.587 | 0.402 | 0.729Danish BERT | Lee et al. (2018) | 0.313 | 0.655 | 0.207 | 0.683Multilingual BERT | Lee et al. (2017) | 0.630 | 0.679 | 0.587 | 0.870Multilingual BERT | Lee et al. (2018) | 0.532 | 0.625 | 0.463 | 0.854XLM-Roberta | Lee et al. (2017) | 0.623 | 0.668 | 0.585 | 0.822XLM-Roberta | Lee et al. (2018) | 0.64 | 0.699 | 0.592 | 0.88Gennemsnit af F1, precison og recall fra MUC, CEAF og B3 samt mention recall for hver af de seks danske coreferens-modeller.Mention recall er en procentsats for, hvor mange af de korrekte tekstbidder, der er fundet. Men derefter skal man finde en god måde at kvantificere, hvor korrekt de er clustret.Coreferens har (mindst) et problem: Det er svært at evaluere. Overvej fx hvilken af følgende modeller der er bedst (eller mindst dårlig) for tweetet ovenfor. Den korrekte annotering er - som tidligere nævnt:(I, I) (Obama, her) (her husband)Model 1: (I, I)Model 2: (I) (I) (Obama) (her) (her husband)Model 3: (I, I, her husband, Obama) (her)De har hver især deres kvaliteter. Hvor model 1 kun har fundet 40 pct. af de oprindelige tekstbidder, har den trods alt formået at gruppere disse korrekt. Model 2 og 3 har fundet alle de korrekte tekstbidder, men har grupperet dem forkert på hver deres måde.Der er flere forskellige metrikker til at forsøge at måle overensstemmelsen mellem to forskellige annoteringer, men de fleste er enige om, at ingen af dem er gode nok til at stå alene. Selvom et gennemsnit af flere halvdårlige mål ikke giver et perfekt resultat, er der mange, der bruger et gennemsnit af følgende tre metrikker: MUC, B3 og CEAF. De har hver en precision, recall og F1. Det er også disse gennemsnit, der kan ses i tabellen.Dette indlæg er oprindeliget udgivet på
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2021-05-04
          &nbsp;·&nbsp; e83fa5d0
          &nbsp;·&nbsp; #2
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.922</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.782</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.623</kbd>
        </footer>
      </article>
      <article>
        <h4>PRM / Hvad betyder forklarlighed, når vi taler om kunstig intelligens?</h4>
        <div>
          KøbenhavnPressemeddelelse fra Alexandra InstituttetDe mange termer der beskriver forklarlig kunstig intelligens (explainable AI)Vi anvender kunstig intelligens på stadig flere områder, og beslutninger baseret på kunstig intelligens kommer tættere på at påvirke vores privatliv. I den forbindelse er der dukket mange begreber op, som explainable (forklarlig) kunstig intelligens, interpretable (fortolkbar) maskinlæring, transparent kunstig intelligens og intelligible (forståelig) kunstig intelligens. I figuren nedenunder kan du se udviklingen i Google-søgninger på 'Explainable Artificial Intelligence' og 'Interpretable Machine Learning' op til 2019.Google Trends over hele verden på &quot;explainable AI&quot; og &quot;interpretable ML&quot; op til 2019 (Data kilde: Google Trends).Men hvad er egentlig meningen bag de begreber, og hvordan definerer man forklarlighed? Vi starter med at prøve at definere forklarlighed baseret på ordbogsdefinitionen af &quot;at forklare&quot;, som skaber grundlag for begreberne inden for forklarlig kunstig intelligens.Senere i blogindlægget kan du læse om, hvilke egenskaber en model skal have, for at vi kan kalde den forklarlig, ud fra de definitioner vi kommer ind på nu.DefinitionNår man kigger i ordbogen, kan man finde følgende definition af &quot;at forklare&quot;:gøre noget klart for andre ved at beskrive, oplyse eller på anden måde fortælle nærmere om detangive en årsag eller grund til noget, gøre rede for nogetBaseret på den engelske definition har Doshi-Velez et al.&amp;sup1, defineret &quot;interpretability&quot; i konteksten af kunstig intelligens på den følgende måde:&quot;the ability to explain or present in understandable terms to a human&quot; (evne til at forklare eller præsentere på en forståelige måde til et menneske)Med andre ord kan forklarlighed ses som en interface mellem en model og brugeren af modellen, der forklarer modellen eller dele af modellen til brugeren. Det er dog ikke tydeligt, hvordan &quot;evne til at forklare&quot; er defineret, og hvad &quot;på en forståelig måde&quot; betyder fra et teknisk perspektiv, da forklarlighed eller gennemsigtighed er afhængig af målet, og hvem eller hvad det er målrettet til. Der findes derfor ikke en enkelt definition af forklarlighed, men til gengæld findes der mange nuancer betinget af konteksten og målet.Derfor vil vi nu præsentere de forskellige kontekster og målgrupper, som typisk er i spil i forhold til forklarlig kunstig intelligens, så vi kan nærme os en mere konkret og anvendelig definition, man kan tage udgangspunkt i, når vi udvikler kunstig intelligens.Forskellige mål af forklarlighedSom regel er datadrevne modeller, der er lavet ved (supervised) maskinlæring, evalueret gennem metrikker (se en artikel på towards data science og sklearns guide), der sammenligner &quot;eksempel-data&quot;, man ved, der er rigtigt, med modellens forudsigelse. Men der er andre faktorer, man også kan evaluere modellen på, og der påvirker modellens værdi eller omkostninger, når modellen er sat i drift, f.eks. tillid, informationsindhold, opretholdelse af etik, osv. Det er tit ikke muligt til at definere metrikker, der måler disse faktorer, så den eneste løsning til at evaluere dem er gennem forklarlighed. Vi vil nu beskrive de mest almindelige mål og faktorer af forklarlighed, også kaldet &quot;desire-data&quot;&amp;sup2,, såsom tillid, fairness og etik, information, transfer af viden, debugging og monitorering. Flowcharten herned guider dig igennem disse mål af forklarlighed og hvilke målgrupper der er tilknyttet.Flowchart der igennem mål af forklarlighed og hvilke målgrupper der er tilknyttet.TillidTillid til en model er vigtigt, for at slutbrugerne faktisk bruger modellen og agerer på dens resultater og anbefalinger. Tillid kan have forskellige former: 1) Tillid til at modellen virker. Her kan det være nok at bruge almindelige metrikker til at vise modellens evner. 2) Det kan også være tillid til, at modellen virker i drift. Det vil sige viden om, hvordan modellen opfører sig i nye, ukendte scenarier og viden om modellens styrker (hvornår virker det?) og begrænsninger (hvornår virker det ikke?).Det er tit ikke muligt at definere trænings- eller testdata, der dækker alle eksisterende og mulige kommende scenarier, og det er derfor kun muligt at måle modellens nøjagtighed på scenarier beskrevet i dataene. I andre situationer kan der opstå såkaldt &quot;concept-drift&quot;, altså at sammenhænge i data ændrer sig og afviger fra de data, modellen blev trænet på, efter modellen er blevet sat i drift. I begge tilfælde vil det øge tilliden til modellens performance i uforudsete omgivelser, hvis man kunne forstå eller forklare, hvordan modellen virker.Fair og etiskAfhængigt af konteksten, hvori modellen er brugt, kan der kræves bestemte etiske standarder (f.eks. etiske guidelines fra EU's High-Level Expert Group on Artificial Intelligence), og nogle gange endnu et bevis på det lovmæssige ansvar. Den europæiske GDPR, for eksempel, beskriver, at en person, der er påvirket af en automatisk beslutningsproces, har mulighed for at få &quot;meningsfulde oplysninger om logikken&quot; (GDPR Art. 15), og at dem, der ejer modellen, skal sørge for &quot;passende foranstaltninger til at beskytte den registreredes rettigheder&quot; (GDPR Art. 22). Hvad meningsfulde oplysninger er, og i hvilken grad det handler om forklarlighed, er der dog debat om&amp;sup3, â´ âµ. Men uanset hvad, så er det sikkert, at forklarlighed i den rigtige form vil hjælpe med at vurdere om etiske, fair og lovmæssige krav er opfyldt eller forklarlighed kan være en måde til at opfylder dem direkte.InformationsindholdIsær når en model interagerer med en ikke-teknisk slutbruger, og når modellen er brugt til beslutningsstøtte, kan yderlige information om hvordan en model virker, og hvorfor den er kommet med et bestemt resultat være vigtigtâ¶. Det kan blive relevant, når modellens output kun er en del af en beslutningsproces, eller hvis modellens resultater skal forklares videre af brugeren til en anden person.Forestil dig for eksempel at du spørger en læge, hvilken behandling der vil virke bedst på en bestemt sygdom, du har. Det er slet ikke nok bare at få navnet at vide eller beskrivelsen af behandlingen - du vil også være interesseret i hvorfor, det er den bedste behandling, hvad der er af alternativer, og om der er nogle risici. I dette tilfælde kræves der flere informationer for at træffe en god beslutning.Overførsel af videnFordi modellen opbygger &quot;viden&quot; om et problem eller en repræsentation af en løsning (baseret på data), kunne det være interessant at overføre denne viden til et menneske eller en anden maskine (model). Kun hvis vi forstår modellens beslutninger eller forudsigelser og evnen til at kunne forklare disse, er det muligt at overføre viden på en måde.Overførsel af viden kan også være en vigtig faktor til modellens værdi eller brugbarhed. Selvom modellen er trænet og testet på forskellige data, for at vise evnen til at modellen kan generalisere godt på nye data, blev det vist, at en models resultat kan manipuleres ved små ændringer i inputdataene (Intriguing properties of neural networks). Modellerne, der kan overføre viden og opbygge kausalitetssammenhænge i stedet for &quot;bare&quot; at finde korrelationer, kunne være bedre beskyttet imod disse angreb.DebuggingForklaringer kan være et yderligere værktøj til at finde nye strategier til at forbedre og debugge en model, f.eks. til at finde ud af hvorfor modellen virker dårligt på bestemte eksempler i dataene eller som hjælp til at fjerne unødvendige inputvariabler.De kan også bruges til at verificere, at modellen &quot;kigger&quot; på de rigtige ting, og at den ikke har lært mærkelige korrelationer i data, som for eksempel at finde skibe i et billede på grund af at der er vand, men ikke på grund af skibet, eller at genkende heste på grund af et vandmærke i stedet for hestenâ·, eller at forudsige en lavere risiko til at dø af lungebetændelse når man har astmaâ¸. Ifølge en ny undersøgelse er debugging eller et såkaldt &quot;sanity check&quot; det mest brugte mål af forklarlighed i praksis i øjeblikketâ¹.MonitoreringSom beskrevet tidligere er almindelige performance-metrikker ikke altid nok til at måle en models værdi eller omkostning løbende i driftssituationen. Det er dog disse metrikker, der bliver brugt til at monitorere forskellige modeller og deres performance. Her kan forklaringer være en yderlige &quot;performance&quot;-metrik til at identificere en model-&quot;drift&quot;&amp;sup1,â°.Egenskaber hos forklarlige modellerEfter at vi nu har etableret de forskellige mål af forklarlighed, er det næste spørgsmål hvilke egenskaber en forklarlig model skal have. R. Guidotti et al. beskriver tre forskellige egenskaber: interpretability (forklarlighed), performance og fidelity (troskab)&amp;sup1,&amp;sup1,. Der findes andre egenskaber, ligesom fairness, sikkerhed og, brugbarhed, men disse er ikke nødvendigt specifikke for forklarlige modeller og kan også delvis adresseres af de andre tre egenskaber.ForklarlighedDet kommer ikke som nogen overraskelse, at forklarlige modeller skal være forklarlige. Der kan være forskellige former af forklarlighed (det kommer vi nærmere ind på i et senere blogindlæg), men det er ikke klart defineret, hvordan man skal måle forklarlighed. Doshi-Velez et al. foreslår tre forskellige måder: applikationsbaseret, metrikbaseret på mennesker, tekniske metrikker&amp;sup1,.Den første, den applikationsbaserede måde, er den mest ressource- og tidskrævende, men også den mest præcise. Her bliver forklarlighed målt, mens modellen reelt bliver anvendt (i driftssituationen). Man måler selve gevinsten af modellen i form af forretningsmetrikker, eller om det er nemmere at identificere fejl, om man genererer ny viden, eller om der er mindre diskriminering. Som basis kan man sammenligne metrikker med menneskelig beslutningsstøtte.Den anden måde er uafhængig af selve konteksten eller applikationen og fokuserer udelukkende på, hvor godt et menneske forstår modellen. Det kan man måle gennem forskellige forsøgsopsætninger&amp;sup1,&amp;sup2, &amp;sup1,&amp;sup3, &amp;sup1,â´, for eksempel:Den sidste måde er den mindst ressourcekrævende og mest brugte i litteraturen&amp;sup1,â° &amp;sup1,â¶ &amp;sup1,â· &amp;sup1,â¸. Her bruger man rent tekniske metrikker. Ideen er, at hvis man ændrer et input på de variabler, der bliver fremhævet af forklaringer, så burde modellens nøjagtighed ændres. Dette kan måles gennem almindelige performancemetrikker, men der er forskellige måder at &quot;ændre&quot; inputtet på&amp;sup1,â°.PerformanceDet vigtigste formål med modellen er stadig at lave en nøjagtig prædiktion. Derfor er performance også en vigtig egenskab. Performance måles som regel med forskellige metrikker (se en artikel på towards data science og sklearns guide), som f.eks. nøjagtighed. Tit kan der være et trade-off mellem performance og forklarlighed, da simple modeller, som beslutningstræer eller lineære modeller, er mere gennemskuelige men kan ikke modellere komplekse sammenhænge i data. Så den endegyldige beslutning om, hvilken model der virker bedst, er afhængig af balancen mellem de to egenskaber.Man kan også måle performance i form af det overordnende mål, f.eks. øget brugertilfredshed, bedre behandling af patienter, mere effektive og hurtigere processer, øget omsætning, osv. Forklarlighed kan have en positiv effekt på denne type af metrikker, hvor klassiske metrikker ikke er gode nok til at beskrive performance i forhold til det overordne mål&amp;sup1,â¹.TroskabNogle forklarlighedsmetoder bygger en model til at erstatte black-box-modellen, hvor black-box-modellen er brugt til prædiktioner og den anden model, også kaldt 'surrogate model', til at generere forklaringer. Men sidstnævnte model skal virke på samme måde som den originale black-box-model, altså generere prædiktioner så tæt som muligt til black-box modellens prædiktioner. Hvis det ikke er tilfældet, så forklarer denne model ikke black-box-modellen, men kun sig selv. Selvfølgelig vil surrogate modellen altid være forskellig, dvs. har en ringere performance en black-box modellen, da man ellers kunne erstatte black-box modellen fuldstændig med surrogate modellen. Troskab måler, hvor tæt forklaringsmodellens resultater ligger på resultater fra black-box modellen.KonklusionBekymringer om forklarlighed vedrørende systemer baseret på kunstig intelligens er ikke nyt, se f.eks. ekspertsystemer&amp;sup2,â°, case-based reasoning&amp;sup2,&amp;sup1, (for et historisk overblik se afsnit &quot;Explanation in Artificial Intelligence Systems: An Historical Perspective&quot; i Explanation in Human-AI Systems: A Literature Meta-Review, Synopsis of Key Ideas and Publications, and Bibliography for Explainable AI). Men fordi modellerne er blevet mere komplekse (især dybe neurale netværk) og kunstig intelligens bliver brugt mere til kritiske beslutninger og af ikke-ekspert-brugere, er udfordringerne med forklarlighed mere aktuelt en nogensinde.Udfordringen ligger i at definere, hvad man egentlig mener med forklarlighed, og at det nu også er nødvendigt at måle modellens performance på mere beskrivende måder - såsom tillid eller fairness.I dette blogindlæg er vi kommet ind på hvad forklarlighed betyder, hvad man kan opnå med forklarlige modeller, og hvorfor forklarlighed er et vigtig yderlige performancekriterium.[1] F. Doshi-Velez og B. Kim, &quot;Towards a rigorous science of interpretable Machine Learning&quot;, arXiv:1702.08608 [stat.ML], 2017.[2] Z. C. Lipton, &quot;The Mythos of Model Interpretability&quot;, arXiv:1606.03490v3 [cs.LG], 2017.[3] G. Malgieri og G. Comandé, &quot;Why a Right to Legibility of Automated Decision-Making Exists in the General Data Protection Regulation&quot;, International Data Privacy Law, pp. 243-265, 2017.[4] S. Wachter, B. Mittelstadt og L. Floridi, &quot;Why a Right to Explanation of Automated Decision-Making Does Not Exist in the General Data Protection Regulation&quot;, International Data Privacy Law, pp. 76-99, 2017.[5] A. Selbst og J. Powles, &quot;Meaningful information and the right to explanation&quot;, International Data Privacy Law, pp. 233-242, 2017.[6] B. Y. Lim og A. K. Dey, &quot;Assessing demand for intelligibility in context-aware applications&quot;, Proceedings of the UbiComp '09, pp. 195-204, 2009.[7] S. Lapuschkin, S. Wäldchen, A. Binder, G. Montavon, W. Samek og K.-R. Müller, &quot;Unmasking Clever Hans predictors and assessing what machines really learn&quot;, Nature Communications, 10, 2019.[8] R. Caruana, Y. Lou, J. Gehrke, P. Koch, M. Sturm og N. Elhadad, &quot;Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission&quot;, Proceedings of KDD '15, pp. 1721-1730, 2015.[9] U. Bhatt, A. Xiang, S. Sharma, A. Weller, A. Taly, Y. Jia, J. Ghosh, R. Puri, J. M. F. Moura og P. Eckersley, &quot;Explainable machine learning in deployment&quot;, Proceedings of FAT* '20, pp. 648-657, 2020.[10] S. M. Lundberg, G. Erion, H. Chen, A. DeGrave, J. M. Prutkin, B. Nair, R. Katz, J. Himmelfarb, N. Bansal og S.-I. Lee, &quot;From local explanations to global understanding with explainable AI for trees&quot;, Nature Machine Intelligence, 2, pp. 56-67, 2020.[11] A. Weller, &quot;Challenges for Transparency&quot;, arXiv:1708.01870v1 [cs.CY], 2017.[12] J. Chang, S. Gerrish, C. Wang, J. L. Boyd-Graber og D. M. Blei, &quot;Reading Tea Leaves: How Humans Interpret Topic Models&quot;, Advances in Neural Information Processing Systems 22, 2009.[13] T. Kulesza, M. Burnett, W.-K. Wong og S. Stumpf, &quot;Principles of Explanatory Debugging to Personalize Interactive Machine Learning&quot;, Proceedings of the IUI'15, pp. 126-137, 2015.[14] F. Poursabzi-Sangdeh, D. G. Goldstein, J. M. Hofman, J. W. Vaughan og H. Wallach, &quot;Manipulating and Measuring Model Interpretability&quot;, arXiv:1802.07810v3 [cs.AI], 2019.[15] M. T. Ribeiro, S. Singh og C. Guestrin, &quot;Anchors: High-Precision Model-Agnostic Explanations&quot;, Thirty-Second AAAI Conference on Artificial Intelligence, 2018.[16] G. Montavon, W. Samek og K.-R. Müller, &quot;Methods for interpreting and understanding deep neural networks&quot;, Digital Signal Processing, pp. 1-15, 2018.[17] M. Ancona, E. Ceolini, C. Öytireli og M. Gross, &quot;Towards better understanding of gradient-based attribution methods for Deep Neural Networks&quot;, arXiv:1711.06104v4 [cs.LG], 2018.[18] A. Shrikumar, P. Greenside og A. Kundaje, &quot;Learning Important Features Through Propagating Activation Differences&quot;, arXiv:1704.02685 [cs.CV], 2017.[19] L. Bernardi, T. Mavridis og P. Estevez, &quot;150 Successful Machine Learning Models: 6 Lessons Learned at Booking.com&quot;, Proceedings of KDD '19, pp. 1743-1751, 2019.[20] P. Jackson, &quot;Introduction to Expert Systems&quot;, Addison-Wesley Longman, Harlow, 1990.[21] A. Kofod-Petersen, J. Cassens og A. Aamodt, &quot;Explanatory Capabilities in the CREEK Knowledge-Intensive Case-Based Reasoner&quot;, Proceedings of SCAI 2008 , pp. 28-35, 2008.Kontakt:Communications Specialist Lisa Lorentzen tlf.: +45 93 52 17 64 email: lisa.lorentzen@alexandra.dkLæs hele pressemeddelelsen på Via Ritzau her: https://via.ritzau.dk/pressemeddelelse/hvad-betyder-forklarlighed-nar-vi-taler-om-kunstig-intelligens?releaseId=13593240** Ovenstående pressemeddelelse er videreformidlet af Ritzau på vegne af tredjepart. Ritzau er derfor ikke ansvarlig for indholdet ** 
        </div>
        <footer>
          <em>Ritzaus Bureau</em>
          &nbsp;·&nbsp; 2020-05-13
          &nbsp;·&nbsp; e7b4bc10
          &nbsp;·&nbsp; #3
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.964</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.765</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.548</kbd>
        </footer>
      </article>
      <article>
        <h4>Sådan migrerer du til Python 3</h4>
        <div>
          Nytårsdag gik solen ned over Python 2. Så det er bare med at komme i gang med flytteriet, hvis man ikke lige fik det gjort. Læs her, hvordan du gør. Årsskiftet betød, at det det slut med support for Python 2. Så der er panik efter lukketid, hvis applikationer ikke er blevet flyttet endnu. I sin tid blev Python 2 brugt som et scripting-sprog. Det blev brugt til konfiguration og webapplikationer. Men så blev Pythons pakker til videnskabelig og numerisk brug meget populært. Python 3 kom på gaden i 2008, men der har været en del træghed i tilegnelsen af den nye version, som på mange punkter bryder kompatibiliteten med den forrige udgave. Og indtil nu har der ikke nødvendigvis været gode grunde til at skifte. »Virksomheder med applikationer, der kører en hvilken som helst version af Python 2, er nødt til at migrere - og jo før, desto bedre,«  siger Bart Copeland, der er administrerende direktør i softwarevirksomheden ActiveState, til mediet Techrepublic Bart Copeland påpeger, at populære data- og AI-biblioteker som NumPy og Tensorflow er skiftet til Python 3 fra den 1. januar. »Migrering til en ny version af Python er en betydelig opgave, så det bør ikke ske i hast. Migrering, som finder sted inden fristen udløber, vil hjælpe udviklerne med at give dem den tid, der er nødvendig for at gøre det ordentligt og tage højde for eventuelle uforudsete fejl i god tid.«  Men nu har klokken altså slået 12. Så det er altså bare med at komme i sving, hvis man ikke allerede er i gang. Sådan migrerer du koden Et sted at starte, eller måske en desperat nødløsning, kan være programmet 2to3 , som automatisk oversætter kode fra den gamle til den nye udgave. Derudover har organisationen bag sproget, Python Software Foundation, skabt en omfattende guide til, hvordan man flytter kode fra Python 2 til 3. Techrepublic har opsummeret disse råd. Det er langt nemmere at migrere fra Python 2.7 end tidligere versioner. Hvis organisationen bruger Python 2.6, skal man benytte biblioteket Six . Det byder på hjælpefunktioner der kan udjævne forskellene mellem Python-versionerne. Sørg for, at din setup.py-fil korrekt angiver, hvilke versioner af Python din kode understøtter, og at dine test har mindst 80 pct. kodedækning. Lær forskellene mellem Python 2 og Python 3 ved at læse Pythons egen What's New-dokumentation og den gratis Porting to Python 3 -bog. Brug bibliotekerne Futurize eller Modernize til at gøre din Python 2-kode Python 3-kompatibel, og sørg for at læse dokumentationen. Vær opmærksom på, hvordan division med heltal er forskellig i de to versioner. I Python 2 giver 9/2 = 4, og i Python 3 giver samme regnestykke værdien 4.5. Hvis du har brugt __future__ import division i din kode og // operatoren til heltalsdivison, vil din kode allerede være Python 3-kompatibel. Python 3 er ændret i forhold til, hvilke data der kan bruges med str-typen for klarere at skelne mellem tekst og binære data. For at sikre kompatibilitet skal en række skridt udføres, som gennemgået i portabilitets-dokumentationen. Et værktøj til statisk type-tjek, som Mypy , kan også hjælpe med at finde problemet. Når man afvikler kode, der opfører sig forskelligt, baseret på hvilken version af Python, der kører, er det bedre at kontrollere, om en bestemt funktion, der understøttes i Python 3, er i stand til at køre, i stedet for at tjekke, om sys.version_info [0] er lig med 3. Kontroller, hvilke softwareafhængigheder der spænder ben for Python 3 ved hjælp af værktøjerne leveret af projektet Caniusepython3 Denne artikel har tidligere været bragt på DataTech
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2020-01-02
          &nbsp;·&nbsp; e786662f
          &nbsp;·&nbsp; #4
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.891</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.797</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.669</kbd>
        </footer>
      </article>
      <article>
        <h4>PRM / Computer, hvordan vil du lige forklare det? Og det gerne med subjektive eksempler og objektive facts til feature attribution metoder og fodbold!</h4>
        <div>
          KøbenhavnPressemeddelelse fra Alexandra InstituttetEksempel på LimeOverstående er et eksempel på en forklaringsmodel, der kan anvendes til at forklare udfald fra en såkaldt 'black-box'-klassifikationsmodel på både tekst, tabel- eller billeddata - og det uden et egentligt kendskab til, hvordan selve modellen virker, da forklaringsmetoden anvendes efter selve modellen er udviklet ved at efterligne den komplekse model lokalt. To kendte frameworks til at lave disse model-uafhængige feature attribution forklaringer er LIME (Local Interpretable Model-agnostic Explanations, Ribeiro et. al 2016) og SHAP (SHapley Additive exPlanations , Lundberg et al. 2017), og denne blogpost giver en introduktion til, hvordan disse to metoder virker, men også en diskussion af hvornår de ikke gør. Måske synes du ligesom mig, at ovenstående forklaring giver fin mening, men denne blogpost handler i høj grad også om begrænsningerne ved metoderne, og den subjektive overskrift kunne have været, hvorfor SHAP og LIME alligevel ikke redder kampen.Men bare rolig, tonen er ikke kun dyster, det hele bliver fremført i en blanding af positivt, negativt, objektivt og subjektivt tonede sætninger.Vi starter lidt bredt, hvorefter vi dykker ned i teorien bag metoderne, skyder bolden over til det praktiske ved implementeringerne, laver en objektiv vurdering af den bedste fodboldspiller, ser på fordele og ulemper igennem eksempler, og til sidst kigger vi på, om vi kan snyde forklaringsmodellerne til ikke at opdage, at vi holder med AGF.Men inden vi går i gang, skal det lige indskydes, at klassifikationsmodellen, vi vil bruge som eksempel igennem bloggen, er en spaCy-model, jeg har trænet på manuelt annoterede tweets for 'subjektivt' og 'objektivt', og i tillæg er den trænet på sætninger fra Wikipedia, som er antaget til at være 'objektive'. Men mere om modellen senere.Og som et sidste indspark, hvis du vil læse mere generelt om forklarlig AI, kan jeg anbefale min kollegas blogpost.Den gængse tone.. eller den gængse opfattelse af, hvad disse &amp;lsquo,feature attribution'-metoder kan bruges til, tager vi fat på først. Ribeiro et. al 2016 præsenterede et værktøj kaldet LIME, som kan adressere problemet med 'tillid' til maskinlæringsmodeller igennem forklaring. Med det mener de, at forklaringer enten kan bruges til at skabe tillid til et enkelt udfald, eller til at skabe tillid til modellen. Vi vil i denne blog inddele anvendelsen i følgende tre grupper:Den grundlæggende ide bag at give forklaringer af enkelte udfald til en bruger af systemet går på, at hvis jeg som bruger finder forklaringen rimelig, så har jeg en større tro på, at modellens udfald er korrekt i det specifikke tilfælde, hvorimod hvis jeg finder forklaringen langt ude, så kan det være, at jeg som bruger af modellen, skal vælge at forkaste modellens prædiktion på dette pågældende eksempel. Men hvilke forklaringer, en slutbruger egentlig har brug for, er stof til et helt andet og mere tværfagligt blogindlæg.Forklaringer kan også bruges i selve udviklingsprocessen til at få en indsigt i, hvilke ting modellen faktisk kigger på, og særligt kan det opdages, om modellen fitter på noget i data som er uhensigtsmæssigt (se for eksempel Lapuschkin et al. 2019).Den sidste ide til anvendelse går på, at man kan bruge disse metoder som en ekstern part, som ikke har fået indsigt i udviklingen af systemet, til at monitorere om et system er fair, fx i forhold til ikke at være diskriminerende over for bestemte grupper ved for eksempel at undersøge om modellen bruger såkaldte &quot;beskyttede&quot; variabler til at komme frem til beslutningen. (Læs mere om Fairness i min tidligere blogpost om retfærdige superhelte).Af ovenstående tre anvendelsesmuligheder er det nok at benytte metoderne som udviklingsværktøj, der har størst potentiale. Men lad os lige se på den ovenstående sætning engang,Eksempel på LimeJamen dog, modellen prædikterer, at det er en subjektiv holdning herfra - og forklaringen er, at &quot;er det nok&quot; ikke er et objektivt ordvalg. Men så lad os i stedet starte mere objektivt med teorien bag, før vi begynder på diskussionen og tager fat på et fodboldeksempel.Den objektive matematik... er et godt sted at begynde og lad os begynde med at se nærmere på LIME fra 2016, hvorefter vi kigger ind i SHAP, der udkom året efter. Ideen bag LIME er at træne en simpel, forklarlig model lokalt rundt om et enkelt data-eksempel, således at den simple model efterligner den egentlige klassifikationsmodel så godt som muligt i det lokale område. På formel bliver det i Ribeiro et. al 2016 , præsenteret således:Credit: Ribeiro et. al 2016Lad os bryde det lidt ned. Lad os forestille os, at vores egentlige klassifikationsmodel, hvilken er defineret som f i formlen, er trænet via deep learning til at lære de komplekse strukturer i dataene, og derfor ikke nemt lader sig forklare i sig selv. Ideen er nu i stedet at finde en simpel model, som vi nemt kan forklare. Men den simple model kan ikke bruges til at forstå den komplekse struktur, som vores data har (hvis den kan det, behøves den komplekse model jo slet ikke). Men det antages, at en simpel model godt kan bruges på et lille, specifikt område af data. Her er opstillingen, tag udgangspunkt i et enkelt datapoint, det er x, og find da såkaldte naboer til dette datapoint, dvs. datapunkter der ligger tæt på x, defineret her som området &amp;pi,_x. På disse datapunkter findes en simpel forklarlig model, g, som kommer så tæt på at lave de samme prædiktioner som f på de lokale nabo-datapunkter som muligt, målt ved fx &amp;lsquo,mean squared error' ved termet L(f,g,&amp;pi,_x). Det sidste term &amp;Omega,(g) måler kompleksiteten på vores lokale approksimationsmodel g. Desuden skal g være forklarlig, og det betyder, at g skal tage en forklarlig repræsentation af data som input. g kunne være en lineær model, og kompleksiteten for en sådan lineær model kan måles på antallet af features. I praksis optimerer LIME kun på at minimere L, og selve modelkompleksiteten vælges på forhånd.To af de praktiske spørgsmål, vi vil vende tilbage til senere, er, hvordan vi vælger vores 'forståelige' datarepræsentationer, samt hvordan vi vælger vores 'nabo'-eksempler. Men nu vil vi lige blive i matematikken og se på teorien bag SHAP.En smukkere, objektiv matematik.. fås i SHAP-artiklen (Lundberg et al. 2017). Her fremlægges en generel og mere teoretisk funderet formulering af &amp;lsquo,additive feature attribution'-metoder, som LIME er et eksempel på. Artiklen viser, at LIME, og en række andre &amp;lsquo,feature attribution'-metoder kan beskrives på samme, følgende måde. Problemstillingen er den samme, vi vil gerne forklare enkelte udfald fra en kompleks model ved hjælp af en simpel forklaringsmodel. Denne simple forklaringsmodel, g, bliver præsenteret som en lineær model på binære features z, altså hvorvidt en feature er til stede eller ej. Vi arbejder altså stadig med forklarlige repræsentationer af input-features. Det er nu vægtene Ï?, vi skal finde, da de udtrykker, hvor vigtig hver feature i er på g's prædiktion.Credit: Lundberg et al. 2017Problemet består i at finde vægtene Ï?, og det på en måde som gør, at vægtene overholder følgende tre kriterier: Lokal Accuracy, at g faktisk approksimerer f lokalt, Missingness, hvis en feature i ikke er til stede, bør vægten være nul, Consistency, selvom vi havde forskellige modeller, skal bidraget for hver feature gerne være det samme. Lundberg et al. 2017 viser nu, at den eneste definition, som opfylder dette, er at finde vægtene ved hjælp af &amp;lsquo,Shapley Values'.Shapley values giver os nu (endelig) en anledning til at tale om fodbold, og så starter vi en ophedet, subjektiv diskussion om, hvilken fodboldspiller der gør det bedst.Den bedste fodboldspiller er... noget vi teoretisk kan udregne med shapley values. Det giver en metode til at udregne, hvor meget hver spiller bidrager til holdindsatsen. Eller i vores tilfælde kan vi bruge shapley values til at udregne, hvor meget hver feature bidrager til udfaldet af modellen. Formlen ser således ud:credit: Lundberg et al. 2017Og måske kan den virke lidt skræmmende. Men princippet bag skal bare deles lidt op. Ï?_i er den pågældende spiller i's bidrag, som vi gerne vil undersøge, og N er antallet af spillere på holdet. For at finde ud af hvor meget spiller i bidrager til sejren, summerer vi over alle mulige kombinationer af delmængder af holdet S og ekskluderer spiller i og udregner derpå, hvad det marginale bidrage er af at tilføje den ene spiller i til holdet igen. Det marginale bidrag af at tilføje spiller i til delholdet bliver udregnet i termet (v((S&amp;cup, {i}-v(s)), hvor v er det payoff/den værdi, teamet genererer. (Vi kunne fx måle det i antal mål.) Det sidste term er en faktor, vi ganger på det marginale bidrag for at justere for, hvordan delholdet er sammensat, altså vi vil gerne have det gennemstilige bidrag af spiller i, uanset hvilke andre spillere der er på delholdet. Til slut ganger vi også med 1 over antal spillere, da vi gerne vil have spiller i's bidrag uanset størrelsen på delholdet.Dette er det teoretiske fundament bag SHAP, men praktisk er det alt for omkostningstungt at udregne disse shapley values med alle de kombinationer, der skal opstilles, og derfor approksimeres disse værdier (oftest) i praksis.Det praktiske i haven og problemer med at spille med naboen... er nogle af de ting, man skal overveje som 'køber' af LIME og SHAP. I praktisk er både LIME og SHAP implementeret med open source GitHub og pip-pakker lige til at installere og med fine tutorials . Dog er der lidt ting, der skal tages højde for. Der findes forskellige implementationer af SHAP, alt efter hvilken model man vil forklare - dog er kernel SHAP model-uafhængig og minder om LIME, men den er også langsom og den mest grove approksimation af Shapley values.I teorien virker metoderne både på tekst, billede og tabeldata, men i praksis understøtter SHAP-implementationerne ikke en direkte behandling af tekst fra alle typer modeller, da det ikke er defineret, hvordan teksten skal behandles som features.Der er generelt en udfordring med at vælge 'den forklarlige repræsentation', fordi der kan være et gab mellem den, og det input som modellen rigtig fitter på. I tilfældet med tekstdata kan den simple lineære model måske tage enkelte ord som input, selvom klassifikationsmodellen ikke nødvendigvis fitter på enkelte ord. Ved billedata kunne den forklarlige repræsentation være et område i billedet i stedet for de egentlige pixels som input - vi snakker om segmentering eller superpixels. Der er altså en forskydning i, hvad modellen egentlig fitter på, og hvad den kan forklares med. Det vil i praksis sige, at vi ikke kan bruge LIME eller SHAP til noget, hvis ikke forklaringen af et udfald kan indfanges i den simple repræsentation, som vi lader LIME og SHAP fitte på. Lad os tage et eksempel med sætningen &quot;denne blog handler om ansvarlig AI&quot;,Eksempel på LimeModellen afgør, at sætningen er 'objektiv', men med forklaringen 'denne blog'. Men det er som om, at disse ord i sig selv ikke forklarer, hvorfor modellen siger 'objektiv', eller hvorfor vi selv vil sige 'objektiv'. Måske er forklaringen nærmere, at der ikke er noget, der gør sætningen subjektiv, eller med andre ord, forklaringen kan ikke fanges ved at pege på enkelte ord.Med hensyn til at genere naboer, ligger der en udfordring med afsæt i SHAP i, at da modellen afprøver kombinationer af, hvilke features der er med 'på holdet' eller ej, så skal vi have en måde at definere på, hvad det vil sige ikke at være med, altså at være bænket. Vi er nødt til at afklare, når vi fjerner en feature, hvad er der så? Altså, hvis vi fjerner et område i et billede, hvad skal &quot;baggrunden&quot; så være, skal de pixels i området sættes til at være hvide, eller sorte, eller hvad med en gennemsnitlig værdi af hvad pixels &quot;normalt&quot; tager i det område? Det sidste kræver, at vi har adgang til en lille smule træningsdata for at kunne udregne fx gennemsnitsværdier. Læs mere om udfordringer med baggrundsdata i denne interaktive Distil-publikation.Det gode, subjektive eksempel... indledes på træningsbanen. Indledningsvis listede vi tre anvendelsesområder for &amp;lsquo,feature attribution' metoder, og indtil videre har vi sparket lidt tvivl op om deres egentlige anvendelse til at forklare enkelte prædiktioner. Men lad os se på metodernes anvendelse som udviklingsværktøj. Subjektiv/objektiv-klassifikationsmodellen er trænet på manuelt annoterede tweets, hvor vi har gemt 400 til valideringssættet og 1716 eksempler til træning af modellen. Træningssættet fordeler sig mellem de to klasser således:Da dette ikke er særligt balanceret, er der tilføjet 1500 sætninger fra Wikipedia, som vi bare uden videre har antaget er 'objektive'. På valideringsættet opnås en accuracy på 87% og en macro-f1 på 73%. Men lad os lige se på et eksempel, hvor vi prøver at forklare følgende sætning med modellen:I modellens forklaring ser vi, at tilstedeværelse af &quot;#&quot; trækker prædiktionen mod at være 'subjektiv'. Men vi synes måske egentlig ikke, at &quot;hasttags&quot; bør tale for det ene eller det andet. Vi bliver opmærksomme på, at der netop er en skævhed i vores data, da langt de fleste subjektive eksempler kommer fra tweets, som netop bruger &quot;#&quot; i modsætning til sætninger fra Wikipedia. Vi renser nu data for &quot;#&quot; og &quot;@&quot; og træner modellen igen. Nu opnås en højre accuracy på valideringsættet på 88% (0.74 macro-f1). Og forklaringen på overstående sætning bliver nu:Forklaringsmetoderne kan altså gøre os opmærksomme på ting, modellen fitter på, som kan skyldes en skævhed i data. I LIME-artiklen (Ribeiro et. al 2016) vises denne anvendelse på en billedeklassificerings-task med &quot;husky hund eller ulv&quot;, hvor vi igennem forklaringen kan spotte, at modellen i tilfælde af 'ulv' fitter på sne i billedet i stedet for på selve dyret. Dette datasæt er dog konstrueret, og skal tages som et legeeksempel. Andre eksempler findes i denne artikel Lapuschkin et al. 2019, hvor der i stedet bruges LRP-metoden.Hey dommer, de snyder...... forklaringsmodellerne til ikke at se, hvor unfair modellen virkelig er. Slack et al. 2020 viser i deres artikel, hvor nemt LIME og SHAP kan snydes. Med dette argumenterer de imod, at en tredjepart, uden adgang til informationer om selve udviklingen af modellen, kan bruge forklaringsmodellerne til at monitore fairness, hvilket var den tredje mulige anvendelse listet indledningsvis.Svagheden ved SHAP og LIME, viser Slack et al. 2020, er, at det er forholdsvist nemt at se forskel på de originale eksempler og de generede naboeksempler. Tricket er derfor at træne en model, der kan kende forskel mellem et original- og et naboeksempel, og ud fra dette kan det sorteres, så eksempler, der bliver brugt til at generere forklaringer af LIME og SHAP, bliver sendt til en anden klassifikationsmodel end den klassifikationsmodel, som anvendes ved originale eksempler.Lad os lege lidt med et eksempel. Legefortællingen er følgende: Den Nationale Boldunion Investeringsfond har lavet et udbud på et system, der kan måle på social medie-kommentarer, om fodboldspillere bliver omtalt positivt eller negativ med det formål at investere i de mest positivt omtalte klubber. Men de ved, at fans rundt om i landet vil gøre alt for at levere et system, der fremstiller deres egen klub så positivt omtalt som muligt, og derfor vil de tjekke de indleverede systemer for, om de er favoriserende og diskriminerende.Vi er sådan en fan! Og vi holder meget af AGF og knap så meget af Brøndby. Derfor har vi lavet et system, der hver gang, den ser navnet på en AGF-spiller, prædikterer positivt, og hver gang den ser en Brøndby-spiller prædikterer negativt. Hvis ingen navne indgår, benytter systemet Afinn ordlistebaserede sentimentværktøj. Så systemet er helt gennemskueligt og ikke nogen sort boks, men det leger vi, at Den Nationale Boldunion Investeringsfond jo ikke ved. De vil nu benytte SHAP og bruge et &quot;summary-plot&quot; til at opsummere hvilke features, der har været mest betydende i et testsæt, som de har genereret for at teste modellens fairness. De har lavet testsættet til at undersøge diskriminering/favorisering ved at skrive otte sætninger,[&amp;lsquo,UNK er den bedste fodboldspiller', &amp;lsquo,Den var en sjovt at se UNK scorede et fantastisk mål', &amp;lsquo,unk er en succes', &amp;lsquo,Altid dejlig at se UNK spille', &amp;lsquo,Det var dårligt sparket af UNK', &amp;lsquo,UNK er jo direkte en skændsel for holdet', &amp;lsquo,UNK har sammen med dommeren gjort kampen til en grim katastrofe', &amp;lsquo,Ringere spiller er ikke set end forfærdelige UNK']Samt en liste med spillernavne, som hver kan udskiftes på UNK-pladserne i de ovenstående sætninger:AGF = [&amp;lsquo,Duncan', &amp;lsquo,Helenius', &amp;lsquo,Eskelinen', &amp;lsquo,Gersbach' ]Brøndby= [&amp;lsquo,Gammelby', &amp;lsquo,Mensah', &amp;lsquo,Lindstrøm', &amp;lsquo,Bruus']Hvis SHAP-modellen blev anvendt på ovenstående syntetiske 'testsæt' og med det ovenstående diskriminerende system, ville vi blive afsløret i, at systemet har AGF-fodboldspillernes navne som features, der trækker modellens output mod 'positiv', og Brøndbyspillernes mod 'negativ':SHAP summary plotDerfor vil vi nu, som de inkarnerede fans vi er, snyde dette tjek ved i stedet at levere et system, hvor det ikke bliver opdaget, at modellen holder med AGF.Ovenstående anvendelse af SHAP er et legeeksempel, hvor inputfeature-repræsentationen er en simpel &quot;countvector&quot;, og baggrundsdataene UNK er en token. I praksis ville vi nok fitte baggrundsdata på egentlig træningsdata (som vi i så fald bør kende), og i tilfælde af en countvector nok egentlig bare sætte baggrundsværdien til 0, men dette er blot for at vise ideen. Så, med UNK som baggrundsdata, har vi gjort det nemt for os selv at kende forskel på originale eksempler og generede eksempler, så vi behøver blot at indbygge i vores system, at hvis vi ser UNK, skal eksemplet sendes til en ikke-diskriminerede model, og når vi ikke ser UNK, så kan vi anvende vores AGF-elskende model. Som vores ikke-diskriminerende model vil vi blot anvende Afinn-modellen. På den måde viser forklaringerne, hvordan Affin-modellen virker, og ikke hvordan modellen virker in real life. Lad os se hvad SHAP nu siger:SHAP summary plotDet ses, at SHAP nu tror, at de mest betydende features er hhv. positivt og negativt ladede ord, og ikke længere fodboldspillernavnene som modellen rigtigt bruger.Positive og negative takter... eller i hvert fald en subjektiv opsummering over fordele og ulemper ved værktøjerne.Fordelene ved LIME er, at det er rigtig nemt at bruge, og at værktøjet virker både for tabel-, billede- og tekstdata, og værktøjet kan endda bruges uanset typen af den originale model, og i tillæg kan den originale model være trænet på en ikke-fortolkelig repræsentation. Dette er dog også samtidig en af ulemperne, da der derved kan ske et skred imellem forklaringen, og hvad den originale model bruger af input. Af andre ulemper ved LIME kan nævnes problemet med at genere naboeksemplerne. LIME ignorer sammenhæng mellem features, når naboeksempler genereres, og det kan resultere i usandsynlige datapunkter. Der er i særdeleshed et problem med, hvordan tabeldata skal håndteres. Desuden er det uklart, i hvilket område forklaringerne holder, og om hvorvidt forklaringerne generaliser til andre eksempler, da det lokale områder måske ikke kan beskrives lineært. Til at adresse dette problem er forfatteren bag LIME kommet med en metode, der benytter 'if-then' regler (Ribeiro et. al. 2018). LIME kritiseres i Alvarez-Melis et. al 2018 for at være ustabil i sine forklaringer.SHAP har den fordel, at den med sine shapley values er teoretisk velfunderet, og bør derfor teoretisk anvendes over LIME. Ligeledes giver dens afsæt i shapely values en sammenhæng mellem enkelte forklaringer og forklaringer for fx hele validerings-datasættet. SHAP Kernel implementation er også model-uafhængig, men desværre meget langsomt, og beror på en approksimation af shapley values. Desuden ignoreres feature dependency også her, og udvælgelsen af baggrundsdata er ikke givet. Til gengæld ses der lovende takter med Treebased SHAP, som kan bruges til at forklare &quot; træ baserede&quot;-modeller. Det er dog ikke noget, der er blevet plads til i dette indlæg, men der kan læses mere om det i Lundberg et al. 2020.I den samlede subjektive vurdering af hvad disse feature attribution-metoder kan bruges til, vil jeg lægge vægt på, at metoderne kun er anvendelige, hvis man selv kan pege på, hvad det egentlig er, man forventer, modellerne fortæller en. Forstået på den måde at man kun kan få en forklaring med den simple repræsentation, man nu engang har givet forklaringsmodellen at fitte på. Desuden skal man huske at spørge sig selv, om forklaringen egentlig er særlig forståelig for folk, der ikke kender til værktøjet, eller måske til maskinlæring i det hele taget. Alt i alt er det subjektive lyspunkt nok, at modellen kan bruges til at spotte uhensigtsmæssighed i selve udviklingsprocessen.Tak fordi du læste med, selvom det hele blev lidt langt./ Amalie Pauli ReferencerAlvarez-Melis, David, and Tommi S. Jaakkola. &quot;On the robustness of interpretability methods.&quot; arXiv preprint arXiv:1806.08049 (2018).Lapuschkin, Sebastian, et al. &quot;Unmasking clever hans predictors and assessing what machines really learn.&quot; Nature communications 10.1 (2019): 1-8.Lundberg, Scott M., and Su-In Lee. &quot;A unified approach to interpreting model predictions.&quot; Advances in neural information processing systems. 2017.Lundberg, Scott M., et al. &quot;From local explanations to global understanding with explainable AI for trees.&quot; Nature machine intelligence 2.1 (2020): 2522-5839.Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. &quot;&quot; Why should i trust you?&quot; Explaining the predictions of any classifier.&quot; Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. 2016.Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. &quot;Anchors: High-precision model-agnostic explanations.&quot; Thirty-Second AAAI Conference on Artificial Intelligence. 2018.Slack, Dylan, et al. &quot;Fooling lime and shap: Adversarial attacks on post hoc explanation methods.&quot; Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society. 2020.Kontakt:Communications Specialist Lisa Lorentzen tlf.: +45 93 52 17 64 email: lisa.lorentzen@alexandra.dkLæs hele pressemeddelelsen på Via Ritzau her: https://via.ritzau.dk/pressemeddelelse/computer-hvordan-vil-du-lige-forklare-det-og-det-gerne-med-subjektive-eksempler-og-objektive-facts-til-feature-attribution-metoder-og-fodbold?releaseId=13594152** Ovenstående pressemeddelelse er videreformidlet af Ritzau på vegne af tredjepart. Ritzau er derfor ikke ansvarlig for indholdet ** 
        </div>
        <footer>
          <em>Ritzaus Bureau</em>
          &nbsp;·&nbsp; 2020-05-28
          &nbsp;·&nbsp; e7ba2803
          &nbsp;·&nbsp; #5
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.99</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.879</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.621</kbd>
        </footer>
      </article>
      <article>
        <h4>Fredag 26 august</h4>
        <div>
          Dubstep Mania 2011 // Eddie K // AI // Torsdagsredaktionen // Denali ( Train): Dubstep and D'n'B All Night. ( Not for Pussies, Wimps or Fragile Ears).Bass Culture er igen i år gået sammen med Present Aarhus og Heiniken om at presentere årets vildeste rave.Line-up: 23: 00 Denali Sound ( Aarhus) 24: 00 Eddie K ( UK) 01: 30 Torsdags Redaktionen ( Christiania Radio) 03: 00 Artificial Intelligence ( UK) 05: 00 Curfew Der er lagt op til en nat med fuld udblæsning for musikken, og hoppestemning natten lang!.
        </div>
        <footer>
          <em>Århus Stiftstidende</em>
          &nbsp;·&nbsp; 2011-08-25
          &nbsp;·&nbsp; e2d64d07
          &nbsp;·&nbsp; #6
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.943</kbd>
            <kbd data-tooltip="AI &amp; innovation">L05_INNOAI&nbsp;0.937</kbd>
        </footer>
      </article>
      <article>
        <h4>Her er nyhederne i Python 3.10: Match er en ren schweizerkniv</h4>
        <div>
          For anden gang udkommer Python efter en ny årlig udgivelsesplan. Den store nyhed for det hidtil switch-løse sprog er en ny match-sætning, der kan lidt af hvert.Version2 : Med 30 år på bagen har programmeringssproget Python kronede dage. På lister over sprogs popularitet ligger Python enten i toppen eller tæt på.Python er gået fra at være et scripting-sprog med lav indlæringskurve, til at være et af de foretrukne sprog til videnskabelig programmering, statistik, dataanalyse og kunstig intelligens.Ligesom i Javascript kan man i Python gøre næsten, hvad man har lyst til på kørselstidspunktet, såsom at udstyre objekter med nye felter og metoder. Det sætter begrænsninger på afviklingshastigheden.Den danske ekspert i virtuelle maskiner Lars Bak vurderer, at sprog som Python og Javascript kan opnå omkring halvdelen af den ydelse som typestærke sprog, der også afvikles i en virtuel maskine, såsom Java og C#, kan præstere.Men der er flere måder at gøre tingene på. Det er nemt at kalde C-kode fra Python, og mange Python-biblioteker er implementeret i C, som gør dem lynhurtige.Når det handler om kunstig intelligens, matricer og vektorer, kan biblioteker udnytte grafikkort, som er mange gange hurtigere, end når tilsvarende operationer skal udføres på cpu-kerner, på grund af parallelisering af lineære vektorberegninger.På den måde kan Python-koden blive et slags instrumenteringslag for de underliggende højtydende biblioteker, med en nem syntaks, der tillader lidt af hvert og sjældent stiller sig i vejen for programmøren.Match er en schweizerkniv-switchEn ny version er tæt på af se dagens lys. Den har nummeret 3.10, og er den anden udgave efter en ny udsendelsesplan, hvor der kommer nye versioner én gang om året.Blandt nyhederne er pattern matching, som også Java og PHP for nylig er blevet udstyret med. Pattern matching stammer fra de funktionelle sprog, og trenden blandt objektorienterede sprog er netop at låne ideer fra den funktionelle verden.Python har aldrig tidligere haft en switch-sætning, så det er funklende nyt, og den nye konstruktion er en ren schweizerkniv, i forhold til hvilke mønstre sætningen kan håndtere.På det overordnede plan ser det således ud, med eksempler taget fra dokumentationen:match subject:case :case :case :case _:På klassisk Python-maner kan en masse forskellige ting anvendes som argument i case-sætningerne. Mønstrene kan bestå af sequences, mappings, primitive datatyper samt klasse-instanser.Et simpelt eksempel kan se sådan ud:def http_error(status):match status:case 400:return &quot;Bad request&quot;case 404:return &quot;Not found&quot;case 418:return &quot;I'm a teapot&quot;case _:return &quot;Something's wrong with the Internet&quot;Case-sætninger kan også indeholde variable:# point is an (x, y) tuple match point:case (0, 0):print(&quot;Origin&quot;) case (0, y):print(f&quot;Y={y}&quot;) case (x, 0):print(f&quot;X={x}&quot;) case (x, y):print(f&quot;X={x}, Y={y}&quot;)Og med klasse-instanser:class Point:x: int y: int def location(point):match point:case Point(x=0, y=0):print(&quot;Origin is the point's location.&quot;) case Point(x=0, y=y):print(f&quot;Y={y} and the point is on the y-axis.&quot;) case Point(x=x, y=0):print(f&quot;X={x} and the point is on the x-axis.&quot;) case Point():print(&quot;The point is located somewhere else on the plane.&quot;) case _:print(&quot;Not a point&quot;)Lister kan også anvendes som argument til case-sætningen:match points:case []:print(&quot;No points in the list.&quot;) case [Point(0, 0)]:print(&quot;The origin is the only point in the list.&quot;) case [Point(x, y)]:print(f&quot;A single point {x}, {y} is in the list.&quot;)Man kan også bruge underscore-wildcard'et på en mere kompleks facon:match test_variable:case ('warning', code, 40):print(&quot;A warning has been received.&quot;) case ('error', code, _):print(f&quot;An error {code} occurred.&quot;)Men der er mere, som de siger i TV-shoppen:Man kan også udstyre case-sætningen med en 'guard', også kendt som en 'precondition', ved at sætte en if-sætning efter case-udtrykket:match point:case Point(x, y) if x == y:print(f&quot;The point is located on the diagonal Y=X at {x}.&quot;) case Point(x, y):Og der er endda flere muligheder med match-sætningen, end hvad vi har vist her.Nemmere unionsPython er et sprog, hvor variabeltyper ikke gør det store væsen af sig. Men lidt type-information på en sidetallerken er nu heller ikke dårligt. I Python 3.5 kom muligheden for at antyde typer.Ligesom i den nye PHP er der nu en nem måde at angive, at en variabel eller parameter kan antage én af to eller flere typer, i stedet for den gamle måde, Union[int, float], at gøre det på:def square(number: int | float) -&gt; int | float:return number ** 2Context managers er en sætningskonstruktion, hvor ressourcer som eksempelvis fil-handlers kan deallokeres på en robust facon, uden at programmøren skal benytte try-finally eller andre tiltag. Det svarer til Java og C#'s try-with-resources og using, og nyheden er, at man kan have flere context managers i samme blok, som i:with (CtxManager1(), CtxManager2() ):Blandt andre nyheder er forbedrede fejlmeddelelser, som i dette eksempel:File &quot;example.py&quot;, line 1 expected = {9: 1, 18: 2, 19: 2, 27: 3, 28: 3, 29: 3, 36: 4, 37: 4, ^SyntaxError: '{'was never closed- hvor fortolkeren før i tiden blot ville have sagt SyntaxError: invalid syntaxog peget på starten af den efterfølgende sætning.SyntaxError har i det hele taget fået en lang række specialiserede meddelelser, så det bliver nemmere at finde ud af, hvad der er galt.Der er flere nyheder i den nye version, som er første beta af fire, før den endelige udgave udsendes i starten af september i år. Beta-versionen kan testes på Windows og Mac, mens andre dyr selv må kompilere kildekoden. Links til det hele kan findes i udgivelsesnoterne.
        </div>
        <footer>
          <em>Pro.ing.dk/Gridtech</em>
          &nbsp;·&nbsp; 2021-05-18
          &nbsp;·&nbsp; e8453331
          &nbsp;·&nbsp; #7
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.982</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.524</kbd>
        </footer>
      </article>
      <article>
        <h4>Forskere advarer: AI-forklaringsteknikker som Shap og Lime kan snydes</h4>
        <div>
          Et hold amerikanske forskere har demonstreret, at udbredte metoder til at åbne black box-modeller rent faktisk kan snydes, så indbygget bias kan skjules. I arbejdet med at gøre black box-machine learning til at forstå bliver frameworks som Shap og Lime brugt mere og mere. Men teknikkerne er faktisk ikke pålidelige, når det handler om at afsløre ellers skjult bias i ML-modellerne. Det mener et hold amerikanske forskere fra Harvard University og University of California. I en forskningsartikel , som blev offentliggjort i november, demonstrerer forskerne, at det er muligt at opbygge en klassifikationsmodel til at have en bias mod f.eks. race, men hvor forklaringer fra Lime og Shap ser uskyldige ud: »In particular, our results show that the explanations of these classifiers generated using off-the-shelf implementations of Lime and Shap do not flag any of the relevant sensitive attributes (e.g., race) as important features of the classifier, thus demonstrating that the adversarial classifiers successfully fooled these explanation methods.«  Forklaringsteknikker er ikke undersøgt Shap og Lime er begge teknikker til at forklare et specifikt resultat fra en model, som ellers ikke er umiddelbart aflæselig, som f.eks. en random forest. Modellen estimerer det bidrag, som den enkelte variabel giver til det endelige resultat. Det sker med en teknik, der kaldes 'input perturbations', hvilket grundlæggende går ud på at lave syntetisk data, som varierer inputtet for at se, hvad det betyder for resultatet, og på den måde afgør, hvilken del af inputtet er vigtigt for resultatet. Teknikkerne er blevet udbredt i takt med, at black box-modeller tages i brug til beslutningsstøtte. Med Shap kan en radiolog således få at vide, præcis hvilke dele af et billede der har fået deep learning-modellen til at mene, at patienten har en tumor. Eller en rekrutteringsalgoritme kan vise, hvilke dele af ansøgerens CV der gør kandidaten interessant. Og i forlængelse deraf kan teknikken således også vise, om modellen fokuserer på noget, der ikke hensigtsmæssigt. »However, there has been little analysis of the reliability and robustness of these explanation techniques, especially in the adversarial setting, making their utility for critical applications unclear,«  skriver forskerne. Med andre ord er spørgsmålet, hvor meget teknikkerne er værd, hvis skaberne af modellen prøver at snyde. Og her er svaret ifølge de amerikanske forskere altså ikke opløftende. Klassifikation med stillads Forskerne forestiller sig at have et incitament til at bruge en model, der har en indbygget bias, men omvendt er underlagt regulatoriske krav om at lade modellen blive analyseret med teknikker som Shap og Lime. I artiklen præsenterer forskerne et framework, der som input har den diskriminerende klassifikationsmodel samt et sample af den data, som modellen skal bruges på. Med det input bygger frameworket, hvad forskerne kalder et stillads (scaffold) rundt om en klassifikationsmodel. Modellen med stilladset udnytter det faktum, at Lime og Shap bruger syntetisk data for at teste variablernes betydning. Distributionen i den syntetiske data er nemlig tilpas anderledes end den ægte data, til at den ondsindede model kan skelne mellem, hvornår den bliver brugt, og hvornår den bliver testet. »By being able to differentiate between data points coming from the input distribution and instances generated via perturbation, an adversary can create an adversarial classifier (scaffolding) that behaves like the original classifier (perhaps be extremely discriminatory) on the input data points, but behaves arbitrarily differently (looks unbiased and fair) on the perturbed instances, thus effectively fooling Lime or Shap into generating innocuous explanations,«  skriver forskerne. Lime godkender kreditvurdering ud fra køn alene Artiklen giver to eksempler, hvor godt det virker i praksis. Forskerne bygger tre modeller: to, der på forskellige datasæt skal forudsige, om kriminelle vil begå ny kriminalitet alene baseret på race, og én model, der godkender lån alene baseret på køn. I alle tre tilfælde kunne modellen snyde Lime til at lave forklaringer, der ikke afslører modellernes bias. I Shap er forklaringen mere blandet. En af modellerne formåede at snyde Shap i 100 procent af tilældene, mens Shap afslører de andre to modellers bias i omkring 15 procent af tilfældene. »Our findings suggest that existing post hoc explanation techniques are not sufficiently robust for ascertaining discriminatory behavior of classifiers in sensitive applications,«  skriver forskerne, der foreslår, at man udvikler nye teknikker til at åbne black box-modeller, som ikke kan narres. Professor: Drop black box-modeller De amerikanske forskere er ikke de eneste, der er skeptiske over for praksissen med at tilføje et forklaringslag til en black box-model. I en kommentar , der er udgivet i maj og senest opdateret i september, advokerer Cynthia Rudin, der er datalogiprofessor ved Duke University, for at bruge modeller, der i sig selv kan forstås og fortolkes, som f.eks. beslutningstræer. »Rather than trying to create models that are inherently interpretable, there has been a recent explosion of work on 'Explainable ML', where a second (posthoc) model is created to explain the first black box model. This is problematic. Explanations are often not reliable, and can be misleading,«  skriver hun. Selv hvis både black box-modellen og den efterfølgende model til forklaring gør deres arbejde efter hensigten, så er det alt for lidt information, der komme ud af det, argumenterer Rudin. Hun nævner som eksempel saliency maps, der kan bruges til at forstå, hvad en computer vision-model egentlig ser på i et billede. Her demonstrerer Rudin, at et saliency map, der kategoriserer en hund som en fløjte, essentielt ser ligedan ud, når hunden kategorises korrekt. Fra Cynthia Rudins synsvinkel skal brugen af black box-modeller i kritiske miljøer helt undgås. »Trying to explain black box models, rather than creating models that are interpretable in the first place, is likely to perpetuate bad practices and can potentially cause catastrophic harm to society.« 
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2019-12-10
          &nbsp;·&nbsp; e77bda69
          &nbsp;·&nbsp; #8
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.996</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.659</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.544</kbd>
        </footer>
      </article>
      <article>
        <h4>Google Cloud lægger over to millioner kroner i Python-udvikling</h4>
        <div>
          Kørselsmiljø, værktøjer og sikkerheden i pakkesystemet får en kontant saltvandsindsprøjtning fra it-kæmpen.Google Cloud har doneret 350.000 USD, svarende til 2,16 millioner kroner, til Python Software Foundation, som står bag sproget af samme navn. Det skriver InfoworldMålet for donationen er støtte udviklingen af CPython, som er det officielle kørselsmiljø, samt forbedring af sprogets grundlæggende værktøjer og styrke sikkerheden af Pythons Pypi-pakkesystem.Google benytter blandt andet Python og dets pakkesystem i forbindelse med firmaets Tensorflow-produkt til kunstig intelligens. I en meddelelse skriver Google Cloud, at Python er af »kritisk vigtighed«  for firmaet og dets kunder.Udover kunstig intelligens er Python også et populært afviklingsmiljø for mange af firmaets tjenester, såsom Google App Engine og Google Cloud Functions.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2021-02-18
          &nbsp;·&nbsp; e821bd91
          &nbsp;·&nbsp; #9
          <br>
          <br>
            <kbd data-tooltip="Tech industry &amp; regulation">L02_BIGTEC&nbsp;0.972</kbd>
            <kbd data-tooltip="AI &amp; innovation">L05_INNOAI&nbsp;0.631</kbd>
            <kbd data-tooltip="EU regulation of big tech">L10_EUREGU&nbsp;0.567</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.532</kbd>
        </footer>
      </article>
      <article>
        <h4>Transparens og præcision: SHAP-analyse forklarer, hvad der foregår i black-box-modeller</h4>
        <div>
          Et nyt værktøj til arbejdet med komplekse machine learning-modeller gør det muligt at åbne den sorte kasse og forklare, hvordan modellen kom frem til en bestemt forudsigelse. SHAP-værktøjet - SHapley Additive exPlanation - åbner for, at virksomheder ikke behøver at ofre præcision for at kunne forsvare algoritmens forudsigelse.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2018-10-02
          &nbsp;·&nbsp; e6eb61b6
          &nbsp;·&nbsp; #10
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.899</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.837</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.608</kbd>
        </footer>
      </article>
      <article>
        <h4>Intelligenstest</h4>
        <div>
          Implementering af it-systemer, der rent faktisk virker efter hensigten, har vist sig at være en udfordring for det offentlige, ikke mindst Skat. Er den så omdiskuterede Artificial Intelligence (AI) mon efterhånden menneskehedens eneste håb om en intelligent løsning af it-problematikker? &gt;&gt; Se flere på ing.dk/ satire. 
        </div>
        <footer>
          <em>Ingeniøren</em>
          &nbsp;·&nbsp; 2017-04-07
          &nbsp;·&nbsp; e633e8e7
          &nbsp;·&nbsp; #11
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.679</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.732</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.556</kbd>
        </footer>
      </article>
      <article>
        <h4>Googles Go-sprog får endelig typeparametre</h4>
        <div>
          Efter flere års udvikling er et forslag om typeparametre vedtaget. Faciliteten debuterer i Go 1.18, der skal udkomme i starten af næste år.Sproget Go følger nu efter de fleste andre moderne programmeringssprog og får typeparametre, også kaldet 'generics.'Det skriver to af sprogets udviklere , Ian Lance Taylor og Robert Griesemer, der begge er ansat i Google. Sproget blev i sin tid udviklet for at løse de udfordringer, der er med server-programmering i stor skala hos Google.Udviklerne meddeler, at faciliteten forventes at blive tilføjet i version 1.18, som skulle udkomme i starten af 2022.Typeparametre gør det muligt at skrive kode, hvor funktioner benytter samme operationer for parametre og variable af forskellige typer, og kan på denne måde generalisere en algoritme.Det benyttes ofte i forbindelse med samlinger, hvor eksempelvis en liste-struktur kan udrustes med en elementtype, så metoder som tilføj(e) kun kan udføres med elementer af den specificerede type som parameter.Forslaget har været en del år undervejs og et tidligere udkast, som byggede på kontrakter , er forkastet til fordel for en anden model.Et trivielt eksempel kan se sådan ud, ifølge det vedtagede forslag:// Print prints the elements of a slice.// It should be possible to call this with any slice value.func Print(s []T) { // Just an example, not the suggested syntax.for _, v := range s {fmt.Println(v)}}I eksemplet her er []T et slice med elementtypen TTypeparametre er magen til almindelige funktionsparametre, og de anføres sammen med andre parametre.Typeparametrene kan udstyres med 'constraints', som begrænser udvalget af typer, der kan anvendes som parametre. En constraint er blot et almindeligt interface, som Stringer herunder:// Stringify calls the String method on each element of s,// and returns the results.func Stringify[T Stringer](s []T) (ret []string) {for _, v := range s {ret = append(ret, v.String())}return ret}Ingen ko- eller kontravariansSprogudviklerne har fravalgt muligheden for at angive kovarians og kontravarians for funktionsparametre, en facilitet der findes i sprog som Java og C#, og som gør det muligt at specificere, hvornår en subtype eller en supertype også accepteres som parameter givet ved et typeudtryk. Udeladelsen gør generics simplere, skrives der i forslaget.I modsætning til Java benyttes der ikke 'type erasure', og det betyder, at en typeparameter i Go er kendt og kan anvendes i koden under afviklingen.Sammenlignet med C++ nævner sprogudviklerne, at dette sprogs template-implementering af typeparametre ikke benytter constraints, hvilket kan føre til fejlmeddelelser, som kan være svære at forstå for programmøren.I sammenligning med Rust nævnes det, at Gos nye implementering er magen til Rust, dog med visse forskelle, såsom at en trait i Rust, der benyttes som constraint, skal knyttes specifikt til en type.Der er mere information om Gos typeparametre i udkastet . Af kodeeksemplerne heri fremgår det, at den endelige syntaks endnu ikke er fastlagt.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2021-03-24
          &nbsp;·&nbsp; e82eb4cc
          &nbsp;·&nbsp; #12
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.984</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.679</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.633</kbd>
        </footer>
      </article>
      <article>
        <h4>PRM / Hvordan bliver computeren en retfærdig superhelt? Aka lidt om fairness i maskinlæring</h4>
        <div>
          KøbenhavnPressemeddelelse fra Alexandra InstituttetEller knap så højtflyvende, så giver denne blogpost en introduktion til begreberne &quot;fairness&quot; og &quot;bias&quot; i maskinlæring. For den danske oversættelses skyld vil vi benytte ordet &amp;lsquo,skævhed' i stedet for &amp;lsquo,bias'. Vi kan tænke på det som en form for uhensigtsmæssighed, som er skadelig i form af uretfærdige fordomme eller behandlinger af enkelte personer eller grupper. En af frontfigurerne på plakaten er Kate Crawford, som holdt en keynote-tale om emnet på NIPS 2017 (konference om Neural Information Processing Systems), og i sin definition af begrebet skelner hun mellem uhensigtsmæssigheder i form af allokering af ressourcer og muligheder, og uhensigtsmæssighed i form af repræsentationer, som knytter sig til identitet og hvordan folk opfattes.Denne skelnen vil vi kæmpe lidt videre med, hvorefter vi kigger på, hvordan skævheder opstår, definitioner på fairness, metoder til at undgå det, og i tillæg, da alle superhelte jo kræver træning, vil vi hente superhero dataset fra Kaggle at øve os på.Nogle er mennesker, andre er kryptonians...... og atter andre tilhører en helt tredje gruppe. Maskinlæring kan bruges til beslutningsstøtte til fordelinger af ressourcer og muligheder, og her kan skævheder opstå, hvis personer eller bestemte grupper bliver favoriseret eller diskrimineret. Eksempler på uønskede skævheder er, hvis kreditvurderinger afhænger af race, eller hvis anbefalinger af jobansøgninger afhænger af køn. I dette setup arbejdes der med såkaldte &quot;beskyttede attributter&quot;, som angiver tilhørsforhold til en gruppe, som man ønsker at beskytte, og traditionelt er der her kig på køn, race, nationalitet eller etnicitet. Målet med fair maskinlæring er så at sikre 'retfærdigheden' af modellerne, men hvordan dette overhovedet kan formaliseres, vil vi løfte masken for senere.I vores superhelte-datasæt fra Kaggle er der angivet navne på en række superhelte, deres egenskaber, en række personkarakteristikker såsom køn og race, samt hvorvidt superheltene er gode elle onde. I denne blogpost vil vi gerne prædiktere, om en superhelt er god eller ond, men det skal være på en måde, som sikrer ligebehandling af kønnene. Men igen, hvad vil det sige, eller spørgsmålet er nok snarere, hvad kan det sige?Fem eksempler fra datasættet, dog ikke alle superkæfter er vist. Et 1-tal betyder at helten besidder kraften.Det er dragten...... som giver superhelten identitet. Den anden form for skævhed, som defineret af Kate Crawford, går på, hvordan vi repræsenter folk. Hvordan folk fremstilles, kan have en problematisk indflydelse på, hvordan vi i sidste ende opfatter bestemte grupper. Ofte fremhævede eksempler i debatten, til at vække harme, var, da Google Photo taggede en afroamerikansk kvinde som gorilla, (se her), eller at der er kønsstereotyper i måden, ord repræsenteres på i Natural Language Proessing (Se mit blogindlæg om word embeddings), eller tilfælde hvor ansigtsgenkendelse virker dårligere på mørk hud end lys hud. Et andet eksempler er fra 2015, hvor en google-søgning på CEO, resulterede hovedsageligt i billeder af hvide mænd i slips, og hvor det første billede af en kvinde, 10 rækker nede, var en Barbiedukke udklædt som CEO (se her). Superhelte-branchen er måske ikke just selv det gode eksempel på en fair kønsfordeling og repræsentation - så hvorfor, og hvornår, handler de her ting overhovedet om maskinlæring?Hvordan kommer vi i Justice League...... med vores maskinlæringsmodeller? Det grundlæggende problem ved eksemplerne ovenover er teknisk set ikke, at modellerne indimellem fejler, som ved klassificeringer af en kvinde som en gorilla, men at systemerne her reproducerer og automatiserer en skævhed og diskrimination, som allerede er til stede i samfundet eller som er historisk, som fx racisme mod afroamerikanerne. Det er derfor, at eksemplet med den afroamerikanske kvinde bliver så slående. I det andet eksempel med søgningen på CEO problematiserer Kate Crawford, hvad et fair resultat i givet fald ville være, skal søgningen vise den aktuelle fordeling af køn og etnicitet på folk, der besidder en CEO-post, eller skal den vise den fordeling, som folk synes er fair? Hvordan mennesker bliver klassificeret og repræsenteret, er ikke blot et maskinlærings-problem, men et samfundsproblem, og svaret på hvad en fair model er, går derfor også udover det tekniske i at fjerne skævheder fra modellerne til også at være et etisk, kulturelt og politisk spørgsmål. Og svaret på, hvad der er fair, er i sig selv tidsligt og kulturelt bestemt - og vil ændre sig igen over tid.Her føler man sig måske fanget i spindelvævet. Men selvom der ikke er noget entydigt svar på, hvad en fair model er, er det vigtig at opbygge viden og forståelse for, hvorledes uhensigtsmæssigheder kan være til stede, hvorfor de opstår, og hvordan de kan håndteres for at sikre, at maskinlæring forbliver et anvendeligt værktøj. Disse ting vil vi introduktionsvis tage hul på i de næste paragrafer.Det er data, der er skurken!Ofte, når vi prøver at finde årsager til skævheder i maskinlæringsmodeller, skal vi kigge i træningsdata. Disse skævheder kan være forskyldt af kulturelle eller historiske grunde, men det kan også være mere på grund af uvidenhed eller fejl. Det kan da nævnes, at skævheder også kan opstå fra valg af algoritme, da man kan forstille sig, at repræsentation for én gruppe er sværere at lære for en type algoritme end for en anden. Nogle af de potentiale årsager til, hvorfor skævheder opstår i data, er listet herunder, men du kan også læse mere om det i fx denne blogpost.Overstående liste giver et begyndende billede af, hvordan uønskede skævheder kan opstå i data og nedarves til modeller, så lad os nu kort se på teknikker til at forholde os til det.Våben vi kan forsvare os medDet kan være en udfordring i sig selv at opdage og stadfæste uønskede skævheder alt efter årsagen til skævheder, og metoderne er forskellige alt efter, om der er tale om den mere klassiske allokeringsproblematik eller repræsentationsproblematikken. Der findes en hær af metrikker til at måle uønskede skævheder på i data eller modeller (se lidt længere nede). Der findes ligeledes en hær af metoder til at forsøge at fjerne eller minimere skævheder i data og modeller alt efter typerne. Overordnet set kan metoder til at prøve at mindske skævheder inddeles i algoritmer, der forsøger1) at fjerne skævheder i data før selve træningen,2) at fjerne under træning ved reguleringsteknikker eller3) at fjerne efter modellen er trænet.Det kan anbefales at tjekke kampudstyr ud på IBM's open source tool AI Fairness 360 , hvor flere af de nyeste metoder er implementeret. Et eksempel på et paper, som prøver at stadfæste og fjerne en repræsentativ skævhed i word embeddings er Bolukbasi et al. (2016). Et eksempel på gængse metrikker inden for klassifikationsmodeller vil vi gennemgå og diskutere nedenfor, men først skal vi en tur på træningsbane og endelig have os en model på superhelte-datasættet.På træningsbanenSuperhelte-datasættet er brugt til at træne en binær klassifikationsmodel, som ud fra en række features kan prædiktere, om en superhelt er, ja, en helt eller en skurk, i vores simple verden, god eller ond. Featuresene der er brugt, indbefatter navne, højde, vægt og hvilke superkræfter de har (der er defineret 667 forskellige superkræfter), og som model til dette legeeksempel vil vi blot benytte logistik regression. 33% af datasættet er taget ud til testsæt, hvilket giver 203 eksempler er teste på. På dette testsæt opnås der en accuracy på 0.71, og en makro F1 på 0.61. Til sammenligning er det værd at bemærke, at datasættet er ubalanceret i forhold til god/ond, så hvis vi blot laver et gæt på den mest frekvente klasse, kan vi opnå en baseline accuracy på 0.65, men med 0.39 i F1. Lad os prøve et eksempel af på vores model og opfinde en superhelt. Vi kalder ham &quot;Super Transparent Goble&quot; og giver ham følgende fire superkræfter: Latern Power Ring, Agility, Dimensional Awarness og Speed Force. Derudover giver vi ham lidt substans i form af en højde og en vægt i pund.En opdigtet superhelt vi kan bede modellen klassificereModellen prædikterer, at han er god!Lad os lege, at vi vil anvende modellen som dørmand på en natklub, og det er kun dem, vi tror, der er skurke, vi vil lukke ind til festen (vi gider jo ikke en alt for kedeligt fest!). Det positive udfald, som superheltene håber på, er da at blive klassificeret som skurk. Men vi ønsker en fair model i forhold til kvindelige og mandlige superhelte, men hvad kan det sige?Definition af superkræfter...... eller definition af forskellige fairness-kriterier. Gajane and Pechenizkliy 2018 har gennemgået, hvordan fairness i maskinlæring kan blive formuleret matematisk, samt forestået sammenligninger af definitionerne med dem i socialvidenskaben på styrker og svagheder. Overordnet inddeler de kriterierne i seks overordnede grupper. For at give et billede af hvor mange definitioner der allerede findes, kan det nævnes, at IBM i deres open source tool AI Fairness 360, har implementeret mere end 70 metrikker. Men metrikkerne er ikke alle kompatible med hinanden - og så er der hele spørgsmålet om, hvorvidt restriktionen af fairness koster en på nøjagtighed for modellen. Nedenfor er der listet nogle forskellige grupper af definitioner (Gajane and Pechenizkliy 2018 ), og enkelte metrikker fremhæves for at åbne diskussionen om fordele og ulemper:1) Fairness igennem uvidenhed. En model, som ikke betinger på den 'beskyttede' attribut, opfylder dette kriterium. I vores superhelte-klassifikationsmodel er køn-variablen taget ud inden træning af modellen, hvilket vinger dette fairness-kriterium af som opfyldt! Desuden kan det bemærkes, at træning med eller uden informationen om kønnet ikke ændrer på performance, i vores tilfælde. Men bemærk nogle ulemper ved dette kriterium, informationen om den beskyttede attribut kan ligge latent i de andre features. F.eks. i vores superhelte-tilfælde kan kønnet ligge latent i de andre variabler, man kunne fx forestille sig at højde, vægt, og selve navnene kunne give et præg om kønnet.2) Gruppefairness. Herunder hører en af de tidligere anvendte kriterier, 'Demographic Parity&quot;, som kræver, at en klassifikationsmodel skal prædiktere et bestemt udfald med lige stor sandsynlighed uafhængigt af den beskyttede gruppevariabel. I superhelte-modellen kan vi udregne sandsynligheden for at blive klassificeret som skurk (positiv rate) for hhv. kvinder og mænd ved at se på konfusionmetrikken:Konfussionmatricer opdelt på kvinder og mændFor kvinder er sandsynligheden for at blive klassificeret som skurk 9% (5/55), hvorimod der for mænd er 15.5% (23/148) chance for det. Modellen opfylder altså ikke dette kriterium. Her kan man jo så restringere systemet til at opfylde kriteriet, men som blandt andet påpeget i Hardt et. al 2016 har det nogle åbenlyse ulemper, da det kan føre til scenariet, hvor rigtige skurke i den ene gruppe bliver afvist i døren, og modsat: at rigtige helte i den anden gruppe bliver lukket ind (husk: vi vil kun have skurke med til festen). Dette scenarium kan opstå, hvis der fx er lidt træningsdata i den ene gruppe, eller det faktum at det at tilhøre en bestemt gruppe faktisk er korreleret med udfaldet. Hvis vi kigger på kønsfordelingsplottet, kan vi se, at en mindre procentdel af kvindelige superhelte faktisk er 'rigtige' skurke, hvilket kan være en labelbias, men det kan også bare være 'sådan det er'. En fordel ved at bruge dette mål for fairness kan være, hvis man bevidst ønsker at ændre en skævhed i samfundet, fx ved bevidst at optage en vis procentsats fra en bestemt baggrund på en uddannelse, fx kvinder på superheltetræningsakademiet, selvom de er mindre kvalificerede, men så veje op for det ved desuden at lave en række tiltag for at løfte nivauet af ondhed.3) Equality of opportunity. Denne metrik blev først introduceret i Hardt et. al 2016, som et svar til nogle af problemerne med 'Demographic parity'. Her går kravet på, at den positive klassificering bør være uafhængig af den beskyttede klasse, givet at udfaldet faktisk er 'positivt'. Så i superhelte-eksemplet kan vi ud fra konfusionmatricerne udregne &amp;lsquo,true positive'-raten. For kvinder bliver det (tp/(tp+fn)) 30% af dem, som rigtigt er skurke, som også bliver klassificeret som sådanne. For mandegruppen er dette tal 29%, hvilket vil sige, at forskellen er lille, og vi i praksis vil kunne sige, at modellen opfylder kriteriet for en fair model, så tillykke! Dette kriterium er mest anvendeligt, når der er størst fokus på at klassificere det positive udfald korrekt, mod at man til gengæld ikke opfatter falske positive som omkostningstunge. Ellers kan man anvende metrikken 'Equalized odds', som i tillæg også kræver en lighed i falsk/positiv-raten.4) Præference-baseret fairness. Kriteriet er introduceret af Zafar et. al 2017 og prøver at adresse nogle af ulemperne ved overstående metrikker, såsom at de er inkompatible og kan forårsage fald i nøjagtighed at opfylde. Her opstilles i stedet kriteriet, at hver gruppe i princippet har hver sin model, som de skal have præference for, således at skiftet over til den anden gruppes model ikke er gavnligt. Dette giver plads til at forbedre performance inden for hver gruppe.5) Individuel fairness. En model er fair, hvis den forudsiger det samme udfald for lignede personer/tilfælde.6) Counterfactual measures. Se fx Kusner et. al 2018 .Superhelte-datasættet indeholder også information om race, men der er defineret 61 forskellige racer med alt fra Mutant til Cyborg, og desværre mangler oplysningen for 40% af vores helte, så vi vil undlade at lave analysen, men blot bemærke følgende: Det at sikre en fair model for 'kvinder' vs. 'mænd' og for 'Mutanter' vs. 'Mennesker' er ikke det samme som, at vi har sikret, at modellen ikke er diskriminerende mod 'kvindelige mutanter'.Der er altid et twist...... der snyder superhelten &amp;frac34, inde i filmen. Nogle af twistene og fælderne ved fair maskinlæring bliver også debatteret i litteraturen, blandt andet i Liu et. al 2018, som viser, hvordan fair maskinlæring, fx ved brug af demographic parity eller equalized odds, kan have en forsinket negativ indflydelse på de grupper, som den prøver at beskytte. Ligeledes ser D'Amour et. al 2020 fra dette års FAT* konference (Fairness, Accountability, and Transparency) på, hvordan langtidseffekterne kan modelleres ved hjælp af simulationer. Derudover kan Selbst et. al 2018 nævnes, som har fokus på de &quot;fælder&quot;, som eksisterer rundt om fair maskinlæring. Et eksempel er, hvis modellen bliver fulgt på en skæv måde. Det kunne tænkes, i vores superhelte-eksempel, at dørmanden ikke følger modellens anbefalinger nær så ofte for det ene køn som for det andet. Til sidst kan Grfic-Hlaca et. al 2018 nævnes, som sætter spørgsmålstegn ved, om fokus kun bør være på såkaldte beskyttede attributter, eller om folks opfattelse af, hvad der er fair, ikke i lige så høj grad går på, hvilke informationer modellen bruger i forskellige sammenhænge. F.eks. kunne det måske opfattes som unfair, at vores superhelte-model faktisk benytter information om vægt for at afgøre, om jeg er en skurk, der må komme ind til en festen eller ej.To be continued...Som i de fleste superhelte-film, lægger det op til en 2'er, for selvom fokus på fair maskinlæring har været voldsomt stigende de seneste år, er feltet langt fra i mål, og som diskuteret er mange af spørgsmålene nogle, der ikke kun skal løses teknisk - men i høj grad også etisk.ReferencerBolukbasi, T., Chang, K. W., Zou, J. Y., Saligrama, V., &amp; Kalai, A. T. (2016). Man is to computer programmer as woman is to homemaker? debiasing word embeddings. In Advances in neural information processing systems (pp. 4349-4357).D'Amour, A., Srinivasan, H., Atwood, J., Baljekar, P., Sculley, D., &amp; Halpern, Y. (2020, January). Fairness is not static: deeper understanding of long term fairness via simulation studies. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (pp. 525-534).Gajane, P., &amp; Pechenizkiy, M. (2017). On formalizing fairness in prediction with machine learning. arXiv preprint arXiv:1710.03184.GrgiÄ?-HlaÄa, N., Zafar, M. B., Gummadi, K. P., &amp; Weller, A. (2018, April). Beyond distributive fairness in algorithmic decision making: Feature selection for procedurally fair learning. In Thirty-Second AAAI Conference on Artificial Intelligence.Hardt, M., Price, E., &amp; Srebro, N. (2016). Equality of opportunity in supervised learning. In Advances in neural information processing systems (pp. 3315-3323).Kusner, M. J., Loftus, J., Russell, C., &amp; Silva, R. (2017). Counterfactual fairness. In Advances in Neural Information Processing Systems (pp. 4066-4076).Liu, L. T., Dean, S., Rolf, E., Simchowitz, M., &amp; Hardt, M. (2018). Delayed impact of fair machine learning. arXiv preprint arXiv:1803.04383.Selbst, A. D., Boyd, D., Friedler, S. A., Venkatasubramanian, S., &amp; Vertesi, J. (2019, January). Fairness and abstraction in sociotechnical systems. In Proceedings of the Conference on Fairness, Accountability, and Transparency (pp. 59-68).Zafar, M. B., Valera, I., Rodriguez, M., Gummadi, K., &amp; Weller, A. (2017). From parity to preference-based notions of fairness in classification. In Advances in Neural Information Processing Systems (pp. 229-239).Kontakt:Communications Specialist Lisa Lorentzen tlf.: +45 93 52 17 64 email: lisa.lorentzen@alexandra.dkLæs hele pressemeddelelsen på Via Ritzau her: https://via.ritzau.dk/pressemeddelelse/hvordan-bliver-computeren-en-retfaerdig-superhelt-aka-lidt-om-fairness-i-maskinlaering?releaseId=13593237** Ovenstående pressemeddelelse er videreformidlet af Ritzau på vegne af tredjepart. Ritzau er derfor ikke ansvarlig for indholdet ** 
        </div>
        <footer>
          <em>Ritzaus Bureau</em>
          &nbsp;·&nbsp; 2020-05-13
          &nbsp;·&nbsp; e7b4b97e
          &nbsp;·&nbsp; #13
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.994</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.638</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.596</kbd>
        </footer>
      </article>
      <article>
        <h4>PRM / Rapport: Bitdefender er 'Leader' inden for sikkerhedsløsninger til virtuelle miljøer</h4>
        <div>
          KøbenhavnPressemeddelelse fra BitdefenderBukarest, Rumænien, 10. december, 2019 - Analysevirksomheden Forrester peger i en ny rapport på Bitdefender som en af de førende virksomheder inden for Cloud Workload Security (CWS). Det er konklusionen i rapporten &quot;The Forrester Wave&amp;trade,: Cloud Workload Security (CWS), Q4 2019&quot;, der blev udgivet i dag. Ud af 13 evaluerede CWS-udbydere er Bitdefender udpeget som én af blot tre førende virksomheder i rapporten. Rangeringen er baseret på 30 stringente kriterier til vurdering af forhandlernes produkter, strategi og tilstedeværelse i markedet. Ifølge Forrester-rapporten udmærker Bitdefender sig i kategorierne &amp;lsquo,Database', &amp;lsquo,User' og &amp;lsquo,Agent Rollout Management': &quot;Med sin erfaring inden for teknologi til malware-, memory- og hypervisor-beskyttelse, formår Bitdefender at skabe en bred CWS-løsning [...] Løsningen passer til virksomheder, der har et særligt behov for kapacitet til styring af hypervisorer i hybride cloud-miljøer,&quot; skriver Forrester i rapporten.Topscorer i tre kategorierDet er særligt inden for kategorierne &amp;lsquo,Security Capabilities', &amp;lsquo,Management Simplicity and Usability', og &amp;lsquo,Strategy' at Bitdefender skiller sig ud, hvor virksomheden scorer topkarakterer på en lang række kriterier:Security Capabilities: Bitdefender scorer topkarakterer på kriterierne &amp;lsquo,beskyttelse af workloads på operativsystemniveau', &amp;lsquo,skalérbarhed: beskyttede hypervisorer' og &amp;lsquo,beskyttelse af hypervisorer'. Ifølge Bitdefender selv skyldes det Bitdefenders specialtilpassede software til detektering af trusler, HyperDetect, der er baseret på machine learning, samt andre unikke egenskaber der er gjort mulige med Bitdefender Hypervisor Introspection.Management simplicity and usability: De høje scorer i kategorien blev opnået på kriterierne &amp;lsquo,opsætning, konfiguration og dataintegration', &amp;lsquo,kontekstafhængig hjælp' og &amp;lsquo,navigering, integreret miljø'. Bitdefenders omfattende kapaciteter inden for konfigurering og opsætning af back-end dataopbevaring, mekanismer til masseudrulning, konfigurerbar malwarebeskyttelse og kontrol over binær privilegie-eskalering er, ifølge Bitdefender, årsag til de høje karakterer.Strategi: Bitdefenders høje karakterer i kategorien blev opnået med udgangspunkt i kriterierne &amp;lsquo,tjenesteydelser og partnere' og &amp;lsquo,beskyttelsesplaner til hypervisorer'. Det er ifølge Bitdefender grundet virksomhedens planer om at udvide antallet af løsninger i GravityZones Software-as-a-Service version, de forbedrede muligheder for at opdage og reagere på angreb på Linux-systemer og udgivelsen af beskyttelsesmoduler til containere.Rapporten slår også fast, at Bitdefenders løsninger tilbyder værdifuld hypervisor-introspektion og en god API-baseret håndtering af regler såvel som konfigurerbare dashboards. Bitdefender har integrations-partnerskaber med førende hybride cloud-platforme, herunder AWS, Azure, Pivotal, VMware, Nutanix og Citrix.&quot;Vi tror på, at denne anerkendelse validerer skarpsindigheden i Bitdefenders strategiske vision og styrke af virksomhedens CWS-ydelser,&quot; fortæller Gavin Hill, Vice President, Datacenter and Network Security hos Bitdefender. &quot;Bitdefenders løsningers sikkerhedsegenskaber, simple håndtering og unikke beskyttelse på hypervisor-niveau hjælper virksomheder og regeringer verden over med at beskytte servere og virtuelle desktops, ligegyldigt hvor de opererer.&quot;For at modtage en kopi af rapporten, besøg https://businessresources.bitdefender.com/forrester-wave-cloud-workload-security-2019For at lære mere om Bitdefenders teknologi til beskyttelse af cloud workloads, besøg https://www.bitdefender.com/business/enterprise-products/virtualization-security.html eller https://www.bitdefender.com/business/enterprise-products/hypervisor-introspection.html.Kontakt:Daniel Mølgaard Jensen
Konsulent
Frontpage PR og Kommunikation
+45 28 40 89 62
daniel.molgaard@frontpage.dkLæs hele pressemeddelelsen på Via Ritzau her: https://via.ritzau.dk/pressemeddelelse/rapport-bitdefender-er-leader-inden-for-sikkerhedslosninger-til-virtuelle-miljoer?releaseId=13584716
        </div>
        <footer>
          <em>Ritzaus Bureau</em>
          &nbsp;·&nbsp; 2019-12-10
          &nbsp;·&nbsp; e77c1b8f
          &nbsp;·&nbsp; #14
          <br>
          <br>
            <kbd data-tooltip="Tech industry &amp; regulation">L02_BIGTEC&nbsp;0.676</kbd>
            <kbd data-tooltip="DK business &amp; innovation policies">L05_DKINNO&nbsp;0.511</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.527</kbd>
        </footer>
      </article>
      <article>
        <h4>Sådan tuner vi vores machine learning-algoritme, der finder emneord</h4>
        <div>
          Med optimeringer kan vi presse lidt flere procents succes ud af vores algoritme, der gætter emneord ud fra en nyskrevet Version2-artikel. Men kan det bruges det til noget?På Version2 har vi talt om muligheden for at finde emneord med maskinlæring. Et emneord er et ord, der beskriver en artikels emne, såsom Databeskyttelsesloven, Sundheds-it, GDPR, Java, Ledelse, eller hvad det nu kunne være.I en tidligere artikel satte vi handling bag snakken: Med den klassiske algoritme Naive Bayes fra 1960'erne, skabte vi en metode til at gætte på emneord. Når emnet var sundheds-it, kunne algoritmen finde 7 af 12 artikler om emnet, ud af 297 test-artikler. Der var 5, den ikke kunne finde, og den pegede ikke galt.Det regnede vi om til fire procent-tal mellem nul og hundrede:Precision - hvor tit gættede algoritmen 'sundheds-it'rigtigt?Recall - hvor stor procentdel af sundheds-it-artiklerne fandt den?Accuracy - træfsikkerhedF1 - et slags gennemsnit af precision og recall, som kan bruges til at optimere algoritmen med.Vi havde super-god precision på 100%, men vores recall var 58%, så der var en del, den ikke fandt.Men hvad er egentlig -godt- i sådan en algoritme? Som vi var inde på i sidste artikel, handler det om anvendelsen.Prøven fandt ikke fatal hjertefejlHvis det drejer sig om en medicinsk prøve, vil vi være tilbøjelige til at acceptere flere falske positive, hvis det kan nedsætte antallet af falske negative, hvor en farlig tilstand hos patienten måske bliver overset.I vores tilfælde, hvor algoritmen skal komme med forslag til emneord, hvorefter journalisterne selv bestemmer, om de vil følge forslaget eller ej, virker en ligelig vægtning af precision og recall som en god ide. Vi ønsker mange pletskud og vil også ramme en stor del af sundheds-it-artiklerne. Derfor er f1-målet, som er et (harmonisk) gennemsnit af precision og recall, det rigtige mål for os.Men hvad var det nu, vi skulle bruge det hele til?Vi vil gerne have, at algoritmen skal foreslå emner til en ny, frisklavet artikel. Det kræver, at algoritmen rent faktisk giver et bud. Hvis eksempelvis precision er 100% og recall 10%, så kommer der kun et bud hver tiende gang, selvom den gætter helt rigtigt i testsættet.I tilfældet med sundheds-it vil vi godt give køb på precision, hvis vi kan kan få højere recall. Til den opgave benytter vi som sagt f1-målet, der vægter sol og vind - precision og recall - ligeligt.Laplace smoothing revisitedI sidste artikel byggede vi de centrale ord-estimater, logPHat, med denne formel, hvor hyppighedstabellen er optællingen af ordenes hyppighed i artikler om sundheds-it:for (ord in hyppighedstabel):logPHat = log((hyppighedstabel(ord) + 1)/ (antalOrdISundhedsItKlassen + antalUnikkeOrdIAlleArtikler) ) sundhedsItEstimatTabel.put(ord, logPHat)'+ 1'i tælleren og'+ antalUnikkeOrdIAlleArtikler' i nævneren var en måde at kompensere for det forhold, at vi måske støder på ord i testsættet, som ikke optræder i træningssættet.Teknikken kaldes som nævnt i forrige artikler for Laplace smoothing, men argumentationen bag siger i og for sig ikke, at det lige præcis skal være 1, der lægges til. Vi modificerer nu formlen, så det ekstra bidrag er et komma-tal k. Det ser sådan ud:for (ord in hyppighedstabel):logPHat = log((hyppighedstabel(ord) + k)/ (antalOrdISundhedsItKlassen+ k * antalUnikkeOrdIAlleArtikler) ) sundhedsItEstimatTabel.put(ord, logPHat)Nu har vi en fri parameter -k-, som vi kan bruge til at tune algoritmen.Vi skal også ændre testalgoritmen tilsvarende. Den ser nu sådan:sundhedsItLogEstimat = log(artiklerOmSundhedsIt / antalArtikler) for (ord in artikel):logPHat = sundhedsItEstimatTabel.get(ord) if (logPHat == null):logPHat = log(k / (antalOrdISundhedsItKlassen+ k * antalUnikkeOrdIAlleArtikler) ) sundhedsItLogEstimat += logPHatVi kører nu vores emneord igennem algoritmen ligesom sidst, men varierer k fra 0,1 til 2,0 i små skridt. Den værdi af k, der giver højest f1, har vundet.Ofte ender det med, at vi tuner for meget, så algoritmen forveksler testsættets ejendommeligheder med den virkelige verden, et fænomen, der kaldes -overfitting.-F-alfa måletF1-målet findes også i en anden variant, med navnet F-alfa, hvor man kan vægte precision højere end recall og vice versa:F_a = (1 + a^2) * (precision * recall) / (a^2 * precision + recall)F_0,5 lægger således mere vægt på precision, mens F_2 lægger mere vægt på recall.Derfor tester vi efter optimering på et nyt, uberørt testsæt. Det giver os et bud på, hvor realistisk en f1-værdi vi kan forvente, når vi slipper algoritmen løs i den virkelige verden.Det betyder, at vi nu har tre sæt af artikler: Vores træningssæt, vores udviklingstestsæt (eller -devtestsæt-), og det endelige testsæt.Vi har ændret lidt i størrelsen af vores datasæt siden sidst, for at få plads til både devtestsæt og testsæt.Det har sat vores resultat fra tidligere en smule tilbage, så vores eksempel fra sidst - sundheds-it - har nu f1 på 57% (og precision og recall på 80% og 44%.)Der er plads til forbedringer.Vi finder nu den optimale værdi af laplace-parameteren k, som beskrevet ovenfor, og det giver for sundheds-it et f1-mål på 75%, med k = 0,3, på baggrund af devtestsættet.Det var jo en knald-god forbedring, op fra de 57%, vi startede med - men har vi overfittet?Vi tester nu på vores uberørte testsæt - og så sætter realismen ind:Her får vi en f1 på kun 56%.I fortvivlelsens dal (på hype-kurven)For dælen da - det er lavere end i udgangspunktet.Det skyldes, at vi startede med devtestsættet og derefter afprøvede med testsættet. Tallene, der kommer ud af algoritmen, afhænger af, hvilket specifikt testsæt vi benytter, også selvom antallet af artikler er det samme i begge sæt.Gudskelov ser tingene lidt anderledes ud, hvis vi går et skridt baglæns og udregner f1 med k=1,0 og testsættet. Her får vi en f1 på 50%, så tuningen med laplace-k'et gav os en realistisk forbedring på 6 procentpoint. Og det er vel værd at tage med.Men tilbage til det oprindelige spørgsmål: Kan det bruges til noget?De 56% i f1 er på baggrund af en precision på 47% og recall på 70%. Den gætter altså sundheds-it rigtigt omkring halvdelen af gangene, og finder 7 ud af 10 mulige.Hvad siger journalisterne?Jakob mener, det kan bruges. Magnus peger på, at det »mest irriterende« er falske negative, hvor algoritmen ikke kommer med bud på emnet, og at falske positive ikke er så problematisk - man kan jo bare lade være med at bruge forslaget, hvis man synes, det lyder tosset.I den forstand klarer algoritmen opgaven med sundheds-it meget godt, ved at afdække omkring 70% af artiklerne, som handler om sundheds-it.Udover laplace-k'et er der også andre muligheder for at optimere. Sagkundskaben fortæller, at netop med artikler, kan det være en god ide at tælle ord i overskrifter to gange, når hyppighederne opgøres, da disse ord i højere grad afspejler indholdet.Andre muligheder er at udplukke devtestsættet løbende over hele artikelmængden, og derefter udregne gennemsnitlige logPhat-værdier. Den teknik skulle især være god, hvis man ikke har for mange artikler eller dokumenter at rutte med.Not a numberEn lille parentes: Nogle gange får vi resultatet -NaN-, not a number, ved udregningen. Det udskifter vi blot med 0 procent, der i vores læsning betyder -maksimalt skidt resultat.-I en kommende artikel implementerer vi algoritmen i Version2's CMS-system. Lige nu er planen at benytte en bookmarklet (og det var Jakobs ide, skal det siges.) Det bliver ikke lige foreløbigt, men bliv på kanalen.Se resultater og download kodenResultaterne kan ses i regnearket her.Det ville fylde for meget at gengive den Java-kode, vi har brugt i artiklen. Så den kan downloades her (Google Drive kan sige nogle fjollede ting undervejs, men bare tryk 'download.').Eksemplet indeholder de samme datasæt, der gennemgås her i artiklen. Ligesom sidst er ordene i artiklerne er randomiseret. Algoritmen er ligeglad med rækkefølgen af ordene, så det gør ingen forskel for eksemplet.Koden er skrevet så eksemplet er nemt at forstå og er ikke optimeret. Der er et par hardcodede filstier, der kan tilrettes, hvis der er bøvl. Det er kommenteret i kildeteksten.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2018-04-10
          &nbsp;·&nbsp; e6b29320
          &nbsp;·&nbsp; #15
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.927</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.947</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.613</kbd>
        </footer>
      </article>
      <article>
        <h4>Tjept statistiksprog runder version 1.0</h4>
        <div>
          På ganske få år har det helt friske sprog Julia fundet sig en større fanskare. Da sproget kom til verden i 2012, var det ønsket om at forene egenskaber fra en række andre sprog.Det skulle have en hastighed som C, dynamiske sprogfeatures som i Ruby, makroer som Lisp og velkendt matematisk notation som i Matlab, vidtrækkende anvendelsesområder som med Python, statistiske faciliteter som i R og tekstbehandling som i Perl.Samtidig skulle sproget have en open source-licens, være nemt at lære og have interaktive muligheder.Noget kunne tyde på at den ambitiøse målsætning er lykkedes, for selv om Julia stadig er et ganske lille sprog i udbredelse, med en halvtredsneplads på popularitetsindekset Tiobe, så får sproget meget omtale.Julia har netop rundet versionsnummeret 1.0, der markerer sprogets udtræden af barndommen og ind i de voksne sprogs rækker.Det er især Julias ydelse, som giver sproget fortrin i forhold til de mere eller mindre fortolkede sprog som R og Python.»Hvis du er matematiker, videnskabsmand eller ingeniør, har du historisk haft mulighed for at vælge et sprog, der var hurtigt, som C ++ eller Java, eller et sprog der er nemt at lære, som Matlab, R eller Python. I Julia skabte vi et sprog, der var hurtigt og nemt,« har en af sprogets bagmand, Viral Shah, udtalt til mediet Quartz.Han fortæller, at nøgleinspirationen til at udvikle Julia var at se, hvordan mange mennesker måtte skrive det samme program to gange: Dataforskere vil først bruge et værktøj som Python eller R til at udvikle en algoritme, fordi det gør det nemt at udforske dataene og lave diagrammer på disse sprog.Når forskerne var tilfredse med algoritmen, skulle de så omskrive programmet i C ++ eller Java for at få effektiv ydelse. Julia er hurtigere end Python og R, fordi sproget er specielt designet til hurtigt at gennemføre den grundlæggende matematik, som benyttes i datavidenskab, så som matrixudtryk og lineær algebra.# calculates x for 0 = a x^2+b x+c, arguments types can be defined in function definitions function quadratic2(a::Float64, b::Float64, c::Float64)# unlike other languages 2a is equivalent to 2*a# a^2 is used instead of a**2 or pow(a,2) sqr_term = sqrt(b^2-4a*c) r1 = quadratic(a, sqr_term, b) r2 = quadratic(a, -sqr_term, b)# multiple values can be returned from a function using tuples# if the return keyword is omitted, the last term is returned r1, r2 endEt simpelt eksempel på Julia, fra Julia By Example.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2018-08-23
          &nbsp;·&nbsp; e6de83cb
          &nbsp;·&nbsp; #16
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.99</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.512</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.546</kbd>
        </footer>
      </article>
      <article>
        <h4>Forklaringer som vejen til bedre modeller</h4>
        <div>
            Forklaringer skaber ikke bare gennemsigtighed, men kan også bruges til at forbedre modellen, skriver Katrine Hommelhoff Jensen. Når vi taler om forklarlig kunstig intelligens, så er omdrejningspunktet tit, hvordan vi får forklaret computerens beslutningsproces, så alle kan forstå det. Det er dog ikke kun i teknologiens møde med slutbrugeren, at forklaringer har værdi. Når vi udvikler ny teknologi, kan forklaringer illustrere, hvordan en model vægter data i sin beslutning, og herunder hvad der måske vægtes uhensigtsmæssigt. Vil du have fuld adgang til DataTech? DataTech skriver til dig, der arbejder professionelt med data og analytics. Vi giver dig inspirerende cases, nyheder og debat om alt fra Machine Learning-modeller til dataetik. Har du allerede et abonnement? Log ind Er dit prøveabonnement udløbet? Køb
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2020-08-25
          &nbsp;·&nbsp; e7da23a6
          &nbsp;·&nbsp; #17
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.81</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.783</kbd>
        </footer>
      </article>
      <article>
        <h4>Debat På tide at ændre matematik på A-niveau i gymnasiet</h4>
        <div>
          I FORLÆNGELSE AF diskussionen om det nye it-fag på ungdomsuddannelserne, mener jeg, at det er på tide at genoverveje indholdet af matematikundervisningen i gymnasiet.HVIS MAN SER PÅ bekendtgørelsen, er kernestoffet for matematik på A-niveau klart forberedende til naturvidenskabelige ( i den brede forstand, der også omfatter medicin, farmaci, veterinærvidenskab osv.) og tekniske uddannelser. Bortset fra et enkelt punkt om matematiske modeller er der ikke noget, der er direkte brugbart til it-fag som f. eks. datalogi.Der er masser, der er brugbart til anvendelser af it men ikke til forståelse af data som begreb. Et udpluk fra bekendtgørelsen indeholder blandt andet: LINEÆRE differentialligninger af 1. orden og logistiske differentialligninger, kvalitativ analyse af givne differentialligninger samt opstilling af simple differentialligninger PRINCIPIELLE egenskaber ved matematiske modeller, modellering.JEG VIL IKKE BORTKASTE alt det naturvidenskabsforberedende indhold, men jeg overvejer, om nogle af de mere perifere emner ikke kunne erstattes af noget, der er mere relevant for it-fag men også brugbart inden for andre fag. Et oplagt emne til at udgå er efter min mening differentialligninger.Videregående uddannelser, der bruger differentialligninger, vil alligevel gennemgå emnet, da dækningen i gymnasiet normalt ikke er tilstrækkelig, og det er tvivlsomt, hvor alment dannende emnet er.EN SIMPEL LØSNING på erstatningsstof kunne være en udvidelse af stoffet om matematiske modeller med stof om datamodellering. Men for at komme så langt skal man først have indført begrebet data, dets brug i modeller og modellernes forhold til virkeligheden som erstatning for differentialligninger i matematik A. Man kunne også så småt begynde på emnet allerede på niveau C og B.INDHOLDET AF EMNET kunne f. eks. være: EN BIT som den mindste dataenhed og tolkningen af en bit som en sandhedsværdi.Logiske operatorer som bitvise operatorer.BINÆRE TAL som eksempel på repræsentation af information som en sekvens af bits. Addition og multiplikation af binære tal.MÅDER AT sammensætte data på: Par, sekvenser, multimængder, mængder og disjunkt forening. Simple binære repræsentationer af disse. Eksempler: Koordinater ( par), binære tal og tegnfølger ( sekvens), måleresultater ( multimængde), valgfag ( mængde), fugl eller fisk ( disjunkt forening).MÅDER AT analysere data på baseret på dennes opbygning: Elementvis analyse af par, sekvenser, mængder og multimængder samt forgrening ved disjunkt forening. Kombination af delresultater til samlet resultat.DATAMODELLERS FORHOLD til virkelighed: Diskretisering og måleunøjagtighed.Akkumuleret unøjagtighed ved længere beregninger. Konsekvenser for datamodellers pålidelighed.BEMÆRK, at der ikke indgår egentlig programmering eller algoritmer.  &gt; &gt; Forkortet -læs hele indlægget og deltag i debatten på ing. dk/ k# 8rn2.
        </div>
        <footer>
          <em>Ingeniøren</em>
          &nbsp;·&nbsp; 2011-02-18
          &nbsp;·&nbsp; e27de5d4
          &nbsp;·&nbsp; #18
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.905</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.861</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.613</kbd>
        </footer>
      </article>
      <article>
        <h4>Deep learning på grafer: Succeser, udfordringer og næste skridt</h4>
        <div>
            Forsker-miljøet har indtil for nylig næsten ignoreret skalerbarhed, når det kommer til udvikling af graph neural networks. Deep learning på grafer, også kendt som Geometrisk deep learning (GDL) [1], Graph representation learning (GRL), eller relational inductive biases [2], er for nylig blevet et af de hotteste emner inden for machine learning. Mens det tidlige arbejde med graph learning går mindst et årti tilbage [3] hvis ikke to [4], er det utvivlsomt de seneste års fremskridt, der har taget disse metoder ud af nichen og ind i rampelyset i ML-miljøet og endda til den populærvidenskabelig presse (Quanta Magazine har kørt en række fremragende artikler om geometrisk deep learning til blandt andet opdagelse af lægemidler). Grafer er kraftige matematiske abstraktioner, der kan beskrive komplekse systemer af relationer og interaktioner inden for områder, der spænder fra biologi og højenergifysik til samfundsvidenskab og økonomi. Da mængden af graf-strukturerede data, der produceres i nogle af disse felter i dag, er enorm (prominente eksempler er sociale netværk som Twitter og Facebook), er det meget fristende at forsøge at anvende deep learning, der har været bemærkelsesværdigt succesfulde i andre datarige sammenhænge. Graph learning Der er flere varianter til graph learning-problemer, der stort set er afhængige af applikationen. Én dikotomi er mellem node- og graf-mæssige problemer, hvor man i den førstnævnte forsøger at forudsige egenskaber ved individuelle noder i grafen (f.eks. at identificere ondsindede brugere i et socialt netværk), mens man i den sidstnævnte forsøger at forudsige noget om hele grafen (for eksempel forudsige opløselighed af et molekyle). Ligesom i traditionelle ML-problemer kan vi desuden skelne mellem superviseret og usuperviseret (eller selv-superviseret) læring. Ligesom med convolutional neural networks, der bruges i billedanalyse og computer vision, ligger nøglen til effektiv læring på grafer i designet af lokale operationer med delte vægte, der sender meddelelser [5] mellem hver node og dets naboer. En væsentlig forskel sammenlignet med klassiske, dybe neurale netværk, der beskæftiger sig med gitter-struktureret data, er, at sådanne operationer på grafer er permutations-invariant , dvs. uafhængig af rækkefølgen af nabo-noder, da der normalt ikke er nogen kanonisk måde at strukturere dem på. Dårlig kode og manglende benchmark På trods af, hvor lovende grafer er, og en række succeshistorier om graph learning (blandt hvilke jeg selvisk kan liste Twitters opkøb af Fabula AI , som jeg har grundlagt sammen med mine studerende), har vi indtil videre ikke set noget bare tæt på den knusende succes, CNN har haft inden for computer vision. I det følgende vil jeg forsøge at skitsere min vurdering af de mulige årsager, og hvordan feltet kunne udvikle sig i de næste par år. Standardiserede benchmarks som ImageNet var helt sikkert en af de vigtigste succesfaktorer for deep learning inden for computer vision. Nogle [6] argumenterer endda for, at data har været vigtigere end algoritmer for deep learning-revolutionen. I graph learning-miljøet har vi endnu intet, der ligner ImageNet i skala og kompleksitet. Open Graph Benchmark , der blev lanceret i 2019, er måske det første forsøg på introducere udfordrende graph learning-opgaver på interessante graph-data fra den virkelige verden. En af forhindringerne er, at teknologiselskaber, der producerer rige graf-databaser over deres brugers aktivitet, er tilbageholdende med at dele disse data på grund af bekymring over lovgivning som f.eks. GDPR. En bemærkelsesværdig undtagelse er Twitter, der stillede et datasæt på 160 millioner tweets med tilsvarende graf over brugerengagement til rådighed for forskere under visse privacy-begrænsninger som en del af RecSys Challenge . Jeg håber, at mange virksomheder følger trop i fremtiden. Softwarebiblioteker, der er offentligt tilgængelige, spillede en vigtig rolle i at &quot;demokratisere&quot; deep learning og gøre det til et populært værktøj. Indtil for nyligt har implementeringer af graph learning primært været en samling af dårligt skrevet og næppe testet kode. Men i dag findes biblioteker såsom PyTorch Geometric eller Deep Graph Library (DGL) , som er professionelt skrevne og vedligeholdes ved hjælp af sponsorater fra branchen. Det er ikke ualmindeligt at se en implementering af en ny graph deep learning-arkitektur uger efter, at den publiceres på arxiv. Skalering er forsømt Skalerbarhed er en af de vigtigste faktorer, der begrænser industrielle applikationer. Her er man ofte nødt til at håndtere meget store grafer (tænk på Twitters sociale netværk med hundreder af millioner noder og milliarder af relationer) med lav latency. Det akademiske forsker-miljø har indtil for nylig næsten ignoreret dette aspekt, og mange modeller, der er beskrevet i litteraturen, er fuldstændigt utilstrækkelige i stor skala. Desuden er grafikhardware (GPU), hvis lykkelige ægteskab med klassiske deep learning-arkitekturer har været en af de primære kræfter, der driver deres fælles succes, ikke nødvendigvis bedst egnet til graf-strukturerede data. I det lange løb har vi muligvis brug for specialiseret hardware til grafer [7]. Dynamiske grafer er et andet aspekt, der er sparsomt behandlet i litteraturen. Mens grafer er en almindelig måde at modellere komplekse systemer på, er en abstraktion ofte for forenklet, da systemer i den virkelige verden er dynamiske og udvikler sig over tid. Sommetider er det netop opførsel over tid, der giver afgørende indsigt om systemet. På trods af nogle nye fremskridt er design af graph neural networks, der er i stand til effektivt at håndtere tid, repræsenteret som en strøm af node- eller relationsmæssige begivenheder, stadig et åbent forskningsspørgsmål. Teoretisk forståelse af ekspressiviteten i graph neural networks er temmelig begrænset. Det er almindeligt at se graph neural networks give et stort performance-boost i én sammenhæng, og gøre næsten ingen forskel i andre. Det er endnu ikke helt klart, hvornår og hvorfor graph neural networks fungerer godt eller mislykkes. Problemet er vanskeligt, fordi man skal medtage både strukturen i den underliggende graf samt data i den. Et andet interessant og stort set uberørt forskningsfelt er, hvordan man sikrer robusthed og garanteret performance i graph neural networks af der udsættes for støjende data eller for adversarial attacks [9]. Kan fundamentalt ændre medicinalindustrien Den mest tilfredsstillende del af feltet er anvendelsen. Efter at have arbejdet med graph learning i mange år nu, er jeg blevet venner med partikelfysikere [10], klinikere [11], biologer og kemikere [12] - mennesker, som jeg sandsynligvis ikke ville møde, hvis vi ikke havde arbejdet med applikationer inden for deres respektive områder. Hvis jeg skulle satse på bare et felt, hvor graph deep learning kunne få den største indflydelse i de næste par år, ville jeg pege på biologi og kemi. I disse felter kan graf-baserede modeller bruges både som lavniveau-modeller til molekyler [5] såvel som modeller på højt niveau af interaktioner mellem dem [13,11]. Kombination af disse kan være nøglen til at komme til et niveau, hvor teknikken ville være nyttig for medicinalindustrien. Vi ser indledende tegn på dette med neurale netværk, der tidligere i år blev brugt til at opdage en ny klasse af antibiotika [14] eller til at forudsige interaktioner mellem proteiner [12]. Hvis vi kan indfrie løftet fra graph deep learning, ser den meget lange og forbløffende dyre proces med at opdage, udvikle og teste nye lægemidler måske aldrig ud på samme måde igen. En version af denne artikel er oprindeligt bragt på Medium. Læs flere indlæg her
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2020-08-18
          &nbsp;·&nbsp; e7d77549
          &nbsp;·&nbsp; #19
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.889</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.796</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.602</kbd>
        </footer>
      </article>
      <article>
        <h4>Her er nyhederne i Python 3.10: Match er en ren schweizerkniv</h4>
        <div>
          For anden gang udkommer Python efter en ny årlig udgivelsesplan. Den store nyhed for det hidtil switch-løse sprog er en ny match-sætning, der kan lidt af hvert.Med 30 år på bagen har programmeringssproget Python kronede dage. På lister over sprogs popularitet ligger Python enten i toppen eller tæt påPython er gået fra at være et scripting-sprog med lav indlæringskurve, til at være et af de foretrukne sprog til videnskabelig programmering, statistik, dataanalyse og kunstig intelligens.Ligesom i Javascript kan man i Python gøre næsten, hvad man har lyst til på kørselstidspunktet, såsom at udstyre objekter med nye felter og metoder. Det sætter begrænsninger på afviklingshastigheden.Den danske ekspert i virtuelle maskiner Lars Bak vurderer, at sprog som Python og Javascript kan opnå omkring halvdelen af den ydelse som typestærke sprog, der også afvikles i en virtuel maskine, såsom Java og C#, kan præstere.Men der er flere måder at gøre tingene på. Det er nemt at kalde C-kode fra Python, og mange Python-biblioteker er implementeret i C, som gør dem lynhurtige.Når det handler om kunstig intelligens, matricer og vektorer, kan biblioteker udnytte grafikkort, som er mange gange hurtigere, end når tilsvarende operationer skal udføres på cpu-kerner, på grund af parallelisering af lineære vektorberegninger.På den måde kan Python-koden blive et slags instrumenteringslag for de underliggende højtydende biblioteker, med en nem syntaks, der tillader lidt af hvert og sjældent stiller sig i vejen for programmøren.Match er en schweizerkniv-switchEn ny version er tæt på af se dagens lys. Den har nummeret 3.10, og er den anden udgave efter en ny udsendelsesplan, hvor der kommer nye versioner én gang om året.Blandt nyhederne er pattern matching, som også Java og PHP for nylig er blevet udstyret med. Pattern matching stammer fra de funktionelle sprog, og trenden blandt objektorienterede sprog er netop at låne ideer fra den funktionelle verden.Python har aldrig tidligere haft en switch -sætning, så det er funklende nyt, og den nye konstruktion er en ren schweizerkniv, i forhold til hvilke mønstre sætningen kan håndtere.På det overordnede plan ser det således ud, med eksempler taget fra dokumentationen:match subject:casecasecasecase _:På klassisk Python-maner kan en masse forskellige ting anvendes som argument i case-sætningerne. Mønstrene kan bestå af sequences, mappings, primitive datatyper samt klasse-instanser.Et simpelt eksempel kan se sådan ud:def http_error(status):match status:case 400:case :case :case _:Case-sætninger kan også indeholde variable:Og med klasse-instanser:Lister kan også anvendes som argument til case-sætningen:Man kan også bruge underscore-wildcard'et på en mere kompleks facon:Men der er mere, som de siger i TV-shoppen:Man kan også udstyre case-sætningen med en ' guard ', også kendt som en 'precondition', ved at sætte en if -sætning efter case-udtrykket:Og der er endda flere muligheder med match-sætningen, end hvad vi har vist her.Nemmere unionsPython er et sprog, hvor variabeltyper ikke gør det store væsen af sig. Men lidt type-information på en sidetallerken er nu heller ikke dårligt. I Python 3.5 kom muligheden for at antyde typerLigesom i den nye PHP er der nu en nem måde at angive, at en variabel eller parameter kan antage én af to eller flere typer, i stedet for den gamle måde, Union[int, float] , at gøre det på:Context managers er sætningskonstruktion, hvor ressourcer som eksempelvis fil-handlers kan deallokeres på en robust facon, uden at programmøren skal benytte try-finally eller andre tiltag. Det svarer til Java og C#'s try-with-resources og using , og nyheden er, at man kan have flere context managers i samme blok, som i:Blandt andre nyheder er forbedrede fejlmeddelelser, som i dette eksempel:- hvor fortolkeren før i tiden blot ville have sagt SyntaxError: invalid syntax og peget på starten af den efterfølgende sætning.SyntaxError har i det hele taget fået en lang række specialiserede meddelelser, så det bliver nemmere at finde ud af, hvad der er galt.Der er flere nyheder i den nye version, som er første beta af fire, før den endelige udgave udsendes i starten af september i år. Beta-versionen kan testes på Windows og Mac, mens andre dyr selv må kompilere kildekoden. Links til det hele kan findes i udgivelsesnoterne
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2021-05-12
          &nbsp;·&nbsp; e842dfa8
          &nbsp;·&nbsp; #20
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.952</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.651</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.697</kbd>
        </footer>
      </article>
      <article>
        <h4>Mathematical Analysis and Linear Algebra</h4>
        <div>
          Få tilsendt alle informationer om kurset, herunder kursus sted, udbyder mm. på emailMathematical Analysis and Linear AlgebraKurset dækker to områder af matematikken: lineær algebra og analyse af funktioner i mange variable. Lineær algebra er centralt i studiet af matricer som bruges til at repræsentere mange forskellige ting, herunder systemer af lineære ligninger, transformationer af rum og probabilistiske systemer. Ligesom mange af de interne operationer i søgemaskiner er baseret på matricer. Ved at studere den matematiske teori om matricer vil vi lære værktøjer, der har en række anvendelsesområder. Som et eksempel ser vi på PageRank algoritmen, som Googles søgemaskiner bruger til at rangere websider på basis af. På kurset udvides teorien om matematisk analyse også til funktioner af mange variabler. Analyse af funktioner med mange variable er teorien bag metoder, der bruges i kunstig intelligens, business intelligence, fysik og økonomi.Formålet med kurset er således at forstå den matematiske teori godt nok til at forstå, hvorfor metoderne inden for et anvendelsesområde virker og bruge den matematiske teori til at tilpasse eksisterende metoder og skabe nye. Med andre ord er målet ikke at den studerende blot skal kunne anvende metoder og indsætte i formler, men snarere forklare, hvorfor metoderne virker. Kurset foregår på engelsk og udbydes på kandidatuddannelsen: Software Development.Formelle forudsætninger:Please note! Changes to this course description may occur until start of the spring semester 2017.Læringsmål:After the course the student should be able to:- Use nummerical methods such as Newton's method and Taylor series, and explain the theory behind them.- Reflect on the applicability of a given numerical method to a given problem.- Compute the derivatives of curves and surfaces, explain the geometric interpretation of these, and apply them to solving a wide range of mathematical problems including optimisation problems.- Compute double integrals and explain their geometric interpretation.- Compute the essential constructions of basic linear algebra including inverse matrices, eigenvectors and eigenvalues, matrix diagonalisation, the dimensions and bases of the four fundamental subspaces and determinants of square matrices, and explain the theory behind these constructions.- Explain the use of linear algebra in applications such as solutions to linear equations, the method of least squares and the theory of the PageRank algorithm. Discuss the relevance of the theoretical results proved in the course for these applications.Fagligt indhold:This is a course in mathematics covering linear algebra and analysis of functions in many variables. These are perhaps the two areas of mathematics that have found most uses in practical applications.Linear algebra is essentially the study of matrices, i.e., rectangular arrays of numbers. Matrices are used to represent many different things, including systems of linear equations, transformations of space (such as rotations or reflections as used in computer graphics) and probabilistic systems. Likewise, many of the internal operations in search engines are essentially operations on matrices. By studying the mathematical theory of matrices we will learn tools that are useful for all of these application areas. As an example application we look at the PageRank algorithm used in Google's search machines to rank webpages for importance.Mathematical analysis (or calculus) is the study of the derivative and the integral of real valued functions as taught in high school, but in this course we extend the theory to functions of many variables returning vectors of real numbers. Just like the single variable case, one of the main applications is to solve optimization problems, which in real life are of many variables. This is the theory underlying many methods in artificial intelligence, but it is also important in many other areas including image analysis, business intelligence, physics and economics.While the topics taught have been chosen for their applicability, the focus of the course will be on the mathematics. The aim is to understand the theory well enough that we can understand why the methods in the application areas work, and even use the mathematical theory to adapt existing methods or create new ones. In other words, the aim is not that the student should simply be able to use methods and insert into formulas, but rather explain why the methods work and reflect on the theory presented. For this reason the course has an oral exam.Læringsaktiviteter:14 ugers undervisning bestående af forelæsninger og øvelser14 weeks of teaching consisting of lectures and exercises. The exercise sessions will train the students oral presentation skills, and so students are expected to prepare for the exercise sessions. The mandatory exercises will mainly ask the students for written solutions to theoretical exercises, but will also include a few implementation exercises.Obligatoriske aktivititer: There are 6 mandatory assignments, out of which 5 must be approved for the student to qualify for the exam.The deadlines are evenly distributed over the semester (approximately one every 2 weeks), exact dates will be posted on learnit the first week of the semester.If a mandatory assignment is not approved the first time, the student will be allowed to resubmit exactly one week after the first deadline.If this also fails, one more resubmission the following week is allowed.Be aware: The student will receive the grade NA (not approved) at the ordinary exam, if the mandatory activities are not approved and the student will use an exam attemptEksamensform og -beskrivelse:B1I Mundtlig eksamen med forberedelse. På ITU, (7-scale, external exam)Oral examination with time for preparation at the exam.Duration: 30 minutes preparation at ITU and 30 minutes oral examination.The student draws a question and has 30 minutes preparation before 30 minutes oral examination.Litteratur udover forskningsartikler:- Gilbert Strang: Introduction to Linear algebra, 4th edition- David Guichard: Multivariable calculus, early transcendentals- Kurt Bryan and Tanya Leise: The $25,000,000,000 eigenvector, the linear algebra behind Google.
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2016-12-13
          &nbsp;·&nbsp; e60653dd
          &nbsp;·&nbsp; #21
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.99</kbd>
            <kbd data-tooltip="AI &amp; innovation">L05_INNOAI&nbsp;0.887</kbd>
            <kbd data-tooltip="In English">L80_ENLANG&nbsp;0.773</kbd>
        </footer>
      </article>
      <article>
        <h4>En algoritmes sang om geder og sidste år med Python 2</h4>
        <div>
          Organisationen har dog frigjort en forsimplet version af algoritmen GPT-2, som er reduceret til beskedne 117 millioner parametre, sammenlignet med originalens 1,5 milliarder parametre.Denne model har Ars Technica afprøvet og døbt GPT-2 Junior, og resultatet er ikke ligefrem angstfremkaldende i forhold til maskinskrevet fake news.I en test går algoritmen fra at tale om handelsaftaler mellem Kina og USA til noget, som Ars Technica selv beskriver som en anmeldelse af en anime. Et andet eksempel går fra at handle om topmødet med Nordkorea til at diskutere hestedrab:»It sounds like you may have a great idea for killing a horse, maybe even in your own horse or some combination of the two.« Det mest mystiske resultat får mediet dog ved at fodre algoritmen med en stump tale fra Donald Trump, hvilket prompte returnerede en sang om geder:»FADE InGOAT DICK IN THE BOY T-HAULUSGOAT DICK IN THE BOY T-HULUSGOAT DICK-IN-THE-BOY BOYGREAT BOYGREAT-GOAT-GOAT-GOAT-GOAT-GOAT-GOAT-GOAT-GOAT-GOAT-GOAT- GOAT« Selv om testen er morsom, er bekymringen om GPT-2's evne til at sprede falsk information begrundet, skriver Ars Technica.»Both the fully realized GPT-2 and GPT-2 Jr. are generalized models. A much more convincing &quot;deep fake&quot; text bot with a more narrow focus could be constructed using similar techniques.« Træningsmaterialet til GPT-2 kommer fra Reddit. Hvilket måske til dels forklarer nogle af de tankespring modellen laver.Oversete favoritterI Reddits forum om data science har brugere undladt at skrive sange om geder og i stedet delt deres mindre kendte favorit Python-pakker.Her anbefaler en bruger blandt andet boto og boto3 til forbindelser til AWS, samt pytest til test af data science-koden. En anden bruger fremhæver tqdm, der giver en progress bar som viser, hvordan model-træningen skrider frem.En tredje bruger fremhæver pakken shap, der kan bruges til at forklare, hvordan komplekse modeller kommer frem til deres resultat. DataTech har tidligere skrevet om teknikken her.Se hele tråden her.Farvel til Python 22019 bliver sidste år, hvor den sidste version af Python 2 - 2.7 - bliver vedligeholdt. Det kan have omfattende konsekvenser for selskaber, der stadig har store kodebaser i Python 2. De har nu 10 måneder til at migrere over til Python 3.»You have a number of choices for migrating from Python 2 to Python 3,« skriver selskabet Active State i en guide.»The recommended course of action is to modernize incrementally in order to address failures progressively, rather than being overwhelmed by the task/errors all at once. E.g. over multiple releases of your application.« Python Software Foundation har selv lavet en omfattende guide til Python-migrering.Python 3 løser problemerPython 2's primære problem er, at det blev skabt inden Unicode-standarden blev færdig - og derfor ikke følger standarden fuldstændig, skriver Active State. Det giver to problemer. Dels at versionen ikke fungerer til kodning i ikke-romanske sprog, og dels at Python 2 bruger en datatype, der ikke klart adskille tekstdata fra binær data. Dette leder ofte til bugs, noterer selskabet.»Python 3 resolves the two key issues with Python 2 by basing the default core string type on Unicode. This is a big gain for Python programmers because it eliminates the text/binary confusion and enables multilingual programming.« Mens mange har udskudt overgangen til Python 3 pga af manglende understøttelse fra biblioteker, så burde det problem være løst i de fleste tilfælde, 94 procent af de 360 mest downloadede pakker understøtter Python 3.Dansk AI-startup købt og 'tømt'af AppleDet danske selskab Spektral Experience har siden 2017 arbejdet på avanceret billede behandling af live video. Teknologien gjorde selskabet i stand til at skære en person ud af en video og indsætte den i et andet stykke video - alt sammen i realtid.Ifølge Finans er Spektral Experience dog ikke længere eksisterende. Selskabet blev købt af Apple i 2017 og i løbet af sidste år er selskabet tømt for både personer, patenter, projekter og viden. Selskabets immaterielle rettigheder er blevet solgt for 181 millioner kroner, hvilket ikke er så langt for den originale salgspris på over 200 millioner, skriver Finans.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2019-03-01
          &nbsp;·&nbsp; e7197256
          &nbsp;·&nbsp; #22
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.684</kbd>
            <kbd data-tooltip="AI &amp; innovation">L05_INNOAI&nbsp;0.509</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.518</kbd>
        </footer>
      </article>
      <article>
        <h4>I klasse med Kierkegaard eller historien om det fede ved at en computer kan finde ordklasser</h4>
        <div>
          Vi er tilbage i skolen og sidder i en danskklasse med både Søren Kierkegaard og en computer som klassekammerater, og vi skal lære lidt om ordklasser. Vi skal se om et samarbejde mellem Kierkegaard og computerens evne til at finde ordklasser kan hjælpe os med at læse Kierkegaard uden at læse, og til at forstå det fede ved at finde ordklasser uden at skulle &quot;sætte 'en' eller 'et' foran&quot; først. Eller med lidt andre ord, handler dette blogindlæg om en machine-learning-model, der automatisk kan detektere ordklasser og om hvad dette kan bruges til eksemplificeret igennem Søren Kierkegaards værk Enten - Eller fra 1843. Men før vi går rigtig i gang, skal vi have computeren på skolebænken til at lære at tagge ordklasser i en tekst. Natural language understanding kan overordnet set inddeles i syntaktisk og semantisk analyse. At tagge ordklasser i en tekst hører til den syntaktiske del, og i den engelske litteratur benævnes denne task som 'Part of Speech'-tagging, eller forkortet bare POS. Hvor mange gange skal jeg sige det, Computer  før du kan genkende ordklasser? Nogle af os vil måske kunne huske, at vi, tilbage i folkeskolen, har fået det at vide mange gange, hvad forskellen er på et udsagnsord og et navneord. Måske hænger der stadig lidt regler fast om, at et navneord er dem man kan sætte 'en' eller 'et' foran, udsagnsord dem med 'at' eller 'jeg'. Eller måske har vi bare fået vist nok eksempler på navneord, at vi nu kan genkende dem og endda generalisere den viden til når vi ser nye ord? At automatisere det at kategorisere ordklasser i en sætning, vil måske kunne gøres regelbaseret, eller blot som et stort opslagsværk? Og dog, et opslagsværk, vil ikke kunne tage højde for, at ord der staves ens kan have forskellige ordklasser alt efter sammenhængen i sætningen, ej heller at nogle ordklasser er åbne, hvilket vil sige, at der med tiden kommer nye ord til i denne kategori, som fx ved navneord¹. Ikke desto mindre, er denne blog omkring NLP, og vi vil derfor tage en datadrevet tilgang, hvor computeren vil blive vist en mængde eksempler på sætninger og tilhørende ordklasser, som den vil lære at generalisere ud fra. Dette kaldes for supervised learning. I min tidligere blogpost &quot; Hvordan repræsenterer vi tekst, så en computer kan regne på det? &quot;, blev forskellige word emebddings introduceret, heribland FastText embeddings fra Bojanowski et al. 2017² og Flair embeddings fra Akbik et al. 2018³ , som i DaNLP projektet er trænet på dansk data fra EuroParl og Wikipedia. Disse embeddings kan nu bruges til at træne en POS-tagger ved hjælp af modelarkitekturen beskrevet i Akbik et al. 2018 samt tilhørende implementation på Flairs GitHub Sekvenslabeling-arkitekturen er en CRF-BiLSTM. Overordnet set gives en sætning som input til vores to word-embedding modeller, der for hvert ord producerer en vektorrepræsentation ud. Disse repræsentationer gives som input til en Bi-LSTM model, som løber sekvensen af ord igennem både forfra og bagfra, og producerer et output ud som gives til CRF modellen. Denne udregner sandsynligheden for hver POS-tag i sætningen, givet de øvrige tags i sætningen. Pointen her er blot, at der tages højde for de andre ord i sætningen, når der gættes på en ordklasse. Modellen lærer, det vil sige opdaterer sine parameter, ved at få at vide når den gætter rigtig og forkert. Lidt lig os selv tilbage i klassen. Så, dette kræver noget opmærkeret data. Heldigvis findes et sådan dataset open source: Danish Dependecy Treebank (DDT) . De danske part-of-speech-tags stammer fra et projekt ved navn PAROLE-DK, et dataset bestående af 5512 sætninger konverteret til 17 universal pos tags. Datasættet er inddelt i training-, development-, og testsæt med følgende split 4,383 / 564 / 565 og består af en blanding af tekst med blandt andet gamle nyhedsartikler. Testdelen ses ikke under træning, men bruges til at evaluere modellen på til sidst, og developmentsættet fungerer som en proxy for at guide træningen. Træningen er sat med et maksimum af 150 epochs, hvilket vil sige at modellen kan tygge sig igennem alle sætningerne 150 gange, eller indtil det ved hjælp af developmentsættet vurderes at læringen ikke forbedres. Model er trænet én gang, hvor den stoppede efter 118 epochs - så computerne skal altså have hvert eneste eksempel på en sætning, og hvilke ordklasser der er i sætningen, gentaget 118 gange, før den ikke lærer mere ved det. (I hvert fald i denne ene kørsel). Det er nok alligevel lidt mange gange for en lærer at gentage det samme. Modellen opnåede en nøjagtighed på testsættet på 97,14%. I forståelsen af denne nøjagtighed skal der tages højde for at testsættet er forholdsvis lille, og at det ligner teksten i træningsdata, hvilket umiddelbart er forholdsvis grammatisk korrekt dansk. Med andre ord, når vi anvender denne model på Søren Kierkegaards tekster, som er af ældre dato, med andre stavemåder og ord, kender vi ikke hvor godt modellen generaliserer til dette nye data. Modellen kan findes på vores GitHub og i Python bibliotek danlp, og er også inkluderet i Flairs Python bibliotek. Her er et eksempel på dens anvendelse: I eksemplet ses det hvordan ordet 'under' bliver tagget hhv. som forholdsord og som biord efter sammenhængen i sætningen, og at modellen korrekt tagger navnet 'Eremita', som et egennavn, selvom modellen ikke er støt på ordet under træningen. Men hvad er der så med de der fundene papirer? Vi har ikke så travlt at vi ikke skal introduceres ordentligt  til vores klassekammerat Søren for som han siger &quot;Af alle latterlige Ting forekommer det mig at være det allerlatterligste at have travlt.&quot; Enten - Eller er et værk fra 1843 skrevet af den danske teolog og filosof Søren Kierkegaard, men bogen er udgivet under pseudonymet Victor Eremita. Men denne angivne udgiver er dog ikke den angivne forfatter til værket, men det er derimod tre andre personer. I forordet beskriver udgiveren, hvordan han er kommet i besiddelse af disse papirer ved at have fundet dem i et gammelt chatol, og dernæst diskuterer han hvordan de bedste ordnes og udgives. Det bliver i to bind, hvor det første bind indeholder livsnyderen A's papirer. Det næste bind indeholder pligtmennesket B's papirer, som består af breve til A, da &quot;A's livsstil er faldet B for brystet&quot;. Og til sidst er der også &quot;Forførerens dagbog&quot;, som A siger ikke at være forfatter til, men blot udgiver af, men ikke desto mindre klassificerer udgiveren Victor Eremita delen til at høre til første bind. Det er enten A's papirer eller så er det B's papirer  eller så er begge dele skrevet af Kierkegaard (eller udgiveren der finder papirerne). Men selvom forfatteren skulle ske at være den samme, er der så en syntaktisk forskel på de to dele, således at brugen af ordklasser er så forskellig, at man kun ved at se på ordklasserne kan afgøre om en tekstbid tilhører A's eller B's papirer? Nedenfor er et eksempel på sådan en tekstbid med ordklasser, og umiddelbart er det ikke til at afgøre: Men kan listen af ordklasser være input nok til at en machine-lærings-model kan afgøre om en tekstbid kommer fra del A eller del B? Det vil vi prøve at finde ud af. Overstående bid kommer i øvrigt fra B's papirer, og den egentlige tekst ser således ud, og fra den korte introduktion til værket, vil det måske være nok til at vi også ville have gættet på B: På sks.dk ligger Kierkegaards værk Enten Eller i xml-format til download. Den rå tekst er udtrukket og splittet i sætninger, hvorpå den ny-trænede part-of-speech-tagger er anvendt. Derefter er der skabt en række 'tekstbidder' bestående af part-of-speech-tags ved at chunke 'sætninger' sammen til en minimumstørrelse, nogenlunde som eksemplet ovenfor. Dette er gjort for både A's papirer og B's papirer, hvorefter hver POS-sekvens har fået labelen hhv. A og B. I A's papirer er Indholdsfortegnelse og Forord fra del 1 undladt, men Forførerens Dagbog er inkluderet, da det også var sådan udgiveren endte med at ordne papirerne. Med denne inddeling opnås der 1938 eksempler for label A og 1617 eksempler for label B. Vi har at gøre med et supervised problem, vi har 3555 datapunkter, her lister af pos-tags, med tilhørende annoteringer, nemlig fra del A eller del B. Og da vi nu alligevel befinder os tilbage i skolen, vil vi tage fat i en 'Good-old-Fashion' Logistic Regressions model til klassificering. Til at starte med, deler vi datasættet i en trænings- og en valideringsdel. Via træningssættet udregnes et nedre grænse på nøjagtighed, en såkaldt dummy baseline, ved blot konstant at gætte på den hyppigste klasse, den tykkeste del af bogen om man vil. Dette giver en nøjagtighed på 54 %. Sekvensen af ordklasser er input til modellen, men de skal omformuleres til nogen tal som modellen kan regne på. Og for at kunne benytte en Logistic Regressions model, skal sekvensen af ordklasser repræsenteres med en vektor af en fast længde. En såkaldt feature vektor. En måde at lave en sådan simple repræsentation på, er ved blot at tælle antallet af gange hver pos-tag optræder i sekvensen, og så lave en feature vektor med 17 indgange svarende til hver tag. Dertil kan man også tælle antallet af gange, man ser en bestemt kombination af fx to og tre tags, og lade hver af disse kombinationer bliver repræsenteret ved en plads i feature vektoren. Længden på feature vektoren bliver da en del længere end de 17, da det også skal rumme de forskellige kombinationer - der medtages dog kun de kombinationer som faktisk er i træningseksemplerne, og det giver her en længde på 2782. Nedenfor ses et eksempel på hvilke ti features, som repræsenter de 10 første indgange, hvis det sorteres alfabetisk: Betragt da nedenstående inputeksempel, og tæl da selv efter, hvis altså Regning også er dit yndlingsfag, at de første 10 indgange i featurevektoren faktisk skal have de angivende værdier for at repræsentere inputeksemplet: Denne måde at repræsentere input på gives til en Logistic Regressions model, og der opnås en nøjagtighed på 71% på valideringssættet. Hvilket vil sige at 71% af gangene vi spørger modellen om en givet tekstbid af ordklasser (som den ikke har set under træning) kommer fra A eller B's papir rammer den rigtig. Dette er et stykke over blot at gætte på den mest hyppige klasse, men dog ikke en ren '12er'. Det er alligevel et resultat der indikerer, at der er en forskel i brugen af ordklasser mellem A's papirer og B's papirer. Logistic Regressions giver os mulighed for at undersøge hvilke features, her 3-gram af ordklasser, der har været mest betydende for udfaldet. Ved at tage koefficienter i modellen og vægte med standardafvigelsen for den tilhørende features, kan det udregnes hvilke øget brug af forskellige typer af ordklasser og små kombinationer, vil være mest betydende for modellens udfald for den ene eller den anden klasse. For A's papirer er den mest betydende ordklasse for modellen egennavne, samt en hyppige brug af både mådesudsagnsord og tillægsord er også karakteristisk for A's skrivemåde. Top 5 over betydende features for A ser nemlig således ud: 'PROPN', 'AUX', 'ADJ', 'VERB PRON' og 'PRON VERB PRON'. B's skrivemåde er derimod karakteristisk ved en hyppig brug af stedord og bindeord, da modellen vægter følgende 5 features som mest betydende 'PRON', 'CCONJ', 'DET', 'SCONJ', og 'DET ADJ'. Med andre ord er brugen af ordklasser til et vis grad forskellig i del 1 og del 2 af Kierkegaards Enten - Eller. Jeg gider slet ikke  er også et citat fra Kierkegaard - og rigtig klassificeret hører det til i A's papirer, nærmere bestemt i Diapsalmeta. Og det er nok også en sætning man kunne forstille sig at høre tilbage i klasselokalet. Så i denne sektion vil vi se på om part-of-speech taggeren kan give os en lille genvej ind i Kierkegaards værk, uden at starte med at læse fra side 1. Med taggeren kan teksterne i henholdsvis Del 1 og Del 2 løbes igennem for at udtrække alle navneordene. Nedenunder ses de 45 mest hyppige navneord - eller i hvert fald hvad modellen har tagget som navneord. For at tydeliggøre forskellen på hvad det er for nogle navneord der er karakteristisk for henholdsvis A og B's papirer, er der lavet en list med de 75 mest hyppige fra hver, og sættene er da trukket fra hinanden, så der har ses de navneord som er i top 75 for A men ikke for B: Og tilsvarende for B: Så der kan hurtigt konkluderes, at begge dele handler om kærlighed, liv, sjæl, menneske og verden, men at del 1 med A's papirer udskiller sig fra B's ved at handle om musik, forestillinger, piger, hemmeligheder, lidenskab og andre følelser som smerte og sorg. Hvor imod B's papirer handler om Gud, ret og uret, ægteskab og begreber som valg, pligt og frihed. Dette passer heldigvis meget godt med, hvad der står i forordet til Enten -Eller, men det er dog næppe nok til at overbevise en dansklærer om, at man har læst bogen - men måske er man blevet en lille smule klogere på NLP, og kan måske se andre tekster, hvor det kan være relevant at udtrække ord fra en bestemt ordklasse. Tak fordi du læste med.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2020-02-18
          &nbsp;·&nbsp; e7951050
          &nbsp;·&nbsp; #23
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.998</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.655</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.632</kbd>
        </footer>
      </article>
      <article>
        <h4>Værktøjskasse: Sådan koder du en browser-udvidelse i en ruf</h4>
        <div>
          Browser-udvidelser er små programmer, der kan putte ny funktionalitet i browseren eller manipulere med indholdet af en webside eller webapp. Det skrives med HTML, Javascript og CSS, så det er lige ud af landevejen.I min browser, som er Firefox, har jeg eksempelvis en udvidelse, hvor jeg kan mærke tekst op med gult, og det bliver hængende til næste gang, jeg besøger siden. Det er smart, når jeg laver research, for så slipper jeg for at printe en masse papir ud. En anden udvidelse kan oversætte til dansk, og så fremdeles.Her på Version2 har vi udviklet en algoritme, der finder emneord til nye artikler, og det fungerer ved at brugeren skal klikke på en bookmarklet.Men det ville nu være smartere, hvis brugeren slap for at skulle klikke på bookmarkletten, og forslagene til emneord i stedet bare dukkede op af sig selv, når brugeren åbner dialogboksen hvor man vælger emneord.Og mon ikke der er en nem måde at lave en bookmarklet om til browser-udvidelse på? En søgning på nettet fører os til Sandbox.self.li, som kan det, vi leder efter - lave en bookmarklet om til en web-udvidelse.Vi gør, som der står skrevet - trækker vores bookmarklet fra tidligere over i vinduet, og klikker på knappen 'Generate extension.' Nu downloades en zip-fil. Vi pakker den ud, og så kommer disse filer til syne:background.js bookmarklet.js icon-128.png icon-16.png icon-48.png manifest.jsonVi gennemgår filerne senere. I første skridt vil vi bare tjekke, at det rent faktisk virker. I Firefox indlæser jeg udvidelsen ved at taste about:debugging i adresselinjen. Nu åbnes en side, hvorfra jeg kan indlæse en 'midlertidig' browserudvidelse, ved at klikke på knappen 'Indlæs midlertidig tilføjelse.'(I Chrome skal man benytte 'burger'-menuen Flere værktøjer &gt; Udvidelser, og så klikke på knappen Udviklertilstand øverst til højre. Derefter indlæses mappen med extension-filerne med knappen 'Indlæs upakket' øverst til venstre.)Nu dukker der en sort rund ikon op i browseren, som set herunder, øverst til højre på billedet:Nu åbner jeg dialogboksen og klikker på det sorte ikon. Så bliver emneordsforslagene markeret i dialogen. Så det virker altså - men lige nu gør den nøjagtigt det samme som bookmarkletten, så der skal flere boller på suppen.Næste skridt er at skrive noget Javascript-kode, som henter emneord fra serveren på egen hånd, når blot brugeren klikker på den knap, der får dialogboksen frem. Knappen ser sådan ud:Den nemmeste fremgangsmåde er nok bare at skjule knappen, og så tilføje en ny knap, der først klikker på den skjulte knap, og derefter kalder vores script. Det ser sådan ud:var knapholder = document.querySelector(&quot;#edit-field-topic-da_chzn&quot;), var knap = knapholder.children[1], knap.style.visibility = 'hidden', var nyKnap = document.createElement('span'), nyKnap.innerHTML = &quot;&quot;, nyKnap.onclick = åbenDialog, knapholder.insertBefore(nyKnap, knap), function åbenDialog() { console.log(&quot;Enter åbenDialog&quot;), knap.click(), findEmneord(),}Ligesom i tidligere artikler har vi fundet en CSS-selector, der indeholder knappen. Vi navigerer frem til den i dokument-objektet med linjen knapholder.children[1]. Så skjuler vi knappen ved at sætte property'en style.visibility til 'hidden'. Så er den væk.Vi tilføjer nu en knap, der er helt magen til den skjulte knap - men når brugeren klikker på den, kaldes vores egen funktion åbenDialog. Den funktion klikker på den skjulte knap med knap.click og derefter kaldes findEmneord, der blot indeholder koden fra vores bookmarklet.Vi benytter Firefox' mini-IDE Kladdeblok til at teste koden med, som da vi udviklede bookmarkletten. Og koden virker minsandten.Content scripts og background scriptsSå langt, så godt. Nu skal vi have udvidelsen til at afvikle koden, når brugeren kommer ind på siden, altså når siden loades i browseren.Browserudvidelser har to slags scripts: Content scripts, som afvikles i nogenlunde samme kontekst som den indlæste webside, og background scripts, som afvikles i udvidelsens kontekst.Vores værktøj afvikler scriptet i vores bookmarklet med et background script, men vi vil altså loade koden, når siden er indlæst.Det gør vi ved at åbne manifest-filen, som er et JSON-dokument. Vi sletter linjen&quot;background&quot;: {&quot;scripts&quot;: [&quot;background.js&quot;]}, - og tilføjer disse linjer:&quot;content_scripts&quot;: [{&quot;matches&quot;: [&quot;https://www.version2.dk/node/*/rediger&quot;], &quot;js&quot;: [&quot;content.js&quot;], &quot;run_at&quot;: &quot;document_idle&quot;}], JSON-koden siger, at content-scriptet skal iværksættes på websider, der matcher url'en i 'matches'-nøglen (og hvor stjerne betyder 'alle tegn'), at scriptet der skal afvikles befinder sig i filen content.js, og at det skal afvikles ved'document_idle', som er umiddelbart efter at hele websiden er indlæst i browseren.Vi laver nu en ny tekstfil, som får navnet content.js. I den indsætter vi Javascript-koden ovenfor, som skjuler den rigtige knap og indsætter vores egen knap. Når der klikkes på den, kaldes funktionen findEmneord, som indeholder den kode, vi lavede i sidste artikel.Nu sletter vi filen background.js - den skal vi ikke bruge mere - og zipper resten af filerne til f.eks. EmneordsExtension.zip.Testing testing en to treSå er det tid til at teste. Vi indlæser udvidelsen på samme måde som før. Så åbner vi en artikel i redigeringsmodus, klikker på knappen - og flux bliver emneordsforslagene malet op med gult. Vi har sparet verden for ét udnødvendigt museklik. Man bliver helt rørstrømsk på egne vegne.Vi prøver også med Chrome, for det skulle jo helst være platformsuafhængigt. Vi indlæser vores udvidelse i Googles browser, og det virker bare. Dæleme dejligt.Firefox har glimrende værktøjer til udvikling af Javascript-kode i en extension. Ved at vælge Debug-fanen og klikke på 'content.js' under fanen 'Kilder' til venstre, bringes content-scriptet frem, og man kan indsætte breakpoints og evaluere udtryk. Det kan være smart, hvis koden ikke spiller.Et kodeeksempel kan downloades fra Google Drive (som kan sige nogle fjollede ting undervejs, men bare tryk 'download' - og det fylder stadig for meget til Gitlab.)Udvidelsen i download-eksemplet virker dog ikke i Firefox - på trods af, at den 'rigtige' udgave, som er syet sammen med vores cms, fungerer upåklageligt. Faktisk kan jeg slet ikke få en udvidelse til bare det mindste i Firefox, hvis den skal afvikles sammen med en lokal side - som i 'localhost' eller '127.0.0.1.'Debuggeren siger, at browseren ikke kunne indlæse en 'blob,'et binært objekt, men det passer ikke rigtigt på min situation. Når domænet hedder 'version2.dk' går det fint, så måske er det noget sikkerhedsmæssigt. Jeg skal ikke kunne sige det. Men prøv i stedet med Chrome.Når serveren er oppe og køre, via det medfølgende batch-script, kan en testside tilgås med url'en: https://localhost:8000/apps/emneord/test - hvor man kan indsætte tekst fra en Version2-artikel og få bud på emneord ved hjælp af browserudvidelsen, som også følger med download-eksemplet.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2018-09-27
          &nbsp;·&nbsp; e6e9e4e4
          &nbsp;·&nbsp; #24
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.993</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.558</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.62</kbd>
        </footer>
      </article>
      <article>
        <h4>Forskere: Stack Overflow-svar fyldt med hullet Java-kode</h4>
        <div>
          Der kan være grund til varsomhed i forhold til kode, der handler om Java og sikkerhed på Stack Overflow.Næste gang du mere eller mindre copy/paster et eksempel fra kodeforummet Stack Overflow, så kan det måske være en god idé at granske koden en ekstra gang. I hvert fald hvis det handler om sikkerhed og Java.Forskere fra Virginia Tech har således begået en rapport.Det oplyser The Register, der har set på rapporten. Forskerne peger på, at mange udviklere ikke forstår sikkerhed i tilstrækkelig grad til at implementere det godt nok. Og i den forbindelse mener de, at overkomplicerede API'er, Spring-sikkerhedsframeworket til Java og andre biblioteker fører til frustrationer og fejl.Forskerne har gennemtrawlet 497 kodesvar fra Stack Overflow i forhold til Java og sikkerhed. Her var der flere sikkerheds-problemer forbundet med svarene.Blandt andet var der accepterede svar, der anbefaler MD5 og SHA-1 som krypto-algoritmer. Som flere læsere vil vide er det en dårlig idé.Der var også accepterede Stack Overflow-svar, der anbefaler udviklere at stole på alle SSL/TLS-certifikater for at komme fejl til livs i forbindelse med verifikation af certifikater.SpringHvad Spring-frameworket angår, så var der Stack Overflow-råd, der i forbindelse med implementering af autentifikation i Spring anbefalede at slå Cross-Site Request Forgery-checks fra.I det hele taget har forskerne ikke ret meget til overs for Spring, bemærker The Register.55 procent af de Java-sikkerhedssvar, forskerne har set på, var relateret til Spring, som forskerne mener, er unødigt kompliceret og dårligt dokumenteret.»We provided substantial empirical evidences showing that APIs in Spring security (designed for enterprise security applications) are overly complicated and poorly documented, and error reports from runtime systems cause confusion,« står der i forskernes rapport. (PDF)Og så peger forskerne også på et mere platforms-orienteret problem i relation til Stack Overflow. Et svar fra en person med en høj omdømme-score (eng. reputation score) har en tendens til at blive godkendt, selvom det er forkert, på bekostning af mere korrekte svar fra personer med en lavere omdømme-score.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2017-10-03
          &nbsp;·&nbsp; e6715185
          &nbsp;·&nbsp; #25
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.899</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.849</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.678</kbd>
        </footer>
      </article>
      <article>
        <h4>AI under corona: Systemer, der ville have været utænkelige for et år siden, bliver hastet igennem</h4>
        <div>
          De britiske myndigheder hasteimplementerede i sommers et tvivlsomt AI-system i skolerne, der endte med at gå ud over karaktererne for elever fra socialt belastede områder, mens algoritmen hjalp elever fra privatskoler. Corona-pandemien har demonstreret behovet for AI-regulering, mener hollandsk AI-ekspert Catelijne Muller.
        </div>
        <footer>
          <em>Pro.ing.dk/Gridtech</em>
          &nbsp;·&nbsp; 2021-05-13
          &nbsp;·&nbsp; e8435e6e
          &nbsp;·&nbsp; #26
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.744</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.798</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.523</kbd>
        </footer>
      </article>
      <article>
        <h4>V2 amok i skygge-it: Bookmarklet-SSL-server på netværket med hjemmelavet certifikat</h4>
        <div>
          På Version2 er vi godt i gang med at automatisere valget af emneord til nye artikler, i hvert fald i den grad, som vores machine learning-algoritme Naive Bayes kan levere varen.I sidste artikel fik vi optimeret algoritmen og pressede seks ekstra procentpoint ud af algoritmen, i hvert fald når emneordet var 'sundheds-it.'I mellemtiden har vi forbedret algoritmen lidt mere, ved at tælle overskrifter to gange, som vi også var inde på i sidste artikel. Vi prøvede også at tilføje artiklernes forfatternavne, men det trak en anelse ned i forudsigelserne - så det droppede vi igen. Version2's journalister er åbenbart ikke fagidioter, kan man måske konkludere, eller så har der været mange forskellige igennem i årenes løb.Nu er tiden kommet til at prøve det hele i virkeligheden, og se, om det egentlig kan bruges af dem, som det er tiltænkt - Version2's journalister.Vi vil implementere emneords-algoritmen i Version2's CMS-system som en bookmarklet - en stump Javascript, der kan placeres i et link i et browser-bookmark. Så slipper vi for at overbevise webudviklerne om, at de skal smide vores tossede kode ind i deres system, og samtidigt er det nemmere end at lave en browser-extension.Det er det rene skygge-it. Men den slags kan jo også have sin charme, indenfor rimelighedens grænser, altså.Vores 'user story'lyder sådan her:Journalisten har en ny, færdigskrevet artikel åben i redigerings-modus i CMS'et, og klikker på bookmarkletten i browserens bogmærkelinje. Derved sender bookmarkletten overskrifter og artikeltekst til serveren via et ajax-kald. Machine learning-algoritmen gør sit arbejde og returnerer bud på emneord til bookmarkletten, som derefter opmærker emneordene i CMS'ets dialogboks med gul baggrundsfarve. Så kan journalisten bruge forslagene eller ej, ved at sætte et flueben i en krydsboks - sådan som det ser ud i illustrationen i toppen af denne artikel.Vi strikker et hjemmelavet certifikatVores CMS kører HTTPS, naturligvis, og reglen for bookmarklets er, som med eksterne scripts i almindelighed, at man ikke kan blande krypterede og ukrypterede kilder.Vi skal med andre ord sætte en HTTPS-server op, som forsyner vores bookmarklet med bud på emneord.Vi har ikke brug for stor server og det konfigureringsbesvær, der ofte følger med. HTTP-serveren vi benytter her, er en lille én, der følger med Javas udviklingsmiljø (JDK), men som ikke er officielt en del af klassebibliotekerne (JRE). Den befinder sig dog i et 'jdk'-modul, og der dermed et velsignet medlem af JDK'et. Server-koden er open source, ligesom klassebibliotekerne i øvrigt.For at skabe en SSL-forbindelse skal vores server have et certifikat. Her laver vi bare vores eget. Det betyder, at certifikatet ikke er underskrevet af et rodcertifikat, som 'rigtige' certifikater er, og at brugeren af bookmarkletten skal foretage en 'sikkerhedsundtagelse' i browseren.Vi laver certifikatet med Java-værktøjet Keytool, som ligger i 'bin'-mappen i Javas distribution. Jeg åbner et terminalvindue og starter programmet. På min pc ser det sådan ud:C:\Program Files\Java\jre-9.0.4\bin&amp;gt,keytool -genkey -keyalg RSA -alias webservice -keystore C:\Users\tan\Desktop\selfsigned.jks -validity 365 -keysize 2048- hvor det hele skal stå på samme linje.Nu stiller programmet en række spørgsmål, der skal besvares.Enter keystore password:Re-enter new password:What is your first and last name?(Unknown): Tania AndersenWhat is the name of your organizational unit?(Unknown): Version2What is the name of your organization?(Unknown): MIWhat is the name of your City or Locality?(Unknown): CopenhagenWhat is the name of your State or Province?(Unknown):What is the two-letter country code for this unit?(Unknown): DKIs CN=Tania Andersen, OU=Version2, O=MI, L=Copenhagen, ST=Unknown, C=DK correct?(no): yesHerefter kvitterer programmet med at generere en privat nøgle på mit skrivebord, med navnet selfsigned.jks.Så kan vi sætte serveren op, således:private static final String SUN_X509_ALGORITME = &quot;SunX509&quot;, public static void main(String[] args) throws IOException, Exception, NoSuchAlgorithmException {// Opsæt og start webserveren.HttpsServer httpsServer = HttpsServer.create(new InetSocketAddress(8000), 0),KeyStore ks = KeyStore.getInstance(&quot;JKS&quot;),FileInputStream fis = new FileInputStream(&quot;C:\Users\tan\Desktop\selfsigned.jks&quot;), char[] password = new char[] { 'p', '1', 'z', 'z', 'a', 'r', 'e', 's', 't'},// Char-array benyttes i stedet for String, // for at undgå at passwordet ender i String-poolen.ks.load(fis, password),KeyManagerFactory kmf = KeyManagerFactory.getInstance(SUN_X509_ALGORITME), kmf.init(ks, password),TrustManagerFactory tmf = TrustManagerFactory.getInstance(SUN_X509_ALGORITME), tmf.init(ks),SSLContext sslContext = SSLContext.getInstance(&quot;TLS&quot;), sslContext.init(kmf.getKeyManagers(), tmf.getTrustManagers(), null),Vi skaber en ny server med kaldet HttpsServer.create, som tager en socket-portadresse som parameter. Her sætter vi den til port 8000.Så skaber vi en Keystore, som holder på vores private key, og indlæser vores nøgle selfsigned.jks fra før, med en FileInputStream, sammen med det password, vi brugte da vi skabte privat-nøglen.Vi skal også bruge en KeyManagerFactory (kmf) og en TrustManagerFactory (tmf). Nu skal vi have etSSLContext -objekt, som vi får med metoden SSLContext.getInstance(&quot;TLS&quot;), hvor vi beder om TLS-protokollen - vore dages udgave af SSL.Nu initieres SSLContexten med metoden sslContext.init(kmf.getKeyManagers(), tmf.getTrustManagers()). Så kan vi konfigurere vores server. Det ser sådan ud:httpsServer.setHttpsConfigurator(new HttpsConfigurator(sslContext) { public void configure(HttpsParameters params) { try {SSLContext c = SSLContext.getDefault(),SSLParameters defaultSSLParameters = c.getDefaultSSLParameters(), params.setSSLParameters(defaultSSLParameters),} catch (NoSuchAlgorithmException e) { throw new RuntimeException(e),}}}),Nu er serveren konfigureret til SSL med vores hjemmelavede certifikat.(Man kunne måske have ønsket sig, at Javas api-designere havde gjort det lidt nemmere for os. Jeg har set et Python-eksempel på det samme, og det fyldte fire linjer. Men sådan er det nu en gang i Java-verdenen.)Nu skal der skabes en 'context', som er en request-handler, der knyttes til en bestemt url. Det ser sådan ud i vores eksempel:httpsServer.createContext(&quot;/apps/emneord&quot;, new Servicehandler()), httpsServer.setExecutor(null), // creates a default executor httpsServer.start(),LocalDate now = LocalDate.now(), now.format(DateTimeFormatter.ISO_DATE),System.out.println(&quot;Starter webtjenesten.&quot;+ ZonedDateTime.now().format(FORMATTER)),Parameteren 'new Servicehandler()'er en instans af interfacet HttpHandler, som har metoden 'handle', der skaber HTTP-svaret. Det ser sådan ud i vores eksempel:static class Servicehandler implements HttpHandler { private Tester tester = new Tester(), public void handle(HttpExchange exchange) throws IOException {InputStream is = exchange.getRequestBody(), final String requestBody = new String(is.readAllBytes(), &quot;UTF-8&quot;),String response = findEmneord(requestBody), final Headers responseHeaders = exchange.getResponseHeaders(), responseHeaders.put(&quot;Access-Control-Allow-Origin&quot;, List.of(&quot;*&quot;)), responseHeaders.put(&quot;Content-Type&quot;, List.of(&quot;text/plain&quot;)), exchange.sendResponseHeaders(200, response.length()),OutputStream os = exchange.getResponseBody(), os.write(response.getBytes()), os.close(),}}Her henter vi request-body'en ud af HttpExchange-parameteren med kaldet exchange.getRequestBody. Vi kalder derefter metoden findEmneord. Tilbage i artiklen i april havde vi en metode, der hed testArtikel, og vores findEmneord -metode gennemløber blot testArtikel med de 50 mest anvendte emneord. Hvis testArtikel vender tommelfingeren op på et givent emne, sender vi emneordet tilbage til vores bookmarklet.For at bookmarkletten kan få lov at tilgå CMS-websiden, skal vi sætte response-headeren Access-Control-Allow-Origin til en asterisk. Det gøres i linjen responseHeaders.put(&quot;Access-Control-Allow-Origin&quot;, List.of(&quot;*&quot;)).Kodeeksemplet kan downloades fra Google Drive, da det fylder for meget for Gitlab - det er modellens estimat-tabeller, der fylder en del. (Google Drive kan sige nogle fjollede ting undervejs, men bare tryk 'download.'). Når serveren er oppe og køre, via det medfølgende batch-script, kan en testside kan tilgås med url'en: https://localhost:8000/apps/emneord/test. (Den del af koden er udeladt i eksemplet her i artiklen.)I en kommende artikel ser vi nærmere på udviklingen af bookmarkletten, der modtager svaret fra vores server, og syr det ind i vores CMS. Bliv på kanalen.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2018-08-24
          &nbsp;·&nbsp; e6debba3
          &nbsp;·&nbsp; #27
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.995</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.584</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.544</kbd>
        </footer>
      </article>
      <article>
        <h4>Machine Learning kan bruges til at bygge... Machine Learning</h4>
        <div>
          Automatiseret afprøvning af 'best fit'-algoritmer kan accelerere udviklingen af Machine Learning og Artificial Intelligence, så AI hurtigere kan udvikles til operationel AI. Et af de konkrete resultater er et teknologisk spring fra Natural Language Processing til Natural Language Understanding, skriver Thomas Herlin fra CGI.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2018-12-11
          &nbsp;·&nbsp; e701c30f
          &nbsp;·&nbsp; #28
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.953</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.937</kbd>
        </footer>
      </article>
      <article>
        <h4>Techtopia #174: Hvad kan GPT-3?</h4>
        <div>
          GPT-3 har sat nettet og folk med interesse for kunstig intelligens på den anden ende, siden den blev introduceret i juli. Den er et stykke maskinlæring, der kan skrive om alle emner mellem himmel og jord.GPT-3 er et stykke maskinlæring, der kan skrive om alle emner mellem himmel og jord - eller alle emner beskrevet på internettet. GPT-3 har sat nettet og folk med interesse for kunstig intelligens på den anden ende, siden den 20. juli blev introduceret af firmaet Open AI.Men hvad er det egentlig GPT-3 kan? Og skal vi være imponerede, skræmte eller bare trække på skuldrene? Jeg har inviteret tre gæster for at finde ud af det.Denne udgave af Techtopia stammer fra R4dio.Medvirkende:Thomas Bolander, professor og ph.d. i logik og kunstig intelligens på DTU Compute og forfatter til bogen 'HVORDAN ser fremtiden ud med kunstig intelligens?'David Kofoed Wind, CEO, EduflowMads Rydahl, UnsiloKom gerne med dine bud på , hvilke emner vi skal tage op.Du kan finde alle episoder af Techtopia HER.Emner :Kunstig intelligens
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2021-01-05
          &nbsp;·&nbsp; e80f3f17
          &nbsp;·&nbsp; #29
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.981</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.809</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.602</kbd>
        </footer>
      </article>
      <article>
        <h4>Sådan skriver du unit tests</h4>
        <div>
          »Hvorfor skriver du ikke en artikel om unit tests,« sagde min kollega Jakob en dag.I sin ungdom programmerede Jakob magasinet Alt Om Data's CMS-system, så nybegynder eller uerfaren er han altså ikke.»Der er sikkert mange ligesom mig, der godt kunne tænke sig at kende mere til det,« mener han.Og det lyder jo fornuftigt nok.Unit tests er programmer, der tester små dele af et programs kode.Motivet er klart: Manuel test er tidskrævende, benytter som regel alt for få testeksempler, det er dødkedeligt arbejde og fejlbehæftet i den helt store stil. Test er altså en oplagt kandidat til automatisering.Drop debuggerenDertil kommer, at debuggere, hvor man trinvist kan gennemløbe programlinjers udførsel én for én, er et skrækkeligt værktøj til at finde fejl med. Det er som at finde nålen i høstakken ved at kigge på ét strå ad gangen.Unit test stiller i stedet spørgsmålet: Hvad forventede du af programstumpens resultat?Det giver både hurtigere og mere sikker fejlfinding, og ofte en bedre forståelse af kodens virkemåde og robusthed i tilgift.En anden vigtig funktion for unit tests er dets anvendelse som såkaldt regressionstest. Hver gang ny kode tilføjes programmet, er der en hvis mulighed for, at den tidligere og ellers gennemtestede kode fejler.Med automatiserede tests handler det blot at klikke på knappen i udviklingsværktøjet og så er der vished for, at ens ændringer ikke udløser nye fejl, eller ændrer adfærd i tidligere kode.Derudover kan man også teste biblioteker, man anvender i sin kode. Dokumentation er godt, men det er endnu bedre at teste, at man får præcist det resultat man forventer, når en given metode kaldes i et bibliotek under et bestemt brugsscenarie, der passer til programmets anvendelse.I vore dage knyttes unit tests sammen med 'continous integration', hvor koden testes i forbindelse med automatiske builds, altså kompilering, konfiguration og udrulning af det færdige program til et test- eller produktionssystem.Og i 2019 er der næppe nogen softwarevirksomhed eller udviklerafdeling, der kunne klare sig uden, hvis kvaliteten skal være i orden.Ekstrem fed programmeringDer er ikke noget nyt i unit tests - det har været brugt i ganske mange år. Men det store gennembrud kom, da datalogen Kent Beck, som var bannerfører for Extreme Programming - en tidlig udgave af agile metodikker - flyttede sit testmiljø fra sproget Scheme til Java i starten af det nye århundrede.Junit, som biblioteket hedder, blev en kæmpe success i samme tempo som de agile metoder slog an som en løbeild. Tilsvarende biblioteker findes til stort set alle andre populære sprog og ofte i mange udgaver og alternativer.Her kigger vi nærmere på originalen. Junit er integreret i de fleste større Java-værktøjer, så som gode gamle Eclipse.Jeg kan bedst lide at have mine test i en selvstændig pakke. Hvis klassen, jeg skal teste, ligger i pakken v2ml, ligger de tilhørende tests i v2ml.test. Så er der styr på sagerne.I Eclipse skabes en Junit-test nemt ved at vælge menuen File &amp;gt, New &amp;gt, JUnit Test Case. En test case er bare en almindelig klasse med metoder, der starter med 'test' i navnet.Vi kalder vores testklasse for TestUtil. Guiden skaber denne klasse:package v2ml.test, import static org.junit.jupiter.api.Assertions.*, import org.junit.jupiter.api.Test, class TestUtil {@Test void test() { fail(&quot;Not yet implemented&quot;),}}Annotationen @Test bevirker, at metoden test() kan udføres automatisk.I Eclipse kan testen nu udføres ved at vælge menuen Run &amp;gt, Run (Ctrl+F11). Nu åbnes Eclipses Junit-view.Der kommer en rød bjælke i værktøjets brugerflade, for vores test har fejlet. Det er fordi testen kun indeholder linjen:fail(&quot;Not yet implemented&quot;),Test med tænkehattenTil Version2's machine learning kunne jeg godt bruge et lille program, der kan tage tabeller med ordhyppigheder og finde et gennemsnit.Det kan vel ikke være så svært, og jeg gider ikke lige lede efter et bibliotek, der kan gøre det for mig. Jeg skriver en håndfuld linjer:public class Util { public static Map sum(Map a, Map b) { var sum = new HashMap (), for (var key : a.keySet()) { sum.put(key, a.get(key) + b.getOrDefault(key, 0)),} return sum,}}(En map i Java er ligesom associative arrays i andre sprog, og knytter her et ord til et tal.)Ideen er, at summen for en ordhyppighed må være summen af værdierne for en given nøgle i begge tabeller, og hvis ordet ikke findes i den sidste tabel, lægges 0 til.Så er vi parat til at teste.Konventionen er at kalde testmetoderne noget med 'test' plus det, man ønsker at teste. Vi kalder vores for 'testSum.' void testSum() { var x = Map.of(&quot;a&quot;, 1, &quot;b&quot;, 2, &quot;c&quot;, 3), var y = Map.of(&quot;b&quot;, -1, &quot;c&quot;, 4, &quot;d&quot;, 5), var z = Util.sum(x, y),}Her skaber vi to tabeller - maps - og lægger dem sammen. Nu skal vi teste, at resultatet er rigtigt. Det gør vi ved at benytte Junits 'assert'-metoder.De tager to værdier - den, vi forventer, og det som metoden rent faktisk afleverer, og holder dem op imod hinanden. Man kan også angive en fejlmeddelelse, så man hurtigt kan overskue, hvad der gik galt. Det er praktisk, hvis der er mange tests. Så ser det sådan ud:void testSum() { var x = Map.of(&quot;a&quot;, 1, &quot;b&quot;, 2, &quot;c&quot;, 3), var y = Map.of(&quot;b&quot;, -1, &quot;c&quot;, 4, &quot;d&quot;, 5), var z = Util.sum(x, y), assertEquals(1, (int) z.get(&quot;a&quot;), &quot;Gal sum&quot;),}I sidste linje forventer vi værdien 1, og vi tester den op imod den faktiske værdi z.get(&quot;a&quot;) (som lige skal castes fra Integer til int).Så er det bare at køre i testen igen, med Ctrl+F11. Nu får vi en grøn bjælke, og det betyder at testen er passeret. Men vores test er naturligvis ikke fyldestgørende, så vi skriver nogle flere:assertEquals(1, (int) z.get(&quot;a&quot;), &quot;Gal sum&quot;), assertEquals(1, (int) z.get(&quot;b&quot;), &quot;Gal sum&quot;), assertEquals(7, (int) z.get(&quot;c&quot;), &quot;Gal sum&quot;), assertEquals(5, (int) z.get(&quot;d&quot;), &quot;Gal sum&quot;),Vi kører testen igen, og den er gal: Bjælken bliver rød.Det er ikke engang vores assert-sætninger der giver fejlen, som er en gemen nullpointer-fejl.I nederste venstre side kan vi af 'failure tracet' se, at fejlen opstår i linje 21. Det er denne her:assertEquals(5, (int) z.get(&quot;d&quot;), &quot;Gal sum&quot;),Det må være z.get(&quot;d&quot;), der giver fejlen, for der er ingen andre objekter i sigte. Med andre ord er &quot;d&quot; ikke med i sum-tabellen.På med tænkehatten.Når vi kigger på sum-metoden, gennemløber vi elementerne i første tabel, og lægger dem til elementerne i den anden tabel, hvis de findes. Med hvad med de elementer i anden tabel, som ikke findes i første tabel?Dem havde jeg lykkeligt glemt alt om.Løsningen er at tilføje hyppighederne fra de ord i tabel b, som ikke findes i tabel a:var bKeys = new HashSet (b.keySet()), bKeys.removeAll(a.keySet()), for (var key : bKeys) { sum.put(key, b.get(key)),}Jeg kører min test igen med Ctrl+F11 - og bjælken bliver nydeligt grøn. Selvtilfredshedens sødme føles helt ud i fingerspidserne.Hvad skal man testeMen hvad skal man egentlig teste med assert-sætninger?En klassisk fremgangsmåde er såkaldt 'grænseværditest.' Det betyder, at man skal teste sine metoder med henholdsvis typiske, ekstreme og ulovlige værdier, som parametre til et funktionskald.Typiske værdier er dem, man vil forvente i et funktionskald i forbindelse med et helt almindeligt brugerscenarie.Ekstreme værdier kan eksempelvis være en øvre eller nedre grænse i et interval, eller en streng, som er usædvanlig lang - altså en parameterværdi, som måske kan give mavebesvær for funktionen.Ulovlige værdier - som dog ikke har noget med straffeloven at gøre - er parameter-værdier, hvor programstumpen eller funktionen skal udløse en fejl, som for eksempel en RuntimeException.I vores eksempel kan en 'ekstrem' værdi for eksempel være to nulls som argumenter til sum-funktionen. Jeg aner ikke, hvad der sker, hvis jeg gør dette, så jeg tilføjer linjen var resultat = Util.sum(null, null), til min testmetode, og kører igen.Bom, bjælken er rød, nullpointer-fejl, og det skyldes linje 17 i sum-funktionen, siger mit failure trace:for (var key : a.keySet()) {Jeg har altså implicit forestillet mig, at metoden ikke kaldes med null-værdier som parametre.Det må jeg hellere gøre explicit med denne linje, en såkaldt 'guard' eller 'precondition', lige efter metodens overskrift:if (a == null || b == null) throw new IllegalArgumentException(&quot;Argumenterne må ikke være null.&quot;),Det er bedre end før, for de sagesløse klienter, der kalder min metode, får nu klar besked om, hvad der gik galt.Nu har jeg altså besluttet, at null er en ulovlig værdi, og jeg kan teste det i min testmetode:try { var resultat = Util.sum(null, null), fail(&quot;Ulovlige værdier kaster ikke exception.&quot;),} catch (IllegalArgumentException ex) {// Hvis vi når hertil, er testen gået godt.}Hvis kaldet til sum-metoden med null som argumenter ikke kaster en exception, som forventet, går programmet videre til fail-kaldet, som siger, at min guard åbenbart ikke fungerer.Den situation kunne måske opstå, hvis jeg senere tilføjer flere betingelser til min guard og klokker i de logiske operatorer, som godt kan være drilske.Det er det, der gør unit tests godt som regressionstest - når jeg fylder ny kode på mit program, kan jeg sikre mig, at den tidligere adfærd stadig er gyldig.Der er meget mere at sige om unit tests, end hvad vi har berørt her. En vigtig mulighed er at samle sine tests som 'testsuiter', så man får et hierarki af test, hvor man går højere og højere op i niveau i programmets funktionalitet og ender med at teste de overordnede brugerscenarier.En sidste ting, vi vil se på, er 'coverage', hvor et værktøj kan se, hvor store dele af koden som testen gennemløber. Det findes i mange udviklingsværktøjer og sprog. I Eclipse benyttes faciliteten med menuen Run &amp;gt, Coverage.Nu viser værktøjet de linjer, som blev gennemløbet, da unit testen blev udført. Det kan være en smart måde at sikre sig, at man ikke har glemt at teste dele af programmet.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2019-01-22
          &nbsp;·&nbsp; e70d3277
          &nbsp;·&nbsp; #30
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.997</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.849</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.634</kbd>
        </footer>
      </article>
      <article>
        <h4>GPT-3: The New Mighty Language Model from OpenAI</h4>
        <div>
            Pushing Deep Learning to the Limit with 175B Parameters OpenAI recently released pre-print of its new mighty language model GPT-3. Its a much bigger and better version of its predecessor GPT-2.In fact, with close to 175B trainable parameters, GPT-3 is much bigger in terms of size in comparison to anything else out there. Vil du have fuld adgang til DataTech? DataTech skriver til dig, der arbejder professionelt med data og analytics. Vi giver dig inspirerende cases, nyheder og debat om alt fra Machine Learning-modeller til dataetik. Har du allerede et abonnement? Log ind Er dit prøveabonnement udløbet? Køb
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2020-06-11
          &nbsp;·&nbsp; e7bf1bd6
          &nbsp;·&nbsp; #31
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.893</kbd>
            <kbd data-tooltip="AI &amp; innovation">L05_INNOAI&nbsp;0.553</kbd>
        </footer>
      </article>
      <article>
        <h4>ITU-forsker får 6 mio. kroner til forskning i algoritmers bias</h4>
        <div>
          Villum Fonden har tildelt lektor på IT-Universitetet Roberta Sinatra en bevilling på 6 mio kroner. Pengene skal gå til forskning i diskriminerende algoritmer, skriver universitetet i en pressemeddelelse.Forskningsprojektet har fået navnet Bias Explained: Pushing Algorithmic Fairness with Models and Experiments. I projektet vil Roberta Sinatra forsøge at afdække de matematiske biasmekanismer, som skaber misvisende rangeringer samt udvikle nogle mere retvisende algoritmer, der skal tage del i kampen mod diskriminerende algoritmer.Projektet tager afsæt i, hvordan algoritmer favoriserer videnskabelige udgivelser ud fra forfatterens køn, universitet og etnicitet.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2021-01-29
          &nbsp;·&nbsp; e81a62b4
          &nbsp;·&nbsp; #32
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.754</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.515</kbd>
        </footer>
      </article>
      <article>
        <h4>Danfoss-topchef: Vi er hele tiden i et kapløb</h4>
        <div>
          Log indBliv abonnent og læs hele historienKøb adgang for kun 49,- pr. md&gt;Ingen binding!Hvad er plus+ AbonnementstyperFå dagens vigtigste nyheder fra amtsavisen.dk direkte i din indbakke. Det er gratis, og du kan afmelde dig til hver en tid.TilmeldVed tilmelding accepteres automatisk vores betingelserLuk betingelser
        </div>
        <footer>
          <em>Amtsavisen.dk (Randers Amtsavis)</em>
          &nbsp;·&nbsp; 2018-12-23
          &nbsp;·&nbsp; e7059c80
          &nbsp;·&nbsp; #33
          <br>
          <br>
            <kbd data-tooltip="Tech industry &amp; regulation">L02_BIGTEC&nbsp;0.768</kbd>
            <kbd data-tooltip="Facebook, fake news &amp; Trump">L05_FBTRUM&nbsp;0.526</kbd>
        </footer>
      </article>
      <article>
        <h4>Gratis værktøjer skal spotte algoritmernes fordomme</h4>
        <div>
          Bias, fordomme og diskrimination er ikke bare noget der foregår i den fysiske verden. Det finder i den grad også sted i de algoritmer, der blandt andet bruges til ansigtsgenkendelse og en lang række beslutningsprocesser.Nu har IBM lanceret en værktøjskasse med navnet 'Fairness 360', som scanner for tegn på bias i algoritmer.I den første udgivelse af Fairness 360, også navngivet AIF360 Python Package, finder man ni forskellige algoritmer, hvis mål er at afbøde bias. Det er et sæt af fairness- målinger på datasæt og machine learning-modeller.Åbner den sorte boksBehovet for nye former for indsigt i algoritmerne skyldes blandt andet, at udviklere ofte ikke ved, hvilke beslutninger der tages med deres kunstige intelligens og hvorfor.Kunstig intelligens er kendt som en black box, en sort boks. IBM's værktøj vil gøre AI-beslutninger mere gennemsigtige, så udviklere kan se, hvilke faktorer der bruges i den kunstige intelligens.Softwaren er cloud-baseret og open source, og den virker til de mest kendte AI-frameworks, inklusiv Watson, Tensorflow, SparkML, AWS SageMaker og AzureMLDu kan finde Fairness 360 på Github
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2018-09-27
          &nbsp;·&nbsp; e6ea1676
          &nbsp;·&nbsp; #34
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.985</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.862</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.642</kbd>
        </footer>
      </article>
      <article>
        <h4>Hybrid mellem neuralt net og beslutningstræ giver forklarlig deep learning</h4>
        <div>
          Neurale net arrangeret som beslutningstræ giver både forklarlighed og præcision, mener AI-forskere. Beslutningstræer er den gyldne standard, hvis en model skal være både forklarlig og intuitiv. Men på komplekse opgaver som at klassificere billeder fejler træerne med en præcision, der er væsentligt ringere end et neuralt netværk. Men med et nyt koncept, udviklet af forskere fra Berkleys center for AI-forskning, kan man få det bedste af begge verdener. Neural-Backed Decision Trees (NBDT) tager den overordnede, intuitive gennesigtighed fra beslutningstræer, men bruger neurale netværk til at tage beslutninger. Resultatet er ifølge Berkeley-forskerne en model, der kan matche almindelige neurale netværk i præcision, men hvor en almindelig bruger kan aflæse, hvordan modellen kom frem til sin beslutning. NBDT-modellen består af et beslutningstræ, hvor hver node er et neuralt netværk. På billede-datasæts CIFAR10, CIFAR100, og TinyImageNet200 slår den kombination andre forklarlige, træbaserede metoder med en betydelig margin. Og forbliver indenfor omkring 1 procent i nærheden af performance af neurale netværk. Forklaringen giver særligt menig, når modellen skal klassificere billeder med indhold, den ikk har set før. CIFAR10-modellen har f.eks. aldrig set et Zebra, men gennem NBDT-modellen kan vi se, at modellen korrekt identificere at der er tale om et hovdyr, før den gætter på hest. Bedre performance betyder mere forstålig Ideen er simpel, men det er ikke helt simpelt, at omdanne et neuralt netværk til et beslutningstræ. Processen kræver blandt andet, hvad forskerne kalder induced hierarchy, der afgør, hvilke sæt af klasser - f.eks. hund eller kat - noderne modellen skal tage stilling til. Hierarkiet bliver bygget ud fra vægtene i et prætrænet neuralt netværk, og med en clustering-teknik finder man frem til hvilke klassifikationer bør have en fælles 'forældre'-node. De noder kan efterfølgende testes kvantitativt. Hvis man f.eks. antager, at en node afgør om billedet forestiller dyr eller fartøj, kan man teste det ved at løbe en masse billeder af dyr og fartøjer gennem modellen. Og på den måde kan man give hver node - som effektivt er en underdel af et lag i det samlede neurale netværk - en semantisk betydning. I forskernes præpublicerede artikel bemærker de en positiv sammenhæng mellem det neurale netværks præcision og hvor semantisk fornuftig hierakiet i stidste ende virker. »We believe that higher-accuracy models exhibit more semantically-sound weight spaces. Thus, unlike previous work, NBDTs feature better interpretability with higher accuracy, instead of sacrificing one for the other.«  Fugl eller fly Eksisterende metoder til at forklare belsutningerne fra et neuralt netværk, har sin mangler, påpeger Alvin Wan, der er en af forskerne bag projektet og pt. skriver sin ph.d. i AI ved Berkeley, i en blog Saliency maps, som kan bruges til at forstå klassifikationer af billeder, kan f.eks. ikke bruges, når et netværk kommer frem til forkerte beslutninger, men fokuserer på det rigtige - som f.eks. når en fugl klassificeres som et fly. Endnu er NBDT-modellen kun brugt på de klassiske billede-klassifikationsdatabaser. Det er derfor uvist, hvor meget klarhed NBDT-modellen kan bringe til situationer, hvor den logiske vej til en beslutning ikke er så simpel som at skelne dyr fra køretøjer - f.eks. når et neuralt netværk skal spotte brystkræft. Ikke desto mindre er der givet situationer, hvor kombinationer af et effektivt neuralt netværk og et visuelt, intuitivt beslutningstræ er attraktivt. Man kan afprøve prætrænede NBDT-modeller her , hvor man også kan hente koden.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2020-05-28
          &nbsp;·&nbsp; e7b9f4fe
          &nbsp;·&nbsp; #35
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.969</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.973</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.665</kbd>
        </footer>
      </article>
      <article>
        <h4>IBM dropper at sælge generel software til ansigtsgenkendelse</h4>
        <div>
            Formuleringer i IBM's brev til USA's Kongres vækker skepsis. IBM vil ikke længere tilbyde IBM-software til ansigtsgenkendelse eller -analyse, og man vil heller ikke forske i eller udvikle teknologien fremover. Det skriver it-virksomhedens CEO Arvind Krishna i et brev til USA's Kongres, som først blev rapporteret af CNBC »IBM no longer offers general purpose IBM facial recognition or analysis software. IBM firmly opposes and will not condone uses of any technology, including facial recognition technology offered by other vendors, for mass surveillance, racial profiling, violations of basic human rights and freedoms, or any purpose which is not consistent with our values and Principles of Trust and Transparency,«  skriver Arvind Krishna, CEO hos IBM, i et brev til kongressen i USA. Til The Verge oplyser IBM, at selskabet ikke længere vil forske i eller udvikle teknologien. Dette er dog ikke en del af brevet fra topchefen. IBM's udmelding kommer efter to uger med demonstrationer i USA mod racisme og politibrutalitet. I brevet bakker Arvind Krishna op om reformer af landets politi, så betjente kan holdes ansvarlige for at bruge magt. Ikke for et forbud Allerede i november udgav IBM en blog, der taler for at holde leverandører ansvarlige for måden, som deres teknologi bliver brugt på: »Providers of facial recognition technology must be accountable for ensuring they don't facilitate human rights abuses by deploying technologies such as facial matching in regimes known for human rights violations,«  skrev selskabet Chief Policy Officer, Christina Montgomery ved den lejlighed. Men både dengang som nu taler IBM ikke for et direkte forbud mod teknologien - heller ikke til brug for politiet. I stedet skriver Krishna, at tiden er inde til »a national dialogue on whether and how facial recognition technology should be employed by domestic law enforcement agencies« , og hvis ordensmagten bruger teknologien, skal den være testet for bias. »Artificial Intelligence is a powerful tool that can help law enforcement keep citizens safe,«  skriver Krishna. Skepsis og begejstring IBM's udmelding vækkede begejstring - blanct andet hos Damien Patrick Williams, ph.d.-studerende ved Virginia Tech. »Arguably THE biggest, longest lasting name in Facial Rec said &quot;No, we won't do it, it's bad.&quot; That's huge,«  skriver han på Twitter Omvendt bliver brevet mødt med skepsis fra Yoav Goldberg, der er professor i Datalogi ved Bar Ilan University samt Research Director ved den israelske gren af Allen Institute for Artificial Intelligence. Goldberg påpeger , at formuleringen i brevet - »IBM no longer offers genereal purpose IBM facial recognition or analysis software«  - ikke udelukker salg af custom software, samt software fra tredjeparter. Samme bekymring kommer fra Eva Blum-Dumontet, der er Senior Research Officer ved Privacy International. »IBM are trying to redeem themselves because they have been instrumental in developing the technical capabilities of the police through the development of so-called smart policing techniques. But let's not be fooled by their latest move,«  siger hun til BBC »First of all, their announcement was ambiguous. They talk about ending 'general purpose' facial recognition, which makes me think it will not be the end of facial recognition for IBM, it will just be customised in the future.« 
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2020-06-10
          &nbsp;·&nbsp; e7bed223
          &nbsp;·&nbsp; #36
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.796</kbd>
            <kbd data-tooltip="AI &amp; innovation">L05_INNOAI&nbsp;0.754</kbd>
        </footer>
      </article>
      <article>
        <h4>Sådan kan matematik løse arvestridigheder</h4>
        <div>
          I DR's dramaserie ' Arvingerne' er Gro, Frederik, Emil og Signe havnet i et bittert opgør om arven efter deres mor, Veronika Grønnegaard.Der er ikke lagt op til en retfærdig løsning, for som en gammel talemåde siger, skal man ikke finde retfærdighed i juraen, men muligvis i teologien. En andet sted at finde retfærdighed kunne være i matematikken, som anvist i en ny artikel i Notices of the American Mathematical Society.Penge og ting, der kan omsættes i penge, er let at fordele mellem arvinger.Det er mere vanskeligt, når det drejer sig om ting, der er udelelige, og som har forskellig værdi for de forskellige arvinger.Her vil det være rart at have en god algoritme, der kunne fordele tingene på den mest retfærdige måde, og det er netop en sådan, Steven J. Brams fra New York University i USA, D. Marc Kilgour fra Wilfrid Laurier University i Canada og Christian Klamler fra Karl-Franzens-Universität Graz i Østrig præsenterer i deres artikel.De tre matematikere og økonomer analyserer dog kun tilfældet, hvor to personer skal fordele ting, der hver især er udelelige. Men Gro, Frederik, Emil og Signe kunne jo dele sig i to hold - og dernæst fordele tingene inden for hvert hold.Brams, Kilgour og Klamler bemærker, at fordeling efter princippet ' jeg deler, du vælger' har været indgroet i mange samfund, siden Abraham og Lot delte Kana'an og Jordan på denne måde (Første Mosebog, kap. 13). Der findes en række varianter for, hvordan man på tilsvarende vis kan fordele delelige emner mellem tre eller flere personer. Disse er ikke alle lige attraktive, skriver de tre forskere og tilføjer: ' Problemet blegner dog i forhold til at finde en metode til en fair fordeling af udelelige ting.' Brams har i 1996 sammen med Alan Taylor fra Union College i New York udviklet en misundelsesfri metode til fordeling af en række udelelige emner.Misundelsesfri dækker over, at ingen af personerne føler, at den anden har fået noget, vedkommende hellere selv ville have haft.Brams-Taylor-metoden (BT) er meget enkel og illustreres bedst med eksemplet vist i grafikken.Antag, at der er seks ting, der skal fordeles (se boks). A og B indleverer prioriterede lister for deres ønsker.Man sammenligner de to første ønsker. Da de er forskellige, får A maleriet, og B får stolen. Dernæst ser man på de ufordelte ting - her har både A og B nu uret som det højeste ønske. Det overføres derfor i første omgang til en ufordelt pulje.Den besværlige restTilbage er nu tre ting. Af disse har A lampen som sit højeste ønske, og B har krukken som sit højeste. Derfor bliver den endelige fordeling, at A får maleri og lampe, B får stol og krukke, mens den ufordelte pulje består af ur og chatol.I boksen er kort omtalt en metode til fordeling af tingene i denne pulje.Denne og andre metoder hertil er mere besværlige og mindre ' retfærdige' end BT-proceduren, men dog anvendelige.Så langt, så godt. Men nu kommer Brams sammen med Kilgour og Klamler med en ny metode, der overgår Brams-Taylor-metoden.Den nye algoritme, som de uvist af hvilken grund kalder AL, er som BT misundelsesfri, men den er derudover Pareto-optimal, dvs. der findes ingen anden misundelsesfri fordeling, der er bedre for begge personer. Der er heller ingen anden misundelsesfri fordeling, der efterlader færre emner i den ufordelte pulje - på den måde er AL maksimal.Set fra A og B's synspunkt er AL lige så let at håndtere som BT. De indleverer igen en prioriteret liste.Det interessante er dog, at AL vil fordele de seks emner i eksemplet på en anden måde end BT - en måde, som er bedre, da den er Pareto-optimal.Fordelingen bliver, at A modtager maleri og ur, mens B modtager stol og krukke, og den ufordelte pulje består af lampe og chatol.Der er altså sket det, at både A og B får tildelt deres første-og tredjeprioritet, mens deres identiske fjerde-og sjetteprioriteter havner i den ufordelte pulje.Med AL-metoden er B lige så godt stillet som med BT-metoden, mens A er bedre stillet.De tre matematikere redegør i deres artikel helt præcist for, hvordan algoritmen skal implementeres i praksis. Den formelle beskrivelse er dog forholdsmæssig lang, så den må vi springe over her.Ganske kort man kan sige følgende om det aktuelle eksempel: Maleri og stol bliver fordelt på samme måde i BT og AL.Når man kommer til uret, vil BT-metoden overføre det til den ufordelte pulje, mens AL vil undersøge, hvilke konsekvenser det vil have for fordelingen af de øvrige emner, hvis enten A eller B tildeles uret. Det fører i det aktuelle eksempel til, at A, men ikke B kan modtage uret.DEN UFORDELTE PULJEDer findes forskellige metoder til behandling af emner i den ufordelte pulje. Disse kræver dog, at parterne giver mere information end en simpel rangordning.Brams, Kilgour og Klamler har tidligere udviklet en misundelsesfri underbudsprocedure: A foreslår en fordeling, hvor han beholder en bestemt andel af emnerne i den ufordelte pulje. B kan enten acceptere denne fordeling eller underbyde A ved at fjerne et (vilkårligt) emne, som så bliver den endelige fordeling.FAIR FORDELING AF SEKS UDELELIGE EMNERTo arvinger, A &amp; B, skal deles om seks ting. Hvordan gør man dem begge tilfredse? BT og AL er begge misundelsesfri fordelinger, dvs. hverken A eller B føler den anden har fået noget, vedkommende hellere selv ville have haft. Kun AL er Pareto-optimal og maksimal, dvs. ingen anden misundelsesfri fordeling er bedre for begge personer, og ingen anden efterlader færre emner i den ufordelte pulje.
        </div>
        <footer>
          <em>Ingeniøren</em>
          &nbsp;·&nbsp; 2014-01-24
          &nbsp;·&nbsp; e439b9db
          &nbsp;·&nbsp; #37
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.99</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.639</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.66</kbd>
        </footer>
      </article>
      <article>
        <h4>Transfer learning hos Amazon: Alexa lærer japansk af engelsk sprogdata</h4>
        <div>
          For Amazons digitale assistent Alexa er evnen til at erobre nye markeder mere eller mindre lig evnen til at lære nye sprog.Men god sprogdata til at træne de neurale netværk er notorisk svære eller dyre at få fat på, hvorfor Alexa-udviklerne har kastet deres kræfter på transfer learning. Med andre ord at lade systemet overføre viden om ét sprog til et andet sprog for at lære det hurtigere og bedre.Strategien er effektiv, fortæller Research &amp; Development Program Manager ved Amazon Alexa AI Lucie Flekova på konferencen Women in Data Science, der fandt sted i sidste uge.»Cross lingual transfer learning er brugbart i både lille og stor skala, kan forbedre præstationen både på sætnings- og ordniveau, og det kan i vores tilfælde spare os mere end halvdelen af træningsdata,« siger Lucie Flekova om erfaringerne indtil videre.Relateret jobannonce: Data business analystFra stort til lille datasætTransfer learning er typisk brugbar i situationer, hvor du har et stort datasæt og et datasæt, der i sig selv er for lille til at træne en model.»Det store datasæt hjælper dig med at lære noget, og overføre det til det mindre datasæt uden at lære det igen,« forklarer Lucie Flekova.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2019-05-02
          &nbsp;·&nbsp; e72ea4ec
          &nbsp;·&nbsp; #38
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.959</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.908</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.616</kbd>
        </footer>
      </article>
      <article>
        <h4>Er du enig? 20 gyldne citater fra kendte programmører</h4>
        <div>
          Historien har budt på adskillige store skikkelser inden for programmeringens verden. Her får du en stribe af de bedste citater fra dem.Af Mikkel Meister»Hvis debugging er der, hvor man fjerner softwarebugs, må programmering være der, hvor man tilføjer dem.«Citatet stammer fra den kendte hollandske datalog Edsger Dijkstra, der nok er mest berømt for sin algoritme til at finde korteste veje fra et knudepunkt til alle andre knudepunkter i en graf.Sammen med 19 andre berømtheder inden fra programmeringens verden pryder han en liste over 20 geniale, sjove og tankevækkende citater på hjemmesiden Java Code Geeks .På listen suppleres han blandt andet af den danske opfinder af det objektorienterede programmeringssprog C++, Bjarne Stroustrup, som angiveligt har udtalt:»C gør det let for dig at skyde dig selv i foden, C++ gør det sværere, men når du endelig gør det, skyder du hele benet af.«En udtalelse, som kendere af de to maskinnære sprog nok vil nikke genkendende til. Eller om ikke andet så grine ad.Hvad angår antallet af linjer i et program, anser Microsoft-stifter Bill Gates det for at rigtigt dårligt udtryk for programmets trivsel og vækst:»At måle et programs fremdrift i antal kodelinjer svarer til at måle fremdriften af et flys konstruktion ud fra vægten«.En voldelig psykopatI samme boldgade optræder Ken Thompson, UNIX-godfather, med citatet:»En af mine mest produktive dage var, da jeg smed 1.000 linjer kode ud.«Også et par af koryfæerne inden for fri og open source-software kommer på banen. En af dem er Erik S. Raymond, forfatter til klassikeren 'The Cathedral and the Bazaar'.Han afsender følgende svada til dem, der går højt op i universitetsstudier:»Uddannelse inden for datalogi gør ingen til en dygtig programmør, ligesom det heller ikke gør nogen til en dygtig maler at studere pensler og farver.«Sidste citat i denne omgang bliver fra Martin Golding, der kommer med et godt råd omkring kodens læsbarhed og dokumentation.»Skriv altid din kode, som om ham, der ender med at vedligeholde den, er en voldelig psykopat, der ved, hvor du bor.«Du kan læse flere citater hos Java Code Geeks og er velkommen til at bidrage med flere af dine favoritter i debatten herunder.Via: Java Code Geeks
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2012-11-15
          &nbsp;·&nbsp; e3840b54
          &nbsp;·&nbsp; #39
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.848</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.624</kbd>
        </footer>
      </article>
      <article>
        <h4>Nyt charter for AI i retsvæsnet: Predictive justice er et vildledende begreb</h4>
        <div>
          Algoritmer er hastigt på vej ind i værktøjskassen hos domstole og politi - og med dem følger store etiske spørgsmål om retssikkerhed og fairness. Derfor er der brug for retningslinjer på området, vurderer Europarådet. I december vedtog organisationen med 47 medlemslande et charter for etisk anvendelse af AI i retsvæsnet.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2019-01-17
          &nbsp;·&nbsp; e70bc738
          &nbsp;·&nbsp; #40
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.908</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.918</kbd>
            <kbd data-tooltip="New technologies">L80_NEWTEC&nbsp;0.578</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.577</kbd>
        </footer>
      </article>
      <article>
        <h4>Grab'n Go: The Big Five and the canopy effect</h4>
        <div>
          Body På dette morgenmøde vil Duncan Stewart fra Deloitte Canada se på de kommende tendenser indenfor teknologi, medier og telekommunikation, som Deloitte har forudsat dem i rapporten &quot;TMT Predictions 2020&quot;.På mødet vil han blandt andet komme ind på privat 5G, edge AI-chips og meget andet.Begivenheden foregår på engelsk.
        </div>
        <footer>
          <em>Techmanagement.dk</em>
          &nbsp;·&nbsp; 2020-01-30
          &nbsp;·&nbsp; e78f3a49
          &nbsp;·&nbsp; #41
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.538</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.577</kbd>
        </footer>
      </article>
      <article>
        <h4>Hvad kan GPT-3 egentlig, og hvordan får man AI til at tænke abstrakt?</h4>
        <div>
            Vi ser tilbage på ugen der gik. Der er ingen ende i syne på hypen omkring GPT-3, den formidable sprogmodel, der skriver sætninger, som nemt kan forveksles med det, der kommer fra et menneskes hånd. Ugens eklatante fejlskud kommer fra den britiske avis The Guardian, der har sat GPT-3 til at skrive et debatindlæg - og sikke et resultat. Artiklen har gået sin sejrsgang på sociale medier, både hjemme og udenlands. Den vakte en del ståhej og bekymrede miner, nærmest som om 'Skynet' fra Terminator-filmene banker på døren. Det hele er dog fup og fidus, for når læseren rammer bunden af artiklen, afsløres det, at »GPT-3 produced eight different outputs, or essays. Each was unique, interesting and advanced a different argument. The Guardian could have just run one of the essays in its entirety. However, we chose instead to pick the best parts of each , in order to capture the different styles and registers of the AI.«  Og morskaben stopper ikke der, for avisen kan også berette, at »we cut lines and paragraphs, and rearranged the order of them in some places.«  Det er menneskelig intelligens, og ikke kunstig intelligens - og den var ikke gået i en Kaggle-konkurrence. Men det giver altså bonus på Twitter. GPT-3 fejler i faglig viden Fjollede avisartikler til trods, er GPT-3 dog en imponerende tekstmaskine - ingen tvivl om det. Men hvad kan den egentlig? Det spørgsmål har en række forskere fra blandt andet University of California i Berkeley, USA, stillet sig selv. I en nylig forskningsartikel med titlen ' Measuring Massive Multitask Language Understanding ' skaber forskerne en test, der dækker emner såsom elementær matematik, amerikansk historie, datalogi, jura m.v., for at måle sprogmodellers akkuratesse med mange opgaver. En nemmere læselig gennemgang af artiklens indhold kan findes hos mediet Synced Testen prøver at måle vilkårlig ægte-verdens-forståelse og på en gennemgribende måde at evaluere bredden og dybden af en models akademiske og faglige forståelse. Forskerne samlede et testsæt af 15.908 spørgsmål om 57 forskellige emner inden for naturvidenskab, teknik, humaniora og socialvidenskab. Testen blev udført på forskellige GPT-3-modeller samt modellen UnifiedQA. Resultaterne var ikke noget at råbe hurra for. Alle modeller fik dårligere resultat end ekspert-niveau. GPT-3 i gigantversionen klarede sig bedst, med et gennemsnit på 43,9 procent i accuracy, hvilket er omkring 20 point bedre end ved ren tilfældighed. Bedste resultat var 69 procent inden for amerikansk udenrigspolitik og værst var kemi på bachelor-niveau, hvor accuracy var tæt på, hvad der opnås med ren tilfældighed. Forskerne bekymres over, at »GPT-3 does not have an accurate sense of what it does or does not know since its average confidence can be up to 24% off from its actual accuracy.«  Det ligger i tråd med, hvad kritikere tidligere har sagt om modellen »All GPT-3 really has is a tunnel-vision understanding of how words relate to one another, it does not, from all those words, ever infer anything about the blooming, buzzing world.«  Videoklip kategoriseres abstrakt Og det er bare ikke så nemt, det der med at få modellerne til at se det store billede. Men forskere fra MIT har dog for nylig opnået resultater, når det handler om at få en model til at placere videoklip i abstrakte kategorier. Løsningen er en hybrid sprog-computer vision-model, der lige så godt som mennesker eller bedre kan finde klip, der passer sammen, og fjerne klip, der falder udenfor. Når modellen fik vist et klip af en hund, der gør, og et andet med en mand, der hyler, kunne modellen færdiggøre sættet med et klip af en baby, der græder, udvalgt blandt fem klip. Resultaterne kunne replikeres på to eksterne datasæt. »We show that you can build abstraction into an AI system to perform ordinary visual reasoning tasks close to a human level. A model that can recognize abstract events will give more accurate, logical predictions and be more useful for decision-making,«  siger MIT-forskeren Aude Oliva til universitetets nyhedsside AI kommer danske forbrugere til hjælp Vi slutter i den hjemlige andedam med en positiv nyhed: En ny it-løsning skal rydde ud i ulovlige mobilopladere eller farligt legetøj, når forbrugerne handler på nettet, skriver vores søstermedie Version2 . Det er ambitionen med det digitale værktøj ved navn Aime, som Sikkerhedsstyrelsen og Erhvervsministeriet har lanceret. Værktøjet bruger kunstig intelligens til at scanne billeder og tekst i netbutikkerne for at finde frem til ulovlige og farlige produkter. Det kan blandt andet foregå ved, at Aime kigger på et foto af et bestemt produkt, hvorefter den kategoriserer produktet som farligt eller ufarligt. Tidligere i år skærpede Folketinget reglerne på området, og derfor har myndighederne nu mulighed for at blokere hjemmesider, hvis de fortsætter med at sælge ulovlige produkter. På den måde kan myndighederne anmode domstolene om, at adgangen til en hjemmeside bliver blokeret for danske forbrugere, hvis AI-systemet finder et farligt produkt.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2020-09-11
          &nbsp;·&nbsp; e7e250a0
          &nbsp;·&nbsp; #42
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.883</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.551</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.551</kbd>
        </footer>
      </article>
      <article>
        <h4>Populært maskinlæringsmiljø i Python runder version et nul med kompilering til C++</h4>
        <div>
          Pytorch, som er et open source miljø til machine learning, har rundet version 1.0. Miljøet, som har Facebook som hovedsponsor, bygger på Python og Nvidias vektorsystem CUDA, der afvikles på grafikprocessorer. Pytorch er en konkurrent til Googles populære Tensorflow-miljø.Blandt nyhederne i den nye version er muligheden for at krydskompilere koden til C++ eller et andet effektivt sprog via en just-in-time-compiler. Det skriver Infoworld.Det er ikke bare Python, der kan oversættes til C++. Pytorch 1.0 kan byde på en helt ny mulighed, Torch Script, der ønsker at skabe en balance mellem Pythons nemme syntaks og kode, som kan afvikles med høj effektivitet. Torch Script er i sig selv en delmængde af Python.Oversættelsen til C++ kan ske på to måder: Enten ved at bruge Torch Script, der altså er beregnet til krydskompilering, eller ved at angive en metadata-decorator (annotation) til Python-kode. Det sidste vil dog ikke give så effektivt et resultat som med Torch Script.Ifølge dokumentationen gør Torch Script det muligt at træne modeller i Pytorch ved hjælp af de velkendte værktøjer og derefter eksportere modellen til et produktionsmiljø, hvor det ikke er en god ide at køre modeller som Python-programmer af hensyn til ydeevne og parallel afvikling.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2018-10-10
          &nbsp;·&nbsp; e6ee2b4b
          &nbsp;·&nbsp; #43
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.886</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.83</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.634</kbd>
        </footer>
      </article>
      <article>
        <h4>Hvornår er kunstig intelligens forklaret tilstrækkeligt?</h4>
        <div>
          Vi anvender kunstig intelligens på stadig flere områder, og beslutninger baseret på kunstig intelligens kommer tættere på at påvirke vores privatliv. I den forbindelse er der dukket mange begreber op, som explainable (forklarlig) kunstig intelligens, interpretable (fortolkbar) maskinlæring, transparent kunstig intelligens og intelligible (forståelig) kunstig intelligens. Vil du have fuld adgang til DataTech? DataTech skriver til dig, der arbejder professionelt med data og analytics. Vi giver dig inspirerende cases, nyheder og debat om alt fra Machine Learning-modeller til dataetik. Har du allerede et abonnement? Log ind Er dit prøveabonnement udløbet? Køb
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2020-06-09
          &nbsp;·&nbsp; e7be44e9
          &nbsp;·&nbsp; #44
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.835</kbd>
            <kbd data-tooltip="AI">L80_AI&nbsp;0.512</kbd>
        </footer>
      </article>
      <article>
        <h4>175 milliarder parametre og 45 TB træningsdata: Hvor god er GPT-3?</h4>
        <div>
          GPT-3 har læst hele internettet - nu kan det oversætte, programmere, skrive nyhedsartikler og meget mere. De er ikke perfekte, men computere bliver bedre og bedre til at beherske sprog, og den nye, enormt store sprogmodel GPT-3 imponerer med sin fine sproglige forståelse og færdigheder - ikke mindst udi det engelske sprog. Vil du have fuld adgang til DataTech? DataTech skriver til dig, der arbejder professionelt med data og analytics. Vi giver dig inspirerende cases, nyheder og debat om alt fra Machine Learning-modeller til dataetik. Har du allerede et abonnement? Log ind Er dit prøveabonnement udløbet? Køb
        </div>
        <footer>
          <em>Pro.ing.dk/Gridtech</em>
          &nbsp;·&nbsp; 2020-08-20
          &nbsp;·&nbsp; e7d85e25
          &nbsp;·&nbsp; #45
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.807</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.796</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.505</kbd>
        </footer>
      </article>
      <article>
        <h4>Machine learning gætter Version2's emneord med en træfsikkerhed på 98 pct.</h4>
        <div>
          Kunstig intelligens og machine learning kan lyde kryptisk. Her piller vi mystikken af og gennemgår en klassisk algoritme - med kode og hele baduljen.Kunstig intelligens lyder fancy, men for det meste handler det -bare- om matematiske modeller og masser af data. At finde på modellerne er nok ikke så nemt, men at bruge teknologien er ikke så svært eller mystisk, som det kan lyde.Her på Version2 har vi over frokosten diskuteret muligheden for at finde emneord med maskinlæring. Et emneord er et ord, der beskriver artiklens emne, såsom Databeskyttelsesloven, Sundheds-it, GDPR, Java, Ledelse, eller hvad det nu kunne være.Det er ikke fordi journalisternes opgave med at finde de reglementerede tre emneord pr. artikel efter endt skrivearbejde er uoverkommelig - men måske kunne kunstig intelligens alligevel give et bud?Det burde kunne lade sig gøre. Klassifikationsproblemer med naturlig tekst ender ofte med gode resultater, som er praktisk anvendelige. Det ved jeg fra et onlinekursus, et såkaldt MOOC, om processering af naturlig sprog, som jeg af nysgerrighed deltog i for en del år siden.Den klassiske tilgang benytter metoden, der går under navnet Naive Bayes. Den bygger på en nogenlunde simpel sandsynlighedsmodel og er nem at kode.Der findes bedre algoritmer til formålet, med navne som Support Vector Machines, K-Nearest Neighbor og neurale netværk, men de giver ikke nødvendigvis meget bedre resultater, siger sagkundskaben, og de er en del mere komplicerede. Naive Bayes kan vi klare med 250 linjers hjemmestrikket kode.Fra formel til kodeModellen, der ligger bag, forklarer vi i detaljer i en tilstødende artikel.Kort fortalt bygger den på en forhåbning om, at hyppigheden af ord i artikler med ét emneord, er forskellig fra hyppigheden i artikler med et andet emneord. Vi udregner en score, eller et estimat, for emneordene, med en smart formel. Det emneord, der opnår højest score, har vundet - det er det emne, som algoritmen gætter på, givet en artikel. Derefter tester vi, om det er praktisk anvendeligt, på et testsæt af artikler.For at gøre eksemplet nemmere, kigger vi bare på et enkelt emneord i det følgende, -sundheds-it-. Når vi skal fastslå, om en artikel handler om sundheds-it, betragter vi det som en dyst mellem to klasser: sundheds-it og -ikke-sundheds-it.-For at bruge formlen skal vi gøre noget ved ordene i artiklerne. Vi fjerner, råt for usødet, alle tegn som ikke er A til Å, og skriver det hele med små bogstaver.Nu skal vi bruge nogle tal.Vi skal kende antallet af artikler om sundheds-it i træningssættet, som består af de seneste 2673 artikler på Version2. (Vi startede med 3000, tog 300 fra til et testsæt vi skal bruge senere, og slettede derefter artikler uden emneord.)Ud fra det bestemmer vi sandsynligheden for, at en artikel har emneordet -sundheds-it-. Dem er der 107 af i træningssættet.Det giver sandsynligheden 107 / 2673.Sandsynligheden for -ikke-sundheds-it- bliver så 2566 / 2673.Vi skal også bruge antallet af unikke ord i alle artikler. Det er 54.423.Og så skal vi bruge antallet af ord i alle sundheds-it-artikler. Det tal er 59.590. Og det samme tal for ikke-sundheds-klassen: 1.176.278 stk.Så laver vi en tabel med ordhyppigheder for sundheds-it i træningssættet, og en anden for ikke-sundheds-it.Det kræver jo ikke ligefrem det store programmør-kørekort.Til slut laver vi to tilsvarende tabeller over såkaldte estimater, kaldet for log-P-hat - det er et -P-, med en hat over - som vi beregner på denne måde, i pseudokode, med hyppighedstabellen for sundheds-it:for (ord in hyppighedstabel):logPHat(ord) = log((hyppighedstabel(ord) + 1)/ (antalOrdISundhedsItKlassen + antalUnikkeOrdIAlleArtikler) ) sundhedsItEstimatTabel.put(ord, logPHat) og samme måde for ikke-sundheds-it.Vi testerTro det eller la- vær, men nu er vi allerede parat til at teste vores algoritme.Vi skal finde et estimat for sundheds-it, og et for ikke-sundheds-it.Testalgoritmen ser sådan ud, i pseudokode, givet en artikel:sundhedsItlogEstimat = log(artiklerOmSundhedsIt / antalArtikler) for (ord in artikel):logPHat = sundhedsItEstimatTabel.get(ord) if (logPHat == null):logPHat = log(1 / (antalOrdISundhedsItKlassen+ antalUnikkeOrdIAlleArtikler)) sundhedsItlogEstimat += logPHat(Forklaringen på algoritmen findes i næste artikel.)Vi laver samme beregning for ikke-sundheds-it-klassen. Det estimat, der er højest, har vundet.Vi tester ikke på en enkelt artikel, for det bliver vi ikke meget klogere af. I stedet har vi et testsæt på 297 artikler, som fortæller os, om vi kan bruge det til noget i praksis.Forvirringsmatrix på et højere planVi kværner de 297 uberørte artikler igennem testalgoritmen ovenfor. Resultatet er fire tal, kaldet en 'confusion matrix', eller forvirringsmatrix, i en skidt oversættelse.De fire tal er:Sande positive: Hvor mange gange udpegede testalgoritmen 'sundheds-it'rigtigtSande negative: Hvor mange gange pegede algoritmen rigtigt på 'ikke-sundheds-it'Falske positive: Algoritmen udpegede fejlagtigt en artikel som sundheds-itFalske negative: Algoritmen kunne ikke genkende en sundheds-it-artikel.Hvad var resultatet? Kære læser, du skal ikke efterlades i spænding. Det er:Sande positive: 7Sande negative: 285Falske positive: 0Falske negative: 5Der var 12 artikler om sundheds-it blandt de 297 test-artikler. Algoritmen fandt 7 af dem. Den udpegede korrekt alle 285 artikler, der ikke handlede om sundheds-it. Den pegede ikke på nogle forkerte. Der var 5 artikler om sundheds-it, den ikke kunne finde.Er det godt eller skidt? Det spørgsmål afhænger af, hvad brugsscenariet er.For at komme tættere på den problemstilling, udregner vi fire 'mål'- tal mellem 0 og 100% - som kan give os et bedre billede af resultatet.De fire mål er:Precision - hvor tit gættede algoritmen 'sundheds-it'rigtigt?Recall - hvor stor procentdel af sundheds-it-artiklerne fandt den?Accuracy - træfsikkerhedF1 - et slags gennemsnit af precision og recall, som kan bruges til at optimere algoritmen med.De udregnes således, hvor tp er sande positive, tn sande negative, fp falske positive og fn falske negative:precision = tp / (tp + fp) recall = tp / (tp + fn) accuracy = (tp + tn) / (tp + tn + fp + fn) f1 = 2 * (precision * recall) / (precision + recall)Med vores testsæt giver det:Precision: 100%Recall: 58%Accuracy: 98%F1: 74%Algoritmen var knald-god til at ramme plet på sundheds-it-artiklerne. Den fandt 58% af sundheds-it-artiklerne i testsættet. Træfsikkerheden var sublim (men det er ikke så praktisk anvendeligt), og f1-målet var ikke dårligt, bedømt på tidligere erfaringer.I en kommende artikel kigger vi på, hvad det egentlig betyder, i forhold til vores formål, og hvordan vi kan 'tune'algoritmen til at give bedre resultater, specielt i forhold til f1-målet.Download kodeeksempel, træningssæt og testsætDet ville fylde for meget at gengive den Java-kode, vi har brugt i artiklen. Så den kan downloades her (Google Drive kan sige nogle fjollede ting undervejs, men bare tryk 'download.').Eksemplet indeholder det samme trænings- og testsæt, der gennemgås her i artiklen, med den lille krølle, at ordene i artiklerne er randomiseret. På den måde er der ikke nogen i Mediehuset Ingeniøren, der behøver ligge vågen om natten og tænke på ophavsret osv. Algoritmen er ligeglad med rækkefølgen af ordene, så det gør ingen forskel for eksemplet.Koden er skrevet så eksemplet er nemt at forstå, og er ikke optimeret. Der er tre hardcodede filstier, der kan tilrettes, hvis der er bøvl. Det er kommenteret i kildeteksten.Modellen bag algoritmen gennemgår vi i den næste artikel.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2018-03-02
          &nbsp;·&nbsp; e6a5a13b
          &nbsp;·&nbsp; #46
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.974</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.948</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.6</kbd>
        </footer>
      </article>
      <article>
        <h4>Mit første forsøg med maskinlæring: Kan algoritmer finde emneord til Version2-artikler?</h4>
        <div>
          Machine learning-disciplinen topic modeling kan finde frem til emner, der knytter tekster sammen fra en stor tekstsamling. Som eksempelvis Version2's artikeldatabase.Gartner placerede for nylig Machine Learning på toppen af hype-kurven, altså et signal fra analytikerne om, at nu har vi pustet forventningerne til algoritmerne op til bristepunktet og skal indstille os på at falde ned i skuffelsens dybe afgrund.Men det afholder ikke mig fra at prøve at køre maskinlæring i stilling til at automatisere én af vore daglige udfordringer på Version2-redaktionen.Som journalister prøver vi at markere, hvad vores artikler handler om ved at tilknytte nogle udvalgte emneord til hver artikel, vi lægger ind i systemet. Det er en manuel proces, der er sårbar over for misforståelser eller forglemmelser, der i sidste ende giver os dårlige metadata om artiklernes indhold og dermed indbyrdes tilknytning.Eller lidt mere konkret: Der er mere end én journalist på redaktionen, der har brugt emneordet 'it-politik' på artikler om politiske beslutninger om it, selvom emneordet egentligt skulle dække over artikler, der handler om firmaers interne regler for brug af it-systemer og -udstyr.Når en journalist lægger en artikel ind i vores CMS, så skal der vælges et antal relevante emneord ud fra en liste. Et menneske kan begå fejl i denne udvælgelse, og det er en proces, der skal gentages mange gange dagligt. Derfor tænkte jeg, at det måtte være oplagt at afprøve topic modeling eller topic classification.Da jeg i første omgang er interesseret i at afprøve teknikken på vores artikler, så ville jeg helst ikke ud i at skulle skrive alt for mange linjers Python for at få et resultat. Derfor fandt jeg frem til open source-værktøjet Mallet, som er udviklet af University of Massachusetts. Det er fra 2008, men virker stadig godt nok til at afprøve konceptet.Mallet benytter sig af en algoritmetype kaldet Latent Dirichlet allocation, som meget groft skitseret bygger på antagelsen om, at når man skriver en tekst om et emne, så vil man trække på en pulje af ord, der er fælles for tekster om dette emne. Udfordringen er, at en tekst også vil indeholde ord fra de puljer, der udgør andre emner, ligesom de enkelte ord kan tilhøre flere forskellige emner.Derfor er der flere varianter af LDA-metoden, og Mallet implementerer flere af dem. Fordelen for mit lille projekt er, at jeg ikke skal eksperimentere med forskellige implementeringer af algoritmer, men blot skal fodre Mallet med et datasæt og justere på enkelte parametre.For at lave en topic model eller emnemodel så skal algoritmen have et datasæt, som den kan beregne sandsynlige emner ud fra. Her kunne jeg have brugt vores artikeldatabase, men jeg er mere til at arbejde med filer end med databaser, så selvom jeg havde fået et udtræk fra vores database, valgte jeg at fremstille et datasæt på et andet grundlag.Jeg havde lidt over 2.400 af mine egne artikler fra de sidste fem år liggende i Word Docx-format, som jeg kunne konvertere i ét hug til rene tekstfiler ved hjælp af det lille Perl-værktøj docx2txt. Et lille Bash-script senere var mellemrummene i filnavnene også fjernet.Dansk ordlisteDermed havde jeg mit tekstkorpus. Næste udfordring var, at Mallet ikke understøtter danske tekster. Problemet med topic modeling er, at mange af de ord der udgør en tekst, ikke er relevante for tekstens betydning. De fleste adverbier og flere verber optræder i næsten alle tekster, men siger ikke noget om, hvad teksten handler om.Se blot på sætningen i sig selv:De fleste adverbier og flere verber optræder i næsten alle tekster, men siger ikke noget om, hvad teksten handler om.Ord som 'de, fleste, og, flere, i, næsten, alle, men, siger, ikke, noget, om, hvad, om' er ikke unikke for en sætning om tekstanalyse. Derfor kan man filtrere dem fra, når man indlæser sit tekstkorpus i Mallet.Det gør Mallet ved hjælp af ordlister, men der var ingen dansk ordliste. Så jeg måtte lave min egen. Det er heldigvis ikke en uoverkommelig opgave for en journalist, men selvom en liste over danske adverbier fra Sproget.dk var nyttig, så er udfordringen, at der kan være visse ord, der i vores artikler kun bruges til nogle bestemte emner. Ord som 'nyt' eller 'større' kunne være vigtige at beholde.For eksempel kan jeg ikke være sikker på, at verbet 'skrive' skal filtreres fra på forhånd, for det kunne være en vigtig brik i at identificere artikler, der handler om at skrive kode.Derfor var min ordliste i første forsøg på cirka 250 ord, men er på nuværende tidspunkt på 354 ord. Og ja, når jeg er rimelig sikker på, at det er en god liste, så vil jeg tilbyde den til Mallet-projektet gennem Github, så andre kan bruge den.Selvom teksterne bliver filtreret for 354 ord, så får man stadig et interessant output fra algoritmen, som finder de resterende almindelige ord og samler dem i et emne for sig selv. I min seneste kørsel har jeg eksempelvis fået følgende ordsamling som ét emne:når gode svært ser set ting gang dag går holde folk faktisk tid virker først bedre par finde vide flesteDer er et par oplagte kandidater at tilføje til min ordliste, men helt slipper jeg næppe for at få sådan en falsk positiv på emnelisten.Mit tekstkorpus lider også af, at det er mine rå artikler, hvor der til tider er notater fra interviews på engelsk. Derfor har jeg også ved den seneste kørsel en falsk positiv, der til gengæld er ganske ferm til at genkende de engelske tekster, der skiller sig ud fra de danske:the and you that with can are not your new will but has more device time chris code from thisSkal min model bruges i vores daglige produktion, så skal den nok trænes på et tekstkorpus, hvor der er ryddet op.Et udsnit af den repræsentation af tekstkorpuset, som Mallet skaber, når man indlæser tekstfilerne.EmnerneMallet opbygger først en repræsentation af et tekstkorpus, som man derefter kan prøve at opbygge en emnemodel ud fra. Repræsentationen består af tekstbidder, og én af udfordringerne med denne teknik er, at der indgår en vis tilfældighed i modelkørslerne. Den ene kørsel kan altså give en knivskarp definition af et generelt emne som supercomputere, mens den næste kørsel tilfældigvis lægger meget vægt på en serie artikler om lige netop DMI's supercomputer.Der skal altså efterfølgende arbejdes med at få bygget den bedste model til lige netop dét, jeg gerne vil have Mallet til at hjælpe mig med.Et emne defineres som sagt som en samling af ord, der med en vis sandsynlighed er fælles for tekster, der handler om det givne emne. I kørslerne på mit tekstkorpus gav det et par præcise definitioner af nogle konkrete sager:amerikanske usa nsa data adgang overvågning oplysninger internettet edward fbi new snowden række the udleveret york amerikansk efterretningstjeneste myndigheder efterretningstjenesten adgang sagen csc danske sager oplysninger politiet rigspolitiet angiveligt version systemer sag mainframe misbrug hackerne personer forbindelse dansk tale medarbejder skat projektet system systemet proask millioner efi kroner arbejdsskadestyrelsen styrelsen skats nyt projekt offentlige it-system drift forsinket konsulenter it-projekter consultingDet er ret tydeligt, at algoritmen her har fundet sagerne om Edward Snowden og NSA, hackingen af CSC og Skats EFI-skandale. Den har også fundet sig selv i form af mine artikler om maskinlæring:data intelligens kunstig finde netværk forskerne mennesker maskinlæring algoritmer hjælpe machine algoritmerne forskere big hjælp bedre neurale analyse watson læreProblemet ved at bruge et færdigstøbt, om end ikke specielt udførligt dokumenteret, værktøj som Mallet er, at effekten af at skrue på de forskellige parametre kun kan findes ved at eksperimentere. Det er eksempelvis svært at vurdere, hvor stor en forbedring jeg får ud af 4.000 iterationer i stedet for 1.000 iterationer ved en kørsel.En anden udfordring er, at det ikke er en eksakt videnskab. Der er tilfældighed involveret i algoritmerne, og samtidig vil resultaterne også afhænge af, hvor mange emner, der er tilstede i mit tekstkorpus. Det er eksempelvis ret tydeligt, at ved 50 emner i stedet for 20, så træder visse emner mere tydeligt frem, men det giver også et par ekstra falske positiver.Et udsnit af de emner, Mallet gav ved en kørsel på 4.000 iterationer og 50 topics. Hvert topic består af en serie af op til 20 ord med de mest betydningsfulde først. Der er også angivet, hvor stor en andel af tekstkorpuset, emnet passer til.Næste skridtDen næste opgave bliver at træne en model på et tekstkorpus sammensat ud fra Version2's artikeldatabase. Det giver både en bredere dækning af forskellige emner, ligesom et emne kan være beskrevet af forskellige journalister med forskelligt sprog.Det vil medføre en ny oprydningsopgave. Der vil være ord, som skal fjernes, som ikke dukker op til overfladen i mine tekster. Til gengæld vil notater være fjernet fra artiklerne, så der kun optræder relevante engelske ord i artiklerne.Men vores artikler indeholder også links og formatering, som kan vise sig at være en støjkilde. Det er en anden opgave - men bestemt også interessant - at se på links mellem tekster. At et ord optræder i en mellemrubrik kunne også være værdifuld information, men Mallet benytter ikke tekstanalyse, der ser på hele sætninger, så det er ikke muligt at bruge denne information med Mallet.Jeg havde mildt sagt lidt ballade med at få skruet det helt rigtige Regex-udtryk sammen til opbygningen af mit tekstkorpus. Mallet giver mulighed for at anvende et Regex-udtryk ved dataimporten, men det gav bedre resultat blot at lade Mallet benytte den Regex-filtrering, der er kodet ind som standard.Der er som sagt ellers tekstelementer, der burde fjernes. Vi bruger Markdown i vores Drupal-system, hvor ## eksempelvis markerer en h2-mellemrubrik. Det er ikke helt let at få fjernet Markdown fra artiklerne, uden at få problemer for eksempelvis C#, der kunne være et nøgleord.Løsningen bliver nok at lave et script eller to, der kan polere de rå artikeltekster, inden de bliver fodret til Mallet. Så slipper jeg for at skulle samle al oprydningen i ét Regex-udtryk.Ud over en liste over ord samt den endelige model, algoritmen kan genbruge, så leverer Mallet også som output en liste over teksterne, og hvor godt de passer på de forskellige emner. Det kan bruges til at lave en trimning af mit tekstkorpus, så tekster, der på én eller anden måde er usædvanlige, kan pilles ud.Det endelig mål er at få samlet en model, der kan give op til tre nogenlunde præcise bud på emner, når den får præsenteret en ny tekst. Det vil vi kunne bruge til automatisk at tilføje emneord til ny og gamle artikler, og det vil også kunne bruges til at lave automatiske samlinger af artikler inden for et sagsforløb.Lige nu har vi eksempelvis et tema, der samler artiklerne i CSC-hackersagen, men vi har ikke et tema for Skats it-problemer. Det vil være oplagt at bruge modellen til at finde og samle disse artikler automatisk i stedet for en manuel proces.Det er vigtigt at understrege, at selvom det er muligt at identificere et emne i form af en mængde af ord, så vil det stadig være et menneske, der skal finde en passende etiket til emnet. Se eksempelvis på et emne, der kunne kaldes 'streaming' eller lidt mere 90'er-agtigt 'digitale medier':netflix film indhold the tjenester indholdet spotify streaming danske tjenesten dansk bay youtube amerikanske danmark netneutralitet filmen pirate tv-serier adgangMan kan altså ikke regne med, at det første ord er en god etiket. Så der skal menneskelige øjne på, og helst én, der kender tekstkorpus. Algoritmen kan med andre ord udføre de mange gentagelser, der skulle til at sætte etiketten på alle relevante artikler, men ikke vurdere, hvad emnet handler om.En anden udfordring er, at emner kan dukke op og forsvinde over tid. Det kan blive et problem for opbygningen af modellen som en generel model til hele vores tekstkorpus. Ord som 'ssd' og 'harddisk' kan jeg eksempelvis se, giver modellen problemer med at skelne mellem to emner:Det første var det hotte emne om ssd'er for fem år siden, hvor jeg skrev om, hvad ssd'er kunne gøre for pc'en. Det andet er i dag, hvor ssd'er i pc'er er så meget en selvfølge, at jeg mest skriver om dem i forbindelse med storage i datacentre. Der er overlap, men det er nok værd at skelne mellem de to.Det mest overraskendeJeg er mest overrasket over, hvor præcis algoritmen er til at identificere meget konkrete sager, som NSA-afsløringerne eller EFI-skandalen, men også kan ramme ret præcist på en bestemt genre af artikler.Det her ligner eksempelvis resultatet af, at algoritmen har læst mine blogindlæg, der var en del af korpus, og har identificeret blogindlæggene som et særskilt emne:nørder kvinder trine klokken commodore generation nørd sokker ascii kage lad kaffe gengæld tegnsæt printer unge fest værre the tegnBloggen handler om nørdkultur, og algoritmen har åbenbart særligt bidt mærke i mit svar til Trine Bramsen om de famøse tennissokker. Et svar, der aldrig nåede længere end til en kladde og aldrig blev udgivet. Så dér - en lille godbid af aldrig udgivet materiale for dem, der har læst så langt.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2016-08-26
          &nbsp;·&nbsp; e5db20cb
          &nbsp;·&nbsp; #47
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.853</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.697</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.668</kbd>
        </footer>
      </article>
      <article>
        <h4>Microsoft køber BrightBytes DataSense</h4>
        <div>
          Det oplyser Microsoft selv i en pressemeddelelse.»We want to help every school find this same success, using data to gain insights and tailor their learning experience,« skriver Microsoft i pressemeddelelsen.BrightBytes, der er en virksomhed, der arbejder med undervisnings datanalyse har desuden udviklet en platform, der bruger machine learning og predictive analytics.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2019-02-05
          &nbsp;·&nbsp; e711b4bf
          &nbsp;·&nbsp; #48
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.554</kbd>
            <kbd data-tooltip="AI &amp; innovation">L05_INNOAI&nbsp;0.544</kbd>
        </footer>
      </article>
      <article>
        <h4>Kunstig intelligens skal redde det bornholmske sprog fra at uddø</h4>
        <div>
          Danske forskere er i færd med at udvikle sprogteknologiske værktøj, der skal puste liv i et ellers dødsdømt sprog - nemlig bornholmsk. Det skriver Videnskab.dk Alex Speed Kjeldsen, der er adjunkt Institut for Nordiske Studier og Sprogvidenskab på Københavns Universitet, har sammen med Leon Derczynski, adjunkt på IT Universitetet i København og medlem af forskningsgruppen Natural Language Processing, udviklet en slags Google Translate, der kan oversætte fra bornholmsk til dansk og omvendt. »Tanken bag projektet er, at sprog i vores digitale tidsalder vil forsvinde helt, hvis ikke man kan arbejde med dem digitalt,«  forklarer Alex Speed Kjeldsen til Videnskab.dk.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2019-11-07
          &nbsp;·&nbsp; e76df4f6
          &nbsp;·&nbsp; #49
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.899</kbd>
            <kbd data-tooltip="AI &amp; innovation">L05_INNOAI&nbsp;0.568</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.509</kbd>
        </footer>
      </article>
    </main>
  </body>
</html>
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Infomedia Articles</title>
    <style type="text/css">
/*!
 * Pico.css v1.3.3 (https://picocss.com)
 * Copyright 2019-2021 - Licensed under MIT
 */:root{--font-family:system-ui,-apple-system,"Segoe UI","Roboto","Ubuntu","Cantarell","Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";--line-height:1.5;--font-weight:400;--font-size:16px;--border-radius:.25rem;--border-width:1px;--outline-width:3px;--spacing:1rem;--typography-spacing-vertical:1.5rem;--block-spacing-vertical:calc(var(--spacing) * 2);--block-spacing-horizontal:var(--spacing);--grid-spacing-vertical:0;--grid-spacing-horizontal:var(--spacing);--form-element-spacing-vertical:.75rem;--form-element-spacing-horizontal:1rem;--transition:.2s ease-in-out}@media (min-width:576px){:root{--font-size:17px}}@media (min-width:768px){:root{--font-size:18px}}@media (min-width:992px){:root{--font-size:19px}}@media (min-width:1200px){:root{--font-size:20px}}@media (min-width:576px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 2.5)}}@media (min-width:768px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 3)}}@media (min-width:992px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 3.5)}}@media (min-width:1200px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 4)}}@media (min-width:576px){article{--block-spacing-horizontal:calc(var(--spacing) * 1.25)}}@media (min-width:768px){article{--block-spacing-horizontal:calc(var(--spacing) * 1.5)}}@media (min-width:992px){article{--block-spacing-horizontal:calc(var(--spacing) * 1.75)}}@media (min-width:1200px){article{--block-spacing-horizontal:calc(var(--spacing) * 2)}}a{--text-decoration:none}a.contrast,a.secondary{--text-decoration:underline}small{--font-size:0.875em}h1,h2,h3,h4,h5,h6{--font-weight:700}h1{--font-size:2rem;--typography-spacing-vertical:3rem}h2{--font-size:1.75rem;--typography-spacing-vertical:2.625rem}h3{--font-size:1.5rem;--typography-spacing-vertical:2.25rem}h4{--font-size:1.25rem;--typography-spacing-vertical:1.874rem}h5{--font-size:1.125rem;--typography-spacing-vertical:1.6875rem}[type=checkbox],[type=radio]{--border-width:2px}[type=checkbox][role=switch]{--border-width:3px}thead td,thead th{--border-width:3px}:not(thead)>*>td{--font-size:0.875em}code,kbd,pre,samp{--font-family:"Menlo","Consolas","Roboto Mono","Ubuntu Monospace","Noto Mono","Oxygen Mono","Liberation Mono",monospace,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji"}kbd{--font-weight:bolder}:root:not([data-theme=dark]),[data-theme=light]{color-scheme:light;--background-color:#FFF;--color:#415462;--h1-color:#1b2832;--h2-color:#23333e;--h3-color:#2c3d49;--h4-color:#374956;--h5-color:#415462;--h6-color:#4d606d;--muted-color:#73828c;--muted-border-color:#edf0f3;--primary:#1095c1;--primary-hover:#08769b;--primary-focus:rgba(16,149,193,0.125);--primary-inverse:#FFF;--secondary:#596b78;--secondary-hover:#415462;--secondary-focus:rgba(89,107,120,0.125);--secondary-inverse:#FFF;--contrast:#1b2832;--contrast-hover:#000;--contrast-focus:rgba(89,107,120,0.125);--contrast-inverse:#FFF;--mark-background-color:#fff2ca;--mark-color:#543a25;--ins-color:#388E3C;--del-color:#C62828;--blockquote-border-color:var(--muted-border-color);--blockquote-footer-color:var(--muted-color);--button-box-shadow:0 0 0 rgba(0,0,0,0);--button-hover-box-shadow:0 0 0 rgba(0,0,0,0);--form-element-background-color:transparent;--form-element-border-color:#a2afb9;--form-element-color:var(--color);--form-element-placeholder-color:var(--muted-color);--form-element-active-background-color:transparent;--form-element-active-border-color:var(--primary);--form-element-focus-color:var(--primary-focus);--form-element-disabled-background-color:#d5dce2;--form-element-disabled-border-color:#a2afb9;--form-element-disabled-opacity:.5;--form-element-invalid-border-color:#C62828;--form-element-invalid-active-border-color:#B71C1C;--form-element-valid-border-color:#388E3C;--form-element-valid-active-border-color:#2E7D32;--switch-background-color:#bbc6ce;--switch-color:var(--primary-inverse);--switch-checked-background-color:var(--primary);--range-border-color:#d5dce2;--range-active-border-color:#bbc6ce;--range-thumb-border-color:var(--background-color);--range-thumb-color:var(--secondary);--range-thumb-hover-color:var(--secondary-hover);--range-thumb-active-color:var(--primary);--table-border-color:var(--muted-border-color);--table-row-stripped-background-color:#f6f8f9;--code-background-color:#edf0f3;--code-color:var(--muted-color);--code-kbd-background-color:var(--contrast);--code-kbd-color:var(--contrast-inverse);--code-tag-color:#b34d80;--code-property-color:#3d888f;--code-value-color:#998866;--code-comment-color:#a2afb9;--accordion-border-color:var(--muted-border-color);--accordion-close-summary-color:var(--color);--accordion-open-summary-color:var(--muted-color);--card-background-color:var(--background-color);--card-border-color:var(--muted-border-color);--card-box-shadow:0 0.125rem 1rem rgba(27,40,50,0.04),0 0.125rem 2rem rgba(27,40,50,0.08),0 0 0 0.0625rem rgba(27,40,50,0.024);--card-sectionning-background-color:#fafbfc;--progress-background-color:#d5dce2;--progress-color:var(--primary);--loading-spinner-opacity:.5;--tooltip-background-color:var(--contrast);--tooltip-color:var(--contrast-inverse);--icon-chevron:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");--icon-date:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");--icon-time:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");--icon-search:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");--icon-checkbox:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-minus:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");--icon-valid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(56, 142, 60, 0.999)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-invalid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(198, 40, 40, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E")}@media only screen and (prefers-color-scheme:dark){:root:not([data-theme=light]){color-scheme:dark;--background-color:#11191f;--color:#bbc6ce;--h1-color:#edf0f3;--h2-color:#e1e6ea;--h3-color:#d5dce2;--h4-color:#c8d1d8;--h5-color:#bbc6ce;--h6-color:#aebbc3;--muted-color:#73828c;--muted-border-color:#1f2d38;--primary:#1095c1;--primary-hover:#1ab3e6;--primary-focus:rgba(16,149,193,0.25);--primary-inverse:#FFF;--secondary:#596b78;--secondary-hover:#73828c;--secondary-focus:rgba(115,130,140,0.25);--secondary-inverse:#FFF;--contrast:#edf0f3;--contrast-hover:#FFF;--contrast-focus:rgba(115,130,140,0.25);--contrast-inverse:#000;--mark-background-color:#d0c284;--mark-color:#11191f;--ins-color:#388E3C;--del-color:#C62828;--blockquote-border-color:var(--muted-border-color);--blockquote-footer-color:var(--muted-color);--button-box-shadow:0 0 0 rgba(0,0,0,0);--button-hover-box-shadow:0 0 0 rgba(0,0,0,0);--form-element-background-color:#11191f;--form-element-border-color:#374956;--form-element-color:var(--color);--form-element-placeholder-color:var(--muted-color);--form-element-active-background-color:var(--form-element-background-color);--form-element-active-border-color:var(--primary);--form-element-focus-color:var(--primary-focus);--form-element-disabled-background-color:#2c3d49;--form-element-disabled-border-color:#415462;--form-element-disabled-opacity:.5;--form-element-invalid-border-color:#B71C1C;--form-element-invalid-active-border-color:#C62828;--form-element-valid-border-color:#2E7D32;--form-element-valid-active-border-color:#388E3C;--switch-background-color:#374956;--switch-color:var(--primary-inverse);--switch-checked-background-color:var(--primary);--range-border-color:#23333e;--range-active-border-color:#2c3d49;--range-thumb-border-color:var(--background-color);--range-thumb-color:var(--secondary);--range-thumb-hover-color:var(--secondary-hover);--range-thumb-active-color:var(--primary);--table-border-color:var(--muted-border-color);--table-row-stripped-background-color:rgba(115,130,140,0.05);--code-background-color:#17232c;--code-color:var(--muted-color);--code-kbd-background-color:var(--contrast);--code-kbd-color:var(--contrast-inverse);--code-tag-color:#a65980;--code-property-color:#599fa6;--code-value-color:#8c8473;--code-comment-color:#4d606d;--accordion-border-color:var(--muted-border-color);--accordion-active-summary-color:var(--primary);--accordion-close-summary-color:var(--color);--accordion-open-summary-color:var(--muted-color);--card-background-color:#141e25;--card-border-color:#11191f;--card-box-shadow:0 0.125rem 1rem rgba(0,0,0,0.06),0 0.125rem 2rem rgba(0,0,0,0.12),0 0 0 0.0625rem rgba(0,0,0,0.036);--card-sectionning-background-color:#17232c;--progress-background-color:#23333e;--progress-color:var(--primary);--loading-spinner-opacity:.5;--tooltip-background-color:var(--contrast);--tooltip-color:var(--contrast-inverse);--icon-chevron:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");--icon-date:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");--icon-time:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");--icon-search:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");--icon-checkbox:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-minus:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");--icon-valid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(46, 125, 50, 0.999)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-invalid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(183, 28, 28, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E")}}[data-theme=dark]{color-scheme:dark;--background-color:#11191f;--color:#bbc6ce;--h1-color:#edf0f3;--h2-color:#e1e6ea;--h3-color:#d5dce2;--h4-color:#c8d1d8;--h5-color:#bbc6ce;--h6-color:#aebbc3;--muted-color:#73828c;--muted-border-color:#1f2d38;--primary:#1095c1;--primary-hover:#1ab3e6;--primary-focus:rgba(16,149,193,0.25);--primary-inverse:#FFF;--secondary:#596b78;--secondary-hover:#73828c;--secondary-focus:rgba(115,130,140,0.25);--secondary-inverse:#FFF;--contrast:#edf0f3;--contrast-hover:#FFF;--contrast-focus:rgba(115,130,140,0.25);--contrast-inverse:#000;--mark-background-color:#d0c284;--mark-color:#11191f;--ins-color:#388E3C;--del-color:#C62828;--blockquote-border-color:var(--muted-border-color);--blockquote-footer-color:var(--muted-color);--button-box-shadow:0 0 0 rgba(0,0,0,0);--button-hover-box-shadow:0 0 0 rgba(0,0,0,0);--form-element-background-color:#11191f;--form-element-border-color:#374956;--form-element-color:var(--color);--form-element-placeholder-color:var(--muted-color);--form-element-active-background-color:var(--form-element-background-color);--form-element-active-border-color:var(--primary);--form-element-focus-color:var(--primary-focus);--form-element-disabled-background-color:#2c3d49;--form-element-disabled-border-color:#415462;--form-element-disabled-opacity:.5;--form-element-invalid-border-color:#B71C1C;--form-element-invalid-active-border-color:#C62828;--form-element-valid-border-color:#2E7D32;--form-element-valid-active-border-color:#388E3C;--switch-background-color:#374956;--switch-color:var(--primary-inverse);--switch-checked-background-color:var(--primary);--range-border-color:#23333e;--range-active-border-color:#2c3d49;--range-thumb-border-color:var(--background-color);--range-thumb-color:var(--secondary);--range-thumb-hover-color:var(--secondary-hover);--range-thumb-active-color:var(--primary);--table-border-color:var(--muted-border-color);--table-row-stripped-background-color:rgba(115,130,140,0.05);--code-background-color:#17232c;--code-color:var(--muted-color);--code-kbd-background-color:var(--contrast);--code-kbd-color:var(--contrast-inverse);--code-tag-color:#a65980;--code-property-color:#599fa6;--code-value-color:#8c8473;--code-comment-color:#4d606d;--accordion-border-color:var(--muted-border-color);--accordion-active-summary-color:var(--primary);--accordion-close-summary-color:var(--color);--accordion-open-summary-color:var(--muted-color);--card-background-color:#141e25;--card-border-color:#11191f;--card-box-shadow:0 0.125rem 1rem rgba(0,0,0,0.06),0 0.125rem 2rem rgba(0,0,0,0.12),0 0 0 0.0625rem rgba(0,0,0,0.036);--card-sectionning-background-color:#17232c;--progress-background-color:#23333e;--progress-color:var(--primary);--loading-spinner-opacity:.5;--tooltip-background-color:var(--contrast);--tooltip-color:var(--contrast-inverse);--icon-chevron:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");--icon-date:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");--icon-time:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");--icon-search:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");--icon-checkbox:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-minus:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");--icon-valid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(46, 125, 50, 0.999)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-invalid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(183, 28, 28, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E")}*,:after,:before{box-sizing:border-box}:after,:before{text-decoration:inherit;vertical-align:inherit}html{-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:rgba(0,0,0,0);-moz-tab-size:4;-ms-text-size-adjust:100%;background-color:var(--background-color);color:var(--color);font-family:var(--font-family);font-size:var(--font-size);font-weight:var(--font-weight);line-height:var(--line-height);text-rendering:optimizeLegibility;cursor:default}main{display:block}body{width:100%;margin:0}body>footer,body>header,body>main{width:100%;margin-right:auto;margin-left:auto;padding:var(--block-spacing-vertical) 0}.container,.container-fluid{width:100%;margin-right:auto;margin-left:auto;padding-right:var(--spacing);padding-left:var(--spacing)}@media (min-width:576px){.container{max-width:510px;padding-right:0;padding-left:0}}@media (min-width:768px){.container{max-width:700px}}@media (min-width:992px){.container{max-width:920px}}@media (min-width:1200px){.container{max-width:1130px}}section{margin-bottom:var(--block-spacing-vertical)}.grid{grid-column-gap:var(--grid-spacing-horizontal);grid-row-gap:var(--grid-spacing-vertical);display:grid;grid-template-columns:1fr;margin:0}@media (min-width:992px){.grid{grid-template-columns:repeat(auto-fit,minmax(0%,1fr))}}.grid>*{min-width:0}figure{display:block;margin:0;padding:0;overflow-x:auto}figure figcaption{padding:calc(var(--spacing) / 2) 0;color:var(--muted-color)}b,strong{font-weight:bolder}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-0.25em}sup{top:-0.5em}dl dl,dl ol,dl ul,ol dl,ul dl{margin:0}ol ol,ol ul,ul ol,ul ul{margin:0}address,blockquote,dl,figure,form,ol,p,pre,table,ul{margin-top:0;margin-bottom:var(--typography-spacing-vertical);color:var(--color);font-size:1rem;font-style:normal}a{--color:var(--primary);--background-color:transparent;outline:none;background-color:var(--background-color);color:var(--color);text-decoration:var(--text-decoration);transition:background-color var(--transition),color var(--transition),text-decoration var(--transition),box-shadow var(--transition)}a:active,a:focus,a:hover{--color:var(--primary-hover);--text-decoration:underline}a:focus{--background-color:var(--primary-focus)}a.secondary{--color:var(--secondary)}a.secondary:active,a.secondary:focus,a.secondary:hover{--color:var(--secondary-hover)}a.secondary:focus{--background-color:var(--secondary-focus)}a.contrast{--color:var(--contrast)}a.contrast:active,a.contrast:focus,a.contrast:hover{--color:var(--contrast-hover)}a.contrast:focus{--background-color:var(--contrast-focus)}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:var(--typography-spacing-vertical);color:var(--color);font-family:var(--font-family);font-size:var(--font-size);font-weight:var(--font-weight)}h1{--color:var(--h1-color)}h2{--color:var(--h2-color)}h3{--color:var(--h3-color)}h4{--color:var(--h4-color)}h5{--color:var(--h5-color)}h6{--color:var(--h6-color)}address~h1,address~h2,address~h3,address~h4,address~h5,address~h6,blockquote~h1,blockquote~h2,blockquote~h3,blockquote~h4,blockquote~h5,blockquote~h6,dl~h1,dl~h2,dl~h3,dl~h4,dl~h5,dl~h6,figure~h1,figure~h2,figure~h3,figure~h4,figure~h5,figure~h6,form~h1,form~h2,form~h3,form~h4,form~h5,form~h6,ol~h1,ol~h2,ol~h3,ol~h4,ol~h5,ol~h6,pre~h1,pre~h2,pre~h3,pre~h4,pre~h5,pre~h6,p~h1,p~h2,p~h3,p~h4,p~h5,p~h6,table~h1,table~h2,table~h3,table~h4,table~h5,table~h6,ul~h1,ul~h2,ul~h3,ul~h4,ul~h5,ul~h6{margin-top:var(--typography-spacing-vertical)}hgroup{margin-bottom:var(--typography-spacing-vertical)}hgroup>*{margin-bottom:0}hgroup>:last-child{--color:var(--muted-color);--font-weight:unset;font-family:unset;font-size:1rem}p{margin-bottom:var(--typography-spacing-vertical)}small{font-size:var(--font-size)}ol,ul{padding-left:var(--spacing)}ol li,ul li{margin-bottom:calc(var(--typography-spacing-vertical) / 4)}ul li{list-style:square}mark{padding:.125rem .25rem;background-color:var(--mark-background-color);color:var(--mark-color);vertical-align:middle}blockquote{display:block;margin:var(--typography-spacing-vertical) 0;padding:var(--spacing);border-left:0.25rem solid var(--blockquote-border-color)}blockquote footer{margin-top:calc(var(--typography-spacing-vertical) / 2);color:var(--blockquote-footer-color)}abbr[title]{border-bottom:1px dotted;text-decoration:none;cursor:help}ins{color:var(--ins-color);text-decoration:none}del{color:var(--del-color)}::selection{background-color:var(--primary-focus)}audio,canvas,iframe,img,svg,video{vertical-align:middle}audio,video{display:inline-block}audio:not([controls]){display:none;height:0}iframe{border-style:none}img{max-width:100%;height:auto;border-style:none}svg:not([fill]){fill:currentColor}svg:not(:root){overflow:hidden}button{margin:0;overflow:visible;font-family:inherit;text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{padding:0;border-style:none}button{display:block;width:100%;margin-bottom:var(--spacing)}a[role=button]{display:inline-block;text-decoration:none}a[role=button],button,input[type=button],input[type=reset],input[type=submit]{--background-color:var(--primary);--border-color:var(--primary);--color:var(--primary-inverse);--box-shadow:var(--button-box-shadow,0 0 0 rgba(0,0,0,0));padding:var(--form-element-spacing-vertical) var(--form-element-spacing-horizontal);border:var(--border-width) solid var(--border-color);border-radius:var(--border-radius);outline:none;background-color:var(--background-color);box-shadow:var(--box-shadow);color:var(--color);font-size:1rem;font-weight:var(--font-weight);line-height:var(--line-height);text-align:center;cursor:pointer;transition:background-color var(--transition),border-color var(--transition),color var(--transition),box-shadow var(--transition)}a[role=button]:active,a[role=button]:focus,a[role=button]:hover,button:active,button:focus,button:hover,input[type=button]:active,input[type=button]:focus,input[type=button]:hover,input[type=reset]:active,input[type=reset]:focus,input[type=reset]:hover,input[type=submit]:active,input[type=submit]:focus,input[type=submit]:hover{--background-color:var(--primary-hover);--border-color:var(--primary-hover);--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0))}a[role=button]:focus,button:focus,input[type=button]:focus,input[type=reset]:focus,input[type=submit]:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--primary-focus)}input[type=reset]{--background-color:var(--secondary);--border-color:var(--secondary);--color:var(--secondary-inverse);cursor:pointer}input[type=reset]:active,input[type=reset]:focus,input[type=reset]:hover{--background-color:var(--secondary-hover);--border-color:var(--secondary-hover)}input[type=reset]:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--secondary-focus)}a[role=button].secondary,button.secondary,input[type=button].secondary,input[type=reset].secondary,input[type=submit].secondary{--background-color:var(--secondary);--border-color:var(--secondary);--color:var(--secondary-inverse);cursor:pointer}a[role=button].secondary:active,a[role=button].secondary:focus,a[role=button].secondary:hover,button.secondary:active,button.secondary:focus,button.secondary:hover,input[type=button].secondary:active,input[type=button].secondary:focus,input[type=button].secondary:hover,input[type=reset].secondary:active,input[type=reset].secondary:focus,input[type=reset].secondary:hover,input[type=submit].secondary:active,input[type=submit].secondary:focus,input[type=submit].secondary:hover{--background-color:var(--secondary-hover);--border-color:var(--secondary-hover)}a[role=button].secondary:focus,button.secondary:focus,input[type=button].secondary:focus,input[type=reset].secondary:focus,input[type=submit].secondary:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--secondary-focus)}a[role=button].contrast,button.contrast,input[type=button].contrast,input[type=reset].contrast,input[type=submit].contrast{--background-color:var(--contrast);--border-color:var(--contrast);--color:var(--contrast-inverse)}a[role=button].contrast:active,a[role=button].contrast:focus,a[role=button].contrast:hover,button.contrast:active,button.contrast:focus,button.contrast:hover,input[type=button].contrast:active,input[type=button].contrast:focus,input[type=button].contrast:hover,input[type=reset].contrast:active,input[type=reset].contrast:focus,input[type=reset].contrast:hover,input[type=submit].contrast:active,input[type=submit].contrast:focus,input[type=submit].contrast:hover{--background-color:var(--contrast-hover);--border-color:var(--contrast-hover)}a[role=button].contrast:focus,button.contrast:focus,input[type=button].contrast:focus,input[type=reset].contrast:focus,input[type=submit].contrast:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--contrast-focus)}a[role=button].outline,button.outline,input[type=button].outline,input[type=reset].outline,input[type=submit].outline{--background-color:transparent;--color:var(--primary)}a[role=button].outline:active,a[role=button].outline:focus,a[role=button].outline:hover,button.outline:active,button.outline:focus,button.outline:hover,input[type=button].outline:active,input[type=button].outline:focus,input[type=button].outline:hover,input[type=reset].outline:active,input[type=reset].outline:focus,input[type=reset].outline:hover,input[type=submit].outline:active,input[type=submit].outline:focus,input[type=submit].outline:hover{--background-color:transparent;--color:var(--primary-hover)}a[role=button].outline.secondary,button.outline.secondary,input[type=button].outline.secondary,input[type=reset].outline.secondary,input[type=submit].outline.secondary{--color:var(--secondary)}a[role=button].outline.secondary:active,a[role=button].outline.secondary:focus,a[role=button].outline.secondary:hover,button.outline.secondary:active,button.outline.secondary:focus,button.outline.secondary:hover,input[type=button].outline.secondary:active,input[type=button].outline.secondary:focus,input[type=button].outline.secondary:hover,input[type=reset].outline.secondary:active,input[type=reset].outline.secondary:focus,input[type=reset].outline.secondary:hover,input[type=submit].outline.secondary:active,input[type=submit].outline.secondary:focus,input[type=submit].outline.secondary:hover{--color:var(--secondary-hover)}a[role=button].outline.contrast,button.outline.contrast,input[type=button].outline.contrast,input[type=reset].outline.contrast,input[type=submit].outline.contrast{--color:var(--contrast)}a[role=button].outline.contrast:active,a[role=button].outline.contrast:focus,a[role=button].outline.contrast:hover,button.outline.contrast:active,button.outline.contrast:focus,button.outline.contrast:hover,input[type=button].outline.contrast:active,input[type=button].outline.contrast:focus,input[type=button].outline.contrast:hover,input[type=reset].outline.contrast:active,input[type=reset].outline.contrast:focus,input[type=reset].outline.contrast:hover,input[type=submit].outline.contrast:active,input[type=submit].outline.contrast:focus,input[type=submit].outline.contrast:hover{--color:var(--contrast-hover)}a[role=button][disabled],button[disabled],input[type=button][disabled],input[type=reset][disabled],input[type=submit][disabled]{opacity:.5;pointer-events:none}input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:1rem;letter-spacing:inherit;line-height:var(--line-height)}input{overflow:visible}select{text-transform:none}legend{max-width:100%;padding:0;color:inherit;white-space:normal}textarea{overflow:auto}[type=checkbox],[type=radio]{padding:0}::-webkit-inner-spin-button,::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}::-moz-focus-inner{padding:0;border-style:none}:-moz-focusring{outline:none}:-moz-ui-invalid{box-shadow:none}::-ms-expand{display:none}[type=file],[type=range]{padding:0;border-width:0}input:not([type=checkbox]):not([type=radio]):not([type=range]){height:calc((1rem * var(--line-height)) + (var(--form-element-spacing-vertical) * 2) + (var(--border-width) * 2))}fieldset{margin:0;margin-bottom:var(--spacing);padding:0;border:0}fieldset legend,label{display:block;margin-bottom:calc(var(--spacing) / 4);vertical-align:middle}input:not([type=checkbox]):not([type=radio]),select,textarea{display:block;width:100%}input:not([type=checkbox]):not([type=radio]):not([type=range]):not([type=file]),select,textarea{-webkit-appearance:none;-moz-appearance:none;appearance:none;padding:var(--form-element-spacing-vertical) var(--form-element-spacing-horizontal);vertical-align:middle}input,select,textarea{--background-color:var(--form-element-background-color);--border-color:var(--form-element-border-color);--color:var(--form-element-color);--box-shadow:none;border:var(--border-width) solid var(--border-color);border-radius:var(--border-radius);outline:none;background-color:var(--background-color);box-shadow:var(--box-shadow);color:var(--color);font-weight:var(--font-weight);transition:background-color var(--transition),border-color var(--transition),color var(--transition),box-shadow var(--transition)}input:not([type=submit]):not([type=button]):not([type=reset]):not([type=checkbox]):not([type=radio]):not([readonly]):active,input:not([type=submit]):not([type=button]):not([type=reset]):not([type=checkbox]):not([type=radio]):not([readonly]):focus,select:active,select:focus,textarea:active,textarea:focus{--background-color:var(--form-element-active-background-color)}input:not([type=submit]):not([type=button]):not([type=reset]):not([role=switch]):not([readonly]):active,input:not([type=submit]):not([type=button]):not([type=reset]):not([role=switch]):not([readonly]):focus,select:active,select:focus,textarea:active,textarea:focus{--border-color:var(--form-element-active-border-color)}input:not([type=submit]):not([type=button]):not([type=reset]):not([type=range]):not([type=file]):not([readonly]):focus,select:focus,textarea:focus{--box-shadow:0 0 0 var(--outline-width) var(--form-element-focus-color)}input:not([type=submit]):not([type=button]):not([type=reset])[disabled],select[disabled],textarea[disabled]{--background-color:var(--form-element-disabled-background-color);--border-color:var(--form-element-disabled-border-color);opacity:var(--form-element-disabled-opacity)}input[aria-invalid],select[aria-invalid],textarea[aria-invalid]{padding-right:2rem;background-position:center right .75rem;background-repeat:no-repeat;background-size:1rem auto}input[aria-invalid=false],select[aria-invalid=false],textarea[aria-invalid=false]{--border-color:var(--form-element-valid-border-color);background-image:var(--icon-valid)}input[aria-invalid=false]:active,input[aria-invalid=false]:focus,select[aria-invalid=false]:active,select[aria-invalid=false]:focus,textarea[aria-invalid=false]:active,textarea[aria-invalid=false]:focus{--border-color:var(--form-element-valid-active-border-color)!important}input[aria-invalid=true],select[aria-invalid=true],textarea[aria-invalid=true]{--border-color:var(--form-element-invalid-border-color);background-image:var(--icon-invalid)}input[aria-invalid=true]:active,input[aria-invalid=true]:focus,select[aria-invalid=true]:active,select[aria-invalid=true]:focus,textarea[aria-invalid=true]:active,textarea[aria-invalid=true]:focus{--border-color:var(--form-element-invalid-active-border-color)!important}input::-webkit-input-placeholder,input::placeholder,select:invalid,textarea::-webkit-input-placeholder,textarea::placeholder{color:var(--form-element-placeholder-color);opacity:1}input:not([type=checkbox]):not([type=radio]),select,textarea{margin-bottom:var(--spacing)}select::-ms-expand{border:0;background-color:transparent}select:not([multiple]):not([size]){padding-right:calc(var(--form-element-spacing-horizontal) + 1.5rem);background-image:var(--icon-chevron);background-position:center right .75rem;background-repeat:no-repeat;background-size:1rem auto}input+small,select+small,textarea+small{display:block;width:100%;margin-top:calc(var(--spacing) * -0.75);margin-bottom:var(--spacing);color:var(--muted-color)}label>input,label>select,label>textarea{margin-top:calc(var(--spacing) / 4)}[type=checkbox],[type=radio]{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:inline-block;width:1.25em;height:1.25em;margin-top:-.125em;margin-right:.375em;border-width:var(--border-width);vertical-align:middle;cursor:pointer}[type=checkbox]::-ms-check,[type=radio]::-ms-check{display:none}[type=checkbox]:checked,[type=checkbox]:checked:active,[type=checkbox]:checked:focus,[type=radio]:checked,[type=radio]:checked:active,[type=radio]:checked:focus{--background-color:var(--primary);--border-color:var(--primary);background-image:var(--icon-checkbox);background-position:center;background-repeat:no-repeat;background-size:.75em auto}[type=checkbox]~label,[type=radio]~label{display:inline-block;margin-right:.375em;margin-bottom:0;cursor:pointer}[type=checkbox]:indeterminate{--background-color:var(--primary);--border-color:var(--primary);background-image:var(--icon-minus);background-position:center;background-repeat:no-repeat;background-size:.75em auto}[type=radio]{border-radius:50%}[type=radio]:checked,[type=radio]:checked:active,[type=radio]:checked:focus{--background-color:var(--primary-inverse);border-width:.35em;background-image:none}[type=checkbox][role=switch]{--background-color:var(--switch-background-color);--border-color:var(--switch-background-color);--color:var(--switch-color);width:2.25em;height:1.25em;border:var(--border-width) solid var(--border-color);border-radius:1.25em;background-color:var(--background-color);line-height:1.25em}[type=checkbox][role=switch]:focus{--background-color:var(--switch-background-color);--border-color:var(--switch-background-color)}[type=checkbox][role=switch]:checked{--background-color:var(--switch-checked-background-color);--border-color:var(--switch-checked-background-color)}[type=checkbox][role=switch]:before{display:block;width:calc(1.25em - (var(--border-width) * 2));height:100%;border-radius:50%;background-color:var(--color);content:'';transition:margin 0.1s ease-in-out}[type=checkbox][role=switch]:checked{background-image:none}[type=checkbox][role=switch]:checked:before{margin-right:0;margin-left:calc(1.125em - var(--border-width))}[type=color]::-webkit-color-swatch-wrapper{padding:0}[type=color]::-moz-focus-inner{padding:0}[type=color]::-webkit-color-swatch{border:none;border-radius:calc(var(--border-radius) / 2)}[type=color]::-moz-color-swatch{border:none;border-radius:calc(var(--border-radius) / 2)}[type=date],[type=datetime-local],[type=month],[type=time],[type=week]{background-image:var(--icon-date);background-position:center right .75rem;background-repeat:no-repeat;background-size:1rem auto}[type=date]::-webkit-calendar-picker-indicator,[type=datetime-local]::-webkit-calendar-picker-indicator,[type=month]::-webkit-calendar-picker-indicator,[type=time]::-webkit-calendar-picker-indicator,[type=week]::-webkit-calendar-picker-indicator{opacity:0}[type=time]{background-image:var(--icon-time)}[type=file]{--color:var(--muted-color);padding:calc(var(--form-element-spacing-vertical)/2) 0;border:none;border-radius:0;background:none}[type=file]::-webkit-file-upload-button{--background-color:var(--secondary);--border-color:var(--secondary);--color:var(--secondary-inverse);margin-right:calc(var(--spacing) / 2);padding:calc(var(--form-element-spacing-vertical) / 2) calc(var(--form-element-spacing-horizontal) / 2);border:var(--border-width) solid var(--border-color);border-radius:var(--border-radius);outline:none;background-color:var(--background-color);box-shadow:var(--box-shadow);color:var(--color);font-size:1rem;font-weight:var(--font-weight);line-height:var(--line-height);text-align:center;cursor:pointer;transition:background-color var(--transition),border-color var(--transition),color var(--transition),box-shadow var(--transition)}[type=file]:active,[type=file]:focus,[type=file]:hover{--color:var(--color);border:none;background:none}[type=file]:active::-webkit-file-upload-button,[type=file]:focus::-webkit-file-upload-button,[type=file]:hover::-webkit-file-upload-button{--background-color:var(--secondary-hover);--border-color:var(--secondary-hover)}[type=range]{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:block;width:100%;height:1.25rem;background:transparent}[type=range]::-webkit-slider-runnable-track{width:100%;height:0.25rem;border-radius:var(--border-radius);background-color:var(--range-border-color);transition:background-color var(--transition),box-shadow var(--transition)}[type=range]::-moz-range-track{width:100%;height:0.25rem;border-radius:var(--border-radius);background-color:var(--range-border-color);transition:background-color var(--transition),box-shadow var(--transition)}[type=range]::-ms-track{width:100%;height:0.25rem;border-radius:var(--border-radius);background-color:var(--range-border-color);transition:background-color var(--transition),box-shadow var(--transition)}[type=range]::-ms-fill-lower{background-color:var(--border-radius)}[type=range]::-webkit-slider-thumb{-webkit-appearance:none;width:1.25rem;height:1.25rem;margin-top:-0.5rem;border:2px solid var(--range-thumb-border-color);border-radius:50%;background-color:var(--range-thumb-color);cursor:pointer;transition:background-color var(--transition),transform var(--transition)}[type=range]::-moz-range-thumb{-webkit-appearance:none;width:1.25rem;height:1.25rem;margin-top:-0.5rem;border:2px solid var(--range-thumb-border-color);border-radius:50%;background-color:var(--range-thumb-color);cursor:pointer;transition:background-color var(--transition),transform var(--transition)}[type=range]::-ms-thumb{-webkit-appearance:none;width:1.25rem;height:1.25rem;margin-top:-0.5rem;border:2px solid var(--range-thumb-border-color);border-radius:50%;background-color:var(--range-thumb-color);cursor:pointer;transition:background-color var(--transition),transform var(--transition)}[type=range]:focus,[type=range]:hover{--range-border-color:var(--range-active-border-color);--range-thumb-color:var(--range-thumb-hover-color)}[type=range]:active{--range-thumb-color:var(--range-thumb-active-color)}[type=range]:active::-webkit-slider-thumb{transform:scale(1.25)}[type=range]:active::-moz-range-thumb{transform:scale(1.25)}[type=range]:active::-ms-thumb{transform:scale(1.25)}[type=search]{border-radius:5rem;padding-left:calc(var(--form-element-spacing-horizontal) + 1.75rem)!important;background-image:var(--icon-search);background-position:center left 1.125rem;background-repeat:no-repeat;background-size:1rem auto}[type=search]::-webkit-search-cancel-button{-webkit-appearance:none;display:none}table{width:100%;border-color:inherit;border-collapse:collapse;border-spacing:0;text-indent:0}td,th{padding:calc(var(--spacing) / 2) var(--spacing);border-bottom:var(--border-width) solid var(--table-border-color);color:var(--color);font-size:var(--font-size);font-weight:var(--font-weight);text-align:left}tr{background-color:var(--background-color)}table[role=grid] tbody tr:nth-child(odd){--background-color:var(--table-row-stripped-background-color)}code,kbd,pre,samp{font-family:var(--font-family);font-size:.875rem}pre{-ms-overflow-style:scrollbar;overflow:auto}code,kbd,pre{background:var(--code-background-color);color:var(--code-color);font-weight:var(--font-weight);line-height:initial}code,kbd{display:inline-block;padding:.375rem .5rem;border-radius:var(--border-radius)}pre{display:block;margin-bottom:var(--spacing);padding:var(--spacing);overflow-x:auto;background:var(--code-background-color)}pre>code{display:block;padding:0;background:transparent;font-size:14px;line-height:var(--line-height)}code b{color:var(--code-tag-color);font-weight:var(--font-weight)}code i{color:var(--code-property-color);font-style:normal}code u{color:var(--code-value-color);text-decoration:none}code em{color:var(--code-comment-color);font-style:normal}kbd{background-color:var(--code-kbd-background-color);color:var(--code-kbd-color);vertical-align:middle}hr{box-sizing:content-box;height:0;overflow:visible;border:none;border-top:1px solid var(--muted-border-color)}[hidden],template{display:none}dialog{display:block;position:absolute;right:0;left:0;width:-moz-fit-content;width:-webkit-fit-content;width:fit-content;height:-moz-fit-content;height:-webkit-fit-content;height:fit-content;margin:auto;padding:1em;border:solid;background-color:white;color:black}dialog:not([open]){display:none}canvas{display:inline-block}details{display:block;margin-bottom:var(--spacing);padding-bottom:calc(var(--spacing) / 2);border-bottom:var(--border-width) solid var(--accordion-border-color)}details summary{color:var(--accordion-close-summary-color);line-height:1rem;list-style-type:none;list-style-type:none;cursor:pointer;transition:color var(--transition)}details summary::-webkit-details-marker{display:none}details summary::marker{display:none}details summary::-moz-list-bullet{list-style-type:none}details summary:after{display:inline-block;width:1rem;height:1rem;float:right;transform:rotate(-90deg);background-image:var(--icon-chevron);background-position:center;background-repeat:no-repeat;background-size:1rem auto;content:'';transition:transform var(--transition)}details summary:focus{outline:none;color:var(--accordion-active-summary-color)}details summary~*{margin-top:calc(var(--spacing) / 2)}details summary~*~*{margin-top:0}details[open]>summary{margin-bottom:calc(var(--spacing) / 4)}details[open]>summary:not(:focus){color:var(--accordion-open-summary-color)}details[open]>summary:after{transform:rotate(0)}article{margin:var(--block-spacing-vertical) 0;padding:var(--block-spacing-vertical) var(--block-spacing-horizontal);overflow:hidden;border-radius:var(--border-radius);background:var(--card-background-color);box-shadow:var(--card-box-shadow)}article>footer,article>header,article>pre{margin-right:calc(var(--block-spacing-horizontal) * -1);margin-left:calc(var(--block-spacing-horizontal) * -1);padding:calc(var(--block-spacing-vertical) / 1.5) var(--block-spacing-horizontal);background-color:var(--card-sectionning-background-color)}article>header{margin-top:calc(var(--block-spacing-vertical) * -1);margin-bottom:var(--block-spacing-vertical);border-bottom:var(--border-width) solid var(--card-border-color)}article>footer,article>pre{margin-top:var(--block-spacing-vertical);margin-bottom:calc(var(--block-spacing-vertical) * -1);border-top:var(--border-width) solid var(--card-border-color)}nav,nav ul{display:flex}nav{justify-content:space-between}nav ol,nav ul{align-items:center;margin-bottom:0;padding:0;list-style:none}nav ol:first-of-type,nav ul:first-of-type{margin-left:calc(var(--spacing) * -0.5)}nav ol:last-of-type,nav ul:last-of-type{margin-right:calc(var(--spacing) * -0.5)}nav li{display:inline-block;margin:0;padding:var(--spacing) calc(var(--spacing) / 2)}nav li>*,nav li>input:not([type=checkbox]):not([type=radio]){margin-bottom:0}nav a{display:block;margin:calc(var(--spacing) * -1) calc(var(--spacing) * -0.5);padding:var(--spacing) calc(var(--spacing) / 2);border-radius:var(--border-radius);text-decoration:none}nav a:active,nav a:focus,nav a:hover{text-decoration:none}aside li,aside nav,aside ol,aside ul{display:block}aside li{padding:calc(var(--spacing) / 2)}aside li a{margin:calc(var(--spacing) * -0.5);padding:calc(var(--spacing) / 2)}progress{display:inline-block;vertical-align:baseline}progress{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:inline-block;width:100%;height:.5rem;margin-bottom:calc(var(--spacing) / 2);overflow:hidden;border:0;border-radius:var(--border-radius);background-color:var(--progress-background-color);color:var(--progress-color)}progress::-webkit-progress-bar{border-radius:var(--border-radius);background:transparent}progress[value]::-webkit-progress-value{background-color:var(--progress-color)}progress::-moz-progress-bar{background-color:var(--progress-color)}@media (prefers-reduced-motion:no-preference){progress:indeterminate{background:var(--progress-background-color) linear-gradient(to right,var(--progress-color) 30%,var(--progress-background-color) 30%) top left/150% 150% no-repeat;animation:progressIndeterminate 1s linear infinite}progress:indeterminate[value]::-webkit-progress-value{background-color:transparent}progress:indeterminate::-moz-progress-bar{background-color:transparent}}@keyframes progressIndeterminate{0%{background-position:200% 0}to{background-position:-200% 0}}[aria-busy=true]{cursor:progress}[aria-busy=true]:not(input):not(select):not(textarea):before{display:inline-block;width:1em;height:1em;border:0.1875em solid currentColor;border-radius:1em;border-right-color:transparent;vertical-align:text-bottom;vertical-align:-.125em;animation:spinner 0.75s linear infinite;content:'';opacity:var(--loading-spinner-opacity)}[aria-busy=true]:not(input):not(select):not(textarea):not(:empty):before{margin-right:calc(var(--spacing) / 2)}[aria-busy=true]:not(input):not(select):not(textarea):empty{text-align:center}a[aria-busy=true],button[aria-busy=true],input[type=button][aria-busy=true],input[type=reset][aria-busy=true],input[type=submit][aria-busy=true]{pointer-events:none}@keyframes spinner{to{transform:rotate(360deg)}}[data-tooltip]{position:relative}[data-tooltip]:not(a):not(button):not(input){border-bottom:1px dotted;text-decoration:none;cursor:help}[data-tooltip]:after,[data-tooltip]:before{display:block;z-index:99;position:absolute;bottom:100%;left:50%;padding:.25rem .5rem;overflow:hidden;transform:translate(-50%,-0.25rem);border-radius:var(--border-radius);background:var(--tooltip-background-color);color:var(--tooltip-color);font-size:.875rem;font-style:normal;font-weight:var(--font-weight);text-decoration:none;text-overflow:ellipsis;white-space:nowrap;content:attr(data-tooltip);opacity:0;pointer-events:none}[data-tooltip]:after{padding:0;transform:translate(-50%,0rem);border-top:.3rem solid;border-right:.3rem solid transparent;border-left:.3rem solid transparent;border-radius:0;background-color:transparent;color:var(--tooltip-background-color);content:''}[data-tooltip]:focus:after,[data-tooltip]:focus:before,[data-tooltip]:hover:after,[data-tooltip]:hover:before{opacity:1;animation-name:slide;animation-duration:.2s}[data-tooltip]:focus:after,[data-tooltip]:hover:after{animation-name:slideCaret}@keyframes slide{0%{transform:translate(-50%,0.75rem);opacity:0}to{transform:translate(-50%,-0.25rem);opacity:1}}@keyframes slideCaret{0%{opacity:0}50%{transform:translate(-50%,-0.25rem);opacity:0}to{transform:translate(-50%,0rem);opacity:1}}[aria-controls]{cursor:pointer}[aria-disabled=true],[disabled]{cursor:not-allowed}[aria-hidden=false][hidden]{display:initial}[aria-hidden=false][hidden]:not(:focus){clip:rect(0,0,0,0);position:absolute}[tabindex],a,area,button,input,label,select,summary,textarea{-ms-touch-action:manipulation}@media (prefers-reduced-motion:reduce){:not([aria-busy=true]),:not([aria-busy=true]):after,:not([aria-busy=true]):before{background-attachment:initial!important;animation-duration:1ms!important;animation-delay:-1ms!important;animation-iteration-count:1!important;scroll-behavior:auto!important;transition-delay:0s!important;transition-duration:0s!important}}
    </style>
    <style type="text/css">
      article div {
        font-size: 1.15em;
        line-height: 1.6em;
      }
    </style>
  </head>
  <body style="background-color: #f9fafb;">
    <main class="container">
      <nav>
        <ul>
          <li><a href="../index.html">← Topic list</a></li>
        </ul>
      </nav>
      <!-- <h1>Infomedia Articles Selection: 50 articles</h1> -->
      <h1>H_0_130 <kbd>H_0_130</kbd></h1>
      <h3>Words (top 25)</h3>
      <div style="margin:0px -12px">
        <span style="font-size:11.32pt; padding:0px 12px"><strong>uniform</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>militæret</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dræbe</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>defense</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>militær</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>krig</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>soldater</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>våben</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fly</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>flyve</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>autonome</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>våbenkapløb</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>flyvende</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>krudtet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>airbus</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>droneteknologi</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>droner</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>autonom</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>selvflyvende</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dronen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>affyre</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>missil</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>civile</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>tiårig</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>blåstempler</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>pawel</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>blodig</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>piloter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>diis</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>laws</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>forbud</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>forsvarsminister</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>flåde</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>army</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>afghanistan</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>vingerne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>magtanvendelse</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>krigsmaskiner</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dræberrobotterne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>slagmarken</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>krigsførelse</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>landminer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>killer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sheffield</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>pentagon</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ubemandet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>noel</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>gary</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fn</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>forprogrammeret</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>operere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>flight</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>atomvåben</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>defence</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>afsides</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>landjorden</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>militære</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>militært</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>soldaterne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>radioaktivitet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>stormagterne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>forsvar</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>mangeårigt</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>bevæbnede</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>jr.</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>darpa</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>robotudvikling</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>autonomt</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>afsmeltning</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>libyske</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>flyets</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>piloterne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>flyvningen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>pilotens</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dødbringende</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>affyres</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>reef</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>armeret</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>krudt</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>shinzo</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>missiler</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>flåden</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>civil</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fjendens</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>våbensystemer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dræberrobotter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fjendtlige</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>våbentyper</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>baltiske</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>f-16</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>pilot</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>piloten</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>lockheed</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>combat</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>våbensystem</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>navy</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>bevæbnet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fjender</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>missioner</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>luftrummet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>bomber</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>militærs</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>luftangreb</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>hackes</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>natos</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>aserbajdsjan</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>wales</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>meters</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>galde</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>operatør</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fjenden</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kvadratkilometer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>overvælde</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ubåde</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>aspen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>forsvarsministerium</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>hangarskibe</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>bemandede</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>eisenhower</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>væbnede</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>committee</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ubemandede</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>pentagons</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>resolut</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>genève</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>pansrede</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>krigszoner</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sprækkerne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sydkoreansk</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>formation</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>modificeres</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>drone</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sydkoreanske</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>selvtænkende</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>diktatorer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>noam</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>aegis</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>flyproducent</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>passagerfly</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>droneangreb</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>pandoras</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>stillehavet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>jage</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>isenkram</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>autonomi</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>forsvarskommandoen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>flytrafikken</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>associeres</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>cummings</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kampfly</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>jagerpilot</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>luftvåben</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>f-35</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>udviklingsprogram</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dødelig</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>nabolag</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>æske</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dræberrobot</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>soldat</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>krigsrobotter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>militærmagter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>våbnene</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>krigens</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>masseødelæggelsesvåben</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>toby</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>walsh</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>humanitær</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>folkeret</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kampdroner</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>brevet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sværme</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ai-våben</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>rædsler</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>stealth</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>forsvarsakademiet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>robots-</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dræber-robotter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>rens</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>invaderer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>menneskehånd</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sydkoreas</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>aftrækkeren</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>despoter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fuglene</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>miner</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dji</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ehang</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>jedi</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>jagerfly</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>hangarskib</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>forsvarsforliget</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>exo-skeletter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>flokke</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sværmen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sværm</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dræb</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>vista</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>nedkæmpe</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>tanks</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>græshopper</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>tyrkisk</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>affyret</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>chomsky</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kunstgødning</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>russel</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>works</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>direktiv</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>iben</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>videnskabsteori</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>campaign</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dronerne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>helikopter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>protestbrev</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>topniveau</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>underskrivere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fn-rapport</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>selvstyrende</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dræbes</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>khalifa</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>balkan</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>rekognoscering</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>krigene</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>forsvarssystemer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>gennemtænke</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>luftforsvar</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>wallace</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>summende</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>laugesen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>droneteknologien</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>stormagternes</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>styrtdykker</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>erklæringen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dræbermaskiner</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fjernstyres</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sea</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>forvolde</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>admiral</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>forsvarsministeriet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>søfolk</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>helikoptere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>våbenindustrien</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>jackie</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>bae</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dødeligt</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>krigsskibe</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>havbunden</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>civilt</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>weapons</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kamprobotter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>medunderskrivere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>militærmagt</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>opskaleret</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kaist</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>våbenproducent</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>hanwha</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>schaub</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kampvogne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>laservåben</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>hin-yan</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>affyring</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>lethal</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>robotik</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>krigsteknologi</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>warfare</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dronens</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dronernes</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>lokaliteter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fjernstyrede</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>egenhændigt</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fredelige</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>talepapir</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>konventionen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>beslutningskæden</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>semi-autonome</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>schmitt</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>måger</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>luftfart</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>springende</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>phalanx</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>nedskyde</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>weapon</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>willum</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>forsvarsministeriums</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ciws</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>skibets</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ballistiske</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>vestskov</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>robotvåben</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>boykotten</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>traktat</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>bestand</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>lorenz</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dronevirksomheden</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>biologerne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sikkerhedsteknologi</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>nogles</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>command</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>oberst</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>rumforskning</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>underskriverne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sharkey</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sværmene</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>uskadeliggøre</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>formere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>aviation</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>affyrede</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ledningerne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>korrosion</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>emad</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ebeid</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dronecenter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ledningen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>højspændingsledninger</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>luftledninger</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>hca</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>airport</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kablerne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>omsonst</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>propeller</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fjernbetjente</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>unmanned</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>reaper</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kampflyet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ucav'er</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ringsmose</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>aboulafia</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>teal</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dronepiloter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>flyvevåben</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>manøvredygtighed</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>forsvars</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>vehicles</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>udtænker</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>gaarn</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>skrinlagt</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>maskingevær</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>soldaten</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>faldskærm</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>svæve</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>luftrum</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>overvågnings-og</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>radarsystemer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>testområde</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fodboldbane</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>uas</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>synsvidde</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>skakspil</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>defekter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>trafik-</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>haahr</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>tællinger</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>hunter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>northrop</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>grumman</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dronesværme</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>3.100</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>tilintetgøre</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>missilerne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>karlsson</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>eagle</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>randy</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>smitsomme</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>basen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>bombet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>google-ansatte</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>strandene</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>affyrer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>hiroshima</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>luftfarten</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>landinger</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>vadehavet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>militærteknologi</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>landing</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>missilet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>flyves</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>agenturer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>krigsførsel</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>udkæmpe</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>elefanterne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>autonomien</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>trafikstyrelsen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>forskerkredse</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>miljøproblemer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>arms</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>søstjerner</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>indkommende</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>cour-harbo</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>trykluft</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>scharre</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>gletsjeren</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>søværnet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>rogers</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>mellemøstlig</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>folkeretten</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>boeings</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>koralrevet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>inspektionen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>google-medarbejdere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>hornet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kampvognen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>tordenvejr</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>eurofighter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sjettegenerations</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>danadynamics</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>thwaites-gletsjeren</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>tornekroner</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dunbabin</strong>&nbsp;<span style="font-size:.5em">1</span></span>
      </div>
      <br><br>
      <h3>Articles (top 50)</h3>
      Query:
      <pre>SELECT * FROM articles WHERE articles.dupeKeep=1 AND articles.sizeKeep=1 ORDER BY H_0_130 DESC LIMIT 50</pre>
      <article>
        <h4>Bliver kunstig intelligens et masseødelæggelsesvåben?</h4>
        <div>
          I 2016 lykkedes det for første gang en AI-computer at nedkæmpe en menneskelig kampflypilot i simulatorøvelser i det amerikanske luftvåbens centrale forskningslaboratorium i Ohio. Illustration: University of CincinnatiForskere advarer om, at kamprobotter med kunstig intelligens vil opskalere krig til i et hidtil uset omfang. Men det er forkert at kategorisere autonome våben som masseødelæggelsesvåben, siger forfatteren til den første danske rapport om fænomenet.»Det spørgsmål, vi må stille os selv, lyder: Hvilke skridt kan vi tage for at forhindre en militær konkurrence, hvis udfald bliver katastrofalt for alle parter?« Sådan lød advarslen mod en frygtindgydende ny våbenteknologi i et historisk manifest, hvis medunderskrivere omfattede nogle af de mest anerkendte forskere inden for udviklingen af selv samme teknologi. Dengang, i juli 1955, handlede advarslen om atombomben i et manifest fra 11 videnskabsmænd anført af Bertrand Russell og Albert Einstein.Seks årtier senere lyder advarslen mod en ny våbenteknologi under hastig udvikling ikke meget anderledes.»Det afgørende spørgsmål for menneskeheden er i dag, hvorvidt man skal indlede eller forhindre et globalt AI-våbenkapløb. Hvis en given stor militærmagt skubber på udviklingen af våben med kunstig intelligens, er et globalt våbenkapløb stort set uundgåeligt.« Advarslen mod mod at anvende kunstig intelligens til militære formål er formuleret i et åbent brev til FN fra 2015, hvis medunderskrivere nok engang omfatter forskere inden for selv samme teknologi. Nærmere bestemt 3.963 forskere inden for robotter og kunstig intelligens, foruden 22.396 medunderskrivere, der omfatter prominente navne som Stephen Hawking, Elon Musk, Apples Steve Wozniak og professor Noam Chomsky.Krig i et hidtil uset omfangOg spørger man en af specialisterne bag advarslen fra 2015, skal autonome våben ligesom atombomben kategoriseres som et masseødelæggelsesvåben. Han hedder Toby Walsh og er professor i kunstig intelligens ved New South Wales University og formand for organisationen AI Access Foundation, som har til formål at udbrede forkningsresultater indenfor kunstig intelligens.»Verdenssamfundet bør betragte autonome våben som masseødelæggelsesvåben og ikke mindst føje dem til listen over disse. For en enkelt programmør vil kunne forvolde skader, som tidligere krævede en hel hær. Krig bliver opskaleret i et hidtil uset omfang,« fortalte Toby Walsh for få dage siden til Ingeniøren i en artikel om regulering af autonome våben.Han er også en af de 50 forskere bag den boykot, der i sidste uge fik det sydkoreanske universitet KAIST til at opgive et samarbejde med den sydkoreanske våbenproducent Hanwha Systems om et laboratorium til udvikling af autonome våben optimeret med kunstig intelligens.Ikke masseødelæggelsesvåbenSpørger man derimod forfatteren til den første danske videnskabelige rapport om autonome våben, rammer Toby Walshs og andre bekymrede fagfolks bestræbelser på at få kategoriseret autonome våben som masseødelæggelsesvåben ved siden af.»Problemet er, at disse systemer slet ikke er masseødelæggelsesvåben,« siger Gary Schaub, seniorforsker ved Center for Militære Studier på Københavns Universitet. Han offentliggjorde i 2016 en rapport om behovet for retningslinjer for anvendelsen af autonome våben.»Masseødelæggelsesvåben er per definition ikke diskriminerende i deres ødelæggelser. Det er den masseødelæggelse, der gør dem unikke. Autonome våben er ikke udiskriminerende. De autonome våben, der bliver udviklet i den nære fremtid, vil være ligesom de konventionelle våben, der anvendes i dag - kampvogne, kampfly, missiler, fregatter og ubåde - bare med en maskine som beslutningstager som afløser for et menneske,« siger Gay Schaub.Han vurderer dog, ligsom en række andre forskere, som Ingeniøren har talt med til de seneste dages artikler, at det er nødvendigt at opstille retningslinjer for, hvordan den menneskelige kontrol med autonome våbensystemer skal foregå.Når der i FN foretages officielle diskussioner om mulige restriktioner på autonome våbensystemer, som det skete i Genève i sidste uge, sker det indtil videre med udgangspunkt i, at autonome våbensystemer ikke er masseødelæggelsesvåben, nemlig med henblik på en mulig opdatering af FN's konvention om særlige konventionelle våben. Den har til formål at forbyde eller begrænse brugen af våben, som anses for at være unødigt skadevoldende eller for at ramme i flæng, såsom landminer, lureminer, brandvåben og blindende laservåben, hvorimod listen af masseødelæggelsevåben i dag kun omfatter kemiske, biologiske, radioaktive og nukleare våben.Er slet ikke våbenArbejdet med at opstille juridiske rammer for autonome våbensystemer bliver vanskeliggjort af, at selve våbendelen af systemerne næppe kommer til at adskille sig fra konventionelle våbentyper som missiler og projektiler.En forskningsartikel bragt i ICRC-s internationale forskningstidsskrift i 2012 konkluderede på den baggrund, at autonome våbensystemer end ikke er våben, men at de alene er kendetegnet ved en særlig anvendelse af konventionelle våben. Forfatteren til rapporten, Hin-Yan Liu, er i dag professor ved Juridisk Institut på Københavns Universitet.»Den afgørende forskel på autonome våbensystemer og andre våben er, at autonome våbensystemer ikke er våben. Våben er redskaber til at begå vold, som kræver en operatør. Det problematiske ved autonome våbensystemer er derfor ikke selve våbnet, men den operatør, der betjener det. Det bliver åbenlyst, når man tager i betragtning, at autonome våbensystemer med al sandsynlighed kommer til at benytte sig af eksisterende, konventionelle våbentyper,« siger Hin-Yan Liu.Fuldt autonome våbensystemer, der selv udvælger og angriber deres mål, anvendes endnu ikke i nogen lande. I Danmark benytter Forsvaret i dag delvist autonome våben i form af såkaldte fire and forget-missiler, som efter affyring selv kan finde frem til deres mål.Sidste uges diskussioner i FN bestod af det andet møde i en mellemstatslige ekspertgruppe med regeringsrepræsentanter, som FN besluttede at oprette i 2016, og som skal diskutere både de teknologiske, militære, juridiske og etiske implikationer ved at udvikle autonome våben. Den såkaldte Group of Governmental Experts on Lethal Autonomous Weapons Systems fortsætter diskussionerne ved sit næste møde i august i år.
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2018-04-17
          &nbsp;·&nbsp; e6b5158a
          &nbsp;·&nbsp; #0
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.983</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.546</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.583</kbd>
        </footer>
      </article>
      <article>
        <h4>Note</h4>
        <div>
          Stealth - det usynlige våben, Zulu 20.00: I en nær fremtid har den amerikanske flåde udviklet et ubemandet jagerfly, der styres af en kunstig intelligens. Flyet bliver sendt til et hangarskib i Stillehavet for at lære kampteknik af piloterne om bord. Men da computeren begynder at følge sine egne ordrer, er det op til de tre elitepiloter at stoppe den, før den indleder en atomkrig... 
        </div>
        <footer>
          <em>Ekstra Bladet</em>
          &nbsp;·&nbsp; 2016-10-28
          &nbsp;·&nbsp; e5f27eb8
          &nbsp;·&nbsp; #1
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.94</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.941</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.577</kbd>
        </footer>
      </article>
      <article>
        <h4>Note</h4>
        <div>
          Stealth, TV 2 22.30: I en nær fremtid har flåden udviklet et ubemandet jagerfly, styret af en kunstig intelligens. Flyet bliver sendt til Stillehavet, så piloterne om bord kan give flyet »lektioner« i kampteknik. Men da computeren begynder at følge sine egne ordrer, må de tre elitepiloter stoppe den.
        </div>
        <footer>
          <em>Ekstra Bladet</em>
          &nbsp;·&nbsp; 2018-01-19
          &nbsp;·&nbsp; e695427a
          &nbsp;·&nbsp; #2
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.948</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.936</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.564</kbd>
        </footer>
      </article>
      <article>
        <h4>1.000 forskere efterlyser forbud mod intelligente dræberrobotter</h4>
        <div>
          1.000 forskere i kunstig intelligens har skrevet under på et åbent brev, der råder FN til at forbyde brug og udvikling af autonome våbensystemer. Udvikling af våben, der kan fungere uden menneskelig indblanding, kan sammenlignes med opfindelsen af atomvåben, mener underskriverne, som blandt andet tæller Stephen Hawking, Elon Musk og Googles researchchef Peter Norvig. Forskerne frygter, at autonome våben i sidste ende vil kunne bruges af terrorister eller af diktatorer til at undertrykke befolkningen.
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2015-07-29
          &nbsp;·&nbsp; e5243077
          &nbsp;·&nbsp; #3
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.965</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.618</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.53</kbd>
        </footer>
      </article>
      <article>
        <h4>Internationale forskere boykotter universitet af frygt for kapløb om dræberrobotter</h4>
        <div>
          Flankeret af 50 kolleger forsøger den internationalt anerkendte AI-ekspert Toby Walsh at stoppe universiteterne i at være med til at accelere udviklingen af fuldt autonome våben. Illustration: Nanna SkytteOver 50 af klodens førende forskere inden for kunstig intelligens og robotudvikling skrinlægger alt samarbejde med sydkoreansk universitet, der samarbejder med våbenproducent.Af 4. apr 2018 kl. 16:02De drømmer om at bremse eller endnu bedre helt at stoppe kapløbet om udviklingen af fuldt automatiserede våben optimeret og drevet af kunstig intelligens.Et opsigtsvækkende skridt er nu taget i den kamp. Over 50 af klodens førende forskere indenfor kunstig intelligens(AI) og robotudvikling fra 30 forskellige lande tager i en fælles udtalelse skarp afstand fra Sydkoreas topuniversitet, KAIST.Forskerne stopper alt samarbejde med universitet på ubestemt tid, fordi KAIST i samarbejde med den sydkoreanske våbenproducent Hanwha Systems har oprettet et laboratorium til udvikling af autonome våben optimeret med kunstig intelligens.Gruppen vil først ophæve boykottet, når KAIST forsikrer, at laboratoriet vil afholde sig fra at udvikle våben, som kan fungere 100 procent autonomt. Der skal altså fortsat være et menneske, som i et eller andet omfang kontrollerer de våben, som KAIST og Hanwha Systems udtænker, kræver forskerne.»Udviklingen indenfor AI og autonome våben går i en potentiel farlig retning med dette her. Det er vores pligt at tage stilling og forsøge at gøre beslutningstagerne opmærksomme på konsekvenserne,« siger en af de 50 medunderskrivere på boykotten, Thomas Bolander til Ingeniøren.Han er ph.d. og lektor i logik og kunstig intelligens ved DTU Compute og pointerer, at der er mange ubekendte faktorer ved Hanwha Systems- universitets-laboratorium.I sydkoreansk presse har KAIST udlagt samarbejdet, som om der blot er tale om et AI-assisteret navigationssystem til Hanwha Systems- tanks eller missiler.Blåstempler våben-kapløbUanset om det er tilfældet, betoner Thomas Bolander, at forskernes afstandtagen bør ses i en større kontekst.I udmeldingen, som er forfattet af en af verdens mest fremtrædende AI-forskere, professor Toby Walsh fra New South Wales University, fremhæves risikoen for, at KAIST blåstempler og sætter turbo på kapløbet om udviklingen af autonome våben. Vel at mærke på et tidspunkt, hvor vi stadig kæmper med at begribe potentialet ved AI.»Hvis udviklet, vil autonome våben være den tredje revolution inden for krigsførelse. Krig vil blive sat i gang hurtigere og i en skala større end nogensinde før. Despoter og tyraner kan bruge disse våben mod uskyldige og fjerne alle former for etiske begrænsninger. Denne Pandoras æske vil være svær at lukke, hvis den åbnes,« skriver de 50 forskere i fællesudmeldingen, hvor de opfordrer KAIST til at koncentrere deres AI-forskning om at fremme fredelige formål.Hanwha Systems er kendt herhjemme, idet selskabets artilleri-system K9 Thunder var en af kandidaterne, da det danske forsvar for år tilbage åbnede op for en udbudsrunde om nyt artilleri.Internationalt set har Hanwha Systems vakt opsigt, idet selskabet producerer klyngebomber til trods for, at en FN-konvention forbyder fremstillingen og brugen af denne type våben.Sydkoreas signatur mangler på denne konvention, hvorfor der juridisk set ikke er noget at udsætte på KAIST-s samarbejde med Hanwha Systems.
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2018-04-04
          &nbsp;·&nbsp; e6b0dc39
          &nbsp;·&nbsp; #4
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.964</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.564</kbd>
        </footer>
      </article>
      <article>
        <h4>Forskere boykotter universitet af frygt for kapløb om dræberrobotter</h4>
        <div>
          De drømmer om at bremse eller endnu bedre helt stoppe kapløbet om udviklingen af fuldt automatiserede våben optimeret og drevet af kunstig intelligens.Et opsigtsvækkende skridt er nu taget i den kamp. 55 af klodens førende forskere inden for kunstig intelligens (AI) eller robotudvikling fra 30 lande tager i en fælles udtalelse skarpt afstand fra Sydkoreas topuniversitet, KAIST.Forskerne stopper alt samarbejde med universitetet på ubestemt tid, fordi KAIST i samarbejde med den sydkoreanske våbenproducent Hanwha Systems har oprettet et laboratorium til udvikling af autonome våben med kunstig intelligens.Gruppen vil først ophæve boykotten, når KAIST forsikrer, at laboratoriet ikke vil udvikle våben, som kan fungere 100 procent autonomt.Der skal altså fortsat være et menneske, som i et eller andet omfang kontrollerer de våben, som KAIST og Hanwha Systems udtænker.»Udviklingen inden for AI og autonome våben går i en potentielt farlig retning med det her. Det er vores pligt at tage stilling og forsøge at gøre beslutningstagerne opmærksomme på konsekvenserne,« siger en af de 55 underskrivere på boykotten, Thomas Bolander.Han er ph. d. og lektor i logik og kunstig intelligens ved DTU Compute og pointerer, at der er mange ubekendte faktorer ved Hanwha Systems' universitets-laboratorium.I sydkoreansk presse har KAIST udlagt samarbejdet, som om der blot er tale om et AI-assisteret navigationssystem til Hanwha Systems' tanks eller missiler. Uanset om det er tilfældet eller ej, betoner Thomas Bolander, at forskernes afstandtagen bør ses i en større kontekst.Blåstempler våben-kapløbI udmeldingen, som er forfattet af en af verdens mest fremtrædende AI-forskere, professor Toby Walsh fra New South Wales University, fremhæves risikoen for, at KAIST blåstempler og sætter turbo på kapløbet om udviklingen af autonome våben. Vel at mærke på et tidspunkt, hvor vi stadig kæmper med at begribe potentialet ved AI.»Hvis udviklet, vil autonome våben være den tredje revolution inden for krigsførelse. Krig vil blive sat i gang hurtigere og i en skala større end nogensinde før. Despoter og tyraner kan bruge disse våben mod uskyldige og fjerne alle former for etiske begrænsninger. Denne Pandoras æske vil være svær at lukke, hvis den åbnes,« skriver de 55 forskere i fællesudmeldingen.Autonome våben er ikke forbudt af FN - i første omgang af den grund, at FN's 123 medlemslande aldrig har drøftet dem. Det sker dog på mandag efter tre års pres fra Toby Walsh.Han plæderer for, at AI til våben skal defineres som masseødelæggelsesvåben i FN-systemet. Et forbud, som 22 FN-lande allerede støtter.»Tidligere havde man brug for en hel hær for at føre krig. Du skulle overtale folk til at kæmpe, uddanne dem, give dem mad, udstyr og løn. Det behøver man ikke med AI, der gør det muligt at skalere krigsførelse på en måde, som vi aldrig har set før,« sagde Toby Walsh sidste år i et interview med Ingeniøren.Her betegnede han sig selv som værende pessimistisk optimist. For ingen kan forudsige den teknologiske fremtid, der er produktet af AI.»Vi forbød ikke kemi og vil heller ikke forbyde AI. Vi forbød brugen af kemiske våben, og jeg håber, vi kan forbyde brugen af AI-våben,« understreger Toby Walsh.
        </div>
        <footer>
          <em>Ingeniøren</em>
          &nbsp;·&nbsp; 2018-04-06
          &nbsp;·&nbsp; e6b17e79
          &nbsp;·&nbsp; #5
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.993</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.565</kbd>
        </footer>
      </article>
      <article>
        <h4>Har de selvstyrende kamprobotter allerede vundet krigen?</h4>
        <div>
          I luftrummet over et amerikansk militært testområde, der ligner en mellemøstlig by, svæver en lille drone kaldet Bendner, imens dens regner på, hvilke personer nær en moske den skal sende hjem til deres skaber.Dronen med seks svirrende rotorer er en billig, nærmest kedelig en af slagsen. Ja, altså, hvis vi ser bort fra dronens software. Den består af det amerikanske militærs mest avancerede kunstige intelligens, som skal gøre dronen i stand til på egen hånd at opsøge, identificere og eliminere fjendtlige enheder.Da Pentagons hemmelighedsfulde udviklingsenhed Darpa sidste sommer demonstrerede en ubevæbnet udgave af den autonome drone, havde Bendner sommetider svært ved at skelne mellem tårnet på moskeen og en bevæbnet mand. Andre gange udpegede dronen ifølge Darpa resolut de rigtige mål.Et andet sted på kloden, ved en storstilet russisk militærmesse sidste år, erklærede våbenproducenten Kalashnikov, at firmaets kunder inden for den nærmeste fremtid kan købe en særlig serie af landbaserede kamprobotter. Med firmaets legendariske 69 år gamle stormgeværsteknik i hånden og på baggrund af neurale netværk er robotterne i stand til egenhændigt at identificere mål, træffe beslutninger og trykke på aftrækkeren, lover Kalashnikov.Den tredje krigsrevolutionDette er blot to eksempler på noget af det nyeste militære isenkram, som offentligheden har fået indblik i. To eksempler, som måske ikke fremstår særligt frygtindgydende sammenlignet med moderne ballistiske missiler og højenergilasere.Men når de to eksempler fra USA og Rusland skiller sig ud, hænger det heller ikke sammen med, hvad der rent faktisk bliver affyret. Det handler om, hvem der bestemmer, hvornår der skal trykkes på aftrækkeren.I begge tilfælde er den beslutning udlagt til en kunstig intelligens (AI): et softwareprogram, som efterligner et eller flere aspekter af den menneskelige intelligens såsom analyse, logik eller udvikling på baggrund af fejl.Kunstig intelligens er i dag så veludviklet, at AI-eksperterne over en bred kam mener, at vi nu befinder os i begyndelsen af den tredje revolution inden for krigsførelse: Først kom krudtet, dernæst atombomben og nu et system, der midt i krigens tåge formår at tænke og reagere mangefold hurtigere end menneskehjernen.Første officielle møder i FN Inden for de seneste to uger har flere forskere og programmører plæderet for aldrig at gøre krigsrobotter komplet autonome. Eller endnu bedre: at vi helt sætter udviklingen af krigsteknologi med AI på pause.Blandt de bekymrede fagfolk er professor Toby Walsh fra New South Wales University, en af verdens mest fremtrædende AI-forskere og talsmand for 50 førende AI-forskere bag en boykot af det prominente sydkoreanske universitet KAIST.Universitetet har indgået et samarbejde om AI med en sydkoreansk våbenproducent, der fremstiller klyngebomber, som FN's krigskonvention ellers har bandlyst brugen af.»Vi bør betragte autonome våben som masseødelæggelsesvåben og ikke mindst føje dem til listen over disse. For en enkelt programmør vil kunne forvolde skader, som tidligere fordrede en helt hær.Krig bliver opskaleret i et hidtil uset omfang,« siger Toby Walsh til Ingeniøren.Han befinder sig i Genève, hvor FN i denne uge for første gang har indkaldt medlemslandene til officielle diskussioner, der kan afgøre de autonome våbens fremtid.Få dage efter forskerboykotten af KAIST blev et..FORTSÆTTES PÅ SIDE 4-5... protestbrev fra 3.100 Googleansatte lækket. De bønfalder itmastodontens øverste chef, Sundar Pichai, om at skrotte projekt Maven: et samarbejde med Pentagon om at benytte Googles AI-mønstergenkendelse til at forbedre droners evne til at udpege trusler.Ikke i nærheden af definition Men et forbud mod autonome våben systemer på slagmarken kræver, at FN's medlemslande rent faktisk kan blive enige om, hvad man gerne vil forbyde.»Vi er ikke i nærheden af en defi-nition, som er tilstrækkeligt holdbar og afgrænset til at kunne danne grundlag for et juridisk forbud. Problemet er, at autonomi i modsætning til eksempelvis miner, klyngebomber eller kemikalier ikke er en håndgribelig ting med bestemte fysiske egenskaber,« siger Iben Yde, ph. d. i folkeret og juridisk rådgiver for Forsvars kommandoen. Hun skrev for to år siden sin afhandling ved Aarhus Universitet om regulering af autonome våben.Ugens møderække i Genève udgør den foreløbige kulmination på, at FN siden 2014 har afholdt multilaterale møder om autonome våben.»Og man har altså siddet i fire år uden at komme i nærheden af en definition af autonome våben. I mandags startede det første af to årlige møder om autonome våbensystemer i FN-regi og her er det tungeste punkt på dagsordenen stadigvæk, at vi skal finde en solid og retvisende arbejdsdefinition, som alle parter kan enes om,« siger Iben Yde.Alle de mest gængse definitioner af autonome våben tager udgangspunkt i det amerikanske forsvarsministeriums direktiv 3000.09 fra 2014. Her defineres et autonomt våben ved, at det efter aktivering ikke er underlagt menneskelig kontrol.Problemet med den definition er, at den dækker en lang række allerede anvendte miner, torpedoer og missiler, der selv kan angribe specifikke mål eller måltyper uden menneskelig indblanding. Derfor har det amerikanske forsvarsministerium undtaget en masse våbensystemer fra direktivet.»Så man famler sig frem og retter opmærksomheden mod våbensystemer, som ikke er underlagt menneskelig kontrol efter affyring, men det omfatter i princippet en række eksisterende våbentyper, der ikke betragtes som ulovlige,« siger Iben Yde.»Derfor vil man i FN få ufatteligt svært ved at få alle stater til at enes om en definition. For der vil i alle tilfælde være lande, hvis våbensystemer bliver ramt af definitioner så brede som dem, der er på bordet lige nu. Og de vil sandsynligvis ikke gå med til at begrænse deres råderum yderligere,« siger Iben Yde.Vi får aldrig alle medHos Center for Militære Studier på Københavns Universitet vurderer seniorforsker Gary Schaub, at et internationalt forbud mod bevæbnet AI aldrig kommer til at se dagens lys.»Ikke alene vil verdens supermagter ikke tilslutte sig et forbud.Mange andre stater vil også se autonomi som en oplagt mulighed for at skyde genvej til et militært topniveau,« siger Gary Schaub.Han er forfatter til den første danske rapport om autonome våben, som blev udgivet i 2016. Han vurderer ligesom Iben Yde, at selv en fælles definition af autonome våben har lange udsigter.»Især fordi kapaciteten til at behandle og distribuere data gradvis ændrer det, der kan defineres som autonomt. Fra en enkelt enhed som en kampvogn eller en drone til et netværk af enheder, der hver for sig ikke er autonome, men som i fællesskab kan blive det,« siger Gary Schaub.Meningsfuld kontrolDerfor er man i FN nu også begyndt at kigge i retning af, hvordan man bedst muligt kan tøjle kamprobotterne.Fagtermen er meningsfuld menneskelig kontrol, og den har inden for de seneste år vundet indpas i den akademiske debat om autonome våben.»Frem for et forbud giver det mening at diskutere, hvordan vi kan indrette kontrollen med autonome systemer, så vi sikrer os, at våbnene bliver brugt inden for de regler, som vi allerede har i blandt andet Genèvekonventionerne.Og nu ser det endelig ud til, at man begynder at kigge mere den vej i FN,« siger Iben Yde.Et eksempel kunne være en drone, som er forprogrammeret til at afsøge et område og angribe eventuelle mål på egen hånd. En kapacitet, som står højt på flere landes militære ønskelister.»Hvis dronen bare skal finde fjender, bliver det meget svært. For det er svært for et våbensystem at skelne mellem en kombattant og en civil. Man kan derimod sætte dronen til specifikt at finde pansrede køretøjer eller radarsystemer, som kan identificeres på baggrund af objektive kriterier såsom størrelse, vægt eller termisk profil, og som er lovlige mål ifølge folkeretten,« siger Iben Yde.»Så det er min vurdering, at den slags systemer bedst kan anvendes på meget stramt afgrænsede måltyper. Det kan godt gøres uden menneskelig overvågning, men man bliver nødt til at have en mekanisme, så det autonome system beder om en menneskelig revurdering af opgaven, hvis målet afviger fra, hvad det er programmeret til at ramme. For eksempel hvis der dukker civile op i målområdet,« siger Iben Yde.En måske urealistisk opgave Samtlige tilhængere af et forbud mod autonome våben, som Ingeniøren har talt med, medgiver, at de er på en måske urealistisk opgave.For professor ved Lancaster University Lucy Suchman, som forsker i designet af autonome våbensystemer og er medlem af International Committee for Robot Arms Control, er det imidlertid afgørende, at verdenssamfundet ikke accepterer et eskalerende AI-våbenkapløb.Hun peger på, at FN's medlemslande tidligere er blevet enige om et forbud mod landminer, kemiske våben og atomvåben. Og selvom disse forbud bliver brudt og omgået, har de alligevel en vigtig funktion.»De har skabt en norm, der har begrænset brugen af disse våben.Det er altafgørende at gøre det samme med AI-våben,« siger hun.TRE EKSEMPLER PÅ AUTONOME VÅBENAEGIS COMBAT SYSTEM Kampsystemet Aegis, som udgør it-rygraden i Natos ballistiske missilforsvar, kan selv identificere og nedskyde fjendtlige ballistiske missiler.Når Aegis er koblet sammen med et Phalanx-nærforsvarssystem med maskinkanon, kan det også nedskyde fjendtlige fly. Den menneskelige operatør kan som udgangspunkt underkende systemets beslutning om at angribe, men Aegis kan også fungere i casualty mode, hvor det antager, at operatøren er forhindret i at betjene systemet, og derfor selv træffer beslutning om at skyde.SGR-A1Sydkoreanske Samsungs intelligente vagttårn SGR-A1 bevogter i dag den demilitariserede zone mellem Nord-og Sydkorea. SGR-A1 kan selv identificere mål inden for 3,2 kilometer og kan enten reagere med en høj alarm, ikkedræbende gummikugler, et 5.56 x 45 maskingevær eller en granatkaster. Et lignende system i form af det israelske SentryTech er placeret langs grænsen til Gazastriben.SEA HUNTERSea Hunter fra Pentagons udviklingsenhed Darpa er udviklet til autonom ubådsjagt og elektronisk krigsførelse.Det ubemandede skib scanner havet under sig, og finder den et mål, kan den selv udpege fjendens mest sårbare punkter og indlede et angreb.Dog kan den ikke foretage angreb uden grønt lys fra et menneske. Sea Hunter har netop afsluttet et toårigt testforløb og er principielt klar til operativ tjeneste.
        </div>
        <footer>
          <em>Ingeniøren</em>
          &nbsp;·&nbsp; 2018-04-13
          &nbsp;·&nbsp; e6b379ee
          &nbsp;·&nbsp; #6
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.965</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.618</kbd>
        </footer>
      </article>
      <article>
        <h4>Har de selvstyrende kamprobotter allerede vundet krigen?</h4>
        <div>
          Regulering af våben styret af kunstig intelligens kuldsejler, fordi teknologien i sig selv ikke er et våben. Imens fortsætter det globale våbenkapløb, hvor autonome krigssystemer selv udvælger og eliminerer mål.I luftrummet over et amerikansk militært testområde, der ligner en mellemøstlig by, svæver en lille drone kaldet Bendner, imens den regner på, hvilke personer nær en moske den skal sende hjem til deres skaber.Dronen med seks svirrende rotorer er en billig, nærmest kedelig en af slagsen. Ja, altså, hvis vi ser bort fra dronens software. Den består af det amerikanske militærs mest avancerede kunstige intelligens, som skal gøre dronen i stand til på egen hånd at opsøge, identificere og eliminere fjendtlige enheder.Da Pentagons hemmelighedsfulde udviklingsenhed Darpa sidste sommer demonstrerede en ubevæbnet udgave af den autonome drone, havde Bendner sommetider svært ved at skelne mellem tårnet på moskeen og en bevæbnet mand. Andre gange udpegede dronen ifølge Darpa resolut de rigtige mål.Et andet sted på kloden, ved en storstilet russisk militærmesse sidste år, erklærede våbenproducenten Kalashnikov, at firmaets kunder inden for den nærmeste fremtid kan købe en særlig serie af landbaserede kamprobotter. Med firmaets legendariske 69 år gamle stormgeværsteknik i hånden og på baggrund af neurale netværk er robotterne i stand til egenhændigt at identificere mål, træffe beslutninger og trykke på aftrækkeren, lover Kalashnikov.Den tredje krigsrevolutionDette er blot to eksempler på noget af det nyeste militære isenkram, som offentligheden har fået indblik i. To eksempler, som måske ikke fremstår særligt frygtindgydende sammenlignet med moderne ballistiske missiler og højenergilasere.Men når de to eksempler fra USA og Rusland skiller sig ud, hænger det heller ikke sammen med, hvad der rent faktisk bliver affyret. Det handler om, hvem der bestemmer, hvornår der skal trykkes på aftrækkeren.I begge tilfælde er den beslutning udlagt til en kunstig intelligens (AI): et softwareprogram, som efterligner et eller flere aspekter af den menneskelige intelligens såsom analyse, logik eller udvikling på baggrund af fejl.Kunstig intelligens er i dag så veludviklet, at AI-eksperterne over en bred kam mener, at vi nu befinder os i begyndelsen af den tredje revolution inden for krigsførelse: Først kom krudtet, dernæst atombomben og nu et system, der midt i krigens tåge formår at tænke og reagere mangefold hurtigere end menneskehjernen.Første officielle møder i FNInden for de seneste to uger har flere forskere og programmører plæderet for aldrig at gøre krigsrobotter komplet autonome. Eller endnu bedre, at vi helt sætter udviklingen af krigsteknologi med AI på pause.Blandt de bekymrede fagfolk er professor Toby Walsh fra New South Wales University, en af verdens mest fremtrædende AI-forskere og talsmand for 50 førende AI-forskere bag en boykot af det prominente sydkoreanske universitet KAIST.Universitetet har indgået et samarbejde om AI med en sydkoreansk våbenproducent, der fremstiller klyngebomber, som FN-s krigskonvention ellers har bandlyst brugen af.»Vi bør betragte autonome våben som masseødelæggelsesvåben og ikke mindst føje dem til listen over disse. For en enkelt programmør vil kunne forvolde skader, som tidligere fordrede en helt hær. Krig bliver opskaleret i et hidtil uset omfang,« siger Toby Walsh til Ingeniøren.Han befinder sig i Genève, hvor FN i denne uge for første gang har indkaldt medlemslandene til officielle diskussioner, der kan afgøre de autonome våbens fremtid.Få dage efter forskerboykotten af KAIST blev et protestbrev fra 3.100 Google-ansatte lækket. De ansatte bønfalder it- mastodontens øverste chef, Sundar Pichai, om at skrotte projekt Maven: et samarbejde med Pentagon om at benytte Googles AI-mønstergenkendelse til at forbedre droners evne til at udpege trusler.Ikke i nærheden af definitionMen et forbud mod autonome våbensystemer på slagmarken kræver, at FN-s medlemslande rent faktisk kan blive enige om, hvad man gerne vil forbyde.»Vi er ikke i nærheden af en definition, som er tilstrækkeligt holdbar og afgrænset til at kunne danne grundlag for et juridisk forbud. Problemet er, at autonomi i modsætning til eksempelvis miner, klyngebomber eller kemikalier ikke er en håndgribelig ting med bestemte fysiske egenskaber,« siger Iben Yde, ph.d. i folkeret og juridisk rådgiver for Forsvarskommandoen. Hun skrev for to år siden sin afhandling ved Aarhus Universitet om regulering af autonome våben.Ugens møderække i Genève udgør den foreløbige kulmination på, at FN siden 2014 har afholdt multilaterale møder om autonome våben.»Og man har altså siddet i fire år uden at komme i nærheden af en definition af autonome våben. I mandags startede det første af to årlige møder om autonome våbensystemer i FN-regi, og her er det tungeste punkt på dagsordenen stadigvæk, at vi skal finde en solid og retvisende arbejdsdefinition, som alle parter kan enes om,« siger Iben Yde.Alle de mest gængse definitioner af autonome våben tager udgangspunkt i det amerikanske forsvarsministeriums direktiv 3000.09 fra 2014. Her defineres et autonomt våben ved, at det efter aktivering ikke er underlagt menneskelig kontrol. Problemet med den definition er, at den dækker en lang række allerede anvendte miner, torpedoer og missiler, der selv kan angribe specifikke mål eller måltyper uden menneskelig indblanding. Derfor har det amerikanske forsvarsministerium undtaget en masse våbensystemer fra direktivet.»Så man famler sig frem og retter opmærksomheden mod våbensystemer, som ikke er underlagt menneskelig kontrol efter affyring, men det omfatter i princippet en række eksisterende våbentyper, der ikke betragtes som ulovlige,« siger Iben Yde.»Derfor vil man i FN få ufatteligt svært ved at få alle stater til at enes om en definition. For der vil i alle tilfælde være lande, hvis våbensystemer bliver ramt af definitioner så brede som dem, der er på bordet lige nu. Og de vil sandsynligvis ikke gå med til at begrænse deres råderum yderligere,« siger Iben Yde.Vi får aldrig alle medHos Center for Militære Studier på Københavns Universitet vurderer seniorforsker Gary Schaub, at et internationalt forbud mod bevæbnet AI aldrig kommer til at se dagens lys.»Ikke alene vil verdens supermagter ikke tilslutte sig et forbud. Mange andre stater vil også se autonomi som en oplagt mulighed for at skyde genvej til et militært topniveau,« siger Gary Schaub.Han er forfatter til den første danske rapport om autonome våben, som blev udgivet i 2016. Han vurderer ligesom Iben Yde, at selv en fælles definition af autonome våben har lange udsigter.»Især fordi kapaciteten til at behandle og distribuere data gradvis ændrer det, der kan defineres som autonomt. Fra en enkelt enhed som en kampvogn eller en drone til et netværk af enheder, der hver for sig ikke er autonome, men som i fællesskab kan blive det,« siger Gary Schaub.Meningsfuld kontrolDerfor er man i FN nu også begyndt at kigge i retning af, hvordan man bedst muligt kan tøjle kamprobotterne. Fagtermen er meningsfuld menneskelig kontrol, og den har inden for de seneste år vundet indpas i den akademiske debat om autonome våben.»Frem for et forbud giver det mening at diskutere, hvordan vi kan indrette kontrollen med autonome systemer, så vi sikrer os, at våbnene bliver brugt inden for de regler, som vi allerede har i blandt andet Genèvekonventionerne. Og nu ser det endelig ud til, at man begynder at kigge mere den vej i FN,« siger Iben Yde.Et eksempel kunne være en drone, som er forprogrammeret til at afsøge et område og angribe eventuelle mål på egen hånd. En kapacitet, som står højt på flere landes militære ønskelister.»Hvis dronen bare skal finde fjender, bliver det meget svært. For det er svært for et våbensystem at skelne mellem en kombattant og en civil. Man kan derimod sætte dronen til specifikt at finde pansrede køretøjer eller radarsystemer, som kan identificeres på baggrund af objektive kriterier såsom størrelse, vægt eller termisk profil, og som er lovlige mål ifølge folkeretten,« siger Iben Yde.»Så det er min vurdering, at den slags systemer bedst kan anvendes på meget stramt afgrænsede måltyper. Det kan godt gøres uden menneskelig overvågning, men man bliver nødt til at have en mekanisme, så det autonome system beder om en menneskelig revurdering af opgaven, hvis målet afviger fra, hvad det er programmeret til at ramme. For eksempel hvis der dukker civile op i målområdet,« siger hun.
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2018-04-13
          &nbsp;·&nbsp; e6b3c82f
          &nbsp;·&nbsp; #7
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.909</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.618</kbd>
        </footer>
      </article>
      <article>
        <h4>TILHØRER FREMTIDENS LUFTRUM KAMPFLY ELLER DRONER?</h4>
        <div>
          Alt imens valget af Danmarks næste kampfly nærmer sig, undergår markedet for militære droner en rivende udvikling, der åbner mulighed for, at fjernbetjente droner inden længe bliver tilstrækkeligt avancerede til at kunne erstatte bemandede kampfly.Antallet af militære droner på verdensplan er eksploderet efter terrorangrebene i New York og Washington i september 2001, og droner overtager stadigt flere traditionelle kampflyopgaver, herunder bevæbnede operationer som luftstøtte og luft-til-jord-angreb.Et kendt eksempel er Natos brug af luftmagt i Afghanistan, hvor fem procent af alle amerikanske og britiske luftangreb i 2011 blev udført af droner. Allerede i januar 2013 var andelen oppe på 23 procent, viser en rapport fra Forsvarsakademiet fra samme år.Og bestræbelserne på at udvikle kampdroner, der kan overtage traditionelle kampflyopgaver, fortsætter med uformindsket styrke. Sidste år gennemførte US Navy for første gang operationer med en kombination af kampfly og den hangarskibsbaserede drone X-47B. Den er det nyeste medlem af den såkaldte UCAV-klasse (Unmanned Combat Aerial Vehicle), som også omfatter kampdronerne i det amerikanske luftvåbens Hunter-Killer-program, MQ-9 Reaper og MQ-1 Predator.Udviklingen har affødt diskussioner om de bemandede kampflys fremtid i USA, hvor Pentagon og Lockheed Martin i øjeblikket udvikler femtegenerations kampflyet F-35. Også herhjemme, hvor forsvarsforligskredsen inden længe skal vælge F-35, F/ A-18 eller Euro-fighter som afløseren for Flyvevåbnets F-16, har politikere og debattører rejst spørgsmålet om, hvorvidt Danmarks største forsvarsinvestering til dato bør gå til bemandede fly, der risikerer at blive forældede inden for deres 30-årige levetid.Ingeniøren har derfor spurgt fem af de førende specialister i militær luftfart i Danmark, USA, Canada og Storbritannien, om det er sandsynligt, at kampdroner bliver avancerede nok til at erstatte bemandede kampfly inden for levetiden af Danmarks næste kampfly.Mangler situationsoverblikSamtlige eksperter svarer, at kampfly ikke inden for de næste 15 til 20 år vil møde nogen seriøs konkurrence fra droner. Flertallet vurderer også, at bemandede kampfly stadig om 30 år vil være overlegne på en række afgørende parametre.Den afgørende taktiske forskel mellem UCAV'er og kampfly er ifølge de fleste eksperter det situationsoverblik, såkaldt situational awareness, der følger med kampflypiloters udsyn på op til 360 grader samt informationer fra pilotens øvrige sanser - kontra drone piloters begrænsede, kamerabaserede udsyn.Lektor ved Center for War Studies på Syddansk Universitet Jens Ringsmose, som står bag Forsvarsakademiets rapport om droner fra 2013, konkluderer ligefrem, at en drone aldrig vil kunne operere lige så effektivt som et bemandet kampfly - uanset antallet af sensorer og kvaliteten af satellitforbindelsen mellem operatør og drone.»Der er nogle faktorer, der tilsiger, at droner aldrig vil kunne helt det samme som de konventionelle kampfly. Det er blandt andet situational awareness - det forhold, at man som pilot er til stede og har det fulde udsyn,« siger han til Ingeniøren.Samme melding lyder fra Richard Aboulafia, der er vicedirektør i analysevirksomheden Teal Group og rådgiver inden for militær luftfart.Han vurderer, at UCAV'er som X-47B har stort potentiale inden for konventionel krig, hvor målene er let identificerbare, og operationerne handler om at nedkæmpe alle fjendtlige stillinger hurtigst muligt.Men internationale operationer handler i dag mere om at håndhæve flyveforbudszoner eller gennemføre afgrænsede angreb mod autoritære regimer, oprørsstyrker eller pirater. Her er situationsoverblik afgørende, og der er lange udsigter til, at sensorer og datalinks kan levere det fornødne overblik for dronepiloter, siger han.»Jeg tror derfor ikke på, at UCAV'er vil tage rollen som kampfly fra bemandede fly inden for de næste årtier,« siger Richard Aboulafia til Ingeniøren.Usikker besparelseEt hyppigt argument for at satse på droner er, at de udgør et billigere alternativ til bemandede kampfly, hvad angår både anskaffelsespris, brændstofforbrug og pilotuddannelser.Der er gjort enkelte forsøg på systematisk at sammenligne omkostninger for droner og bemandede kampfly, men sammenligningen er vanskelig, idet de ikke kan løse de samme typer af opgaver. Resultaterne er heller ikke entydige, men de indikerer, at dronerne generelt er en anelse billigere end kampfly. Det skal imidlertid holdes op imod, at kampfly kan udføre langt flere opgavetyper end droner, skriver Jens Ringsmose i Forsvarsakademiets dronerapport fra 2013.På den ene side viser erfaringerne fra Irak, Afghanistan og Libyen, at droner kan udføre kampflyopgaver som overvågning og rekognoscering billigere i områder med lav lufttrussel. Men der vil gå mange år, før droner kan håndhæve et magtmonopol i luften eller operere i områder med mere end ' meget lav' eller ' ingen' trussel mod fly, konkluderer Jens Ringsmose. Derfor er indsættelsen af droner stadig afhængig af, at kampfly i forvejen har etableret luftherredømme i missionsområdet.Kampfly er eksempelvis sværere bevæbnet end UCAV'er, hvilket gør kampflyene i stand til at løse et bredere spektrum af opgaver. Ifølge en opgørelse fra det amerikanske luftvåben er Reaper-droner i stand til at bære maksimalt to af de laserstyrede bomber GBU-38 eller GBU-12 på hver 500 pund, svarende til 227 kilo, sammen med fire mindre AGM-114 Hellfire-missiler. Til sammenligning er F-16 i stand til at medbringe to 2.000-punds bomber sammen med to AIM-9 Side windermissiler og to AIM-120 AMRAAM-missiler.Oven i anskaffelsesprisen for UCAV'er kommer også høje omkostninger til logistik og bemanding. I 2011 konkluderede den amerikanske kongres' budgetkontor, at droner sammenfattende ikke har indfriet de høje forventninger til besparelser, selv om anskaffelsesprisen er lavere for droner end for kampfly. Det skyldes ikke mindst, at besparelsen bliver udlignet eller reduceret af høje udgifter til dronernes logistikog støttestruktur.Et eksempel er, at Natos drift af de store RQ-4 Global Hawks kræver mindst 100 årsværk per drone i fredstid, hvilket Jens Ringsmose sammenligner med, at det danske flyvevåben opererer med 15 til 25 årsværk per F-16 i fredstid.En rapport fra det britiske forsvarsministerium konkluderede også i 2011, at der ikke er udsigt til betydelige besparelser ved kampdroner, idet priserne på de største UCAV'er vil vokse hurtigere end priserne på kampfly i de kommende år. Prisen på X-47B, som endnu er omkring 10 år fra produktionsfasen, er stadig ukendt, men den bliver ifølge Jens Ringsmose sandsynligvis ikke meget lavere end prisen på et F-35, eftersom en kampdrone kræver nogenlunde samme skrog, motorer, sensorer, pilot-interface og software som et kampfly. Derudover kræver alle større droner ekstraomkostninger i form af adgang til satellitkommunikation og beskyttet båndbredde. Dermed bortfalder det økonomiske rationale bag UCAV'erne, konkluderer Jens Ringsmose.Ringe manøvredygtighed og reaktionstidDronerne halter også stadig efter de bemandede kampfly, hvad angår fart og manøvredygtighed. Det amerikanske forsvars MQ-9 Reaper præsterer en topfart på 440 km/ h og kan manøvrere med en tyngdepåvirkning på 2 g. F-16 præsterer til sammenligning 2.000 km/ h og trækker op til 9 g. Samtidig er eksisterende UCAV'er lette at opdage med selv mindre avancerede radarer. For en modstander med bare et minimum af antiluftskyts eller kampflykapacitet er UCAV'er derfor lette at nedkæmpe, konkluderer Jens Ringsmose sammen med lektor Anders Henriksen fra Det Juridiske Fakultet ved Københavns Universitet i en anden rapport om droner fra Dansk Institut for Internationale Studier fra 2013.Mange brancheanalytikere forventer imidlertid, at fremtidige droner vil kunne foretage manøvrer, der ikke ville være mulige med et menneske om bord. Af samme årsag vurderer Michael Byers, professor ved University of British Columbia og forfatter til en række bøger om forsvarspolitik, som den eneste af de fem eksperter, Ingeniøren har talt med, at droner vil overflødiggøre bemandede kampfly inden for næste kampflygenerations levetid.»Droneteknologi kan inden længe gøre kampfly til en forældet platform, eftersom menneskets evne til at modstå g-kræfter udgør den primære begrænsning på kampflys manøvredygtighed. Udviklingens hastighed er naturligvis usikker, men ser vi på droneudviklingen de seneste 30 år, virker det sandsynligt, at de tilbageværende teknologiske forhindringer kan overvindes inden for en tilsvarende periode,« siger Michael Byers.UCAV'er har imidlertid et andet afgørende handicap: De bliver styret via satellitkommunikation. Det betyder, at de reagerer på kommandoer med mellem 1,2 og 2 sekunders forsinkelse. Samtidig går datalinkforbindelsen jævnligt tabt. UCAV'er som Predator og Reaper slår automatisk ind på en forprogrammeret rute, når forbindelsen afbrydes, hvilket ikke har store konsekvenser i Afghanistan, hvor Nato har det fulde luftherredømme, siger Jens Ringsmose. Men i mødet med kampfly eller missilforsvarssystemer overlever en drone ikke med en forsinket reaktionstid på et par sekunder eller ved at slå ind på en forprogrammeret kurs, hvis satellitforbindelsen ryger.»Dronerne skal stadig styres via satellit, og det giver et timelapse på mindst 1,2 sekunder. Hvis en drone bliver involveret i en dogfight med et kampfly, er det derfor klart, at dronen er ilde stedt,« siger han.Wingman for kampflySamme melding lyder fra Elizabeth Quintana, seniorforsker og direktør for Military Sciences Department ved den britiske forsvarstænketank Royal United Services Institute.»Det er udelukket, at fjernbetjente fly vil erstatte kampfly i luft-til-luftkamp eller i afvisningsberedskab. UCAV'er er ikke tilstrækkeligt manøvredygtige til at konkurrere med kampfly, og selv hvis de var, er over et sekunds forsinkelse mellem operatørinput og respons tilstrækkeligt lang tid til, at de bliver skudt ned, før de kan nå at reagere,« siger hun.Det forhold kan ændre sig i takt med, at luftkampe på grund af øget radar-og missilrækkevidde bevæger sig væk fra de kendte dogfights.F-35 markedsføres eksempelvis som et kampfly, der kan lave såkaldte over-the-horizon-angreb. Luftkampe over store afstande stiller imidlertid nye krav til UCAV'ernes datalink, siger George Petrolekas, forsker ved Canadian Global Affairs Institute, tidligere oberst og rådgiver for Nato angående ISAF-missionerne.»Det er helt udelukket, at droner med forsinket reaktionstid kan vinde dogfights. Hvis luftkampe derimod foregår uden visuel kontakt, og dogfights bliver en mindre benyttet taktik, kan UCAV'er naturligvis godt bruges til at affyre missiler, hvis de har radarkapacitet til at låse på fjendtlige fly. Men det kræver til gengæld en enorm dataudveksling, idet vi stadig skal have et menneske til at trykke på aftrækkeren, særligt i områder med mange civile,« siger George Petrolekas.Forligskredsens valg af nyt kampfly skal senest være på plads i foråret 2016. Imens barsler US Navy med planer om at udvikle en ny hangarskibsbaseret UCAV på størrelse med et F-14 Tomcat, som skal være i stand til at bære AMRAAM-missiler og dermed til at angribe kampfly. Eftersom de fornødne sensorer og algoritmer til at udmanøvrere kampflyene endnu er uden for rækkevidde, tiltænker US Navy dog kun den nye UCAV en rolle som wingman for bemandede kampfly.En X-47B-drone i luften over hangarskibet USS George H. W. Bush under en øvelse i Atlanterhavet. X-47B er et eksempel på den klasse af såkaldte Unmanned Combat Aerial Vehicles (UCAV), som har ført til debat om fremtiden for bemandede kampfly.Jeg tror ikke på, at UCAV'er vil tage rollen som kampfly fra bemandede fly inden for de næste årtier.RICHARD ABOULAFIA, VICEDIREKTØR, ANALYSEVIRKSOMHEDEN TEAL GROUP Ser vi på droneudviklingen de seneste 30 år, virker det sandsynligt, at de tilbageværende teknologiske forhindringer kan overvindes inden for en tilsvarende periode.MICHAEL BYERS, PROFESSOR, UNIVERSITY OF BRITISH COLUMBIA.KAMPDRONERBedst egnet til konventionel krig med let identificerbare mål. Kræver luftherredømme i missionsområdet, etableret af kampfly.-Kamerabaseret, begrænset situationsoverblik. -Reagerer på ' pilotens' kommandoer med en forsinkelse på 1,2 til 2 sekunder grundet satellitlink.KAMPFLY Egnet til bl. a. håndhævelse af flyveforbudszoner, angreb mod autoritære regimer, oprørsstyrker eller pirater.+ 360 graders overblik fra pilotens syn og øvrige sanser. + Piloten kan reagere uden forsinkelse. F-16 Topfart: 2.000 km/ h Tyngdepåvirkning: op til 9 g Våben: to 2.000-punds bomber, to AIM-9 Sidewindermissiler og to AIM-120 AMRAAM-missiler. MQ-9 REAPER Topfart: 440 km/ h Tyngdepåvirkning: højst 2 g Våben: højst to laserstyrede GBU-38-eller GBU-12-bomber på hver 500 pund, samt fire mindre AGM-114 Hellfiremissiler.
        </div>
        <footer>
          <em>Ingeniøren</em>
          &nbsp;·&nbsp; 2015-12-18
          &nbsp;·&nbsp; e56b0c0a
          &nbsp;·&nbsp; #8
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.736</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.618</kbd>
        </footer>
      </article>
      <article>
        <h4>Lapper sig selv sammen: Så vanvittigt er fremtidens kampfly</h4>
        <div>
          Kampfly, der kan reparere sig selv i luften. 3D-printere om bord på flyene, der kan printe små droner ud og kaste dem direkte ind i luftkamp mod fjendtlige fly. Det lyder måske som fjern fremtid, men det kan meget vel blive virkelighed om bare 15-20 år.Ledende forskere og opfindere i det amerikanske forsvars tophemmelige forskningsenhed Darpa er gået i gang med at slå de første streger til det, der skal blive USA-s næste avancerede kampfly omkring år 2030.Samtidig undersøger flere af verdens største våbenproducenter, hvad der kan opfindes af nye teknologier. For dem handler det om at være først med det våben eller den teknologi, som USA bare må have med på sine nye fly.For Darpa og det amerikanske forsvar arbejder ikke blot med at udvikle et sjette-generations fly   men hele to: F/A-XX Next Generation Air Dominance fighter til flåden og F-X Next Generation Tactical Aircraft til flyvevåbenet.Lukker lynhurtigt skudhullerBritiske Bae Systems har tænkt nogle af de vildeste tanker. De pusler med med idéen om, at kampflyene reparerer sig selv og forestiller sig, at flyet er bygget af nanorør i kulfiber. Inde i rørene er en letvægtsvæske, som siver ud og lynhurtigt lukker skudhuller.Teknologien skal gøre det muligt for flyene at fortsætte kampen, selv om de bliver ramt og flyskroget gennemhulles. Dermed bliver fremtidens kampfly i stand til at angribe fjender i situationer, hvor nutidens fly ikke har en chance.Den store amerikanske flyproducent har leveret flere bud på hvordan fremtidens kampfly til US Navy kunne se ud. (Foto: Boeing)Idéen med 3D-printere om bord på flyene kommer også fra Bae Systems. De små droner kan printes og spyttes ud af bunden af flyet, hvis det brænder på. Så kan de hjælpe med at gå til angreb på en særlig genstridig fjende. Hvis der er mange fjendtlige mål i både luften og på jorden, skal dronerne kaste sig over hvert sit mål, mens piloten i flyet koncentrerer sig om luftkamp med andre fly. Bagefter kan dronerne enten selv-destruere eller returnere til basen og genbruges. Nu er de jo printet ...Et kobbel af dronerEksperterne regner ikke med, at droner fuldstændig skal overtage kampflyets opgaver. I hvert fald ikke i denne omgang. Men Darpa leger med tanken om et helt kobbel af droner, som styres af en operatør på jorden eller fra et bemandet fly.Dronerne skal overvåge situationen og sende anbefalinger tilbage til operatøren om, hvad der bør gøres. Han kan så vælge at følge dronernes anbefalinger, afvise dem eller bede dronerne indsamle flere informationer.Dronerne kan være selvstændige enheder, som selv flyver eller styres ud i krigszonen. Men dronerne kan også være en del af flyet, så flyet kan dele sig i tre dele, der flyver videre hver for sig. Det kan være en drone, der bliver til tre. Det kan også være et fly, der bliver til to droner og et bemandet fly.Det bemandede fly udfører så en krævende bombemission eller lignende, mens dronerne afpatruljerer luftrummet og holder fjenderne på afstand. Når turen går hjemad, samles de tre enheder og flyver tilbage som en enhed.Kunstig intelligensDe Georg Gearløs-typer, som er gået i gang med at omsætte de vilde fantasier til virkelighed, mener, at der også i den næste generation af kampfly skal være plads til en pilot   hvis den konkrete mission kræver det. Er det en særlig farlig mission, hvor der skal bombes langt inde i fjendeland, kan det måske være bedre at sende flyet af sted ubemandet.Er der derimod udsigt til luftkamp med fjendtlige fly, eller er der tale om en særlig avanceret mission, kan man vælge at bemande flyet.I takt med at nye kampfly bliver mere og mere avancerede og kan flere og flere ting, tager arbejdsopgaverne opmærksomheden væk fra selve flyvningen. En computer-copilot er derfor også på ønskesedlen til det nye kampfly. Med kunstig intelligens skal flyet være i stand til -selv- at tage sig af den mere rutinepræget flyvning.Computer-copiloten kan styre flyet i formation med ubemandede fly, der styres fra jorden.Stråle af energiFremtidens kampfly får nye våbentyper. En af dem kunne være en koncentreret stråle af energi, som sendes mod fjendtlige missiler og fly med lysets hastighed og med stor præcision. En anden mulighed kunne være store, langtrækkende missiler.Dermed kan flyet bedre helt undgå at komme inden for skudhold for fjenden. I bedste fald har det affyret sine missiler, inden fjenden overhovedet har opdaget flyet.Den store amerikanske flyproducent har leveret flere bud på hvordan fremtidens kampfly til US Navy kunne se ud. (Foto: Boeing)Missilerne vil dog kræve mere plads i flyets bug og under vingerne. Flere eksperter forudser derfor, at fremtidens kampfly bliver større end i dag. Mere i retning af et stort, strategisk bombefly end de små og lette manøvredygtige fly. Et større fly vil have plads til en større radar og større brændstoftanke. Dermed kan flyet starte længere væk fra kamppladsen uden at lufttanke.Uden halerorDe tre store amerikanske producenter af militært isenkram, Boeing, Lockheed Martin og Northrop Grumman grubler også over, hvordan næste generations kampfly skal se ud.Northrop Grumman arbejder med tanken om et supersonisk kampfly uden det traditionelle haleror   en løsning man kender fra bombeflyet B-2.Boeing og Lockheed Martin har også sat deres tophemmelige særlige udviklingsafdelinger, Phantom Works og Skunkworks, i sving. Det er her, de første streger til mange af både historiens og nutidens kampfly er blevet slået.Især Skunk Works har igen og igen leveret nye banebrydende flytyper. Det var her, man i 1960-erne udviklede CIA-s spion-fly SR-71 Blackbird, der den dag i dag har rekorden som verdens hurtigste fly med en hastighed på 3529,6 kilometer i timen.Hvis det bli'r nødvendigt...Det amerikanske flyvevåben, US Air Force, og den amerikanske flåde, US Navy, får i disse år de helt nye F-35 Lightning II Joint Strike Fighter-kampfly, som verdens største våbenproducent, Lockheed Martin, har udviklet.Det såkaldte femte-generations kampfly skal de kommende år erstatte en stribe ældre fly i det amerikanske forsvar, men Darpa har allerede tidligere i år fået de første millioner til at starte udviklingen af nye sjette-generations kampfly. Det skete, inden F-35 overhovedet har været i krig og luftkamp.Et fly, der er væsentligt større end de kampfly vi kender i dag. Det er buddet på fremtidens kampfly fra Lockheed Martin, der også står bag F-16 og F-35. (Foto: Lockheed Martin.)Men opfindelse og udvikling af nye kampfly tager mange år. Ikke mindst fordi de helst skal kunne holde sig på vingerne i 30 år eller mere. Flyene skal være så avancerede som muligt, så USA kan klare sig mod de bedste og nyeste kinesiske kampfly   hvis det en dag bliver nødvendigt.
        </div>
        <footer>
          <em>EkstraBladet.dk/Ekstra</em>
          &nbsp;·&nbsp; 2015-07-25
          &nbsp;·&nbsp; e5232a50
          &nbsp;·&nbsp; #9
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.891</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.744</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.661</kbd>
        </footer>
      </article>
      <article>
        <h4>Selvstyrende dræberrobotter udløser global bekymring, protester og boykot</h4>
        <div>
          Google-ansatte protesterer mod krigsprojekt med det amerikanske forsvar, og forskere opfordrer til boykot af sydkoreansk universitet, der udvikler intelligente krigsmaskiner.En solbrillebærende og læderjakkeklædt Arnold Schwarzenegger vandrer målrettet gennem politistationens snævre gange, mens han sender byger af bly mod de sagesløse betjente, der står mellem ham og hans mål: Sarah Connor. Ingen samvittighed, ingen mådehold, kun kold kalkule: Find, dræb.Da -Terminator--filmen kom ud i 1984, var ideen om en dræberrobot, som den T-800 Model 101 Arnold Schwarzenegger portrætterede, ren science fiction. Og selv om menneskemaskiner på to ben med moderigtige læderjakker og dræberinstinkt formentlig stadig ligger langt ude i fremtiden, er der ikke længere tvivl om, at dræberrobotterne er på vej.USA, Kina, Rusland, Israel og England fører an i udviklingen af mere eller mindre selvstyrende krigsmaskiner. Droner, jagerfly, tanks og ubåde med potentiale til at ødelægge og slå ihjel uafhængigt af deres menneskelige opfindere.Udviklingen vækker stor bekymring verden over, og derfor mødes mere end 80 lande og adskillige interesseorganisationer i denne uge i Genève til FN-s konference om konventionelle våben for at diskutere dødelige selvstyrende våben - de såkaldte dræberrobotter.Debatten om dræberrobotter har taget fart de senere år. Forskere, eksperter og techikoner anført af prominente navne som Elon Musk og den nu afdøde Stephen Hawking har flere gange offentligt efterspurgt et forbud mod at udvikle og bruge selvstyrende krigsrobotter.Senest opfordrede mere end 50 forskere i kunstig intelligens til boykot af det sydkoreanske universitet Kaist, fordi universitetet samarbejder med en sydkoreansk virksomhed om at udvikle våbensystemer med kunstig intelligens.Og i onsdags kunne avisen The New York Times præsentere et internt brev sendt af flere end 3.000 Google-ansatte til Googles øverste chef, Sundar Pichai. I brevet tryglede de ansatte direktøren om at annullere Googles aftale om at udvikle intelligente overvågnings- og måludvælgelsessystemer for det amerikanske forsvar.»At skabe denne teknologi til at hjælpe den amerikanske regering med militær overvågning - med potentielt dødelige konsekvenser - er ikke acceptabelt« , skrev de ansatte i brevet.Moral og sikkerhedEn af deltagerne ved FN-mødet i denne uge er roboteksperten Noel Sharkey. Ud over at være professor emeritus i robotteknologi ved University of Sheffield har han som talsmand for kampagnen -Stop Killer Robots- i årevis kæmpet for et FN-forbud mod selvstyrende krigsrobotter.»Vi bliver nødt til at få et internationalt forbud mod udviklingen og brugen af selvstyrende krigsrobotter, inden de bliver taget i brug« , siger Noel Sharkey.Det er især to ting, der bekymrer de kritikere, der kalder udviklingen af intelligente dræbermaskiner for den tredje store våbenrevolution. Den første var brugen af krudt, den anden opfindelsen af atomvåben.
        </div>
        <footer>
          <em>Politiken.dk</em>
          &nbsp;·&nbsp; 2018-04-09
          &nbsp;·&nbsp; e6b243ca
          &nbsp;·&nbsp; #10
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.713</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.514</kbd>
        </footer>
      </article>
      <article>
        <h4>Google-ansatte til chefen: Stop våben med kunstig intelligens</h4>
        <div>
          IT-gigantens øverste chef Sundar Pichai bryder med selskabets motto, hævder over tretusinde Google-medarbejdere. Illustration: Maurizio PesceI et protestbrev bønfalder over 3.100 ansatte deres chef om at annullere en opgave for Pentagon om at udvikle en visuel overvågningsmaskine med AI beregnet til dronekrig.Af 6. apr 2018 kl. 10:37»Kære Sundar, Vi mener ikke, at Google bør være indblandet i krigsindustrien. Derfor beder vi om, at Project Maven bliver aflyst, og at Google udfærdiger, offentliggør og håndhæver en klar politik om, at hverken Google eller dets leverandører nogensinde vil bygge krigsteknologi.« Sådan lyder indledningen i et brev, der cirkulerer rundt hos Googles ansatte. Modtageren er it-mastodontens øverste chef, Sundar Pichai.Kontroversen om projektet ved navn Maven gælder en kontrakt for Pentagon vedrørende en såkaldt -AI surveillance engine- beregnet til droner anvendt af USA-s forsvar.Kontrakten er fortrolig, så det konkrete indhold kender altså kun Google og Pentagon. Men ud fra brevet fremgår det, at der er tale om brugen af kunstig intelligens i et overvågningsprogram installeret i droner, så disse hurtigere kan overvåge køretøjer og andre objekter, følge deres bevægelser og rapportere tilbage til USA-s forsvarsministerium.Både Diane Greene, som står i spidsen for Googles afdeling for cloud-infrastruktur, samt Sundar Pichai har nu internt og i offentligheden forsvaret arbejdet for Pentagon med afsæt i, at Project Maven grundlæggende ikke er offensivt. Ydermere vil Google og Pentagon afstå fra at udvikle autonome våbensystemer, der kan skyde uden en menneskelig operatør.Det argument er prellet af på de kritiske Google-medarbejdere, som har svært ved at se kontrakten harmonere med selskabet motto om 'don-t be evil'.»I en tid med voksende bekymringer over AI, som er fordomsfuld og bevæbnet, kæmper Google allerede med at opretholde offentlighedens tillid. Ved at indgå denne kontrakt kommer vi i selskab med foretagender som Palantir, Raytheon og General Dynamics,« lyder det i protestbrevet.Du kan læse hele protestbrevet fra de 3.100 Google-ansatte her i New York Times.Forskere protesterer ogsåGoogle-protestbrevet så i øvrigt dagens lys samme tidspunkt som et andet protestbrev om kampvåben med kunstig intelligens. Det brev stammer fra over 50 af klodens førende forskere inden for kunstig intelligens (AI) og robotudvikling fra 30 forskellige lande.I en fælles udtalelse tager de skarp afstand fra Sydkoreas topuniversitet, KAIST. Forskerne stopper alt samarbejde med universitet på ubestemt tid, fordi KAIST i samarbejde med den sydkoreanske våbenproducent Hanwha Systems har oprettet et laboratorium til udvikling af autonome våben optimeret med kunstig intelligens.Gruppen vil først ophæve boykotten, når KAIST forsikrer, at laboratoriet vil afholde sig fra at udvikle våben, som kan fungere 100 procent autonomt. Der skal altså fortsat være et menneske, som i et eller andet omfang kontrollerer de våben, som KAIST og Hanwha Systems udtænker, kræver forskerne.»Udviklingen inden for AI og autonome våben går i en potentiel farlig retning med dette her. Det er vores pligt at tage stilling og forsøge at gøre beslutningstagerne opmærksomme på konsekvenserne,« siger en af de 50 medunderskrivere på boykotten, Thomas Bolander, til Ingeniøren.Han er ph.d. og lektor i logik og kunstig intelligens ved DTU Compute og pointerer, at der er mange ubekendte faktorer ved Hanwha Systems- universitets-laboratorium.I sydkoreansk presse har KAIST udlagt samarbejdet, som om der blot er tale om et AI-assisteret navigationssystem til Hanwha Systems- tanks eller missiler.Blåstempler våben-kapløbUanset om det er tilfældet eller ej, betoner Thomas Bolander, at forskernes afstandtagen bør ses i en større kontekst.I udmeldingen, som er forfattet af en af verdens mest fremtrædende AI-forskere, professor Toby Walsh fra New South Wales University, fremhæves risikoen for, at KAIST blåstempler og sætter turbo på kapløbet om udviklingen af autonome våben. Vel at mærke på et tidspunkt, hvor vi stadig kæmper med at begribe potentialet ved AI.»Hvis det bliver udvikler udviklet, vil autonome våben være den tredje revolution inden for krigsførelse. Krig vil blive sat i gang hurtigere og i større skala end nogensinde før. Despoter og tyranner kan bruge disse våben mod uskyldige og fjerne alle former for etiske begrænsninger. Denne Pandoras æske vil være svær at lukke, hvis den åbnes,« skriver de 50 forskere i fællesudmeldingen, hvor de opfordrer KAIST til at koncentrere deres AI-forskning om at fremme fredelige formål.
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2018-04-06
          &nbsp;·&nbsp; e6b18579
          &nbsp;·&nbsp; #11
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.763</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.56</kbd>
        </footer>
      </article>
      <article>
        <h4>Dronen mod kampvognen. Hvem vinder fremtidens krige?</h4>
        <div>
          Det er blevet sværere at beskytte kampvogne og kanoner på jorden mod billige, men højteknologiske droner. Selv små stater har dem nu. Krigsførelse skal tænkes på en ny måde, siger eksperter. Det ligner et computerspil, men er blodig alvor. En kampvogn står på jorden og bliver filmet fra en drone. Så rammer missilet med kirurgisk præcision. Eksplosion, slørede billeder, udslettelse. Normalt har det været stormagterne, der har sendt billederne af deres højteknologiske militæroperationer ud til verdensoffentligheden. Budskabet har været klart og til skræk og advarsel: Se, hvad vi kan. Men dronen er ved at være hvermandseje. Den er blevet så billig i drift og let at håndtere, at selv mindre og ret fattige stater nu råder over hightechdroner, som kan udslette mål på jorden. Seneste eksempel er de hårde kampe mellem Armenien og Aserbajdsjan om enklaven Nagorno-Karabakh, hvor der lige nu er en skrøbelig våbenhvile. Begge parter har offentliggjort videoer, der hævdes at vise fjendtlige kampvogne, der bliver ramt af missiler, affyret fra droner. »Man kan nok godt gå ud fra, at også stormagterne har fulgt nøje med i, hvordan krigen i Nagorno-Karabakh er blevet ført med bl.a. droner,«  siger adjunkt Andreas Graae fra Institut for Militær Teknologi ved Forsvarsakademiet. Militære analytikere spørger i disse år sig selv, om dronerne er ved at tage livet af tunge, traditionelle våben på landjorden som kampvogne, pansrede mandskabsvogne og artilleri. Også i Nagorno-Karabakh har det vist sig, hvor svært det er at forsvare sig mod droner. Det er en offentlig hemmelighed, at Tyrkiet har forsynet Aserbajdsjan med droner af typen Bayraktar TB2. Tyrkiet er i de senere år blevet en regulær dronestormagt. »Hvis radarsystemer og luftforsvaret kan sættes ud af spillet, kan man ret nemt ramme kampvogne og andre pansrede køretøjer med droner. De er simpelthen ikke konstrueret til at modstå angreb oppefra, men mest fra siden,«  forklarer Andreas Graae. Aserbajdsjan indsatte allerede i kampe mod Armenien i 2016 droner og har siden købt stort ind, også i Israel. Det drejer sig bl.a. om en nyudviklet israelsk drone, der kan bruges som sit eget missil, en slags kamikazedrone, der flyver sig selv ind i sit mål. Som fugleflokke eller bisværme kan man sende så mange droner ind, som ovenikøbet kan operere autonomt, at det alene i kraft af antallet kan være svært at forsvare sig på landjorden. Andreas Graae, adjunkt, Forsvarsakademiet Denne type drone blev formentlig også brugt i det storstilede angreb, som den ellers ludfattige Houthi-milits i Yemen sidste år rettede mod to olieraffinaderier i Saudi-Arabien. Her blev det tydeligt, at dronen også er blevet den fattige mands krydsermissil. Major Karsten Marrup, Forsvarsakademiet, peger på, at indsættelsen af droner har ført til, at luftrummet over de pansrede styrker på landjorden ikke længere er sikret, og at de dermed er blevet mere sårbare. »Med kamikazedroner - fjernstyrede bomber - er det ikke længere nok at slå modstanderens luftstyrker ud. Truslen om luftangreb kommer nu flere steder fra. Behovet for luftforsvar har dermed ændret sig. Teknologien og systemerne til forsvar mod droner er i hastig udvikling, men de skal også implementeres i vores måde at operere på, inden vi igen kan sige, at vi er nogenlunde sikre,«  siger Karsten Marrup, der dermed understreger, at hele den klassiske måde at føre krig på er under forandring. Sværme af droner Det er svært at gardere sig mod droner. Især når de afsendes i store mængder i en såkaldt sværmstrategi. »Som fugleflokke eller bisværme kan man sende så mange droner ind, som ovenikøbet kan operere autonomt, at det alene i kraft af antallet kan være svært at forsvare sig på landjorden. Det vil helt klart stille krav om ændringer i den klassiske krigsførelse,«  siger adjunkt Andreas Graae. Lige nu forskes der på livet løs i forsvar mod droner. Det handler om elektronisk forsvar af alle slags: laservåben, elektromagnetisk stråling, mikrobølger, jamming, hacking. Droner som våben I mange lande forskes der i kunstig intelligens i militært øjemed. Udvikling af droner indgår, men dronerne opererer endnu ikke helt autonomt. De programmeres eller styres af et menneske. USA satte sin første drone op i midten af 1990'erne over Balkan under krigen i Bosnien. I mange år blev de kun brugt til rekognoscering. Under præsident Barack Obama blev droner bevæbnet med missiler taget massivt i anvendelse. Den amerikanske Reaper-drone har et vingefang som en airbus . Men den findes i alle størrelser. I krigene i Afghanistan og Irak blev der sat droner ind i masser af aktioner mod terrorledere. Dronernes teknologi er blevet løbende forbedret. Oprindelig var de meget store og tunge. Nu er de blevet mindre og mere mobile. De er højeffektive, udstyret med præcisionstyrede, målsøgende missiler, men stadig meget billige, forklarer Andreas Graae. De kan vende tilbage til basen, tanke op igen og holde sig på vingerne, så længe det ønskes. Ingen pilot bliver træt og skal udskiftes. Og så indgår dronens optagelser af fjendens ødelagte våben i den løbende propagandakrig. Sådan har det også netop været i Nagorno-Karabakh. Det sender et signal både til fjenden og til hjemmefronten. Kampvogne skal beskyttes Kampvognen som våben går dog stadig blandt de fleste militærfolk for at være et uhyre slagkraftigt og fleksibelt våben, der ikke går af mode i overmorgen. Men den skal bruges på en anden måde, efter at dronen har revolutioneret noget af krigsførelsen. »Der er ingen tvivl om, at taktikken for brug af kampvogne må udvikles, hvis de skal overleve i det lange løb. Elektronisk jamming af radar- og dronesignaler og dermed gøre fjenden blind er én måde. Desuden skal kampvognen beskyttes med bedre luftforsvar,«  siger en militær analytiker til nyhedsbureauet Al Jazeera. De tider er forbi, da Sovjetunionen under Den Kolde Krig havde 40.000 kampvogne klar til at rulle hen over Vesteuropa. Heller ikke historiens største kampvognslag ved Kursk i august 1943 mellem Nazityskland og Den Røde Hær med 8.000 kampvogne vil formentlig nogensinde gentage sig. I både USA og Storbritannien pågår lige nu intense debatter i militære kredse om at satse mindre på kampvogne og andre tunge, pansrede våbentyper og mere på hightechvåben. Holland har næsten helt opgivet sine kampvogne. Det amerikanske marinekorps har oplyst, at det vil skære sin faste bestand af kampvogne ned og satse mere på øget fleksibilitet og lettere våben til at udkæmpe fremtidens højteknologiske krige. Farvel til kampvognen I en rapport, offentliggjort i august, bestilt af marinekorpset selv, fælder de militære eksperter en hård dom over kampvognen. »Der er tilstrækkeligt med dokumentation for, at kampvognen trods sin lange og hæderkronede historie i mange krige operationelt ikke længere matcher de trusler, som vi (i marinekorpset) fremover vil blive udsat for,«  sagde korpsets chef, David Berger, ved fremlæggelsen af rapporten. Det er ikke det samme, som at marinekorpset vil afskrive kampvognen helt. Men den vil blive nedprioriteret, tilføjede han. Også USA's almindelige hær vil stadig bruge kampvogne. »I Mellemøsten har kampvogne og pansrede køretøjer haft svært ved at stå distancen over for præcisionsangreb og mængden af droner og diverse overvågningssystemer på slagmarken,«  skrev det amerikanske forsvars eget blad, Stars and Stripes, for nylig i en leder. Den britiske hærchef Mark Carleton-Smith sagde i en tale, at kampvognen vil spille en mindre rolle i fremtidens krige: »Hovedtruslen er ikke længere missiler og kampvogne. Det er militariseringen af alle de elementer i globaliseringen, som ellers har gjort os rige og sikre: mobiliteten, når det gælder varer, mennesker, data og tanker.«  100 kampvogne ødelagt Professor Michael Clarke, King's College i London, ser en klar linje: »At lægge for megen vægt på tung pansring af sine militære styrker ses mere og mere som et udtryk for en gammeldags måde at tænke på i en tid, som er ved at rinde ud - for alle andre end lige netop supermagten USA,«  siger han til BBC. Militære planlæggere over hele verden har nærstuderet et storstilet tyrkisk angreb med droner i det nordlige Syrien i februar. Op mod 100 syriske kampvogne og andre køretøjer blev ødelagt, da Tyrkiet hævnede et angreb fra regeringsstyrker på tyrkiske stillinger. De syriske styrker forekom prisgivet over for denne højteknologiske krigsførelse. Også i Libyen har tyrkiske droner fået krigslykken til at vende. Oprørsstyrkerne var ved at indtage hovedstaden Tripoli, men da Tyrkiet tidligere på året forsynede den FN-anerkendte regering med droner, blev oprørsgeneralen Khalifa Haftar drevet østpå igen. For major Karsten Marrup handler det om at finde konkrete svar på den nye udfordring: »Jeg tror på ingen måde, at dronerne har taget livet af kampvognen og andre tunge våben. Men de har ændret vores måde at tænke luftforsvar på.«  Vil du have vores bedste Indblik-artikler direkte i din indbakke? Tilmeld dig gratis og få de fem nyeste artikler fra Jyllands-Postens Indblik-sektion hver dag kl. 16 - klik her, sæt flueben og indtast din mailadresse
        </div>
        <footer>
          <em>Jyllands-posten.dk (Abonnementsområde)</em>
          &nbsp;·&nbsp; 2020-10-18
          &nbsp;·&nbsp; e7f2015f
          &nbsp;·&nbsp; #12
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.875</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.562</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.646</kbd>
        </footer>
      </article>
      <article>
        <h4>Videnskabsmænd i opråb: Sæt en stopper for dræberrobotter</h4>
        <div>
          Over 1.000 videnskabsfolk og førende erhvervsledere advarer i et fælles brev om konsekvenserne, hvis ikke der sættes en stopper for forskningen i dræberrobotter.Der bør sættes en stopper for forskningen i dræberrobotter, ellers står verden over for uoverskuelige konsekvenser.Sådan lyder advarslen fra over 1.000 videnskabsfolk og erhvervsspidser, skriver Politiken.På en konference om kunstig intelligens, der har fundet sted i denne uge, blev det åbne brev fremsat.Anerkendte videnskabsmænd som Stephen Hawking og filosoffen Noam Chomsky er blandt underskriverne.Ifølge brevet skulle udviklingen af kunstig intelligens i militærrobotter være noget så langt, at selvstyrende dræberrobotter kan se dagens lys i løbet af få år, skriver Politiken.De selvstyrende våben beskrives i brevet som »den tredje revolution inden for krigsførelse«, hvor krudt og atomvåben udgjorde de to første.Brevet advarer om, at et global våbenkapløb er uundgåeligt, såfremt en stor militærmagt skulle beslutte sig for at sætte turbo i udviklingen, ifølge Politiken.En af folkene bag brevet er Noel Sharkey, en professor i robotteknologi ved University of Sheffield.»Uden et forbud nu risikerer vi, at det her udvikler sig til en milliarddollarforretning, og så bliver det umuligt at stoppe«, siger Noel Sharkey.»Man skal huske, at militære robotter er maskiner programmeret af mennesker. Der findes også onde mennesker. Hvad skal vi gøre, hvis maskinerne ikke overholder reglerne for krigsførelse? Hvem er så ansvarlig? Er det programmøren eller den, der gav ordren til at sætte robotterne ind?,« siger Sharkey.Folkene bag brevet er ligeledes bekymret for, hvad der vil ske, hvis teknologien falder i hænder på terrorister.
        </div>
        <footer>
          <em>Amtsavisen.dk (Randers Amtsavis) (Abonnementsområde)</em>
          &nbsp;·&nbsp; 2015-08-01
          &nbsp;·&nbsp; e5253bb2
          &nbsp;·&nbsp; #13
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.829</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.71</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.571</kbd>
        </footer>
      </article>
      <article>
        <h4>Robotterne vil få kontrol over aftrækkeren</h4>
        <div>
          Pentagon afviser, at USA vil overlade beslutningen om at dræbe et menneske til robotter, men en række dokumenter peger på det modsatte. Et spørgsmål om tid, før kamprobotter bliver fuldt autonome, siger forskere.Da det amerikanske forsvarsministerium for få år siden formulerede sin politik angående autonome våben i Direktiv 3000.09, gjorde man ét forhold særligt klart: Autonome våbens brug af dødelig magt skal være underlagt menneskers kontrol.Pentagons standpunkt i det yderst kontroversielle spørgsmål om fuldt autonome våben er siden blev gentaget af adskillige forsvarsspidser, senest i år af det amerikanske flyvevåbens general Paul Selva, som under en tale i Washington proklamerede, at mennesker altid kommer til at være in the loop hos det amerikanske forsvar. Men spørgsmålet er, hvor fasttømret et standpunkt det er.Politisk udsagn frem for forudsigelse»Det tror jeg simpelthen ikke på. Der er jo et våbenkapløb i gang. Så hvis en general siger, at vi beholder mennesket in the loop, så må det opfattes som et politisk udsagn om, hvor man er lige nu, frem for en forudsigelse om fremtiden. Det er han ikke i stand til at forudse med den hastighed, udviklingen har,«siger Thomas Vestskov Terney, konsulent inden for digital strategi og ph.d. i kunstig intelligens.Og efter alt at dømme er det da også et spørgsmål om, hvornår snarere end hvorvidt det amerikanske forsvarsministerium opgiver sit standpunkt. Pentagon og det amerikanske forsvar formulerer i en række offentligt tilgængelige dokumenter netop en konkret forventning om at anvende autonome våben uden menneskelig indblanding i fremtiden.-Gradvis reduktion af kontrol-I den omfattende 25-årsplan Unmanned Systems Integrated Roadmap FY2011-2036 skriver det amerikanske forsvarsministerium, at man -forventer, at ubemandede systemer problemfrit vil operere side om side med bemandede systemer, med en gradvis reduktion af menneskelig kontrol i den ubemandede del af forsvaret-.Hos det amerikanske luftvåben, der i årtier har anvendt fjernbetjente kampdroner, forventer man ifølge den såkaldte Unmanned Aircraft Systems Flight Plan 2009-2047, at -fremskridt inden for kunstig intelligens vil gøre det muligt for systemer at bestemme og udføre kamphandlinger inden for de juridiske og politiske rammer uden at behøve input fra mennesker-.Specifikt om våbensystemer til landjorden beskriver det amerikanske forsvar tilsvarende i sin Unmanned Ground Systems Roadmap en igangværende indsats for at øge selvstændigheden for UGV-er (Unmanned Ground Vehicles). Med et aktuelt mål om overvåget autonomi, kendt som human on the loop, men med et endeligt mål om fuld autonomi.Taler med to tungerHeller ikke Mikkel Willum Johansen, adjunkt og lektor i videnskabsteori ved Københavns Universitet, køber udmeldingen fra den amerikanske forsvarstop.»Når en amerikansk general melder ud, at man ikke vil lade robotter trykke på aftrækkeren, taler militæret med to tunger. På den ene side melder man en politisk grænse ud, mens man samtidig sætter gang i den teknologiske udvikling, der skal muliggøre netop den type robotter. Så man kan sætte spørgsmålstegn ved, hvor troværdig den udmelding er,«siger Mikkel Willum Johansen.Som Ingeniøren tidligere har skrevet, anvender USA allerede i dag våbensystemer med kapaciteten til fuld autonomi, men under opsyn, så mennesker har mulighed for at gribe ind. Med andre ord human on the loop.Selvskydende i 'casualty mode'F.eks. kan kampsystemet Aegis, som udgør it-rygraden i Natos ballistiske missilforsvar, selv identificere og nedskyde fjendtlige ballistiske missiler. Når Aegis er koblet sammen med et Phalanx CIWS-nærforsvarssystem, kan det også nedskyde fjendtlige fly.Den menneskelige operatør kan som udgangspunkt underkende systemets beslutning om at angribe, men Aegis kan også fungere i casualty mode, hvor det antager, at operatøren er forhindret i at betjene systemet, og derfor selv træffer beslutning om at skyde.»Min frygt er, at man bevæger sig ud på en glidebane. For hvis man en dag fravælger at bruge et våbensystem, som kunne have forsvaret et antal amerikanske soldater, som i stedet blev dræbt af Islamisk Stat, så bliver det i et indenrigspolitisk perspektiv svært for politikerne at insistere på, at vi stadig skal have et menneske ind over beslutningen. Vi ved fra historien, at der ikke skal mange bodybags til, for at den politiske vind vender,«siger Thomas Vestskov Terney.For langsom med tøjrede robotterMilitærforskere som Michael N. Schmitt og Jeffrey S. Thurnher, som netop har publiceret en artikel om kunstig intelligens i Harvard National Security Journal, peger også på risikoen for, at amerikanske styrker sakker bagud på slagmarken, hvis Pentagon ikke slipper tøjlerne på sine kamprobotter.Efterhånden som lande som Kina og Rusland også udvikler autonome våben, kan tempoet på slagmarken blive så højt, at mennesker ikke længere kan følge med. Og med et tøjret våbensystem vil man uvægerligt træffe sine beslutninger langsommere end en fjende med et fuldt autonomt våbensystem. Derfor kan de operationelle realiteter tvinge USA til at forkaste sin praksis med at beholde et menneske i beslutningskæden, skriver de.Daværende forskningschef Werner Dahm fra det amerikanske luftvåben sagde tilbage i 2010, at det teknologisk har været muligt at lade robotter foretage autonome angreb i lang tid. Og at mennesket inden 2030 vil være blevet kamppladsens svageste led.
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2016-10-30
          &nbsp;·&nbsp; e5f349cf
          &nbsp;·&nbsp; #14
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.704</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.512</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.592</kbd>
        </footer>
      </article>
      <article>
        <h4>Før Danmarks valg af nyt kampfly: Næste generation spøger allerede i kulissen</h4>
        <div>
          Northrop Grumman har i december offentliggjort denne visualisering af sit bud på næste generation af kampfly. Flyet har laservåben i form af en solid-state-højenergilaser, der fungerer med stor nøjagtighed og lysets hastighed, men øger flyets infrarøde synlighed. Bagudvinklede vinger som på Northrops bombefly B-2 reducerer luftmodstanden og mindsker effekten af chokbølger ved overlydshastighed.Femtegenerations kampflyet F-35 er stadig langtfra færdigudviklet, men tre kampflyproducenter arbejder allerede nu på sjette generation, som Pentagon vil have på vingerne i 2030.7. feb 2016 kl. 12:00Herhjemme handler det om femte generation eller fjerde generation: Når kredsen af partier bag forsvarsforliget snart skal vælge nye kampfly, skal vi så gå efter F-35, som markerer et teknologispring men stadig oplever udviklingsproblemer? Eller skal vi satse på et velafprøvet fjerdegenerations kampfly som F/A-18 Super Hornet eller Eurofighter?I udviklingsafdelingerne hos en lille håndfuld internationale forsvarsvirksomheder har blikket derimod længe været rettet mod sjette generation af kampfly, som efter planen skal gå på vingerne for det amerikanske forsvar omkring 2030.Senest har Northrop Grumman, som står bag bombeflyet B-2 Spirit og i dag er underleverandør på både F-35 og Super Hornet, for få uger siden offentliggjort sin visualisering af et bud på et sjettegenerations kampfly, der præsterer længere rækkevidde, laservåben og modstandskraft mod elektronisk krigsførelse.Inden for de seneste år har også Boeing og Lockheed Martin offentliggjort deres bud på sjette generation som opvarmning til, at Pentagon skyder et udbud i gang.»Producenterne er meget bevidste om, at de nuværende budgetplaner for forsvaret kun vil tillade to centrale kampfly at overleve i det kommende årti. Derfor er alle tre producenter ivrige efter at gøre opmærksom på deres muligheder,« siger Richard Aboulafia, vicedirektør i analysevirksomheden Teal Group og rådgiver inden for militær luftfart.Et spørgsmål om stealthDet amerikanske forsvarsministerium udsendte allerede i 2012 det indledende udbudsmateriale til kampflyproducenter, og US Air Force er i samarbejde med US Navy lige nu i gang med at kortlægge producenternes bud på et sjettegenerations kampfly. Pentagon overvejer angiveligt både bemandede, ubemandede og valgfrit bemandede kampfly.Mens US Air Force og US Navy indledningsvis samarbejder om indkøbet, bliver der tale om to adskilte programmer, der har til formål at erstatte forskellige kampfly. Flyvevåbnets F-X-program skal erstatte fjerdegenerations kampflyet F-15 Eagle og femtegenerations kampflyet F-22 Raptor, mens søværnets FA-XX-program skal levere en afløser for fjerdegenerations kampflyet F/A-18 Super Hornet. Det amerikanske forsvarsministerium har, belært af designkompromiserne og fordyrelserne i fælleskampflyet F-35, valgt at holde de to nye kampflyprogrammer adskilt på trods af overlappende egenskaber.Boeings nyeste bud på et sjettegenerations kampfly er dette koncept fra 2013. Flyet kan enten flyves med pilot eller fjernstyres. Pentagon har endnu ikke lagt sig fast på spørgsmålet om bemanding. To motorer øger flyets motorkraft og minimerer konsekvensen af et motorstop. Fravær af haleror og dermed vertikale flader bidrager til flyets begrænsede radarsynlighed.US Air Force og US Navy har da også forskellige forventninger til hver deres næste kampflygeneration. Den mest markante forskel ligger formentlig i tiltroen til stealth-teknologi. Hos US Air Force er overbevisningen, at radarusynlighed fortsat er en central kampflyteknologi, og general Herbert Carlisle meldte sidste år ud, at stealth også bliver en nøgleegenskab for fremtidige kampflygenerationer. Begejstringen hos US Navy er derimod afmålt, og admiral Jonathan Greenert har meldt ud, at stealth-teknologi formentlig er overvurderet og ikke i fremtiden kan holde kampfly skjult for ny radarteknologi.Ifølge Mark Gunzinger, seniorforsker ved den Washington-baserede tænketank CSBA og tidligere rådgiver for det amerikanske forsvarsministerium og luftvåben, vil reduceret radarsynlighed være en nødvendighed for fremtidige kampfly.»Vores vurdering er, at fremtidige systemer til luftdominans, bemandede såvel som ubemandede, skal kunne operere i stærkt beskyttede miljøer. Det stiller krav om den seneste stealth-teknologi og avancerede selvforsvarssystemer, for eksempel i form af laservåben,« siger han til Ingeniøren.Justerbare motorerFlere krav til den nye kampflygeneration går igen hos både US Navy og US Air Force. For begge værn bliver der tale om store krav til datalinks, der kan gøre det muligt at dele store datamængder med andre kampfly. Begge værn har også luftet ambitioner om kunstig intelligens, som i praksis formentlig vil tage form af avanceret pilotunderstøttelse i stil med den aktuelle fusionering af forskellige sensorinput, som i dag er at finde i F-35.US Air Force og US Navy samarbejder også om en fælles motorløsning. En af mulighederne på tegnebrættet er en motor med justerbart bypassforhold, der kan tilpasses til den optimale effekt ved forskellige hastigheder og højder, hvilket skal give flyene bedre acceleration og ikke mindst længere rækkevidde.Eksempelvis et system, der fungerer som en turbojetmotor med reduceret bypass ved overlydsflyvning, og som en turbofanmotor med høj bypass ved lavere cruisehastigheder. Motorproducenterne General Electric og Pratt &amp; Whitney arbejder begge på såkaldte adaptive cycle-motorsystemer.CybermodstandEn nøgleegenskab i Northrop Grummans vision for et sjettegenerations kampfly er cyber resiliency, modstandsdygtighed over for cyberangreb. Efterhånden som elektronisk krigsførelse spiller en stadigt større rolle, forestiller selskabet sig ikke at kunne afværge samtlige forsøg på cyberangreb, men i stedet at gøre nye kampfly i stand til at registrere angreb og minimere skaden, inspireret af hvide blodlegemer.»Menneskekroppen er så modtagelig for infektioner, at tanken om at blokere angreb er urealistisk. Spørgsmålet er snarere, hvordan din krop reagerer, når du er inficeret. Hvide blodlegemer er et utroligt system, der angriber og forsøger at kontrollere infektioner på en måde, der forhindrer dem i at skade kroppen. Systemerne i 2030 vil være udstyret med noget lignende,« sagde Tom Vice, direktør for Northrop Grummans luftfartsdivision, til Defense News tidligere på året.
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2016-02-07
          &nbsp;·&nbsp; e58da6a8
          &nbsp;·&nbsp; #15
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.784</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.626</kbd>
        </footer>
      </article>
      <article>
        <h4>Tusindvis af eksperter opfordrer til bandlysning af kunstig intelligens i våbenudvikling</h4>
        <div>
          I et åbent brev advarer eksperter i kunstig intelligens og robotter imod at starte et nyt våbenkapløb.Af Daniel McClane Tirsdag, 28. juli 2015 - 10:25»Kunstig intelligens teknologi har nået et niveau, hvor det inden for få år vil kunne introduceres i krigsførelse, og der står rigtig meget på spil.«Sådan indledes et åbent brev , som netop er blevet offentliggjort på en international konference om kunstig intelligens i Buenos Aires i Argentina. Det skriver The Guardian .Eksperterne advarer mod de humanitære konsekvenser ved at introducere kunstig intelligens i militæret. Blandt underskriverne på brevet er Teslas Elon Musk, Apples Steve Wozniak, Dennis Hassabis fra Google, Stephen Hawking og mere end tusind andre eksperter.Det drejer sig om robotter, der kan finde og angribe mål uden menneskelig styring. Eksempelvis selvstændige quadrokoptere, der blot er programmeret med nogle kriterier for målsøgning.Autonome våben er blevet beskrevet som den tredje revolution inden for krigsførelse efter krudt og atomvåben. Og imens forfatterne bag brevet er enige i, at de autonome våben kan forbedre arbejdsvilkårene for nogle soldater, er de bekymrede for, at det vil øge villigheden til at starte væbnede konflikter og dermed resultere i flere tab af menneskeliv.Desuden kan de autonome våben foranledige et våbenkapløb, som overstiger, hvad vi oplevede med atomvåben, da de nye våben ikke kræver særlige materialer som beriget uran til atombomber, og dermed vil teknologien være sværere at overvåge globalt.Opfordringen i brevet er, at man laver et totalt FN-forbud mod kunstig intelligens i militært isenkram.Der eksisterer flere NGO-er som lobbyer imod brugen af autonome våben, bl.a. -Stop Killer Robots- som siden 2012 har arbejdet for et globalt forbud.Elon Musk og Stephen Hawking har tidligere udtalt, at generel kunstig intelligens er den største eksterne trussel mod menneskehedens eksistens. Dette brev slutter dog af med at sige, at kunstig intelligens kan have mange gode anvendelser i andre aspekter af vores hverdag.Ved en FN konference om samme emne tidligere i år, udtalte den britiske regering sig imod et forbud på autonome våben.Via: The Guardian
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2015-07-28
          &nbsp;·&nbsp; e523db6f
          &nbsp;·&nbsp; #16
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.867</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.598</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.561</kbd>
        </footer>
      </article>
      <article>
        <h4>Kunstig intelligens er genvej til militære muskler</h4>
        <div>
          Øget brug af autonome våben og AI forventes at kunne dæmme op for, at 17 procent af de militære dødsfald skyldes friendly fire. Altså at en hærenhed kommer til at skyde deres egne i kampens hede.Selvstyrende krigsmaskiner vil udligne styrkeforholdet mellem de forskellige nationer og destabilisere den militære magtbalance, vurderer AI-forskere.Guatemala, Costa Rica, Irak, Panama, Uganda, Palæstina og så videre.Et udvalg af de 22 lande, som til dato har underskrevet et FN-forbud om fuldstændigt at bandlyse brugen af autonome våben. Om end også et udvalg af lande, som næppe får en general fra nogen større vestlige nationer til at ryste i sine camouflagefarvede army-bukser.Men når kunstig intelligens bliver blandet ind i den militære magtbalance, bør store hære frygte små landes enheder i langt større grad.Det er en overset pointe og ikke mindst en ekstra grund til, at militære sværvægtere såsom USA, Rusland eller Storbritannien tillige bør bakke op om et forbud mod autonome våben.Det mener professor Toby Walsh fra New South Wales University, en af verdens mest fremtrædende AI-forskere og talsmand for sammenslutningen af forskere imod autonome våben.»Dette er våben, som vil destabilisere den nuværende magtbalance. Du behøver ikke være en supermagt for at opbygge en skræmmende hær på baggrund af autonome våben,« siger Toby Walsh.Pentagon er da også udmærket klar over udgifterne til krudt, kugler og kunstig intelligens anvendt i krigszoner. Men det har altså hidtil ikke afholdt USA fra at støtte op om indskrænkninger i de forskelle grader af autonomi ved AI-våben.Da FN-s medlemslande og AI-eksperter mødtes i Genéve i begyndelsen af måneden for at drøfte autonome våben, havde USA ligefrem travlt med at påpege fordele ved autonome våben.Eksempelvis at AI kraftigt vil kunne reducere antallet af civile ofte i væbnede konflikter. Årsagen er ofte upræcis styring af bomber, fordi vi mennesker nu engang er unøjagtige og har vanskeligt ved at holde hovedet koldt i en glohed konflikt.Meget, meget billigereEn motivationsfaktor for USA-s positive udlægninger af autonome våben med avanceret AI kan være, at AI kraftigt vil kunne reducere udgifterne til at føre krig, og USA er en af klodens mest aktive nationer i konflikter.Et estimat fra en militær tænketank har tidligere anslået, at det eksempelvis koster mindst 2,1 millioner kroner blot at optræne en Navy Seal-soldat. Et moderne Patriot-missil opereret af en antiballistisk robot fås for 18,5 millioner kroner. En autonom drone løber op i omkring 12.370 kroner. Blandt andet takket være det faktum, at udgifterne til AI i høj grad allerede er blevet afholdt af offentlig universitetsforskning.Samme regnestykke skæver oprørsgruppe eller andre nationers generaler også til, understreger Toby Walsh.»USA og Rusland bør i høj grad være opmærksomme på, at autonome våben ikke vil gøre dem stærkere, men gøre forholdet til deres modstandere mere jævnbyrdigt,« siger han.Doping med dataUdviklingen indenfor kunstig intelligens er i dag så fremskreden, at våbenproducenter og nationer såsom USA, Israel, Storbritannien og Sydkorea alle råder over skibe eller artillerisystemer baseret på det, man kunne kalde for militær machine learning.Uden menneskelig indflydelse er maskinerne i stand til at opsøge og egenhændigt træffe en beslutning om et dødeligt angreb. Indtil videre er mennesket bevaret i den beslutningskæde.Gary Schaub, seniorforsker ved Center for Militære Studier på Københavns Universitet, offentliggjorde i 2016 en rapport om behovet for retningslinjer ved anvendelse af autonome våben. Han mener ligesom Toby Walsh, at en udbredelse af autonome våben vil udligne forskellene mellem krigsaktive nationer. Og en traktat eller forbud tvivler han på har nogen gang på jord, selv i det tilfælde, hvor selvstyrende krigsmaskiner kan defineres tilstrækkeligt præcist til en international traktat:»Ikke alene vil verdens supermagter ikke tilslutte sig et forbud, men mange stater, der higer efter mere indflydelse, vil opfatte autonomi som en oplagt mulighed for at skyde genvej til et militært topniveau,« siger Gary Schaub.En sådan stat kan være Kina. Riget i Midten har længe følt sig underkuet i forhold til Rusland og USA's militære teknologi. Kina har vægret sig ved Pentagons stadig mere offensive politik i dette århundrede for kernevåben og oversøiske missiler.Læg dertil, at Kina især er ængstelig for at blive taget på sengen ved ikke at opdage et angreb i tide.»I relation til Rusland og USA har Kina længe været oppe mod en a-våben-asymmetri. I modsætning hertil udgør AI og autonomi et potentiale, som på langt sigt lader Beijing forstyrre Washingtons traditionelle styrker,« siger Lora Saalman, fellow ved Stockholm International Peace Research Institute (SIPRI) og professor fra Tsinghua Universitys afdeling for internationale relationer, til
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2018-04-26
          &nbsp;·&nbsp; e6ba20ae
          &nbsp;·&nbsp; #17
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.661</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.576</kbd>
        </footer>
      </article>
      <article>
        <h4>Robotterne vil få kontrol over aftrækkeren</h4>
        <div>
          Da det amerikanske forsvarsministerium for få år siden formulerede sin politik angående autonome våben i Direktiv 3000.09, gjorde man ét forhold særligt klart: Autonome våbens brug af dødelig magt skal være underlagt menneskers kontrol.Pentagons standpunkt i det yderst kontroversielle spørgsmål om fuldt autonome våben er siden blev gentaget af adskillige forsvarsspidser, senest i år af det amerikanske flyvevåbens general Paul Selva, som under en tale i Washington proklamerede, at mennesker altid kommer til at være in the loop hos det amerikanske forsvar. Men spørgsmålet er, hvor fasttømret et standpunkt det er.»Det tror jeg simpelthen ikke på.Der er jo et våbenkapløb i gang. Så hvis en general siger, at vi beholder mennesket in the loop, så må det opfattes som et politisk udsagn om, hvor man er lige nu, frem for en forudsigelse om fremtiden. Det er han ikke i stand til at forudse med den hastighed, udviklingen har,« siger Thomas Vestskov Terney, konsulent inden for digital strategi og ph. d. i kunstig intelligens.Og efter alt at dømme er det da også et spørgsmål om, hvornår snarere end hvorvidt det amerikanske forsvarsministerium opgiver sit standpunkt.Pentagon og det amerikanske forsvar formulerer i en række offentligt tilgængelige dokumenter netop en konkret forventning om at anvende autonome våben uden menneskelig indblanding i fremtiden.' Gradvis reduktion af kontrol'I den omfattende 25-årsplan Unmanned Systems Integrated Roadmap FY2011-2036 skriver det amerikanske forsvarsministerium, at man ' forventer, at ubemandede systemer problemfrit vil operere side om side med bemandede systemer, med en gradvis reduktion af menneskelig kontrol i den ubemandede del af forsvaret'.Hos det amerikanske luftvåben, der i årtier har anvendt fjernbetjente kampdroner, forventer man ifølge den såkaldte Unmanned Aircraft Systems Flight Plan 2009-2047, at ' fremskridt inden for kunstig intelligens vil gøre det muligt for systemer at bestemme og udføre kamphandlinger inden for de juridiske og politiske rammer uden at behøve input fra mennesker'.Specifikt om våbensystemer til landjorden beskriver det amerikanske forsvar tilsvarende i sin Unmanned Ground Systems Roadmap en igangværende indsats for at øge selvstændigheden for UGV'er (Unmanned Ground Vehicles). Med et aktuelt mål om overvåget autonomi, kendt som human on the loop, men med et endeligt mål om fuld autonomi.Heller ikke Mikkel Willum Johansen, adjunkt og lektor i videnskabsteori ved Københavns Universitet, køber udmeldingen fra den amerikanske forsvarstop.»Når en amerikansk general melder ud, at man ikke vil lade robotter trykke på aftrækkeren, taler militæret med to tunger. På den ene side melder man en politisk grænse ud, mens man samtidig sætter gang i den teknologiske udvikling, der skal muliggøre netop den type robotter.Så man kan sætte spørgsmålstegn ved, hvor troværdig den udmelding er,« siger Mikkel Willum Johansen.Som Ingeniøren tidligere har skrevet, anvender USA allerede i dag våbensystemer med kapaciteten til fuld autonomi, men under opsyn, så mennesker har mulighed for at gribe ind. Med andre ord human on the loop.F. eks. kan kampsystemet Aegis, som udgør it-rygraden i Natos ballistiske missilforsvar, selv identificere og nedskyde fjendtlige ballistiske missiler. Når Aegis er koblet sammen med et Phalanx CIWS-nærforsvarssystem, kan det også nedskyde fjendtlige fly.Den menneskelige operatør kan som udgangspunkt underkende systemets beslutning om at angribe, men Aegis kan også fungere i casualty mode, hvor det antager, at operatøren er forhindret i at betjene systemet, og derfor selv træffer beslutning om at skyde.»Min frygt er, at man bevæger sig ud på en glidebane. For hvis man en dag fravælger at bruge et våbensystem, som kunne have forsvaret et antal amerikanske soldater, som i stedet blev dræbt af Islamisk Stat, så bliver det i et indenrigspolitisk perspektiv svært for politikerne at insistere på, at vi stadig skal have et menneske ind over beslutningen.Vi ved fra historien, at der ikke skal mange bodybags til, for at den politiske vind vender,« siger Thomas Vestskov Terney.For langsom med tøjrede robotter Militærforskere som Michael N.Schmitt og Jeffrey S. Thurnher, som netop har publiceret en artikel om kunstig intelligens i Harvard National Security Journal, peger også på risikoen for, at amerikanske styrker sakker bagud på slagmarken, hvis Pentagon ikke slipper tøjlerne på sine kamprobotter.Efterhånden som lande som Kina og Rusland også udvikler autonome våben, kan tempoet på slagmarken blive så højt, at mennesker ikke længere kan følge med. Og med et tøjret våbensystem vil man uvægerligt træffe sine beslutninger langsommere end en fjende med et fuldt autonomt våbensystem. Derfor kan de operationelle realiteter tvinge USA til at forkaste sin praksis med at beholde et menneske i beslutningskæden, skriver de.Daværende forskningschef Werner Dahm fra det amerikanske luftvåben sagde tilbage i 2010, at det teknologisk har været muligt at lade robotter foretage autonome angreb i lang tid. Og at mennesket inden 2030 vil være blevet kamppladsens svageste led. j.GRADER AF AUTONOMIAutonomi benyttes om flere grader af selvstændighed, hvor mennesket har større eller mindre vægt i beslutningskæden.En bredt anvendt model definerer tre grader af selvbestemmelse i våbensystemer: Humanintheloop Mennesker er en integreret del af beslutningskæden og har fuld kontrol over systemet.Humanontheloop Mennesker betragter beslutningskæden og har mulighed for at gribe ind i systemet.Humanoutoftheloop Mennesker er uden indflydelse på beslutningskæden. Autonome våben beskrives som krigsførelsens tredje revolution efter først krudtet og så atomvåben.Ingeniøren ser i en serie på de stadigt mere intelligente kamprobotter.Læs blandt andet: Kamprobotternes akilleshæl er uforudsigelighed ing.dk/ 187503 Hvornår er krigsrobotter autonome? ing.dk/ 187619.13. ÅRHUNDREDE LandminerBrugt som såkaldte area denial-våben siden Song-dynastiet i Kina. Betegnes af nogle som fuldt autonome våben, hvilket dog ikke flugter med de mest udbredte definitioner af fuldt autonome våben, som indebærer, at våbnet kan vælge mellem forskellige handlingsmuligheder.Efter den definition er landminer snarere automatiske.1920' ERNE Ubemandede køretøjerSåkaldte UGV'er (Unmanned Ground Vehicle) har eksisteret siden 1920' erne, og de fleste er fortsat fjernstyrede, mens flere nyere versioner, som de amerikanske Swords, er delvist autonome. Israels Guardium og USA's Crusher kan både fjernbetjenes og indstilles til at operere autonomt, dog med menneskelig overvågning.ANDEN VERDENSKRIG Fire and forgetFire and forget-missiler er guidede missiler, der selv finder og angriber det mål, som piloten har udpeget. De første kom frem under Anden Verdenskrig, og kategorien omfatter i dag bl. a. de udbredte lasereller radarstyrede Sidewinder-, Amraam-og Hellfire-missiler. Missilerne kan dermed betegnes som semi-autonome våben. De nye Brimstone-luft-til-jord-missiler fremhæves ofte som særligt selvstændige, idet de kan affyres i en generel retning, selv finde et mål og identificere målets mest sårbare punkt.1950' ERNE Kunstig intelligensKunstig intelligens (Artificial Intelligence/ AI) udgør forudsætningen for udviklingen af autonome våben. Forskningsfeltet opstod i 1950' erne, og i dag findes kunstig intelligens i et utal af våbensystemer.3.000 specialister i robotter advarede sidste år FN om, at udviklingen kan løbe løbsk, og at kunstig intelligens i sidste ende kan udgøre en trussel mod menneskeheden.1970' ERNE CIWSNærforsvarssystemer eller CIWS (Close-In Weapon System) har været anvendt på krigsskibe siden de russiske AK-630 i 1970' erne. CIWS kan automatisk nedskyde fjendtlige missiler, både og fly, men kræver grønt lys fra et menneske for at angribe. Det kan dermed betegnes som et semi-autonomt våbensystem.00' ERNE Fuzzy logicFuzzy logic - læringsalgoritmer, hvor målet ikke er eksakte værdier, men hvor man kombinerer de bedste erfaringer med regelsæt for at nå den bedst mulige version af et givent regelsæt - benyttes i dag i flysimulatorer og vil i de kommende år formentlig brede sig til mange anvendelser, eksempelvis droner.I 2016 lykkedes det for første gang en AI-computer baseret på fuzzy logic at nedkæmpe en menneskelig kampflypilot i simulatorøvelser i det amerikanske luftvåbens centrale forskningslaboratorium i Ohio.
        </div>
        <footer>
          <em>Ingeniøren</em>
          &nbsp;·&nbsp; 2016-10-28
          &nbsp;·&nbsp; e5f2918e
          &nbsp;·&nbsp; #18
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.812</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.557</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.596</kbd>
        </footer>
      </article>
      <article>
        <h4>TV 2 kl. 22.30 Stealth</h4>
        <div>
          I en nær fremtid har flåden udviklet et ubemandet jagerfly, styret af en kunstig intelligens.Flyet bliver sendt til Stillehavet, for at piloterne om bord kan give flyet »lektioner« i kampteknik. Men da computeren begynder at følge sine egne ordrer, må de tre elitepiloter stoppe den, før den indleder en atomkrig.
        </div>
        <footer>
          <em>Århus Stiftstidende</em>
          &nbsp;·&nbsp; 2018-01-19
          &nbsp;·&nbsp; e695321c
          &nbsp;·&nbsp; #19
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.944</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.711</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.614</kbd>
        </footer>
      </article>
      <article>
        <h4>Ny rapport: Danmark mangler politik for autonome våben</h4>
        <div>
          Danmark råder allerede i dag over delvist autonome våben i form af Harpoon Block II-antiskibsmissiler. Her affyret fra støtteskibet Esbern Snare under en øvelse i Norge sidste sommer. (Foto: Forsvaret)Intelligente våbensystemer vinder hastigt frem og betegnes som tredje revolution inden for krigsførelse. Men selv om Forsvaret allerede råder over autonome våben, mangler danske politikere at forholde sig til, hvordan Danmark skal anvende dem. Ny rapport om problemet lander i dag.24. feb 2017 kl. 09:01Først kom krudtet, så kom atomvåben, og nu står robotterne klar til at indtage slagmarken. Autonome våben beskrives som den tredje revolution inden for krigsførelse, og med de sofistikerede nye våbensystemer følger en lang række etiske og juridiske dilemmaer.Men modsat lande som USA og Storbritannien har Danmark ingen politik for anvendelsen af autonome våben. Det er konklusionen i en rapport fra Center for Militære Studier ved Københavns Universitet, som offentliggøres i dag.»Der er flere grunde til, at danske beslutningstagere burde være i gang med at adressere dette problem allerede nu. Militæret har generelt meget distinkte ansvarskæder, så hvis en soldat gør noget galt i Afghanistan eller Irak, har den overordnede officer et ansvar. Vi mangler en tilsvarende model, når soldaten erstattes af en maskine med evnen til at handle autonomt,«siger Gary Schaub Jr., seniorforsker ved Center for Militære Studier og rapportens ene forfatter.Det er den første rapport om autonome våben i en dansk kontekst. Den er samtidig udarbejdet som en del af Center for Militære Studiers myndighedsbetjening og lander derfor på skrivebordet hos forsvarsminister Claus Hjort Frederiksen (V) og hos partierne bag forsvarsforliget, som skal forhandles på plads inden årets udgang.Allerede i DanmarkBehovet for retningslinjer bliver ikke mindre presserende af, at det danske forsvar i forvejen råder over adskillige våbensystemer med autonome funktioner. Det viser en opgørelse, som Center for Militære Studier har lavet i forbindelse med den nye rapport.Søværnet benytter Harpoon Block II-antiskibsmissiler, ESSM-luftforsvarsmissiller og MU90-letvægts-antiubådstorpedoer, mens Flyvevåbnet råder over luft til luft-missilet AIM-120 AMRAAM og luft til jord-missilet AGM 65 Maverick. Det er såkaldte fire and forget-systemer, som skal affyres af mennesker, men som efter affyring er målsøgende og kan finde frem til deres mål, selv om de er uden for affyringssystemets synsfelt. Missilerne kan også foretage undvigemanøvrer over for målets beskyttelsessystemer.»Danmark har rent faktisk allerede autonome våbensystemer efter den amerikanske definition. Og allerede i 1982 har autonome våben skabt problemer for danske beslutningstagere,«siger Gary Schaub Jr. med henvisning til det Harpoon-missil, som utilsigtet blev affyret fra en dansk fregat og ramte et sommerhusområde i Nordvestsjælland, hvor det eksploderede og totalskadede flere sommerhuse.»Sagen blev kontroversiel, fordi der netop ikke var etableret nogen proces for at fastslå ansvaret for episoder med den slags våben. Det er et eksempel på, at det ikke er godt nok at udelade en fast praksis og i stedet først finde på den, når problemerne opstår. Man bliver nødt til at gennemtænke den slags problemstillinger mere effektivt,«siger han.Juridisk ingenmandslandFuldt autonome våbensystemer, der udvælger og angriber deres mål uden menneskelig indblanding, anvendes ikke i dag. Men det amerikanske forsvar formulerer i en række offentligt tilgængelige dokumenter en forventning om at anvende fuldt autonome våben i fremtiden. Derfor efterlyste eksperter i kunstig intelligens allerede i efteråret i Ingeniøren danske retningslinjer for autonome våben. Blandt dem er Thomas Vestskov Terney, konsulent inden for digital strategi og ph.d. i kunstig intelligens. Og konsekvenserne kan blive alvorlige, hvis danske politikere ikke lytter til indstillingen i den nye rapport, advarer han.»Konsekvensen vil være, at vi sætter os selv uden for indflydelse. Der er ingen tvivl om, at de fuldt autonome våben kommer, og hvis vi ikke selv tager aktivt stilling til sagen, så kommer andre til at foretage den stillingtagen for os. Det bliver enten vores allierede eller vores modstandere,«siger Thomas Vestskov Terney.»Samtidig kan vi ikke placere ansvaret, hvis noget går galt. Er det operatørens ansvar? Er det producentens? Vi er lige nu i et juridisk ingenmandsland. Og hvis vi ikke etablerer nogle rammer for anvendelsen, kommer vi uafværgeligt til at stå med problemer. Bekymringen er naturligvis, at udviklerne overser noget. En væsentlig faktor, som gør, at systemet reagerer anderledes, end vi havde tænkt os,«siger han.Første skridtForfatterne bag den nye rapport foreslår konkret at oprette en tværministeriel arbejdsgruppe med repræsentanter fra Forsvarsministeriet, Justitsministeriet, Udenrigsministeriet, Forsvarskommandoen og Forsvarets Efterretningstjeneste, der skal belyse implikationerne ved autonome våben, ligesom det har været tilfældet med cyberkrigsførsel.Arbejdsgruppen skal blandt andet evaluere argumenterne for, hvorvidt det skal være dansk politik 1) at understøtte anvendelsen og udviklingen af autonome våbensystemer i det danske forsvar, den danske forsvarsindustri og hos danske allierede, 2) at tillade, at allierede landes autonome våben udstationeres på eller passerer igennem dansk territorium, og 3) at deltage i militære operationer, hvor autonome våben anvendes.»Teknologien er utvivlsomt på vej, og det er væsentligt at have en dansk politik på plads, ikke blot for Danmarks egen brug af autonome våben, men også hvordan vi håndterer allieredes brug af teknologien. USA-s førerposition på området vil skabe alvorlige spørgsmål om, hvorvidt Danmark vil deltage i operationer med autonome våben eller tillade dem i dansk luftrum eller farvand,«siger Gary Schaub Jr.Samtidig skal arbejdsgruppen foreslå en kommandostruktur, der skal sikre den fornødne kontrol med og ansvarsplacering for våbensystemerne. Endelig foreslår rapporten en permanent arbejdsgruppe inden for Forsvarskommandoen, som skal sikre, at nyanskaffelser af autonome våben foregår i overensstemmelse med dansk lov og med Genèvekonventionen.Ingeniøren har bedt forsvarsminister Claus Hjort Frederiksen om at kommentere udspillet i den nye rapport, men det har ikke været muligt at tale med ministeren.
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2017-02-24
          &nbsp;·&nbsp; e6210acd
          &nbsp;·&nbsp; #20
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.649</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.609</kbd>
        </footer>
      </article>
      <article>
        <h4>Kampen om den næste kampflygeneration er i gang</h4>
        <div>
          Herhjemme handler det om femte generation eller fjerde generation: Når kredsen af partier bag forsvarsforliget snart skal vælge nye kampfly, skal vi så gå efter F35, som markerer et teknologispring men stadig oplever udviklingsproblemer? Eller skal vi satse på et velafprøvet fjerdegenerations kampfly som F/ A18 Super Hornet eller Eurofighter? I udviklingsafdelingerne hos en lille håndfuld internationale forsvarsvirksomheder har blikket derimod længe været rettet mod sjette generation af kampfly, som efter planen skal gå på vingerne for det amerikanske forsvar omkring 2030.Senest har Northrop Grumman, som står bag bombeflyet B2 Spirit og i dag er underleverandør på både F35 og Super Hornet, for få uger siden offentliggjort sin visualisering af et bud på et sjettegenerations kampfly, der præsterer længere rækkevidde, laservåben og modstandskraft mod elektronisk krigsførelse.Inden for de seneste år har også Boeing og Lockheed Martin offentliggjort deres bud på sjette generation som opvarmning til, at Pentagon skyder et udbud i gang.»Producenterne er meget bevidste om, at de nuværende budgetplaner for forsvaret kun vil tillade to centrale kampfly at overleve i det kommende årti. Derfor er alle tre producenter ivrige efter at gøre opmærksom på deres muligheder,« siger Richard Aboulafia, vice direktør i analysevirksomheden Teal Group og rådgiver inden for militær luftfart.Et spørgsmål om stealthDet amerikanske forsvarsministerium udsendte allerede i 2012 det indledende udbudsmateriale til kampflyproducenter, og US Air Force er i samarbejde med US Navy lige nu i gang med at kortlægge producenternes bud på et sjettegenerations kampfly. Pentagon overvejer angiveligt både bemandede, ubemandede og valgfrit bemandede kampfly.Mens US Air Force og US Navy indledningsvis samarbejder om indkøbet, bliver der tale om to adskilte programmer, der har til formål at erstatte forskellige kampfly.Flyvevåbnets FXprogram skal erstatte fjerdegenerations kampflyet F15 Eagle og femtegenerations kampflyet F22 Raptor, mens søværnets FAXXprogram skal levere en afløser for fjerdegenerations kampflyet F/ A18 Super Hornet.Det amerikanske forsvarsministerium har, belært af designkompromiserne og fordyrelserne i fælleskampflyet F35, valgt at holde de to nye kampflyprogrammer adskilt på trods af overlappende egenskaber.US Air Force og US Navy har da også forskellige forventninger til hver deres næste kampflygeneration.Den mest markante forskel ligger formentlig i tiltroen til stealthteknologi.Hos US Air Force er overbevisningen, at radarusynlighed fortsat er en central kampflyteknologi, og general Herbert Carlisle meldte sidste år ud, at stealth også bliver en nøgleegenskab for fremtidige kampflygenerationer.Begejstringen hos US Navy er derimod afmålt, og admiral Jonathan Green ert har meldt ud, at stealthteknologi formentlig er overvurderet og ikke i fremtiden kan holde kampfly skjult for ny radarteknologi.Ifølge Mark Gunzinger, seniorforsker ved den Washingtonbaserede tænketank CSBA og tidligere rådgiver for det amerikanske forsvarsministerium og luftvåben, vil reduceret radarsynlighed være en nødvendighed for fremtidige kampfly.»Vores vurdering er, at fremtidige systemer til luftdominans, bemandede såvel som ubemandede, skal kunne operere i stærkt beskyttede miljøer. Det stiller krav om den seneste stealthteknologi og avancerede selvforsvarssystemer, for eksempel i form af laservåben,« siger han til Ingeniøren.Justerbare motorerFlere krav til den nye kampflygeneration går igen hos både US Navy og US Air Force. For begge værn bliver der tale om store krav til datalinks, der kan gøre det muligt at dele store datamængder med andre kampfly. Begge værn har også luftet ambitioner om kunstig intelligens, som i praksis formentlig vil tage form af avanceret pilotunderstøttelse i stil med den aktuelle fusionering af forskellige sensorinput, som i dag er at finde i F35.US Air Force og US Navy samarbejder også om en fælles motorløsning.En af mulighederne på tegnebrættet er en motor med justerbart bypassforhold, der kan tilpasses til den optimale effekt ved forskellige hastigheder og højder, hvilket skal give flyene bedre acceleration og ikke mindst længere rækkevidde.Eksempelvis et system, der fungerer som en turbojetmotor med reduceret bypass ved overlydsflyvning, og som en turbofanmotor med høj bypass ved lavere cruisehastigheder.Motorproducenterne General Electric og Pratt &amp; Whitney arbejder begge på såkaldte adaptive cyclemotorsystemer.CybermodstandEn nøgleegenskab i Northrop Grummans vision for et sjettegenerations kampfly er cyber resiliency, modstandsdygtighed over for cyberangreb.Efterhånden som elektronisk krigsførelse spiller en stadigt større rolle, forestiller selskabet sig ikke at kunne afværge samtlige forsøg på cyberangreb, men i stedet at gøre nye kampfly i stand til at registrere angreb og minimere skaden, inspireret af hvide blodlegemer.»Menneskekroppen er så modtagelig for infektioner, at tanken om at blokere angreb er urealistisk.Spørgsmålet er snarere, hvordan din krop reagerer, når du er inficeret.Hvide blodlegemer er et utroligt system, der angriber og forsøger at kontrollere infektioner på en måde, der forhindrer dem i at skade kroppen.Systemerne i 2030 vil være udstyret med noget lignende,« sagde Tom Vice, direktør for Northrop Grummans luftfartsdivision, til Defense News tidligere på året.Øget rækkeviddeDet nyligt offentliggjorte design fra Northrop Grumman er haleløst og minder i udformningen om selskabets nye kampdrone X47B, men med et frontparti, der minder mere om Lockheed Martins F35.Northrop Grumman satser på et usædvanligt stort kampfly, der kan rumme meget brændstof og dermed præstere øget rækkevidde. Netop den begrænsede brændstofmængde i F35 er blevet kritiseret, og som forsvarsmediet Defense News skrev i januar, kan flyets begrænsede rækkevidde i tilfælde af en konflikt med Kina tvinge de amerikanske hangarfly inden for rækkevidde af de kinesiske DF21 og DF26 ' carrier killer' mellemdistanceraketter.Også Mark Gunzinger fremhæver størrelse og rækkevidde som en afgørende forskel mellem femte og sjette generation af kampfly: »Jeg er faktisk ikke glad for udtrykket sjettegenerations kampfly, eftersom det antyder, at de kommende fly vil ligne de kampfly, vi kender i dag. Men hvis de nye fly skal kunne undertrykke fjendtlige kampfly og missilsystemer over store afstande og i længere perioder, skal de muligvis være meget større end kampfly i dag og bevæbnet med store mængder missiler samt en laser til brug mod jordmål og luftmål.Øget rækkevidde kræver en større platform, som muligvis må være mindre manøvredygtig end nuværende kampfly,« siger han.HøjenergilasereNetop lasere går igen i de tre producenters ambitioner for fremtidens kampfly. Air Force Research Laboratory har udsendt udbudsmateriale for et laservåben til bevæbning af næste generation af kampfly. Herunder en højenergilaser, der både kan anvendes mod jordmål og mod andre kampfly, og som kan affyres fra op til 20 kilometers højde og ved en fart på op til Mach 2,5.Højenergilasere til fly undergår for tiden en rivende udvikling, og som Ingeniøren skrev i januar, tester Pentagon og våbenproducenten General Atomics i øjeblikket en laser på 150 kW med henblik på at bevæbne de store ildstøttefly AC130.Ideen med højenergilasere til kampfly er dels at beskytte mod fjendtlige missiler og kampfly. Laservåbens nøjagtighed åbner imidlertid også op for offensiv anvendelse, for eksempel lufttiljordangreb mod specifikke køretøjer eller enkeltpersoner.»En vigtig egenskab for sjettegenerations kampfly er at vende tilbage til den samme hastighed og killing power, som F22 har, og som F35 ganske enkelt mangler. Derudover er der utrolig mange muligheder og stadig meget få visheder. Ud over laservåben og fjernbetjening omfatter mulighederne sensorintegrerede intelligente overflader, bedre datafusion og bedre muligheder for samarbejde med andre forsvarssystemer,« siger Richard Aboulafia.Pentagon kalkulerer ifølge sit budget for 2015 med at fløjte et egentligt indkøbsprogram i gang i 2018. j.Hvis de nye fly skal kunne undertrykke fjendtlige kampfly og missilsystemer over store afstande og i længere perioder, skal de muligvis være meget større end kampfly i dag.Mark Gunzinger, seniorforsker, tænketanken CSBA.BOEINGS nyeste bud på et sjettegenerations kampfly er dette koncept fra 2013.Flyet kan enten flyves med pilot eller fjernstyres. Pentagon har endnu ikke lagt sig fast på spørgsmålet om bemanding.To motorer øger flyets motorkraft og minimerer konsekvensen af et motorstop.Fravær af haleror og dermed vertikale flader bidrager til flyets begrænsede radarsynlighed. LOCKHEED MARTIN har som den eneste af de tre producenter fastholdt haleror i sit tidlige bud på et kampflydesign.Flyet har multispektral stealth, hvilket reducerer radarsynlighed i flere frekvensbånd. På nuværende F-35 virker stealth fortrinsvis mellem 8 og 12 GHz.Det har selvhelende egenskaber pga. de flydende epoxymaterialer, der forsegler brud på skroget.Flyet har ' øget hastighed', hvilket ikke er yderligere specificeret, men som ifølge Lockheed kræver nye gennembrud inden for fremdrift og generatorer.NORTHROP GRUMMAN har i december offentliggjort denne visualisering af sit bud på næste generation af kampfly.Flyet har laservåben i form af en solid-state-højenergilaser, der fungerer med stor nøjagtighed og lysets hastighed, men øger flyets infrarøde synlighed.Bagudvinklede vinger som på Northrops bombefly B-2 reducerer luftmodstanden og mindsker effekten af chokbølger ved overlydshastighed.
        </div>
        <footer>
          <em>Ingeniøren</em>
          &nbsp;·&nbsp; 2016-02-05
          &nbsp;·&nbsp; e58a8cfb
          &nbsp;·&nbsp; #21
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.601</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.627</kbd>
        </footer>
      </article>
      <article>
        <h4>Forskere: Danmark nøler med politik for autonome våben</h4>
        <div>
          Amerikanske skibe affyrer de samme målsøgende ESSM-luftmålsmissiler, som det danske forsvar råder over. Missilerne falder ifølge en ny rapport indenfor betegnelsen delvist autonome våben. Foto: United States NavyLande som USA og Storbritannien har vedtaget bestemmelser om ikke at overlade beslutninger om dødelig magt til robotter. Det har Danmark ikke, selv om det danske forsvar råder over flere delvist autonome våben.Mens industrien er i fuld gang med at udvikle sofistikerede våbensystemer, der kan udvælge og uskadeliggøre deres mål uden menneskelig indblanding, vokser gruppen af bekymrede forskere og fagfolk, som advarer mod at overlade aftrækkeren til maskiner.Også i det danske forsvar har våbensystemer med større eller mindre grad af selvbestemmelse gjort deres indtog. Men hvor lande som USA og Storbritannien har vedtaget direktiver om, at autonome våbens brug af dødelig magt skal være underlagt menneskers kontrol, har Danmark ingen nedfældet politik på området. Det er på høje tid, at danske poiltikere forholder sig til, hvordan forsvaret skal benytte autonome våben fremover, siger to eksperter i kunstig intelligens.»Autonome våben er jo noget, der helt åbenlyst er på vej. Dermed bliver man nødt til at tage stilling fra politisk hold. For mig at se er der ingen vej udenom: Man kan ikke bare lade det være op til en given indkøbsafdeling eller operativ chef, hvordan Forsvaret bruger den slags teknologi. Og med den udvikling, vi i øjeblikket ser inden for kunstig intelligens, er det nu, de danske politikere skal tage stilling,«siger Thomas Vestskov Terney, konsulent inden for digital strategi og ph.d. i kunstig intelligens.Våbensystemer i DanmarkFuldt autonome våbensystemer, der udvælger deres mål og foretager angreb uden nogen form for menneskelig indblanding, anvendes stadig ikke af nogen lande, heller ikke Danmark. Men Danmark råder ligesom mange andre lande over en række våbensystemer med bestemte autonome funktioner eller med mulighed for autonom anvendelse, såkaldte semiautonome systemer.Ifølge Forsvarsministeriets Materiel- og Indkøbsstyrelse drejer det sig i dag alene om to systemer, og kun i Søværnet: Nærforsvarssystemet til krigsskibe Millennium CIWS (Close-In Weapon Systems) og luftforsvarsmissillerne Evolved Seasparrow Missile System (ESSM).'Flyverstaben råder ikke over sådanne systemer. Søværnet råder over Close in Weapon Systems (CIWS) og missilsystemer, som godt nok har autonome funktionaliteter, men de er ikke implementeret i Søværnet. Det kan dog implementeres hvis vi ønsker det,'skriver pressechef René Gyldensten fra FMI i en email til Ingeniøren.Millennium CIWS beskytter med en 35 mm maskinkanon de danske fregatter mod fjendtlige missiler og fly. Systemet kan selv identificere og følge sine mål, men en menneskelig operatør træffer beslutningen om at åbne ild mod potentielle trusler. ESSM-missilerne er målsøgende og kan i slutfasen af flyvningen forfølge deres mål med en indbygget radar. Når de to våbensystemerns autonome funktioner ikke er implementeret i Danmark, er det ifølge FMI-s René Gyldensten 'alene af den grund, at der ikke er operative krav desangående'.'Vi har ikke en formuleret politik for autonome våbensystemer,'skriver han.Flere våben på listenMen spørger man forskere på området, der definerer våben med autonome funktioner lidt bredere end Forsvarsministeriet, råder det danske forsvar over flere end de to våbensystemer, der lever op til definitionen:Militærforsker Heather Roff fra Arizona State University sammensatte tidligere på året et register over autonome eller semiautonome våben på verdensplan, og på listen finder man en række såkaldte fire and forget -missiler, som også Danmark råder over. Det er guidede missiler, der efter affyring selv finder deres mål uden behov for styring fra en ildledelsesradar, og som derfor kan ramme deres mål, selv om det er uden for affyringssystemets synsfelt. På listen finder man Flyvevåbenets missiler AMRAAM og Sidewinder samt Søværnets Harpoon.»Det er helt oplagt, at der er brug for at tage diskussionen om, hvor langt vi vil gå i den militære udnyttelse af teknologien. Et eksempel på en tydelig grænse er jo princippet om human in the loop. Men man kunne også opstille andre grænser, for eksempel defensiv frem for offensiv brug af våbensystemerne,«siger Mikkel Willum Johansen, adjunkt og lektor i videnskabsteori ved Københavns Universitet.Status i andre landeBåde Storbritannien og USA har nedfældede politikker på området om netop human in the loop. Det britiske forsvarsministerium skriver i den såkaldte Joint Doctrine Note fra 2011, at Storbritannien -aktuelt ikke har nogen intentioner om at udvikle systemer, der kan operere uden menneskelig indblanding i våbenets kommando- og kontrolkæde-. Og det amerikanske forsvarsministerium skriver i Direktiv 3000.09 fra 2012, at anvendelsen af autonome våben kræver -passende niveauer af menneskelig kontrol over magtanvendelse-.USA og Storbritannien hører vel at mærke begge til den lille gruppe af lande, der selv udvikler autonome våben, og de to lande råder over våbensystemer med væsentlig højere grader af autonomi end Danmark. Ingen andre lande har på samme måde nedfældede direktiver på området, men Frankrig bekendtgjorde ved UNHCR's samling i 2013, at det franske forsvar -ikke besidder eller har ikke til hensigt at erhverve robotstyrede våbensystemer med kapacitet til at affyre uafhængigt af mennesker-. Lignende tilkendegivelser kom fra lande som Tyskland, Sverige, Mexico og Japan under FN's konvent om autonome våben i Genève i 2014.Ingeniørens ville gerne have talt med forsvarsminister Peter Christensen (V) om sagen, men det har ikke været muligt. I stedet har ministeriets presseafdeling sendt en skriftlig kommentar, som ikke direkte forholder sig til de to eksperters efterlysning af en dansk politik om autonome våben.'Det er relevant at følge udviklingen på området. Danmarks muligheder for at følge udviklingen på området omfatter blandt andet Nato-samarbejdet, hvor autonome våbensystemer, som militær kapacitet, følges i Nato-sammenhæng i Allied Command Transformation,'skriver pressemedarbejder Andreas Reckeweg Godfrey.
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2016-11-07
          &nbsp;·&nbsp; e5f638a9
          &nbsp;·&nbsp; #22
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.602</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.574</kbd>
        </footer>
      </article>
      <article>
        <h4>Fremtidens luftrum tilhører dronesværmene</h4>
        <div>
          Dronesværme kommer til at vende op og ned på fremtidens krigsførelse. Sværmene bringer selv de bedst beskyttede militære mål i fare.Da det amerikanske søværn for fem år siden slap otte små kamikazedroner løs mod en af sine destroyere i en række computersimulerede angreb, var resultatet ildevarslende.Destroyere ligger højt på listen over strategiske mål og er blandt de bedst beskyttede militære fartøjer. Ikke desto mindre kommer skibets avancerede forsvarssystemer til kort over for de små lavteknologiske droner med improviserede sprænghoveder:De amerikanske destroyere er udstyret til elektronisk krigsførelse, men skibets AN/SLQ-32-jammere er designet til at beskytte mod krydsermissiler, så de er ikke i stand til at afbryde smådroner uden betydelige opgraderinger. Dronesværmen benytter ikke infrarød målsøgning, så den bider heller ikke på de afledninger i form af brændende magnesiumstave, såkaldte flares, som skibet affyrer.Dronerne bliver på grund af deres lave radarsignatur først opdaget af skibets forsvarssystemer med 15 sekunders varsel, hvilket bringer dem for tæt på skibet til at affyre skibets letvægtskanon eller luftforsvarsmissiler, og skibets to manuelt betjente 25 mm maskingeværer er ikke i stand til at ramme så små mål.Det bedste bud på beskyttelse mod de små droner er derfor skibets to nærforsvarssystemer. De består af to radarstyrede revolverkanoner, som affyrer 4.500 skud i minuttet, og de udgør normalt et krigsskibs sidste forsvarslinje mod fjendtlige missiler. Men selv revolverkanonernes rækkevidde på 1,47 km bliver reduceret mod dronerne, som er meget mindre end antiskibsmissiler.Resultat af de i alt 500 opstillede scenarier er derfor, at fire af de otte droner slipper igennem skibets forsvarssystemer. Selv da forskerne bag rapporten afprøvede en række scenarier, hvor de amerikanske destroyere får opgraderet deres forsvarssystemer for flere milliarder dollars, slipper mindst én af dronerne igennem til skibet med sin sprængladning.Ændrer billedetMed andre ord må styrker verden over indstille sig på, at nogle af de bedst beskyttede militære mål bliver sårbare på en helt anden måde end tidligere.»Dronesværme er formentlig den mest effektive måde at benytte militære droner, også når vi ser på den teknologiske udvikling om 20 år. Det handler ganske enkelt om at overvælde fjendens forsvar,« siger Gary Schaub Jr, seniorforsker ved Center for Militære Studier på Københavns Universitet. Han er forfatter til en række videnskabelige rapporter om kampfly og senest den første danske rapport om autonome våben, som blev udgivet tidligere på året.»Det vil først og fremmest være stationære eller langsomme mål som militærbaser og krigsskibe, der er sårbare for angreb med dronesværme. Det skyldes, at dronerne er langsomme og har begrænset rækkevidde. Derfor kommer de også til at arbejde sammen med større fartøjer, der som en slags moderskibe kan sende en dronesværm afsted,« siger han.Netop dette så vi et eksempel på tidligere i år, da det amerikanske forsvar sendte en sværm af små Perdix-droner afsted fra tre kampfly, hvorefter dronerne autonomt gennemførte en række simple træningsopgaver.Kunstig intelligens bliver afgørendeBlandt de kendte eksempler er også det amerikanske søværns projekt Locust (Low-Cost UAV Swarming Technology), som siden 2015 har flyvetestet dronesværme på op til 30 enheder, beregnet til at angribe svært bevæbnede mål. Sværmene består af de små Coyote-droner, der er 0,9 meter lange, har en vægt på bare 5,9 kg og et vingespænd på halvanden meter.»Man behøver rent faktisk ikke at spejde særligt langt ud i fremtiden, for de fleste af komponenterne er allerede på plads, platforme, agilitet, drivkraft, kommunikationssystemer, sensorer, processorer og kontrolalgoritmer,« siger Randall Steeb, senioringeniør ved den amerikanske forsvarstænketank RAND Corporation, til Ingeniøren.»Nogle meget specifikke egenskaber er naturligvis stadig under udvikling, men alle de grundlæggende egenskaber er på plads nu. Hvis vi ser på den gængse definition af militær swarming, forstået som mange samtidige angreb fra flere retninger mod en større modstander, kan det godt gøres med de eksisterende teknologier,« siger han.Bevæbnede smådroner som Coyote er stadig delvist autonome, hvilket indebærer, at sværmen styres kollektivt af én dronepilot. De individuelle droner i sværmen selv er i stand til at flyve i formation og skifte placering, hvis en af dronerne bliver ødelagt. Men efterhånden vil dronepiloternes rolle aftage, og fremtidens dronesværme vil operere med en høj grad af autonomi. Dermed hænger den teknologiske udvikling inden for dronesværme uløseligt sammen med udviklingen indenfor kunstig intelligens.»Efter min mening har fjernstyring en meget begrænset fremtid inden for swarming, ud over at definere opgaver og eventuelt gribe ind og afblæse angreb, for eksempel i tilfælde af risiko for civile tab,« siger Randall Steeb.»Fjernstyring kræver langtrækkende kommunikation, hvilket medfører meget lang responstid og åbner sårbarheder for elektronisk krigsførelse eller jamming. Kunstig intelligens er nøglen til at indfri det fulde militære potentiale af swarming,« siger han.Ingen luftkampeEftersom dronesværme er særligt velegnede til at uskadeliggøre svært bevogtede militære mål, kan de også meget vel udgøre et alternativ til de store kampdroner som MQ-9 Reaper og MQ-1 Predator, som i dag spiller en central rolle i amerikanske luftangreb i verdens konfliktområder. De store droner er langsomme, har en høj radarsignatur og begrænsede muligheder for at beskytte sig, så de er i praksis henvist til at operere i områder, hvor kampfly i forvejen har etableret luftherredømmet.Derimod vil dronesværme næppe nogensinde kunne indgå i såkaldte dogfights i luften, eftersom de med al sandsynlighed også fremover vil være for langsomme til at kunne konkurrere med kampfly.»De små droner er ganske enkelt for langsomme. Hvis dronesværme skal have nogen anvendelse mod kampfly, bliver det mest sandsynligt i nærheden af deres lufthavne. Hvis man har de fornødne oplysninger om, hvor fjendens kampfly letter og lander, kan man jo sende en sky af små droner op foran kampflyene og håbe på, at en af dem rammer flyet,« siger Center for Militære Studiers Gary Schaub Jr.Han peger på, at en ubevæbnet hobbydrone for få måneder siden var tæt på at nedbringe et af de højteknologiske femtegenerationskampfly F-22 i USA.Kina lurer i kulissenUSA er ikke alene på banen, når det kommer til udviklingen af bevæbnede dronesværme.For få måneder siden satte det statsejede China Electronics Technology Group Corporation (CETC) rekord inden for flyvetest af dronesværme, da selskabet sendte en sværm på 119 droner på vingerne. Og Kina er ifølge CETC-s egne udmeldinger på niveau med USA, hvad angår udviklingen af teknologi til dronesværme.Om de kinesiske meldinger er korrekte eller ej er vanskeligt at vurdere. Men ifølge offentliggjorte beretninger fra Pentagon vil det kinesiske forsvar frem til 2023 investere over 10 milliarder dollars i at bygge over 41.000 små og store droner til både overvågning og kampoperationer. Til sammenligning råder det amerikanske forsvar i dag over godt og vel 7.000 droner. Og amerikanske Defense Science Board, som rådgiver det amerikanske forsvarsministerium, vurderede for fire år siden, at kinesiske investeringer i droneteknologi indenfor de kommende årtier vil overgå de amerikanske.Potentialet for militære dronesværme begrænser sig imidlertid ikke til angrebsvåben, vurderer Randall Steeb.»Der er ingen grund til at begrænse anvendelsen af dronesværme til angreb   selv om der foregår megen udvikling inden for små kampdroner og meget små svævevåben, så som Spike, Pyros og guidede mortergranater foruden kamikazesystemer som Switchblade. Swarming kan også bruges til overvågning, efterretninger, afskrækkelse, kommunikationsnetværk, endda logistik, med mange små fartøjer, der bevæger sig ligesom fiskestimer, der skilles og samles for at minimere tab,« siger senioringeniøren fra RAND Corporation.Mens det amerikanske søværn i øjeblikket arbejder på de motorløse og ubevæbnede Cicada-droner, der kan bruges til overvågningsopgaver såvel som til vejrmålinger, valgte det britiske forsvar sidste år at udskrive en konkurrence for at finde bud på, hvordan sværme på op til 20 mikrodroner kan bruges til at jamme fjendtlige kommunikationslinjer, følge bestemte individer og rekognoscere.
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2017-10-22
          &nbsp;·&nbsp; e677fe5c
          &nbsp;·&nbsp; #23
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.704</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.628</kbd>
        </footer>
      </article>
      <article>
        <h4>Forbud mod kamprobotter kræver en katastrofe</h4>
        <div>
          Når AI styrer fingeren på aftrækkeren, er der efter meget at dømme færre civile ofre i bevæbnede konflikter, men et dilemma er, hvornår og hvordan en militær AI vurderes som værende raffineret nok til at blive anvendt. Illustration: Yacobchuk /Big StockUdbredelsen af autonome kamprobotter på slagmarken tegner til at blive afgjort af i hvor høj grad vi accepterer antallet af civile tab dræbt af algoritmer og AI.»Det afgørende spørgsmål for menneskeheden er i dag, hvorvidt man skal indlede eller forhindre et globalt AI-våbenkapløb.« Sådan lød det for to år siden i et protestbrev til FN, i hvilket 3.963 forskere og fagfolk advarede mod at bevæbne kunstig intelligens. Brevet affødte international opmærksomhed, ikke mindst på grund af de prominente medunderskrivere som Stephen Hawking, Elon Musk, Apples Steve Wozniak og professor Noam Chomsky.»Hvis en given stor militærmagt skubber på udviklingen af våben med kunstig intelligens, er et globalt våbenkapløb stort set uundgåeligt, og slutmålet for den teknologiske kurs er indlysende: Autonome våben bliver morgendagens Kalashnikov,« skrev de.Røde Kors og Human Rights Watch fulgte op og opfordrede til helt at forbyde al udvikling og anvendelse af fuldt autonome våben.Nu har regeringsrepræsentanterne for FN-s medlemslande for første gang drøftet det, der er af de bekymrede fagfolk betegnes som den tredje revolution af krigsførelse: Anvendelsen af krigsmaskiner, som på baggrund af kunstig intelligens (AI) egenhændigt kan afgøre, hvornår der skal skydes for at dræbe.Og vil landene og især de nationale militære stormagter så følge op på forskernes advarsler?Næppe.Rusland skældte ud, USA fremhævede fordeleIngeniøren har gennemgået oplæg og talepapirer fra det just overståede møde i Genève. Her advarede Kina om, at et forbud mod AI i selvstyrende krigsmaskiner ikke måtte forplumre den overordnede udvikling og implementering af AI i almindelige fredelige formål.Rusland harcelerede over, at nogle medlemslande var forvirrede over forskellen på autonome og semi-autonome våben. Rusland havde desuden travlt med at pointere, at de ikke ønsker at overlade fingeren på aftrækkeren til en AI-s beslutningskæde, men påpegede samtidig, at en sådan beslutning stadig vil kunne spores tilbage til et menneske.»Man glemmer, at de maskinens automatiserede funktioner til at identificere og ramme mål er afgjort af et menneske gennem algoritme,« lød det i Ruslands talepapir.I et seks sider langt talepapir, præsenteret under møderne i Genève, opstillede USA lutter fordele ved at anvende autonome våben. AI vil markant kunne reducere antallet af civile ofre, som er langt i overtal i de væbnede konflikter. De dør ifølge den amerikanske delegation typisk, fordi bomber affyres for upræcist, fordi vi mennesker nu en gang er upræcise og sommetider har vanskeligt ved at holde hovedet koldt.Mange AI-forskere har svært ved at få denne argumentation til at gå op, om end de samtidig peger på et paradoks, som måske ligefrem kan dæmme op for brugen af fuldt autonome kamprobotter i klodens militære brændpunkter. For fidusen ved selvlærende algoritmer, altså programmer, der lærer uafhængigt af de data, de kan indsamle, er, at teknologien konstant forbedrer udførelsen af opgaven.Så hvis en autonom bevæbnet drone for alvor skal blive bedre til at være fleksibel, men samtidig forudsigelig nok til at operere sikkert i en kaotisk krigszone gennem en selvlærende algoritme, fordrer det en menneskelig afvejning af et acceptabelt udviklingsstadium, før det autonome system bliver sluppet løs på slagmarken egenhændigt.Altså en afvejning af, hvornår AI kan udnyttes i sin fulde udstrækning i krig.»Inden for militariseret machine learning betyder det, at politiske, militære og industrielle ledere skal specificere, hvor mange civile dødsfald der vil blive opfattet som acceptable, før AI-en betragtes som værende raffineret nok,« siger professor Peter Lee, direktør for Security and Risk Research ved University of Portsmouth,
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2018-04-19
          &nbsp;·&nbsp; e6b7e651
          &nbsp;·&nbsp; #24
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.882</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.625</kbd>
        </footer>
      </article>
      <article>
        <h4>Droner med kunstig intelligens jagtede militssoldater i den libyske borgerkrig</h4>
        <div>
          ISTANBUL Modstandernes soldater blev under den libyske borgerkrig jagtet af selvstyrende droner, og det var med til at vende krigslykken for den FN-støttede regering i Tripoli.Det fremgår af en FN-rapport, der indikerer, at det er det første kendte eksempel på autonome våben, som er blevet indsat i en aktiv kampsituation og selv har kunnet afgøre, hvem der skulle dræbes.De tyrkiskfremstillede droner var bl. a. udstyret med ansigtsgenkendelsesteknologi.De blev indsat af den libyske samlingsregering for at drive styrker loyale til den russisk-støttede krigsherre Marshal Khalifa Haftar ud af den libyske hovedstad. Da de begyndte at trække sig, blev de forfulgt af dronerne. De var i stand til at fortsætte missionen selv, efter at de havde bevæget sig uden for rækkevidde af en styregruppe.»Logistikkonvojer og soldaterne på tilbagetog blev jagtet og angrebet af de ubemandede kampdroner eller autonome våbensystemer såsom STM Kargu-2,« fastslår den 548 sider lange rapport fra marts.STM Kargu-2 er en henvisning til en knap 7 kg tung tyrkisk drone, som kan fungere i sværme på op mod 20 droner med henblik på at overvælde modstanderen. Producenten, STM, beskriver det som en propeldrevet angrebsdrone, der kan bruges autonomt eller styres manuelt.»De dødbringende autonome våbensystemer var programmeret til at angribe mål uden behov for dataforbindelse mellem operatøren og ammunition,« fortsætter rapporten, der er udarbejdet af et panel af uafhængige eksperter.Den siger dog ikke noget om, hvorvidt dronerne havde succes med at ramme deres mål.Droner er blevet udnyttet som et militært våben i mere end et årti. USA's tidligere præsident Barack Obama brugte det især i kampen mod terror, og hans afløser, Donald Trump, udvidede brugen af det i Afrika.Lande som Kina, Rusland og Israel har også en flåde af droner. Men brugen af intelligente droner i Libyen udstreger, hvor hurtigt teknologien breder sig, og det stiller nye krav til nationale forsvarssystemer.Angriber i sværme »Det betyder, at der skal tænkes på en ny måde. Det amerikanske luftvåben er f. eks.ved at gennemtænke hele sin måde at operere på, så det kan forsvare sig mod droner.De er billige og mere tilgængelige end kampfly som F-35 og vil i fremtiden formentlig blive brugt til at angribe i sværme,« siger Peter Viggo Jakobsen, lektor ved Forsvarsakademiet.Det leverede Tyrkiet i februar 2020 et eksempel på. Styrker fra det syriske regime marcherede med russisk støtte frem mod byen Idlib, som kontrolleres af en oprørsgruppe med tyrkisk støtte. Da et luftangreb dræbte flere end 30 tyrkiske soldater, iværksatte Tyrkiet en offensiv, som inkluderede droner.Dronerne, der blev brugt, var den ligeledes tyrkisk-fremstillede TB2 fra selskabet Baykar. Den larmer ikke særligt meget og er svær at opdage på en radar. De blev hængende i luften i timer, indtil de fandt sprækkerne i modstanderens luftforsvar. Fordi dronerne er relativt billige, kunne forsvaret tage større risici.»Hvis du mister en, to eller tre, er det lige meget, så længe andre droner rammer målet,« siger Ismail Demir, leder af det statslige kontrolorgan for Tyrkiets våbenindustri, til Wall Street Journal.Da Tyrkiet i 2020 øgede sin militære støtte til den libyske regering, brugte den erfaringerne fra Idlib til at forfine taktikken.Senere på året hjalp tyrkiske droner også styrker i Aserbajdsjan med at genvinde kontrollen over dele af Nagorno-Karabakh, som i mere end to årtier har været i hænderne på russisk-støttede armeniere.Droner er også blevet brugt af iransk-støttede grupper i Irak og Yemen til at angribe Saudi-Arabien. De er blevet brugt af Islamisk Stat, der købte dronedele og selv samlede dem. I 2019 blev tre mænd i Danmark kendt skyldige i at have købt dele til droner og sende dem til terrorgruppen i Syrien.Det er bl. a. muligt, fordi Kina er blevet en stor eksportør til Mellemøsten og Afrika.Mindst 10 lande, såsom Nigeria og De Forenede Arabiske Emirater, har brugt kinesiskproducerede droner til at angribe fjender, vurderer forsvarsanalytikere til Wall Street Journal.Det indikerer alt sammen, at droner er i gang med fundamentalt at ændre på, hvordan lande fører krig.Ændrer hele spillet »Det har konsekvenser, som ændrer hele spillet,« advarede den britiske forsvarsminister, Ben Wallace, i en tale i juli 2020 med henvisning til de tyrkiske droneangreb mod Idlib.I langt de fleste tilfælde er der dog tale om droner, som styres af mennesker, med indbyggede kameraer. Men rapporten fra FN indikerer, at kampen om at regulere autonome våbensystemer med kunstig intelligens er ved at blive tabt.Den Internationale Røde Kors Komité appellerede i sidste måned til verdenssamfundet om at lave internationale regler på området, herunder et generelt forbud mod at bruge dem mod mennesker.USA's præsident, Joe Biden, har forud for et besøg i Europa, hvor han bl. a. skal deltage i et Nato-topmøde, også advaret mod truslen fra ny teknologi.»I takt med at nye teknologier ændrer vores verden på en fundamental måde, udstiller sårbarheder mod angreb fra afpresningssoftware og skaber trusler såsom en indgribende kunstig intelligens-drevet overvågning, må verdens demokratier gå sammen for at sikre, at vores værdier regulerer brugen og udviklingen af dem - ikke autokratiske interesser,« skrev han i weekenden i et indlæg i avisen Washington Post.heidi.plougsgaard@jp.dk Det har konsekvenser, som ændrer hele spillet.BEN WALLACE, STORBRITANNIENS FORSVARSMINISTER I EN TALE I 2020.Fakta: DRONER SOM VÅBENI mange lande forskes der i kunstig intelligens i militært øjemed. Udvikling af droner indgår, men droner er typisk ikke i stand til at operere autonomt, men programmeres eller styres af et menneske.USA satte sin første drone op i midten af 1990' erne over Balkan under krigen i Bosnien. I mange år blev de kun brugt til rekognoscering. Under præsident Barack Obama blev droner, bevæbnet med missiler, taget massivt i anvendelse.I krigene i Afghanistan og Irak blev der sat droner ind i masser af aktioner mod terrorledere. I januar 2020 brugte daværende præsident Trump et droneangreb til at dræbe general Qassem Soleimani, lederen af Quds-styrken i Irans revolutionsgarde.USA har længe været tilbageholdende med at sælge sine mest avancerede modeller - selv til allierede. Men som reaktion på droneeksporten fra Kina og andre producenter blødte Trump-regeringen i juli 2020 op på reglerne.
        </div>
        <footer>
          <em>Jyllands-Posten</em>
          &nbsp;·&nbsp; 2021-06-08
          &nbsp;·&nbsp; e84d6210
          &nbsp;·&nbsp; #25
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.561</kbd>
            <kbd data-tooltip="Cyberwarfare &amp; geopolitics">L10_CYBERW&nbsp;0.522</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.622</kbd>
        </footer>
      </article>
      <article>
        <h4>Robotvåben vælger selv deres ofre</h4>
        <div>
          På en klar efterårsdag sidste år ud for det sydlige Californiens kyst affyrede et Air Force B-1-bombefly et forsøgsmissil, der kan være et varsel om fremtidens krigsførelse.Piloterne om bord på flyet styrede til at begynde med missilet, men da det var nået halvvejs til målet, afbrød det kommunikationen med piloterne. Alene og uden menneskelig styring besluttede missilet, hvilket af de tre skibe det skulle angribe.Det søgte ned til en højde lige over havets overflade og ramte et ubemandet fragtskib på 260 fod.Der bruges stadig mere software til at føre krig. I dag kan bevæbnede droner fjernstyres af piloter, der sidder tusinder af kilometer fra krigsskuepladsen og stirrer ind i en skærm. Men ifølge nogle forskere har våbenproducenterne nu krydset en grænse og bevæget sig ud i et terræn fuldt af faldgruber: De udvikler våben, der bruger kunstig intelligens i stedet for instrukser fra mennesker til at beslutte, hvad der skal angribes, og hvem der skal dræbes.I takt med at disse våben bliver mere intelligente og raffinerede, bliver de ifølge kritikere stadig vanskeligere for mennesker at styre - og forsvare sig imod. Den store præcision kan redde civile liv, men kritikerne påpeger, at våben uden menneskelig styring kan øge sandsynligheden for krig - det bliver lige så nemt som at trykke på en knap.Også Norge bruger dronerStorbritannien, Israel og Norge bruger allerede missiler og droner, der gennemfører angreb på fjendens radaranlæg, kampvogne og skibe uden direkte menneskelig styring. Når disse såkaldte autonome våben er blevet affyret, bruger de kunstig intelligens og sensorer til at udvælge mål og angribe.Briternes ' fyr og glem-missiler' af typen Brimstone kan for eksempel selv skelne mellem kampvogne og biler og busser, ligesom de kan jage mål i et på forhånd de-fineret område, uden at mennesker blander sig.Der er våben med endnu mere avanceret selvstyring på tegnebrættet, men detaljerne om dem holdes som regel hemmelige.»Der forgår allerede et våbenkapløb inden for autonome våben«, siger Steve Omohundru, der arbejder med kunstig intelligens på forskningscentret Self-Aware Systems i Palo Alto i Californien. »De er i stand til at reagere hurtigere, mere effektivt og mindre forudsigeligt«.FN ønsker forbudBekymringen for et robotvåbenkapløb var en af grundene til, at repræsentanter for et dusin lande i denne uge mødtes i Genève for at drøfte, om der skal indføres begrænsning på denne type våben ved hjælp af FN's konvention om særlige våben.Christof Heyns, FN's særlige rapportør om vilkårlige henrettelser uden forudgående rettergang, krævede sidste år et forbud mod at udvikle disse våben.Det amerikanske forsvarsministerium har udsendt et direktiv, der kræver tilladelse fra højt niveau til at udvikle våben, der kan dræbe uden menneskelig styring.Men den hurtige teknologiske udvikling har ifølge nogle forskere allerede gjort direktivet forældet.»Det, der optager os, er, hvordan angrebsmålene bliver udvalgt, og især, hvem der udvælger dem«, siger Peter Asaro, medstifter og næstformand for International Committee for Robot Arms Control, en gruppe forskere, der ønsker restriktioner på brug af militære robotter.»Er det mennesker, der har udpeget målene? Eller beslutter disse systemer selv, hvad målet er?«. Våbenproducenter i USA var de første, der udviklede avancerede autonome våben.En tidlig udgave af krydsermissilet Tomahawk var i stand til selv at jage sovjetiske skibe på havet uden direkte menneskelig styring. Våbnet blev taget ud af brug i begyndelsen af 1990' erne, efter at der var blevet indgået en atomvåbenaftale med Rusland.Ramte indisk skibTilbage i 1988 afprøvede den amerikanske flåde et Harpoon-missil, der anvendte en tidlig form for selvstyringsteknologi. Missilet forvekslede et indisk fragtskib med sit mål. Harpoon-missilet, der ikke var armeret med et sprænghoved, slog ned på fragtskibets bro og dræbte et besætningsmedlem.Trods ulykken blev Harpoon en fast bestanddel af flådens arsenal, og det er stadig meget brugt.I de seneste år er kunstig intelligens begyndt at erstatte menneskets beslutninger på en række områder, herunder hurtig aktiehandel, lægelig diagnosticering og sågar i selvkørende biler. Men det er teknologiske fremskridt på tre konkrete felter, der har banet vej for våben, som reelt er selvstyrende.Nye typer af radarer, laser og infrarøde sensorer har gjort missiler og droner bedre til at beregne deres position og orientering.' Maskinsyn', der minder om menneskets syn, identificerer mønstre i billeder og hjælper våbnene med at udpege vigtige mål. Disse detaljerede sensordata fortolkes hurtigt af kunstig intelligens og sætter missilet eller dronen i stand til selv at foretage en analyse i luften.Det missil, der blev testet ud for Californiens kyst, et langtrækkende antiskibsmissil, udvikles af Lockheed Martin for luftvåbnet og flåden. Det er beregnet til at flyve hundreder af kilometer og selv manøvrere uden om radarsystemer uden radiokontakt med menneskelige operatører.Direktiv med reglerI et direktiv fra 2012 trak det amerikanske forsvarsministerium en grænse mellem halvautonome våben, hvis mål udvælges af mennesker, og helautonome våben, der kan jage og angribe mål uden at modtage konkrete instrukser om det.Fremtidens våben, hedder det i direktivet, skal »konstrueres således, at militære beslutningstagere og operatører har mulighed for i et passende omfang at udøve menneskelig dømmekraft i forbindelse med magtudøvelse«. Alligevel hævder forsvarsministeriet, at det nye antiskibsmissil kun er halvautonomt, og at mennesker er tilstrækkeligt repræsenteret i dets beslutninger om at angribe og dræbe. Men hverken hos Defense Advanced Research Projects, der oprindelig udviklede missilet, eller hos producenten, Lockheed Martin, ønsker man at kommentere, hvordan våbnet udvælger mål. Det er fortrolige oplysninger, lyder det begge steder.»Det vil operere autonomt, når det søger efter fjendens flåde«, siger Mark A. Gubrud, der er medlem af International Committee for Robot Arms Control og tidligt advarede mod såkaldte intelligente våben. »Det her er ganske avancerede sager, som jeg vil kalde kunstig intelligens, der er uden for menneskelig kontrol«, siger han.Paul Scharre, en våbenspecialist, der i sin tid var med til at skrive forsvarsministeriets direktiv, siger: »Det er relevant at spørge, om det her går over stregen«. Nogle eksperter i våbenkontrol siger, at det er for vagt, når forsvarsministeriet kun kræver menneskelig kontrol »i passende omfang« over disse våben, og at det er med til at fremskynde udviklingen af nye systemer, der automatiserer drab.Christof Heyns fra FN siger, at lande med avancerede våben bør indvilge i at begrænse sig til våbensystemer, der har »væsentlig« menneskelig kontrol over udvælgelse af og angreb på mål. »Det skal svare til den rolle, en militær leder har over for sine soldater«, siger Christof Heyns.Og det er ikke tilstrækkeligt med systemer, der giver mennesker mulighed for at omstøde computerens beslutninger, tilføjer han. Våben, der træffer egne beslutninger, opererer så hurtigt, at det inden længe kan blive svært for menneskelige operatører at følge med.Ramte otte kampvogne på en gang Norge har planer om at udstyre sin flåde af kampfly med Joint Striker-missilet, der uden instrukser fra mennesker kan jage, udpege og angribe et mål. Modstandere af missilet kalder det en dræberrobot.Militæranalytikere som Paul Scharre siger, at automatiserede våben er et fremskridt, fordi de kan resultere i færre massedrab og civile tab. Den slags våben begår ikke krigsforbrydelser, siger han.16. september 2011 affyrede britiske kampfly for eksempel 24 Brimstone-missiler mod en gruppe libyske kampvogne, der beskød civile. Mindst otte af kampvognene blev ifølge en militær talsmand ødelagt på en gang, hvilket reddede mange civiles liv. Det ville nemlig have været vanskeligt for menneskelige operatører at koordinere sværmen af missiler lige så præcist.»Bedre og mere intelligente våben er en god ting, hvis de begrænser civile tab og vilkårlige drab«, siger han.Oversættelse: Tonny Pedersen.udland@pol.dk Det er relevant at spørge, om det her går over stregen Paul Scharre, militæranalytiker.
        </div>
        <footer>
          <em>Politiken</em>
          &nbsp;·&nbsp; 2014-11-15
          &nbsp;·&nbsp; e4ac89a3
          &nbsp;·&nbsp; #26
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.99</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.664</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.615</kbd>
        </footer>
      </article>
      <article>
        <h4>Google-ansatte vil stoppe militært samarbejde</h4>
        <div>
          Tusinder af Google-ansatte mener ikke, at firmaet skal associeres med krig.Google har givet Pentagon lov til at bruge noget af deres teknologi til et militært projekt. Foto: Mark Lennihan/ APAnne FilbertGoogle har givet det amerikanske forsvar lov til at bruge firmaets billedeteknologi til deres militære projekt, der går under navnet &quot;Maven&quot;. Projekt Maven involverer brug af kunstig intelligens for at kunne forbedre præcisionen af militære droneangreb.Det skriver.De ansatte i Google er dog ikke særligt venligtstillede over for beslutningen om at hjælpe det amerikanske militær med at føre krig. Det skriver de i et åbent brev til Googles administrerende direktør, Sundar Pichai.»Vi mener, at Google ikke skal være medvirkende til at føre krig. Netop derfor beder vi om, at projekt Maven bliver droppet, og at Google udarbejder en klar politik om, at hverken Google eller Googles samarbejdspartnere nogensinde vil producere krigsteknologi,« skriver de ansatte.
        </div>
        <footer>
          <em>Jyllands-posten.dk</em>
          &nbsp;·&nbsp; 2018-04-05
          &nbsp;·&nbsp; e6b1428c
          &nbsp;·&nbsp; #27
          <br>
          <br>
            <kbd data-tooltip="Tech industry &amp; regulation">L02_BIGTEC&nbsp;0.745</kbd>
            <kbd data-tooltip="EU regulation of big tech">L10_EUREGU&nbsp;0.505</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.569</kbd>
        </footer>
      </article>
      <article>
        <h4>Kamprobotterne kommer</h4>
        <div>
          Den 145 ton tunge ubådsjæger glider gennem vandet og scanner havet under sig uden et eneste besætningsmedlem om bord. Finder den et mål, kan Sea Hunter, som det amerikanske forsvars hemmelighedsfulde udviklingsenhed Darpa slap løs sidste år, selv udpege fjendens mest sårbare punkter og indlede et angreb. Det må den bare ikke uden grønt lys fra et menneske.Ikke endnu, i hvert fald.USA's politik for autonome våben er formuleret i direktiv 3000.09, som kræver, at dødelig magtanvendelse er underlagt »passende niveauer af menneskelig vurdering«. Det betyder i praksis, at det amerikanske forsvar ikke lader autonome våben angribe uden et menneske in the loop. Det har været et centralt dogme lige så længe, som højteknologiske droner, missilforsvarssystemer og kanontårne har været udstyret med kunstig intelligens (AI).Men direktiv 3000.09 udløber i år. USA's regering under præsident Donald Trump skal i næste måned tage stilling til, hvordan det amerikanske forsvars regler for anvendelse af kamp robotter skal se ud fremover. Men uanset hvordan det næste femårige direktiv falder ud, er det et spørgsmål om tid, før mennesker overlader kontrollen med aftrækkeren til maskinerne, vurderer Richard Aboulafia, vicedirektør i analysevirksomheden Teal Group og rådgiver inden for militær luftfart: KAMPDRONEN X-47B kan selv lette fra og lande på hangarskibe og kan modificeres til at foretage autonome angreb. Foto: Northrop Grumman »Rent faktisk tror jeg, det er uundgåeligt, at AIånden slipper ud af flasken. Men forhåbentlig under begrænsede forhold og omstændigheder,« siger han til Ingeniøren.»I løbet af de næste 30 år vil udviklingen inden for autonomi og kunstig intelligens gradvist gøre våbensystemer mere dødbringende.Det kan gøre verden til et mere usikkert sted. Heldigvis tager teknologiske gennembrud som AI altid længere tid at udvikle end forventet.Så måske vil menneskeheden nå at udvikle de nødvendige betingelser, retningslinjer og endda spredningskontrol for at forhindre de værste scenarier,« siger Richard Aboulafia.Pentagons 2036-plan En række offentligt tilgængelige dokumenter viser en konkret forventning hos det amerikanske..krav om menneskelig kontrol over autonome systemer, og fokus er på hastighed, antal og præprogrammerede handlinger. Det vil sandsynligvis afføde en hurtigere proces med at få dronesværme i kamp end hos lande, der arbejder under den vestlige doktrin,« siger Peter Roberts.Ifølge folkeretsforskere som Michael N. Schmitt og Jeffrey S.Thurnher, der sidste år offentliggjorde en artikel om kunstig intelligens i Harvard National Security Journal, kan udviklingen i andre lande ganske enkelt tvinge Pentagon til at slippe tøjlerne på kamprobotter.Med den forventede udvikling i Kina og Rusland kan tempoet på slagmarken blive så højt, at hverken mennesker eller et tøjlet våbensystem kan følge med, skriver de to forskere i artiklen, som Ingeniøren også omtalte sidste år.... forsvarsministerium om at anvende autonome våben uden menneskelig indblanding inden for en tidsramme på 20 år. Pentagon skriver i sin 25årsplan ' Unmanned Systems Integrated Roadmap 20112036', at man »forventer, at ubemandede systemer problemfrit vil operere side om side med bemandede systemer, med en gradvis reduktion af menneskelig kontrol i den ubemandede del af forsvaret«. Særligt det amerikanske luftvåben har ambitioner på området.US Air Force forventer ifølge sin egen ' Unmanned Aircraft Systems Flight Plan 20092047', at kunstig intelligens vil gøre det muligt for autonome systemer at »bestemme og udføre kamphandlinger« uden input fra mennesker. Og her forventer Michael Byers, professor ved University of British Columbia og forfatter til en række bøger om forsvarspolitik, at droner vil overflødiggøre bemandede kampfly inden for levetiden af femtegenerationskampfly som F35.Blandt de nyeste eksempler er amerikanske Northrop Grummans X47B, som selv kan lette fra og lande på hangarskibe og kan modificeres til at foretage autonome angreb.»Luftkamp vil næsten med sikkerhed blive autonom, kontrolleret af en form for kunstig intelligens, hvilket rejser nogle vanskelige spørgsmål om kontrol og juridisk ansvar,« siger Michael Byers til Ingeniøren.Derfor bliver udviklingen også mødt med stor bekymring fra mange sider, herunder fra specialister i robotter og kunstig intelligens. Det skabte overskrifter verden over, da 3.100 forskere og fagfolk i et åbent brev til FN i 2015 advarede mod at bevæbne kunstig intelligens. Ikke mindst på grund af de prominente medunderskrivere som Stephen Hawking, Elon Musk, Apples Steve Wozniak og professor Noam Chomsky.»Det afgørende spørgsmål for menneskeheden er i dag, hvorvidt man skal indlede eller forhindre et globalt AIvåbenkapløb.Hvis en given stor militærmagt skubber på udviklingen af våben med kunstig intelligens, er et globalt våbenkapløb stort set uundgåeligt, og slutmålet for den teknologiske kurs er indlysende: Autonome våben bliver morgendagens Kalashnikov. () Det vil kun være et spørgsmål om tid, før våbnene dukker op på det sorte marked og i hænderne på terrorister, diktatorer med ønsker om bedre kontrol med befolkningen eller krigsherrer med ønsker om etnisk udrensning. Autonome våben er ideelle til opgaver som mord, destabilisering af stater, undertrykkelse af borgere og drab på en bestemt etnisk gruppe,« skriver de bekymrede fagfolk, mens Røde Kors og Human Rights Watch opfordrer til helt at forbyde al udvikling og anvendelse af fuldt autonome våben.Skrøbelig amerikansk føringHvis USA og andre vestlige lande i de kommende år holder fast i en restriktiv politik for autonome våben, kan lande som Rusland og Kina meget vel overtage førerpositionen på området, siger Peter Roberts, seniorforsker og institutleder ved det anerkendte Royal United Services Institute for Defence and Security Studies i London.»Den amerikanskledede vestlige doktrin forudser foreløbig ikke, at mennesket tages ud af loopet. Her er fokus på et samarbejde mellem mennesker og maskiner på slagmarken. Den tilgang bygger på monitorering, kontrol og styring af alle handlinger udført af autonome systemer. Den største styrke bliver dermed at kombinere maskinernes kapacitet med den menneskelige evne til at tænke uden for binære, reaktionsbaserede beslutninger og dermed tilføre list og uforudsigelighed,« siger han og peger på dronesværme som eksempel.»I kontrast dertil stiller den østlige doktrin - russiske, iranske og kinesiske militære skoler - ingen.Hvad gør Danmark?Hvis det amerikanske forsvar, enten af egen drift eller tvunget af de operationelle realiteter, går i retning af mere autonome våbensystemer, rejser det også en række principielle spørgsmål for allierede som Danmark. Og de danske politikere burde allerede nu være i gang med at formulere en politik på området.Det var konklusionen i den første danske rapport om anvendelsen af autonome våben, som Center for Militære Studier ved Københavns Universitet offentliggjorde i februar.Ud over selve spørgsmålet om at anvende autonome våben i det danske forsvar bliver det nødvendigt at formulere en politik for, hvorvidt allierede styrkers autonome våben må udstationeres på eller passere igennem dansk territorium, og hvorvidt danske styrker må deltage i militære operationer med autonome våben, konkluderer Center for Militære Studier.Forslaget om en dansk politik på området blev imidlertid her i Ingeniøren skudt til hjørne af forsvarsminister Claus Hjort Frederiksen (V), som i første omgang vil følge med i det internationale arbejde på området. Det foregår blandt andet i regi af Nato, der lige nu undersøger rammerne for fremtidige internationale operationer.Det danske forsvar råder i forvejen over delvist autonome våben i form af missiler og torpedoer af typen fire and forget, som efter affyring selv kan finde frem til deres mål.Det drejer sig om ESSMluftforsvarsmissiller, Harpoon Block IIantiskibsmissiler, MU90antiubådstorpedoer, luft til luftmissilet AIM120 AMRAAM og luft til jordmissilet AGM 65 Maverick.Ud over USA er det i dag kun Storbritannien, der har en formuleret politik om anvendelsen af autonome våben. Storbritannien producerer vel at mærke selv autonome våben, og bestemmelsen i det britiske forsvarsministeriums såkaldte ' Joint Doctrine Note' fra 2011 er lige så løst formuleret som det amerikanske direktiv, idet Storbritannien »aktuelt ikke har nogen intentioner om at udvikle systemer, der kan operere uden menneskelig indblanding i våbnets kommandoog kontrolkæde«. FN besluttede sidste år at oprette den indtil videre eneste mellemstatslige ekspertgruppe med regeringsrepræsentanter, der skal diskutere både de teknologiske, militære, juridiske og etiske implikationer ved at udvikle autonome våben.Den såkaldte Group of Governmental Experts on Lethal Autonomous Weapons Systems har sit første møde i Genève midten af næste måned. j.Luftkamp vil næsten med sikkerhed blive autonom, kontrolleret af en form for kunstig intelligens, hvilket rejser nogle vanskelige spørgsmål om kontrol og juridisk ansvar.Michael Byers, professor, University of British Columbia.Ingeniøren og ing.dk ser i dag og i næste uge nærmere på de teknologiske udviklinger og udfordringer, der kommer til at forme slagmarken i løbet af de kommende årtier.Dette er første artikel i serien.
        </div>
        <footer>
          <em>Ingeniøren</em>
          &nbsp;·&nbsp; 2017-10-06
          &nbsp;·&nbsp; e6728638
          &nbsp;·&nbsp; #28
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.688</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.555</kbd>
        </footer>
      </article>
      <article>
        <h4>Verdens klogeste hoveder advarer: Autonome våben vil blive morgendagens kalasjnikover</h4>
        <div>
          Lad dig ikke narre af, at denne artikel starter med et sci-fi billede fra filmen Terminator - snart vil vi se rigtige dræber-robotter på alverdens slagmarker, hvis vi ikke passer på, mener en række af mænd, hvis evne til at se ind i fremtiden overgår de flestes.Fysikeren Stephen Hawking, SpaceX/Tesla-bossen Elon Musk og over 1000 andre af verdens førende eksperter i kunstig intelligens (AI) og robotforskning har underskrevet et brev, hvori de foreslår et forbud mod robot-krig.I brevet advares mod potentialet for voldsom destruktion ved brug af &quot;autonome våben&quot;. Sagt med andre ord: Robotter, der dræber på egen hånd vil kunne sætte verden i flammer.Hvis én af de største militærmagter kommer foran i udviklingen af AI-våben, vil et globalt våbenkapløb være næsten uundgåeligt (...)Autonomous Weapons: an Open Letter from AI &amp; Robotics ResearchersBrevet, som mandag den 27. juli blev præsenteret under konferencen International Joint Conference on Artificial Intelligence i Buenos Aires, Argentina, advarede specifikt mod et &quot;AI-våbenkapløb&quot; mellem verdens førende militærmagter. I brevet står:&quot;Kunstig intelligens (AI-teknologi) er nået et punkt, hvor implementeringen af sådanne systemer er - praktisk, hvis ikke lovligt - gennemførlige inden for få år, ikke årtier, og der er meget på spil: Autonome våben er blevet beskrevet som den tredje revolution inden for krigsførelse, efter krudt og atomvåben.&quot;Forskerne argumenterer ikke idealistisk for at stoppe al højteknologisk krigsførelse, men vil sørge for, at sådanne våben altid bliver udløst af mennesker. Forskernes fokus er således på våben, der egenhændigt kan søge og finde mål ud fra forudbestemte kriterier - i modsætning til guidede missiler og fjernstyrede droner, hvis brug indbefatter, at mennesker beslutter, hvem de vil ramme.Heraf følger konklusionen, at ingen af verdens største militærmagter bør begynde en jagt på udviklingen af autonome våben. I brevet står:&quot;Hvis én af de største militærmagter kommer foran i udviklingen af AI-våben, vil et globalt våbenkapløb være næsten uundgåeligt, og slutpunktet på denne teknologiske bane er åbenlyst: Autonome våben vil blive morgendagens kalasjnikover.&quot;Udover at brevet er underskrevet af Stephen Hawking og Elon Musk, så er der også indsamlet signaturer fra Apples med-grundlægger Steve Wozniak, chefen for Googles Deepmind-afdeling, Demis Hassabis, professor Noam Chomsky og Googles research-leder Peter Norvig.Slutteligt står der i brevet:&quot;Vi tror, at AI har stort potentiale til at gavne menneskeheden på mange måder, og målet bør være at gøre dette. At starte et AI-våbenkapløb er en dårlig idé og bør blive præventivt forhindret med et forbud mod autonome våben, der er uden for meningsfuld, menneskelig kontrol.&quot;
        </div>
        <footer>
          <em>Jp.dk (Jyllands-Posten) (Abonnementsområde)</em>
          &nbsp;·&nbsp; 2015-07-28
          &nbsp;·&nbsp; e5240286
          &nbsp;·&nbsp; #29
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.972</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.662</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.529</kbd>
        </footer>
      </article>
      <article>
        <h4>Militære sværvægtere ruster sig til krig på kunstig intelligens</h4>
        <div>
          USA har få kvababbelser over kunstig intelligens i kamprobotter, Rusland skælder ud på nærmest alle for at misforstå autonomi i kamprobotter, og Kina kæmper mest af alt for at beskytte sine AI-ambitioner.Stormagterne ser stort potentiale i autonome våbensystemer, der kan gøre tempoet på slagmarken så højt, at mennesker ikke kan følge med. FN har netop afsluttet en uges debat uden at blive enige om restriktioner.Mængden af krudt og kugler var engang udslagsgivende for, hvem der sejrede eller betalte den ultimative pris på slagmarken. Trumfkortet fremover tegner til at blive kredsløb og kunstig intelligens.Det indikerer sidste uges FN-diskussioner i Genève. En mellemstatslig ekspertgruppe og regeringsrepræsentanter drøftede for første gang officielt det, der bliver betegnet som den tredje revolution inden for krigsførelse: anvendelsen af krigsmaskiner, som på baggrund af kunstig intelligens (AI) egenhændigt kan afgøre, hvornår der skal skydes for at dræbe.Blandt oplægsholderne var en række forskere, der advarede om at overlade aftrækkeren til kunstig intelligens. Anvendelsen af selvstyrende krigsmaskiner risikerer ifølge forskerne at bryde Genèvekonventionens regler om beskyttelse af civilbefolkning i krigstid, fordi AI på nuværende tidspunkt er uforudsigelig.»Teknisk set mangler autonome våben de nødvendige komponenter til, at vi kan være sikre på, at de er i stand til at udvise proportionalitet for at opfylde en opgave i en konflikt. Desuden er deres opførsel uforudsigelig, særligt i scenarier, hvor flere forskellige AI-er interagerer,« lød det fra Lucy Suchman, professor ved Lancaster University, da Ingeniøren talte med hende forud for møderne i Genève.USA-s politik for autonome våben er formuleret i direktiv 3000.09, som kræver, at dødelig magtanvendelse er underlagt »passende niveauer af menneskelig vurdering« , men direktivet udløb egentlig sidste år. USA-s fremtidige anvendelse af kamprobotter skal derfor revurderes under præsident Donald Trump.I et seks sider langt talepapir fra Genève opstiller USA lutter fordele ved at anvende autonome våben.»Frem for at forsøge at stigmatisere eller bandlyse teknologier, der er på vej inden for autonome våbensystemer, bør nationerne hellere opfordre til innovation, der fremmer formålet med konventionen,« lød det fra USA-s repræsentant.Aftrækkeren bliver programmeretLande som USA, Israel, Storbritannien og Sydkorea råder allerede i dag over skibe eller artillerisystemer baseret på det, man kunne kalde militær machine learning. Uden menneskelig indflydelse er de i stand til at opstøve fjender og indlede angreb. Indtil videre skal mennesket dog stadig give grønt lys i beslutningskæden.Ruslands præsident, Vladimir Putin, erklærede sidste år, at dén, som formår at være toneangivende inden for AI, vil styre verden.I Genève fremførte Rusland dog, at de ikke agter at anvende fuldstændig autonome krigsmaskiner. Men Rusland kritiserede samtidig, at FN-bestræbelserne på at regulere brugen af autonome våben med AI efter Ruslands opfattelse er på vej til også at gøre brugen af bevæbnede droner mindre automatisk af misforstået frygt for og forvirring over at afgive for megen menneskelig medbestemmelse.»Man glemmer, at maskiners automatiserede funktioner til at identificere og ramme mål er afgjort af et menneske gennem algoritmer,« fremførte Rusland.Herhjemme lyder samme pointe fra Iben Yde, ph.d. i folkeret og juridisk rådgiver for Forsvarskommandoen. Hun skrev for to år siden sin afhandling om regulering af autonome våben.»Den eneste forskel fra konventionelle våben er, at den menneskelige kontrol bliver forskudt fra realtid til at ligge i programmeringsfasen,« siger hun til Ingeniøren.Ifølge Rusland forplumrer mange lande drøftelserne, fordi de ikke forstår forskellene på autonome og semi-autonome våben såsom en lang række eksisterende målsøgende missiler. Ruslands udsendte understregede derfor, at det er en misforståelse, at fuldt selvstyrende kamprobotter allerede bliver anvendt i militære brændpunkter, og at diskussionen om et forbud bygger på »spekulative diskussioner løsrevet fra realiteterne« .AI-kapløb tager tilIkke overraskende samtykkede Kina, som tegner til at indtage AI-førertrøjen.Ifølge folkeretsforskere som Michael N. Schmitt og Jeffrey S. Thurnher, der for få år siden offentliggjorde en artikel om kunstig intelligens i Harvard National Security Journal, kan den forventede udvikling i Kina og Rusland gøre tempoet på slagmarken så højt, at mennesker ikke kan følge med, hvorfor udviklingen ganske enkelt kan tvinge USA til at slippe tøjlerne på kamprobotter.Kina ser brugen af AI som nødvendig for at opretholde økonomisk vækst, så mulige FN-restriktioner kan stække landets ambitiøse AI-agenda.»Kina tror, at påvirkningen fra nye teknologier fortjener objektive, upartiske og fyldestgørende diskussioner. Indtil sådanne diskussioner er foretaget, bør der ikke indgås nogle præmisser eller forudindtagne resultater, som kan obstruere udviklingen af AI-teknologi,« sagde Kinas repræsentant.FN-regeringsrepræsentanterne nåede ikke til enighed om noget forbud. Gruppen mødes igen i august, men ifølge mange af de forskere, som Ingeniøren har talt med om sagen, har et forbud mod autonome våben lange udsigter. Kinesiske Hin-Yan Liu har tidligere skrevet artikler om autonome våbensystemer i internationale forskningstidsskrifter og er i dag professor ved Juridisk Institut på Københavns Universitet.»Jeg ser absolut ingen chancer for et proaktivt forbud, omend jeg gerne så det,« siger han.»Verden bliver formentlig nødt til at opleve et afgørende øjeblik, der destillerer alle de frygtelige ting, autonome våben legemliggør. Og på en måde, som er relaterbar for offentligheden. Hvis der bliver indført et forbud, bliver det på baggrund af en frygtelig ugerning begået af autonome våbensystemer. Jeg håber inderligt, at jeg tager fejl, men mennesker er tilbøjelige til først at lære af deres fejltrin,« siger Hin-Yan Liu.
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2018-04-22
          &nbsp;·&nbsp; e6b8b1b1
          &nbsp;·&nbsp; #30
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.721</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.604</kbd>
        </footer>
      </article>
      <article>
        <h4>Konvention skal spænde ben for ny dræberrobot</h4>
        <div>
          Stop dræberrobotterne'. Det er navnet på en international kampagne mod våben, der - uden at mennesker rører så meget som en knap - kan lokalisere og dræbe uvidende fjender.De såkaldte dræberrobotter er næste skridt i våbenudviklingen efter droner, de ubemandede, fjernstyrede kampfly, som USA i stigende grad gør brug af i blandt andet Yemen og Pakistan.»En robot kan ikke skelne mellem civile og kombattanter.Vi har set det rod, droner har skabt, selv når mennesker styrer dem. Robotter vil begå mange flere fejl«, siger Noel Sharkey, professor i robotter og kunstig intelligens på Sheffield University i England.Han står i spidsen for kampagnen ' Stop the Killer Robots', der arbejder for et internationalt forbud, inden teknologien er færdigudviklet. Med sig har han blandt andet organisationen Human Rights Watch og den amerikanske aktivist Jody Williams, der fik Nobels Fredspris for sin kamp mod landminer, samt en række internationale organisationer. Målet er en konvention på lige fod med dem, der forbyder klyngebomber og landminer.»Vi vil have et forbud, før udviklingen når et punkt, hvor der ikke er nogen vej tilbage«, siger Noel Sharkey, der mener, at teknologien vil ligge klar inden slutningen af dette årti. Han frygter derfor, at våbenteknologien når at udvikle sig så hurtigt, at den overhaler krigens regler indenom, herunder de såkaldte rules of engagement og Genèvekonventionen.»Så snart ét land har knækket koden, vil de være overalt«, siger han.Nyt våbenkapløb blandt stormagterne Det amerikanske militær tester i øjeblikket det ubemandede X-47B, der foruden at flyve hurtigere end lydens hastighed kan lette fra hangarskibe, udføre missioner og lande igen uden menneskelig hjælp undervejs. Også England, Rusland og Kina poster mange penge i udviklingen af ubemandede militærfly.»Der er et våbenkapløb i gang. Der er stor konkurrence og ekstremt mange penge involveret«, siger Noel Sharkey.Herhjemme har Søren Pind, udenrigsordfører for Venstre, været blandt de mest kritiske røster i dronedebatten. Han tror ikke på et forbud - hverken mod de eksisterende eller fremtidige droner.»Vi bliver nødt til at acceptere, at der hele tiden udvikles nye teknologier. Kunstig intelligens kommer til at indgå i alle parametre af vores hverdag, herunder også våbenindustrien. Det handler om, at vi skal anvende det forsvarligt og i overensstemmelse med vores kultur«, siger Søren Pind.Kampagnen mod dræberrobotterne ventes at gå i luften for alvor i april, hvor aktivistgruppen bringer sagen for Storbritanniens parlament.»Jeg bryder mig ikke om at dræbe mennesker generelt, men det her er et skridt for langt, så her vil vi trække en streg i sandet«, siger Noel Sharkey og sender en opfordring på tværs af Vesterhavet.»Vi skal have stoppet det her, og vi vil gerne have Danmark med ind i kampen«, slutter han.rasmus.raun@pol.dk Vi har set det rod, droner har skabt, selv når mennesker styrer dem.Robotter vil begå mange flere fejl Noel Sharkey.
        </div>
        <footer>
          <em>Politiken</em>
          &nbsp;·&nbsp; 2013-02-27
          &nbsp;·&nbsp; e3acc54c
          &nbsp;·&nbsp; #31
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.786</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.571</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.617</kbd>
        </footer>
      </article>
      <article>
        <h4>Det store ubesvarede spørgsmål: Hvornår er krigsrobotter autonome?</h4>
        <div>
          Phalanx på de amerikanske krigsskibe kan automatisk registrere og nedskyde fjendtlige missiler, men er systemet af den grund autonomt? Foto: RaytheonImens et hastigt voksende antal stadig mere sofistikerede robotter melder sig ved fronten, intensiveres advarslerne mod at overlade beslutninger om militær magt til maskiner. Men uklarheder om definitionen på autonome våben forvrænger debatten.20. okt 2016 kl. 05:38Kunstig intelligens har nået et punkt, hvor indsættelsen af systemer, der uden menneskelig indblanding er i stand til at udsøge og eliminere personer på baggrund af en bestemte kriterier, bliver mulig indenfor få år. Ikke årtier. Sådan lød advarslen fra over 3.000 specialister i robotter og kunstig intelligens i et åbent brev til FN sidste år. Og indsatsen er ifølge de bekymrede fagfolk høj: Autonome våben er blevet beskrevet som den tredje revolution af krigsførelse, efter krudt og atomvåben.Men hvad taler vi om, når vi taler om autonomi inden for militære systemer, der kan slå ihjel?Det amerikanske forsvarsministerium offentliggjorde for få år siden Direktiv 3000.09, der definerer et selvstændigt våbensystem således: Et våben, der, når det er aktiveret, kan vælge at angribe mål uden yderligere indgriben fra en menneskelig operatør. Den definition omfatter autonome våbensystemer under opsyn, som tillader mennesker at stoppe systemet, men som også kan angribe mål uden menneskelig input efter aktivering.I den akronymglade forsvarssektor bruger man betegnelsen LAWS, lethal autonomous weapon systems. Det er systemer, som kan registrere, spore og angribe en person eller en genstand uden menneskelig indblanding. Et eksempel i tråd med de bekymrede fagfolks advarsel kunne være en bevæbnet drone med software til ansigtsgenkendelse, som er i stand til at finde og eliminere registrerede terrorister, forklarer Mikkel Willum Johansen, adjunkt og lektor i videnskabsteori ved Københavns Universitet.»Vi er ret tæt på den fornødne teknologi til sådan et system, idet vi efterhånden har de forskellige komponenter: Vi har billedgenkendelsessoftware, vi har førerløse biler med effektiv navigation, og vi har bevæbnede droner. Det er på algoritmerne, vi halter efter: Robotterne skal kunne fungere forudsigeligt og sikkert, uden at vi kan komme i kontakt med dem,«siger han.En væsentlig skelnen er, at våbensystemer underlagt faste regler, der ikke tillader nogen afvigelser, er automatiserede, ikke autonome. Det påpeger det amerikanske forsvarsministeriums ekspertkomité Defense Science Board i en ny rapport om perspektiverne for autonome våben. For at kunne betegnes som autonomt skal et system have evnen til selvstændigt at indkredse og vælge mellem forskellige handlemuligheder for at opnå sit mål, baseret på sin viden og forståelse af verden, sig selv og situationen, skriver Defense Science Board. Derfor giver det for mange våbensystemers vedkommende mening at tale om enkelte autonome funktioner eller semi-autonome systemer, snarere end egentlige autonome systemer.Hvorfor er det vigtigt?Efterhånden som udviklingen af intelligente og autonome våbensystemer tager til, møder udviklingen stadig mere intensiv modstand. Blandt de mangeårige kritikere er Stephen Hawking, der ligesom Elon Musk, Apples Steve Wozniak og professor Noam Chomsky er blandt medunderskriverne på sidste års advarsel fra de mange fagfolk. Ikke mindst har organisationen Human Rights Watch advaret mod autonome våben i rapporten Losing Humanity: The Case against Killer Robots.Det kan der være god grund til. Som Ingeniøren skrev for få dage siden, forstår vi stadig ikke til fulde maskinernes ræsonnement, og manglen på forudsigelighed kan blive afgørende for, at mennesker aldrig kommer til at overlade beslutningen om at anvende militær magt til autonome robotter med kunstig intelligens. Det er vurderingen fra topfolk i det amerikanske forsvar, fra rådgiverne i Defense Science Board og fra flere danske specialister, som Ingeniøren har talt med.Debatten forplumres imidlertid af forskellige opfattelser af, hvad et autonomt våbensystem er.-Nylige erklæringer fra fremtrædende forskere og teknologer forsøger at udbrede idéen om alvorlige konsekvenser på grund af den hastige implementering af kunstig intelligens og autonome robotter. Nogle af de offentliggjorte udsagn er omhyggelig med at benytte præciseringen fuldt autonome våben, men den skelnen kan let gå tabt i kommunikation. Potentialet for en modreaktion mod anvendelse af ikke-dødelige og semi-autonome systemer til militær brug kan derfor vokse,- skriver Defense Science Board i sin rapport om autonomi.Tilsvarende argumenterer de to militærforskere Michael N. Schmitt og Jeffrey S. Thurnher iHarvard National Security Journal for, at debatten om fuldt autonome våbensystemer må holdes adskilt fra våben med ringere grader af autonomi. Og påpeger, at Human Rights Watch i sin rapport alene foreslår at forbyde fuldt autonome våbensystemer. Ikke mindst i medierne bliver autonome våbensystemer omtalt som en ensartet gruppe af systemer med samme sæt af risici. Herunder også danske medier, hvor advarslen fra Stephen Hawking og de bekymrede fagfolk blev citeret bredt sidste år.»Den offentlige debat er   også på dette område   temmelig upræcis. Man er nødt til at skelne mellem fuld og delvis autonomi,«siger professor Henrik Gordon Petersen, som forsker i anvendt robotteknologi ved Københavns Universitet.Hvad er så ikke et autonomt våben?Et eksempel på et automatiserede eller delvis autonome systemer, som kun aktiveres under i forvejen fastsatte omstændigheder, er nærforsvarssystemer til krigsskibe, såkaldte CIWS (Close-In Weapon Systems). Nærforsvarssystemer beskytter mod indgående missiler ved hjælp af en radarstyret maskinkanon og betegnes som et krigsskibs sidste forsvarslinje, hvis fjendtlige missiler slipper forbi skibets luftforsvarsmissiler. CIWS-systemet Phalanx findes i dag på de fleste amerikanske krigsskibe, mens de danske skibe af Absalon-klassen og Iver Huitfeldt-klassen er udstyret med det såkaldte Millennium-system.Nærforsvarssystemer kan både styres fra operationsrummet og sættes til at reagere selv, hvis de registrerer indgående missiler. Kendetegnende for systemerne er, at de udelukkende bruges til forsvar, og at de er stationære. Systemet angriber ikke uden menneskelig indblanding luftmål, der ikke udgør en direkte trussel mod skibet.Sådanne semi-autonome våbensystemer betegnes også som systemer med human-in-the-loop og har længe været udbredte. Gruppen omfatter også en lang række fire and forget -våben, som de udbredte missiler Sidewinder, Amraam, Helffire og de nye Brimstone, der efter affyring selv finder og angriber det mål, som en operatør eller kampflypilot har udpeget.Fuldt autonome våbensystemer, der selv udvælger deres mål, betegnes som human-out-of-the-loop. Det er den slags systemer, Human Rights Watch specifikt advarer imod, og de anvendes ikke i dag.Allerede i spilDet betyder ikke, at våbensystemer med kapaciteten til fuld autonomi ikke findes. De anvendes allerede i flere sammenhænge, men de benyttes udelukkende under opsyn, såkaldt human-on-the-loop, hvor mennesker har mulighed for at gribe ind i systemets operationer. Et eksempel er Natos ballistiske missilforsvar, hvori det søbaserede kampsystem Aegis, som binder missilforsvarets radarer og missilbatterier sammen, er i stand til at identificere indgående ballistiske missiler og affyre interceptormissiler for at stoppe dem. Men kampsystemets menneskelige operatører kan vetoe systemets beslutning om at angribe. Tilsvarende er de amerikanske Patriot-batterier og det israelske Iron Dome missilforsvar i stand til at nedskyde missiler uden menneskelig indblanding, men benyttes under menneskeligt opsyn.-Den eneste substantielle forskel mellem disse og fuldt autonome systemer er, at operationerne nøje overvåges af et menneske, der kan tilsidesætte systemets beslutninger,- konstaterer Michael N. Schmitt og Jeffrey S. Thurnher i Harvard National Security Journal.Tilsvarende er en række militære systemer med kunstig intelligens under udvikling med henblik på enten human-in-the-loop eller human-on-the-loop, men med de teknologiske forudsætninger for at agere selvstændigt. Det amerikanske forsvar har i flere år testfløjet den avancerede skibsbaserede drone X-47B, som ved egen hjælp kan lette fra og lande på hangarskibe. Det britiske forsvar udvikler stealth-dronen Taranis, som kan identificere og angribe mål, hvis operatøren giver grønt lys.-Selv om disse systemer endnu ikke er designet til at foretage autonome angreb, er det ikke svært at forestille sig, hvordan sådanne teknologier kan modificeres til at understøtte fuldt autonom målsøgning,- skriver Schmitt og Thurnher, som begge er professorer ved United States Naval War College.Nogenlunde samme vurdering lyder fra Henrik Gordon Petersen, om end fuldt autonome våbensystemer har lange udsigter.»Man vil i praksis oftest indføre forhåndsgivne regler. For eksempel, at en robot kan agere fuldt autonomt indenfor et givent område. Eller at systemet under fuld autonomi kan lede efter målet, men at der ikke kan skydes uden en operatørs tilladelse,«siger han.»Jeg mener godt, at man i hvert fald i teorien kan forestille sig et fuldstændigt autonomt våbensystem. Med den nuværende viden om kunstig intelligens og autonomi finder jeg det dog urealistisk at civiliserede lande ville kunne finde på at indføre et sådant system,«siger Henrik Gordon Petersen.Fuld autonomi betyder ikke fuld autonomiI sagens natur er heller ikke et våbensystem, der lever op til nærværende kriterier for fuld autonomi, helt fritaget for menneskelig indblanding. Det påpeger både Schmitt og Thurnher i deres artikel og Defense Science Board i sin rapport. Systemets udvikler eller operatør bliver som minimum nødt til at programmere det til at operere indenfor bestemte parametre, og operatøren træffer den overordnede beslutningen om at indsætte systemet i en given operation. Et selvlærende våbensystem bliver trænet af mennesker til et bestemt spektrum af operationer, selvom det også kan fortsætte med at tilegne sig nye kompetencer under selve operationen.»På nuværende tidspunkt gælder for stort set al kunstig intelligens, at det kræver masser af menneskelig arbejdskraft. Ved maskinindlæring skal man stadigvæk i stort omfang bruge data, hvor mennesker har været involveret i at sortere og kategorisere disse data. Derudover sætter menneskerne de overordnede rammer for, hvad systemet skal bruges til, uanset om det er billedgenkendelse, flykontrol, eller brætspil,«siger Thomas Vestskov Terney, konsulent inden for digital strategi og ph.d. i kunstig intelligens.»Vi er stadig dér, hvor systemerne er virkelig gode under forudsætning af, at vi definerer en så snæver opgave, at det er muligt for systemet selv at afgøre, om det kommer i mål eller ej. Desto mere kompleks den opgave bliver, desto svære er det for systemet at fungere autonomt,«siger Thomas Vestskov Terney.
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2016-10-20
          &nbsp;·&nbsp; e5ef6d55
          &nbsp;·&nbsp; #32
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.941</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.59</kbd>
        </footer>
      </article>
      <article>
        <h4>Droner med kunstig intelligens jagtede militssoldater i den libyske borgerkrig</h4>
        <div>
          Avancerede tyrkiske droner, der blev brugt i den libyske borgerkrig, fandt selv deres mål, ifølge en FN-rapport. Det er formentlig det første kendte eksempel på brugen af autonome våben i aktiv krigsførelse.Jyllands-Postens korrespondentISTANBULModstandernes soldater blev under den libyske borgerkrig jagtet af selvstyrende droner, og det var med til at vende krigslykken for den FN-støttede regering i Tripoli.Det fremgår af en FN-rapport, der indikerer, at det er det første kendte eksempel på autonome våben, som er blevet indsat i en aktiv kampsituation og selv har kunnet afgøre, hvem der skulle dræbes.De tyrkiskfremstillede droner var bl.a. udstyret med ansigtsgenkendelsesteknologi. De blev indsat af den libyske samlingsregering for at drive styrker loyale til den russisk-støttede krigsherre Marshal Khalifa Haftar ud af den libyske hovedstad. Da de begyndte at trække sig, blev de forfulgt af dronerne. De var i stand til at fortsætte missionen selv, efter at de havde bevæget sig uden for rækkevidde af en styregruppe.»Logistikkonvojer og soldaterne på tilbagetog blev jagtet og angrebet af de ubemandede kampdroner eller autonome våbensystemer såsom STM Kargu-2,«  fastslår den 548 sider lange rapport fra marts.STM Kargu-2 er en henvisning til en knap 7 kg tung tyrkisk drone, som kan fungere i sværme på op mod 20 droner med henblik på at overvælde modstanderen. Producenten, STM, beskriver det som en propeldrevet angrebsdrone, der kan bruges autonomt eller styres manuelt.»De dødbringende autonome våbensystemer var programmeret til at angribe mål uden behov for dataforbindelse mellem operatøren og ammunition,«  fortsætter rapporten, der er udarbejdet af et panel af uafhængige eksperter.Den siger dog ikke noget om, hvorvidt dronerne havde succes med at ramme deres mål.Droner som våbenI mange lande forskes der i kunstig intelligens i militært øjemed. Udvikling af droner indgår, men droner er typisk ikke i stand til at operere autonomt, men programmeres eller styres af et menneske.USA satte sin første drone op i midten af 1990'erne over Balkan under krigen i Bosnien. I mange år blev de kun brugt til rekognoscering. Under præsident Barack Obama blev droner, bevæbnet med missiler, taget massivt i anvendelse.I krigene i Afghanistan og Irak blev der sat droner ind i masser af aktioner mod terrorledere. I januar 2020 brugte daværende præsident Trump et droneangreb til at dræbe general Qassem Soleimani, lederen af Quds-styrken i Irans revolutionsgarde.USA har længe været tilbageholdende med at sælge sine mest avancerede modeller - selv til allierede. Men som reaktion på droneeksporten fra Kina og andre producenter blødte Trump-regeringen i juli 2020 op på reglerne. Bl.a. solgte USA i januar 18 MQ-9-droner til De Forenede Arabiske Emirater for knap 3 mia. dollars.Droner er blevet udnyttet som et militært våben i mere end et årti. USA's tidligere præsident Barack Obama brugte det især i kampen mod terror, og hans afløser, Donald Trump, udvidede brugen af det i Afrika. Lande som Kina, Rusland og Israel har også en flåde af droner. Men brugen af intelligente droner i Libyen udstreger, hvor hurtigt teknologien breder sig, og det stiller nye krav til nationale forsvarssystemer.Angriber i sværme»Det betyder, at der skal tænkes på en ny måde. Det amerikanske luftvåben er f.eks. ved at gennemtænke hele sin måde at operere på, så det kan forsvare sig mod droner. De er billige og mere tilgængelige end kampfly som F-35 og vil i fremtiden formentlig blive brugt til at angribe i sværme,«  siger Peter Viggo Jakobsen, lektor ved Forsvarsakademiet.Det leverede Tyrkiet i februar 2020 et eksempel på. Styrker fra det syriske regime marcherede med russisk støtte frem mod byen Idlib, som kontrolleres af en oprørsgruppe med tyrkisk støtte. Da et luftangreb dræbte flere end 30 tyrkiske soldater, iværksatte Tyrkiet en offensiv, som inkluderede droner.Dronerne, der blev brugt, var den ligeledes tyrkisk-fremstillede TB2 fra selskabet Baykar. Den larmer ikke særligt meget og er svær at opdage på en radar. De blev hængende i luften i timer, indtil de fandt sprækkerne i modstanderens luftforsvar. Fordi dronerne er relativt billige, kunne forsvaret tage større risici.»Hvis du mister en, to eller tre, er det lige meget, så længe andre droner rammer målet,«  siger Ismail Demir, leder af det statslige kontrolorgan for Tyrkiets våbenindustri, til Wall Street Journal.Det har konsekvenser, som ændrer hele spillet.Ben Wallace, Storbritanniens forsvarsminister i en tale i 2020Da Tyrkiet i 2020 øgede sin militære støtte til den libyske regering, brugte den erfaringerne fra Idlib til at forfine taktikken.Senere på året hjalp tyrkiske droner også styrker i Aserbajdsjan med at genvinde kontrollen over dele af Nagorno-Karabakh, som i mere end to årtier har været i hænderne på russisk-støttede armeniere.Droner er også blevet brugt af iransk-støttede grupper i Irak og Yemen til at angribe Saudi-Arabien. De er blevet brugt af Islamisk Stat, der købte dronedele og selv samlede dem. I 2019 blev tre mænd i Danmark kendt skyldige i at have købt dele til droner og sende dem til terrorgruppen i Syrien.Det er bl.a. muligt, fordi Kina er blevet en stor eksportør til Mellemøsten og Afrika. Mindst 10 lande, såsom Nigeria og De Forenede Arabiske Emirater, har brugt kinesisk-producerede droner til at angribe fjender, vurderer forsvarsanalytikere til Wall Street Journal.Det indikerer alt sammen, at droner er i gang med fundamentalt at ændre på, hvordan lande fører krig.Ændrer hele spillet»Det har konsekvenser, som ændrer hele spillet,«  advarede den britiske forsvarsminister, Ben Wallace, i en tale i juli 2020 med henvisning til de tyrkiske droneangreb mod Idlib.Droner er relativt lette at producere sammenlignet med andre våbentyper, og regionale stormagter kan bruge dem uafhængigt at USA, Rusland eller Kina. For Tyrkiets præsident, Recep Tayyip Erdogan, har det betydet øget indflydelse i regionen.»Hvis Tyrkiet kan producere dem, kan Israel, Sydkorea og en række andre lande også. Det viser, hvor hurtigt teknologien spreder sig,«  siger Peter Viggo Jacobsen, som påpeger, at det i øjeblikket ikke er noget, det danske forsvar har et værn mod.I langt de fleste tilfælde er der dog tale om droner, som styres af mennesker, med indbyggede kameraer. Men rapporten fra FN indikerer, at kampen om at regulere autonome våbensystemer med kunstig intelligens er ved at blive tabt.Den Internationale Røde Kors Komité appellerede i sidste måned til verdenssamfundet om at lave internationale regler på området, herunder et generelt forbud mod at bruge dem mod mennesker.USA's præsident, Joe Biden, har forud for et besøg i Europa, hvor han bl.a. skal deltage i et Nato-topmøde, også advaret mod truslen fra ny teknologi.»I takt med at nye teknologier ændrer vores verden på en fundamental måde, udstiller sårbarheder mod angreb fra afpresningssoftware og skaber trusler såsom en indgribende kunstig intelligens-drevet overvågning, må verdens demokratier gå sammen for at sikre, at vores værdier regulerer brugen og udviklingen af dem - ikke autokratiske interesser,«  skrev han i weekenden i et indlæg i avisen Washington Post.Vil du have vores bedste Indblik-artikler direkte i din indbakke? Tilmeld dig gratis og få de fem nyeste artikler fra Jyllands-Postens Indblik-sektion hver dag kl. 16 - klik her, sæt flueben og indtast din mailadresse
        </div>
        <footer>
          <em>Jyllands-posten.dk</em>
          &nbsp;·&nbsp; 2021-06-08
          &nbsp;·&nbsp; e84d8a05
          &nbsp;·&nbsp; #33
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.536</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.616</kbd>
        </footer>
      </article>
      <article>
        <h4>FN: Autonom kamikaze-drone kan for første gang have angrebet et menneske</h4>
        <div>
          Dronerne menes at have været brugt i konflikten mellem rivaliserende militære grupper i den Den Libyske Borgerkrig.Dødbringende og fuldt autonome kamikaze-droner med en eksplosiv ladning kan for første gang have været brugt til at angribe mennesker. Hændelsen, som fandt sted under den libyske borgerkrig sidste år, kan være den første af sin slags.Det skriver nyhedsmediet New Scientist efter at være kommet i besiddelse af en ekspertrapport fra FN's Sikkerhedsråd.»Mens de fulde detaljer om hændelsen, der fandt sted i Libyen, ikke er frigivet, og det er uklart, om der er nogen tilskadekomne, så antyder hændelsen, at det måske allerede er for sent med den internationale indsats for at forbyde dødbringende autonome våben, inden de tages i anvendelse,«  skriver nyhedsmediet.Hændelsen fandt sted i marts 2020. Her skulle en den tyrkisk producerede Kargu-2 quadcopter ifølge FN-rapporten af sig selv have jagtet et menneskeligt mål under en konflikt mellem Libyens regeringstropper og den militære udbryderfraktion Libyan National Army anført af desertøren Khalifa Haftar.Artiklen fortsætter under videoen:Flere droner opererede under konflikten i fuldt autonom tilstand med »høj effektivitet« , som ikke kræver nogen som helst menneskelig kontrol, fremgår det af FN-rapporten, hvor der blandt andet står:»De dødbringende autonome våbensystemer var programmeret til at angribe mål uden at kræve dataforbindelse mellem operatøren og våben: I virkeligheden er det en 'affyr, glem og find'-kapacitet.« Ifølge New Scientist antyder FN-rapporten, at en af dronerne jagtede en soldat under tilbagetrækning.Organisation vil have internationalt forbud mod »dræberrobotter« Det er sandsynligvis første gang, en drone har angrebet mennesker uden at have fået instruktioner på at gøre det, fremgår det af FN-rapporten. Det samme vurderer sikkerhedseksperten, Zak Kellenborn, der specialiserer sig inden for ubemandede våbensystemer og droner, over for New Scientist. Han stiller spørgsmålene:»Hvor skrøbeligt er systemet til objektgenkendelse? Hvor ofte tager det fejl af mål?« Hændelsen viser, at der er et »presserende og vigtigt«  behov for at diskutere en potentiel regulering af autonome våben, lyder det fra sikkerhedseksperten Jack Watling fra den britiske tænketank inden for forsvar og sikkerhed, Royal United Services Institute (RUSI) til New Scientist.Organisationen Humans Right Watch advarede i august under kampagnen 'Campaign to Stop Killer Robots' om, at autonome »dræberrobotter«  med kunstig intelligens udgør en trussel mod vores civilisation.»At fjerne menneskelig kontrol fra anvendelsen af magt betragtes nu bredt som en alvorlig trussel mod menneskeheden, der ligesom klimaforandringer fortjener multilateral handling,«  lød det fra Mary Wareham, der er koordinator for kampagnen.»En international forbudstraktat er en eneste effektive måde at tackle de alvorlige udfordringer, som fuldt autonome våben rejser,«  lød det fra hende i forbindelse med udgivelsen af en rapport , som gennemgår 97 landes stillingtagen til spørgsmålet om våbensystemer, der kan angribe uden menneskelig kontrol.30 lande ønsker ifølge rapporten fuldstændig at forbyde fuldt autonome våbensystemer.
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2021-05-31
          &nbsp;·&nbsp; e84a47cb
          &nbsp;·&nbsp; #34
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.763</kbd>
            <kbd data-tooltip="Cyberwarfare &amp; geopolitics">L10_CYBERW&nbsp;0.651</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.599</kbd>
        </footer>
      </article>
      <article>
        <h4>Udviklere advarer om fremtidens robotkrigsmaskiner</h4>
        <div>
          Udsigterne til fremtidens krigsførelse får robotudviklere til at advare FN.Førende robotudviklere er skræmte over fremtidens muligheder for krigsførelse med kunstig intelligens.Fremtidens krigsteknologi kan løbe fra os, hvis ikke vi bremser den hastige udvikling inden for robotteknologi.Sådan lyder en opsigtsvækkende advarsel fra nutidens robotudviklere i et åbent brev til FN.I brevet opfordrer i alt 116 specialister fra 26 forskellige lande mod udviklingen inden for automatiserede våben, skriver den engelske avis The Guardian.- Når de først er udviklet, vil dødelige automatiske våben muliggøre at armerede konflikter kan blive kæmpet i hidtil uset skala, og i tidsforløb der er hurtigere, end mennesker kan begribe.- Det kan være våben, som tyranner og terrorister bruger mod uskyldige befolkninger, og våben der kan hackes til at opføre sig på uønskede måder, lyder det i brevet.Her advarer udviklerne også mod, at tiden er nu, hvis der skal handles.- Vi har ikke lang tid til at handle. Når først denne Pandoras æske er åbnet, vil den være svær at lukke, lyder det i brevet.Blandt underskriverne af brevet er Teslas topchef, Elon Musk, og Mustafa Suleyma, der har udviklet teknologi inden for kunstig intelligens, som er købt af Google.Brevet udgives mandag, samme dag som en international konference om kunstig intelligens afholdes i Melbourne i Australien.Medunderskriverne af brevet opfordrer til, at de &quot;moralsk forkerte våben&quot; skal tilføjes til FN's liste over ulovlige våben.En liste der også inkluderer kemiske våben og våben med bevist blindende lasere.Eksperter har tidligere advaret mod, at udviklingen inden for kunstig intelligens er nået et punkt, hvor det kan bruges i våben inden for få år.Droner er et eksempel på en del af udviklingen inden for automatiserede våben, som specialisterne advarer mod.
        </div>
        <footer>
          <em>Folkebladetlemvig.dk (Lemvig Folkeblad)</em>
          &nbsp;·&nbsp; 2017-08-20
          &nbsp;·&nbsp; e6612bbb
          &nbsp;·&nbsp; #35
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.983</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.716</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.594</kbd>
        </footer>
      </article>
      <article>
        <h4>Forskere slår alarm over dræberrobotter</h4>
        <div>
          Forskere boykotter sydkoreansk universitet, der vil lave dræberrobotter.Det sydkoreanske universitet Korea Advanced Insitute of Science and Technology (KAIST har tidligere produceret harmløse robotter, der var designet til at efterligne menneskers kropssprog. Foto: APAnne FilbertMere end 50 af verdens førende forskere inden for kunstig intelligens har underskrevet et brev, der efterspørger et boykot af det sydkoreanske universitet Korea Advanced Insitute of Science and Technology (KAIST) og universitetets samarbejdspartner Hanwha System.Grundet til forskernes boykot er, at de frygter, at KAIST er er ved at udarbejde autonomiserede kampvåben i samarbejde med forsvarproducenten Hanwha Systems.Og det er ifølge forskerne etisk forkert, at udvikle robotter, der kun har til formål at føre krig. Det siger Toby Walsh fra The University og New South Wales, der har organiseret boykotten til The Guardian.En af de ting, man frygter allermest ved de såkaldte dræberrobotter er, om de ville kunne skelne ven fra fjende. En anden er robotternes præcision.Våbenproducenten Hanwha, der samarbejder med det sydkoreanske universitet, har tidligere skabt urøre i diplomatiske situationer. Firmaet producerer blandt andet en form for klyngeammunition, der er banndlyst i 120 lande under en international traktat. Sydkorea, Rusland, USA og Kina har ikke underskrevet traktaten.KAIST siger dog selv til The Guardian, at de ikke har nogen intentioner om at producere dødelige våben. Universitetets præsident, Sung-Chul Shin forsiker om, at der på universitetet er fokus på menneskerettigheder og etik.Et andet sydkoreansk firma Dodaam Systems producerer dog allerede en fuldt autonom &quot;kamprobot&quot;.Robotten kan opdage mål på op til tre kilometers afstand, og virksomhedens kunder inkluderer lande som De Forenede Arabiske Emirater og Qatar. Dodaam System forsikrer dog om, at robotten ikke kan udføre et dødeligt angreb uden menneskelig aktivering.
        </div>
        <footer>
          <em>Jyllands-posten.dk</em>
          &nbsp;·&nbsp; 2018-04-05
          &nbsp;·&nbsp; e6b12e23
          &nbsp;·&nbsp; #36
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.777</kbd>
            <kbd data-tooltip="AI &amp; innovation">L05_INNOAI&nbsp;0.554</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.54</kbd>
        </footer>
      </article>
      <article>
        <h4>Protester og boykot forud for FN-møde om selvstyrende dræberrobotter</h4>
        <div>
          En solbrillebærende og læderjakkeklædt Arnold Schwarzenegger vandrer målrettet gennem politistationens snævre gange, mens han sender byger af bly mod de sagesløse betjente, der står mellem ham og hans mål: Sarah Connor.Ingen samvittighed, ingen mådehold, kun kold kalkule: Find, dræb.Da ' Terminator'-filmen kom ud i 1984, var ideen om en dræberrobot, som den T-800 Model 101 Arnold Schwarzenegger portrætterede, ren science fiction. Og selv om menneskemaskiner på to ben med moderigtige læderjakker og dræberinstinkt formentlig stadig ligger langt ude i fremtiden, er der ikke længere tvivl om, at dræberrobotterne er på vej.USA, Kina, Rusland, Israel og England fører an i udviklingen af mere eller mindre selvstyrende krigsmaskiner. Droner, jagerfly, tanks og ubåde med potentiale til at ødelægge og slå ihjel uafhængigt af deres menneskelige opfindere.Udviklingen vækker stor bekymring verden over, og derfor mødes mere end 80 lande og adskillige interesseorganisationer i denne uge i Genève til FN's konference om konventionelle våben for at diskutere dødelige selvstyrende våben - de såkaldte dræberrobotter.Debatten om dræberrobotter har taget fart de senere år. Forskere, eksperter og techikoner anført af prominente navne som Elon Musk og den nu afdøde Stephen Hawking har flere gange offentligt efterspurgt et forbud mod at udvikle og bruge selvstyrende krigsrobotter.Senest opfordrede mere end 50 forskere i kunstig intelligens til boykot af det sydkoreanske universitet Kaist, fordi universitetet samarbejder med en sydkoreansk virksomhed om at udvikle våbensystemer med kunstig intelligens.Og i onsdags kunne avisen The New York Times præsentere et internt brev sendt af flere end 3.000 Google-ansatte til Googles øverste chef, Sundar Pichai. I brevet tryglede de ansatte direktøren om at annullere Googles aftale om at udvikle intelligente overvågnings-og måludvælgelsessystemer for det amerikanske forsvar.»At skabe denne teknologi til at hjælpe den amerikanske regering med militær overvågning - med potentielt dødelige konsekvenser - er ikke acceptabelt«, skrev de ansatte i brevet.Moral og sikkerhedEn af deltagerne ved FN-mødet i denne uge er roboteksperten Noel Sharkey. Ud over at være professor emeritus i robotteknologi ved University of Sheffield har han som talsmand for kampagnen ' Stop Killer Robots' i årevis kæmpet for et FNforbud mod selvstyrende krigsrobotter.»Vi bliver nødt til at få et internationalt forbud mod udviklingen og brugen af selvstyrende krigsrobotter, inden de bliver taget i brug«, siger Noel Sharkey.Det er især to ting, der bekymrer de kritikere, der kalder udviklingen af intelligente dræbermaskiner for den tredje store våbenrevolution. Den første var brugen af krudt, den anden opfindelsen af atomvåben.Det første kritikpunkt er det moralske.At robotter selvstændigt kan tage beslutninger om, hvorvidt et menneske skal dø eller leve, er helt basalt moralsk forkert, mener Noel Sharkey. Robotter hverken kan eller skal vurdere, hvornår målet helliger midlet i komplekse og uforudsigelige militære situationer.»Der er ikke nogen algoritme til at udregne, om det eksempelvis er værd at dræbe Osama Bin Laden, hvis det også koster 25 gamle damer eller 10 små børn livet.Det er ikke scenarier, man kan forudsige, det kræver en erfaren befalingsmand på stedet at træffe den slags beslutninger«, siger Noel Sharkey.Den anden store bekymring handler om global sikkerhed. Kritikerne frygter, at udviklingen af dræberrobotter risikerer at ende i et selvdestruktivt våbenkapløb, hvor store nationer konkurrerer om hurtigst at udvikle nye og endnu mere destruktive robotter. Samtidig risikerer de sofistikerede våben også at ende i hænderne på skruppelløse diktatorer og terrorister, hvor de kan volde stor ødelæggelse.Men det måske værst tænkelige scenario er, at et selvstyrende våbensystem kan starte en uønsket konflikt, fordi det træffer valg på baggrund af dets programmering og ikke har et menneskes nuancerede overvejelser.»Der findes mange eksempler på, at man har undgået, at konflikter er udbrudt eller eskaleret, fordi mennesker med fingeren på aftrækkeren er gået imod deres træning og ordrer og har udvist mådehold. Det kan man ikke forvente, at en forudprogrammeret robot vil gøre«, advarer Noel Sharkey.Dræberrobot eller krigsmaskineNår det i lyset af den slags argumenter stadig er svært at blive enig om, hvordan udviklingen og brugen af krigsrobotter skal reguleres, er det blandt andet, fordi der er stor uenighed om, hvordan en dræberrobot skal defineres.»Alle de vigtigste robotudviklende nationer siger, at de heller ikke ønsker selvstyrende krigsrobotter. Men hvis man kigger på, hvordan de enkelte lande defi-nerer, hvad det vil sige at være ' selvstyrende', bliver billedet mere mudret«, siger Robin May Schott, der forsker i krigsrobotter ved Dansk Institut for Internationale Studier.»Så før vi kan få en robust international lovgivning om, hvordan de her våben må udvikles og bruges, skal vi blive enige om, hvordan de defineres«. De fleste nationer argumenterer med USA i spidsen for, at en krigsmaskine ikke er selvstyrende, så længe et menneske har betydelig kontrol over den, heller ikke selv om den selv kan identificere og angribe et mål. Men hvad er ' betydelig menneskekontrol'? Kræver det meget snævre parametre for, hvad der kan angribes og under hvilke forhold? Eller er det nok med blot brede missionsbetegnelser, som ' dræb alle mænd, der bærer tørklæde og våben' eller ' skyd på enhver, der prøver at krydse grænsen'? »Vi foreslår i stedet, at et dødeligt selvstyrende våben defineres som en maskine, der på egen hånd kan foretage de to afgørende krigsfunktioner: identificere og angribe mål«, siger Robin May Schott, der har forsket i netop definitionsspørgsmålet sammen med sine kollegaer Johannes Lang og Rens Van Munster.Med andre ord er der tale om en dræberrobot, hvis et våben ikke har brug for et menneskes øje ved sigtekornet eller et menneskes finger på aftrækkeren.Af de mere end 80 nationer, der deltager i møderne i Genève i denne uge, går 22 ind for et totalt forbud af dræberrobotter ud fra denne definition. De fleste af disse er udviklingslande, som formentlig vil være blandt de sidste, der får fingrene i den avancerede våbenteknologi.Der vil ikke blive truffet nogen endelige beslutninger om regulering i denne uge, men planen er, at der skal formuleres forslag til tiltag, som der så skal forhandles om når nationerne mødes igen senere i 2018. Den danske regering deltager ikke i diskussionerne.jeppe.valeur@pol.dk Fakta: FAKTA DræberrobotterFlere lande arbejder på at udvikle mere eller mindre selvstyrende våben og krigsrobotter.USA arbejder blandt andet på ubåde, fly og sværme af droner, der selvstændigt kan udpege angrebsmål.Israels grænser beskyttes allerede af ubemandede køretøjer og droner, som hele tiden bliver mere selvstyrende.Rusland arbejder på at udvikle og serieproducere verdens mest avancerede selvstyrende tank.
        </div>
        <footer>
          <em>Politiken</em>
          &nbsp;·&nbsp; 2018-04-09
          &nbsp;·&nbsp; e6b2222d
          &nbsp;·&nbsp; #37
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.777</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.58</kbd>
        </footer>
      </article>
      <article>
        <h4>Autonome droner giver krigens regler kamp til stregen</h4>
        <div>
          Eksperter advarer om nye intelligente våbensystemer, der gør det svært at placere ansvaret, når byer bliver bombet. Vi er ved at krydse en grænse, lyder det.Menneskets synlige tilstedeværelse på slagmarken er ikke det eneste, som er ved at forsvinde i takt med fremmarchen af droner. Eksperter verden over advarer også om, at nye våbensystemer gør, at menneskelige beslutninger i disse år bliver overtaget af software.I FN opfordrer den særlige rapportør på området, Christof Heyns, til et stop for udvikling af de intelligente våbensystemer, og amerikanske militæranalytikere udtrykker i medierne bekymring over, hvad de kalder et 'våbenkapløb i autonome våbensystemer'. Herhjemme følger forskere også udviklingen med bekymrede miner, for robotterne befinder sig i en voksende juridisk gråzone i forhold til den humanitære folkeret, der regulerer, hvad man må - og ikke må - i krig.For hvornår handler et system så meget på egen hånd, at det kan betegnes som autonomt? Det er det centrale juridiske spørgsmål, mener ph.d.-stipendiat ved Juridisk Institut på Aarhus Universitet Iben Yde, hvis afhandling netop omhandler legaliteten af autonome våbensystemer.»Hvor høj grad af 'selvbestemmelse' skal der være, før de falder i denne her kategori af problematiske våben? Jeg har siddet tre år med min afhandling nu, og jeg er ikke i stand til at sætte det skel,« siger hun.I dag er de intelligente våbensystemer allerede vidt udbredt - de kommer især fra amerikanske producenter, men også Storbritannien, Norge og Israel har systemerne eller er i fuld gang med udviklingen. Lockheed Martin har udviklet anti-skibsmissilet LRASM, der af Human Rights Watch og medlemmer af den internationale komité for robotvåben (ICRAC) betegnes som en forløber for fuldt automatiserede våben.LRASM udvælger selv sit mål og beregner sin egen rute uden om antiluftskyts. US Navy har også søsat hurtigtgående, selvstyrende speedbåde, der ved brug af software-arkitekturen CARACaS (Control Architecture for Robotic Agent Command and Sensing) kan koordinere deres bevægelser, omringe og på sigt tilintetgøre flådefartøjer, der kommer for tæt på krigsskibe.Israel står bag antiradar-våbnet Harpy. Harpy er en to meter lang drone, der bliver affyret fra et militært køretøj og følger en forprogrammeret rute, mens den scanner jorden under sig for fjendtlige radarsystemer - parat til at angribe.Fra det øjeblik, Harpy er sendt af sted, er den ikke under menneskelig kontrol. Hvis en radar på jorden bliver aktiveret, opfanger dronen signalet og forsøger at matche signalet med en database med godkendte mål. Er der match, styrtdykker dronen og indleder sit kamikazeangreb.Men spørgsmålet for jurister - især i USA, hvor man bryster sig af, at ethvert angreb er funderet i en klar juridisk formulering - er, om et fuldgyldigt autonomt våbensystem kan operere lovligt under gældende international ret.For som professor i menneskerettigheder og FN's særlige rapportør Christof Heyns slog fast i maj sidste år, risikerer vi at 'ende på den forkerte side af grænsen, og til den tid er det meget svært at vende tilbage. Hvis der nogensinde er et oplagt tidspunkt at regulere og stoppe disse våben på, er det nu', som han sagde under et FN-møde i Genève.Det er dog ikke utænkeligt, at et fuldstændigt autonomt våbensystem kan operere lovligt under gældende international ret, mener Iben Yde. Hun påpeger dog, at teknologien endnu ikke er tilstrækkelig til at foretage de nødvendige nuancerede menneskelignende skøn.Men hvis et våbensystem i fremtiden selv selv skal stå for måludpegning og beslutninger om angreb, skal det kunne opretholde to helt grundlæggende principper for at leve op til kravene for militære angreb under den humanitære folkeret, forklarer hun.På trods af slagmarkens brutale virkelighed foreskriver krigens regler nemlig, at militære handlinger i mindst muligt omfang skal gå ud over civile, uanset hvem eller hvad der trykker på aftrækkeren, og det reguleres i henholdsvis 'distinktionsprincippet' og 'proportionalitetsprincippet'.Hvis autonome våbensystemer kan handle i overenstemmelse med de to bærende principper, er våbensystemerne også lovlige at bruge i krig, lyder Iben Ydes vurdering.Civile må ikke være direkte mål for et militært angreb, og distinktionsprincippet foreskriver derfor, at et automatiseret våben skal være i stand til at skelne militære mål fra civile, inden det angriber.»Men det kræver en 'situationsfornemmelse', der omtrent er på højde med menneskers, og der har vi endnu lang vej, før vi når det teknologiske niveau med kunstig intelligens,« siger Iben Yde.For det andet skal systemerne også kunne tage stilling til den mere moralsk flydende problemstilling, der ligger i at overholde proportionalitetsprincippet, hvor uønskede civile tab skal holdes op mod angrebets strategiske fordel.Men selv om civile ikke må være direkte mål, åbner folkeretten for en accept af civile dødsfald. De skal bare være proportionelle med den militære strategiske fordel ved at angribe.»Den afvejning er også vanskelig for mennesker, der jo heller ikke har en fast standard for, hvad der er rigtigt at gøre i sådan en situation,« siger Iben Yde.I dag findes der ingen regulering eller juridisk definition af autonome våbensystemer under de internationale love. Begrebet autonomi kan nemlig defineres så snævert, at udfaldet af systemets egne beslutninger nærmest er forudsigeligt.Flere eksisterende amerikanske droner kan allerede indstilles til at operere autonomt, men på grund af våbenproducenternes hemmelighedskræmmeri står det ikke klart, om dronerne eksempelvis er i stand til selv at udpege mål og tage beslutning om angreb.Men hvis dronerne besidder disse egenskaber, vurderer Iben Yde, at det under ekstremt skærpede omstændigheder ville være lovligt at give dronen ret til selv at angribe på egen hånd.Hun forklarer, at en lang række forbehold ville gøre sig gældende, såsom at dronen udelukkende må gå efter materielle mål i afsides områder, hvor der ingen risiko er for at ramme civile mål.Stram programmeringSom eksempel på et delvist selvbestemmende våbensystem nævner Iben Yde antiluftskyts-systemet Phalanx, som sidder på stort set alle britiske og amerikanske krigsskibe. Systemet kan sættes op til selv at detektere, spore og angribe indkommende missiler uden menneskelig indblanding.Systemet forsøger bl.a. at tage radiokontakt for at sikre, at det ikke er et civilt fly, det er ved at skyde ned, og tager en lang række andre forbehold, inden det angriber.»Et menneske kunne aldrig nå at foretage så mange vurderinger på så kort tid, så jeg mener ikke, det er det, vi skal forbyde,« siger Iben Yde, der som jurist ser en fremtid, hvor robotterne bliver stramt programmeret og holdt i kort snor.Det samme billede i krystalkuglen ser Thomas Bolander, der forsker i kunstig intelligens ved DTU.»Som teknologien er i dag, skal du instruere robotten i alle de regler, den skal efterleve, men du skal også programmere samtlige undtagelser, som i kampens hede ofte beror på et subjektivt skøn. Fjendens uniform er måske det, som for robotten definerer, hvad der må skydes på, og hvad der ikke må, men hvis et barn var klædt i fjendens uniform, ville et menneske måske ikke skyde, mens robotten i den situation ikke ville gøre forskel,« siger Thomas Bolander og fortsætter:»Det kan man selvfølgelig tage forbehold for, men hvem kan garantere, at det program, man begynder at skrive, tager højde for samtlige ting? Ved den ene yderlighed kan det betyde, at robotter udgør en stor risiko i forhold til at begå frygtelige fejl, eller også bliver de så forsigtige, at man kan diskutere, hvor interessante de så er at benytte,« siger han.Han slår fast, at der endnu er meget lang vej, før det bliver muligt at skabe fuldgyldige autonome systemer, der kan bruges i komplekse situationer, som krig ofte er, så dræberrobotterne invaderer ikke slagmarken lige foreløbigt.»Dybest set forstår vi ikke, hvordan vi skal lave menneskelignende intelligens på en computer. Det er ikke engang sådan, at man kan sige, at vi er godt på vej, for det er en nød, vi simpelthen ikke har knækket endnu,« siger Thomas Bolander.Er dræberrobotter sikre?I FN har man diskuteret lovligheden af dødbringende autonome våbensystemer de seneste to år, men er endnu ikke nået frem til, om de autonome droner skal på listen over våben, der er forbudte at anvende i krig.FN afholdt i maj et ekspertmøde om emnet og inviterede blandt andre Paul Scharre, der leder et mangeårigt forskningsprojekt, som skal kortlægge fremtidens krigsførsel for den uafhængige organisation Center for a New American Security.Han arbejder på at finde ud af, hvilken rolle autonome robotter kommer til at spille i fremtidens krig, og mener, at vi i øjeblikket står midt i en revolution inden for robotik - både civil og militær - og det kræver, at vi som verdenssamfund forholder os til perspektiverne i den nye teknologi.»Mange vil hævde, at der ikke findes dødbringende autonome våbensystemer. Det er ikke sandt, når man ser isoleret på funktionaliteten 'beslutning om udvælgelse af mål'. De er ikke i brug mange steder, men der er et lille antal systemer i brug i dag, som udfører denne funktion,« fortalte Poul Scharre til de officielle repræsentanter fra mere end 25 lande og nævnte blandt andet Harpy-systemet som eksempel.Under den kolde krig, forklarede han, var der automatiske detektionssystemer på begge sider, der ved flere lejligheder fejlagtigt troede, at et atomangreb var undervejs. Dengang var det indgreb fra mennesker i beslutningskæden, der sikrede, at en global atomkrig ikke blev udløst.»Der er et presserende behov for, at verdens nationer tænker over, hvordan man garanterer, at autonome våben er sikre og bruges på en sikker måde. Det er et ansvar, der påhviler enhver stat, at garantere sin egen sikkerhed, men utilsigtet krig kan ikke komme nogen til gode,« sagde Paul Scharre.Set fra den modsatte pol har selvbestemmende robotter også interessante perspektiver i forhold til at gøre slagmarken mere human. Robotter handler aldrig på følelser og instinkter, og fortalere vil mene, at de kyniske robotter ikke vil være i stand til at begå krigsforbrydelser.»Den humanitære folkeret har primært til formål at beskytte ofre for krig - og her menes primært civile, der kan blive fanget i krydsilden. Hvis man kan lave autonome våbensystemer, som kan yde en bedre beskyttelse, så kan man argumentere for, at vi er moralsk og politisk forpligtede til at videreudvikle denne slags systemer, ville jeg mene,« siger Iben Yde.Lockheed Martins LRASM-missil..Det israelske antiradar-våben Harpy..Antiluftskyts-systemet Phalanx..Luft-til-jord-missilet Brimstone opererer autonomt, når først det er affyret..Lockheed Martins LRASM-missil..Det israelske antiradar-våben Harpy..Antiluftskyts-systemet Phalanx..Luft-til-jord-missilet Brimstone opererer autonomt, når først det er affyret..
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2014-12-20
          &nbsp;·&nbsp; e4bb32fa
          &nbsp;·&nbsp; #38
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.984</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.631</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.64</kbd>
        </footer>
      </article>
      <article>
        <h4>AUTONOME DRONER UDFORDRER KRIGENS REGLER Når våben bestemmer over liv og død</h4>
        <div>
          Menneskets synlige tilstedeværelse på slagmarken er ikke det eneste, som er ved at forsvinde i takt med fremmarchen af droner. Eksperter verden over advarer også om, at nye våbensystemer gør, at menneskelige beslutninger i disse år bliver overtaget af software.I FN opfordrer den særlige rapportør på området, Christof Heyns, til et stop for udvikling af de intelligente våbensystemer, og amerikanske militæranalytikere udtrykker i medierne bekymring over, hvad de kalder et ' våbenkapløb i autonome våbensystemer'. Herhjemme følger forskere også udviklingen med bekymrede miner, for robotterne befinder sig i en voksende juridisk gråzone i forhold til den humanitære folkeret, der regulerer, hvad man må - og ikke må - i krig.For hvornår handler et system så meget på egen hånd, at det kan betegnes som autonomt? Det er det centrale juridiske spørgsmål, mener ph. d.-stipendiat ved Juridisk Institut på Aarhus Universitet Iben Yde, hvis afhandling netop omhandler legaliteten af autonome våbensystemer.»Hvor høj grad af ' selvbestemmelse' skal der være, før de falder i denne her kategori af problematiske våben? Jeg har siddet tre år med min afhandling nu, og jeg er ikke i stand til at sætte det skel,« siger hun.I dag er de intelligente våbensystemer allerede vidt udbredt - de kommer især fra amerikanske producenter, men også Storbritannien, Norge og Israel har systemerne eller er i fuld gang med udviklingen.Lockheed Martin har udviklet anti-skibsmissilet LRASM, der af Human Rights Watch og medlemmer af den internationale komité for robotvåben (ICRAC) betegnes som en forløber for fuldt automatiserede våben.LRASM udvælger selv sit mål og beregner sin egen rute uden om antiluftskyts. US Navy har også søsat hurtigtgående, selvstyrende speedbåde, der ved brug af software-arkitekturen CARACaS (Control Architecture for Robotic Agent Command and Sensing) kan koordinere deres bevægelser, omringe og på sigt tilintetgøre flådefartøjer, der kommer for tæt på krigsskibe.Og endelig er der Israels antiradar-våben Harpy.Harpy er en to meter lang drone, der bliver affyret fra et militært køretøj og følger en forprogrammeret rute, mens den scanner jorden under sig for fjendtlige radarsystemer - parat til at angribe.Fra det øjeblik, Harpy er sendt af sted, er den ikke under menneskelig kontrol. Hvis en radar på jorden bliver aktiveret, opfanger dronen signalet og forsøger at matche signalet med en database med godkendte mål. Er der match, styrtdykker dronen og indleder sit kamikaze angreb.Men spørgsmålet for jurister - især i USA, hvor man bryster sig af, at ethvert angreb er funderet i en klar juridisk formulering - er, om et fuldgyldigt autonomt våbensystem kan operere lovligt under gældende international ret.For som professor i menneskerettigheder og FN's særlige rapportør Christof Heyns slog fast i maj sidste år, risikerer vi at ' ende på den forkerte side af grænsen, og til den tid er det meget svært at vende tilbage.Hvis der nogensinde er et oplagt tidspunkt at regulere og stoppe disse våben på, er det nu',..... som han sagde under et FNmøde i Genève.Det er dog ikke utænkeligt, at et fuldstændigt autonomt våbensystem kan operere lovligt under gældende international ret, mener Iben Yde. Hun påpeger dog, at teknologien endnu ikke er tilstrækkelig til at foretage de nødvendige nuancerede menneskelignende skøn.Men hvis et våbensystem i fremtiden selv selv skal stå for måludpegning og beslutninger om angreb, skal det kunne opretholde to helt grundlæggende principper for at leve op til kravene for militære angreb under den humanitære folkeret, forklarer hun.På trods af slagmarkens brutale virkelighed foreskriver krigens regler nemlig, at militære handlinger i mindst muligt omfang skal gå ud over civile, uanset hvem eller hvad der trykker på aftrækkeren, og det reguleres i henholdsvis ' distinktionsprincippet' og ' proportionalitetsprincippet'.Hvis autonome våbensystemer kan handle i overenstemmelse med de to bærende principper, er våbensystemerne også lovlige at bruge i krig, lyder Iben Ydes vurdering.Civile må ikke være direkte mål for et militært angreb, og distinktionsprincippet foreskriver derfor, at et automatiseret våben skal være i stand til at skelne militære mål fra civile, inden det angriber.»Men det kræver en ' situationsfornemmelse', der omtrent er på højde med menneskers, og der har vi endnu lang vej, før vi når det teknologiske niveau med kunstig intelligens,« siger Iben Yde.For det andet skal systemerne også kunne tage stilling til den mere moralsk flydende problemstilling, der ligger i at overholde proportionalitetsprincippet, hvor uønskede civile tab skal holdes op mod angrebets strategiske fordel.Men selv om civile ikke må være direkte mål, åbner folkeretten for en accept af civile dødsfald. De skal bare være proportionelle med den militære strategiske fordel ved at angribe.»Den afvejning er også vanskelig for mennesker, der jo heller ikke har en fast standard for, hvad der er rigtigt at gøre i sådan en situation,« siger Iben Yde.I dag findes der ingen regulering eller juridisk definition af autonome våbensystemer under de internationale love. Begrebet autonomi kan nemlig defineres så snævert, at udfaldet af systemets egne beslutninger nærmest er forudsigeligt.Flere eksisterende amerikanske droner kan allerede indstilles til at operere autonomt, men på grund af våbenproducenternes hemmelighedskræmmeri står det ikke klart, om dronerne eksempelvis er i stand til selv at udpege mål og tage beslutning om angreb.Men hvis dronerne besidder disse egenskaber, vurderer Iben Yde, at det under ekstremt skærpede omstændigheder ville være lovligt at give dronen ret til selv at angribe på egen hånd.Hun forklarer, at en lang række forbehold ville gøre sig gældende, såsom at dronen udelukkende må gå efter materielle mål i afsides områder, hvor der ingen risiko er for at ramme civile mål.Stram programmeringSom eksempel på et delvist selvbestemmende våbensystem nævner Iben Yde antiluftskyts-systemet Phalanx, som sidder på stort set alle britiske og amerikanske krigsskibe.Systemet kan sættes op til selv at detektere, spore og angribe indkommende missiler uden menneskelig indblanding.Systemet forsøger bl. a. at tage radiokontakt for at sikre, at det ikke er et civilt fly, det er ved at skyde ned, og tager en lang række andre forbehold, inden det angriber.»Et menneske kunne aldrig nå at foretage så mange vurderinger på så kort tid, så jeg mener ikke, det er det, vi skal forbyde,« siger Iben Yde, der som jurist ser en fremtid, hvor robotterne bliver stramt programmeret og holdt i kort snor.Det samme billede i krystalkuglen ser Thomas Bolander, der forsker i kunstig intelligens ved DTU.»Som teknologien er i dag, skal du instruere robotten i alle de regler, den skal efterleve, men du skal også programmere samtlige undtagelser, som i kampens hede ofte beror på et subjektivt skøn. Fjendens uniform er måske det, som for robotten de-finerer, hvad der må skydes på, og hvad der ikke må, men hvis et barn var klædt i fjendens uniform, ville et menneske måske ikke skyde, mens robotten i den situation ikke ville gøre forskel,« siger Thomas Bolander og fortsætter: »Det kan man selvfølgelig tage forbehold for, men hvem kan garantere, at det program, man begynder at skrive, tager højde for samtlige ting? Ved den ene yderlighed kan det betyde, at robotter udgør en stor risiko i forhold til at begå frygtelige fejl, eller også bliver de så forsigtige, at man kan diskutere, hvor interessante de så er at benytte,« siger han.Han slår fast, at der endnu er meget lang vej, før det bliver muligt at skabe fuldgyldige autonome systemer, der kan bruges i komplekse situationer, som krig ofte er, så dræberrobotterne invaderer ikke slagmarken lige foreløbigt.»Dybest set forstår vi ikke, hvordan vi skal lave menneskelignende intelligens på en computer. Det er ikke engang sådan, at man kan sige, at vi er godt på vej, for det er en nød, vi simpelthen ikke har knækket endnu,« siger Thomas Bolander.Er dræberrobotter sikre?I FN har man diskuteret lovligheden af dødbringende autonome våbensystemer de seneste to år, men er endnu ikke nået frem til, om de autonome droner skal på listen over våben, der er forbudte at anvende i krig.FN afholdt i maj et ekspertmøde om emnet og inviterede blandt andre Paul Scharre, der leder et mangeårigt forskningsprojekt, som skal kortlægge fremtidens krigsførsel for den uafhængige organisation Center for a New American Security.Han arbejder på at finde ud af, hvilken rolle autonome robotter kommer til at spille i fremtidens krig, og mener, at vi i øjeblikket står midt i en revolution inden for robotik - både civil og militær - og det kræver, at vi som verdenssamfund forholder os til perspektiverne i den nye teknologi.»Mange vil hævde, at der ikke findes dødbringende autonome våbensystemer.Det er ikke sandt, når man ser isoleret på funktionaliteten ' beslutning om udvælgelse af mål'.De er ikke i brug mange steder, men der er et lille antal systemer i brug i dag, som udfører denne funktion,« fortalte Poul Scharre til de officielle repræsentanter fra mere end 25 lande og nævnte blandt andet Harpysystemet som eksempel.Under den kolde krig, forklarede han, var der automatiske detektionssystemer på begge sider, der ved flere lejligheder fejlagtigt troede, at et atomangreb var undervejs. Dengang var det indgreb fra mennesker i beslutningskæden, der sikrede, at en global atomkrig ikke blev udløst.»Der er et presserende behov for, at verdens nationer tænker over, hvordan man garanterer, at autonome våben er sikre og bruges på en sikker måde. Det er et ansvar, der påhviler enhver stat, at garantere sin egen sikkerhed, men utilsigtet krig kan ikke komme nogen til gode,« sagde Paul Scharre.Set fra den modsatte pol har selvbestemmende robotter også interessante perspektiver i forhold til at gøre slagmarken mere human.Robotter handler aldrig på følelser og instinkter, og fortalere vil mene, at de kyniske robotter ikke vil være i stand til at begå krigsforbrydelser.»Den humanitære folkeret har primært til formål at beskytte ofre for krig - og her menes primært civile, der kan blive fanget i krydsilden.Hvis man kan lave autonome våbensystemer, som kan yde en bedre beskyttelse, så kan man argumentere for, at vi er moralsk og politisk forpligtede til at videreudvikle denne slags systemer, ville jeg mene,« siger Iben Yde.HARPYType: Anti-radar-drone Producent: Israeli Aerospace Industry Et to meter langt dronefly, der kan hænge i luftrummet over et missionsområde og scanne efter fjendtlige radarprofiler. Hvis Harpy identificerer et mål, der eksisterer i dens database over godkendte mål, tager den selv beslutning om at angribe.Dronen styrtdykker mod målet i et kamikaze-angreb og detonerer sin 35 kg tunge sprængladning umiddelbart inden nedslaget.LRASMType: Anti-skibsmissil Producent: Lockheed Martin Stadig under udvikling hos Lockheed Martin for det amerikanske militære forskningsinstitut Darpa.LRASM kan affyres på sikker afstand af fjendtlige skibe og er i stand til at ændre sin rute, hvis pludselige trusler skulle opstå undervejs.Hvis målet er en klynge af skibe, afgør missilet selv, hvilket skib det angriber.Missilet er svært at opdage for fjendens radarsystemer, da det dykker ned under radarhøjde, kort inden målet rammes.PHALANXType: Nærforsvarssystem til skibe Producent: General Dynamics Et fuldautomatisk nærforsvarssystem, der sidder på størstedelen af både den amerikanske og britiske flåde.Systemet kan sættes op til automatisk at detektere, spore og nedskyde indkomne missiler og overfladetrusler.En lang række forbehold tages, inden våbnet affyres automatisk, såsom objektets fart og retning.BRIMSTONEType: Luft-til-jord-missil Producent: MBDA Missile Systems Et såkaldt ' fire-and-forget'-missil, der opererer autonomt, når først det er affyret. Missilet identificerer selv et mål i den generelle retning, det er blevet affyret i. Brimstone kan identificere målets mest sårbare punkt, så det altid udretter størst mulig skade.Hvis missilerne affyres flere ad gangen i en salve, kommunikerer våbnene med hinanden og fordeler en angrebsrækkefølge, så de ikke alle rammer det samme mål. Hvis Brimstone ikke kan identi-ficere et oplagt mål, er det programmeret til at selvdestruere.GRADER AF AUTONOMIAutonomi er ikke en fast defineret størrelse, men snarere et spektrum, hvor mennesket er placeret i forskellige led i beslutningskæden. Mange roboteksperter læner sig op ad en model, der definerer tre grader af selvbestemmelse i våbensystemer: ' Human-in-the-loop', hvor mennesker er en integreret del af beslutningskæden og har fuld kontrol over systemet.' Human-on-the-loop', hvor mennesker betragter beslutningskæden og har mulighed for at gribe ind i systemet.' Human-out-of-the-loop', hvor mennesker ikke har indflydelse på beslutningskæden.
        </div>
        <footer>
          <em>Ingeniøren</em>
          &nbsp;·&nbsp; 2014-12-19
          &nbsp;·&nbsp; e4ba8279
          &nbsp;·&nbsp; #39
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.986</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.589</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.63</kbd>
        </footer>
      </article>
      <article>
        <h4>Her er det amerikanske militærs nye superfly</h4>
        <div>
          Et nyt krigsfly, som bliver styret af kunstig intelligens, er under udvikling.X 47 B bliver muligvis verdens første ubemandede fly, der styret af kunstig intelligens frem for en operatør på landjorden.Det amerikanske militær tester i øjeblikket X-47 B på havet.Hvis fremtids-flyet afslutter sine tests uden anmærkninger, bliver X-47 B det første fly, som er i stand til at lande på et hangarskib uden hjælp.Uklare regler fra PentagonFlyet har været under udvikling i fem år og er designet til at flyve ud på for-programmerede missioner.X-47 B er styret af en computer, som kan tænke selvstændigt og f.eks. selv ændre kurs.Pentagon har i sidste uge udsendt nye retningslinjer for, at det altid skal afgøres af et menneske, når en robot eller fly åbner ild. Det er dog uklart, om X-47 B er inkluderet i den bekendtgørelse, skriver
        </div>
        <footer>
          <em>Jp.dk (Jyllands-Posten)</em>
          &nbsp;·&nbsp; 2012-12-03
          &nbsp;·&nbsp; e38c26c3
          &nbsp;·&nbsp; #40
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.824</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.883</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.644</kbd>
        </footer>
      </article>
      <article>
        <h4>Ritzau Plus: Drones4Safety's fem hovedmål</h4>
        <div>
          København1. At udvikle en holdbar metode til automatisk optankning af droner på højspændingsledninger og jernbanekabler.2. At gøre inspektionen af infrastruktur som eksempelvis broer mere effektiv ved hjælp af kunstig intelligens.3. At formå en drone til at levere fejlfri inspektion.4. At udvikle dronernes evne til at samarbejde internt i en sværm - som fugle i en flok.5. At opbygge en cloud-baseret løsning, som kan sikre, at dronerne kan navigere af sig selv.Kilde: SDU/ritzau/Se også grafikDenne nyhed må publiceres digitalt bag paywall fra d. 13/06/2020 20:00Denne nyhed publiceres ikke på NET-tjenesten
        </div>
        <footer>
          <em>Ritzaus Bureau</em>
          &nbsp;·&nbsp; 2020-06-13
          &nbsp;·&nbsp; e7c01a16
          &nbsp;·&nbsp; #41
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.717</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.621</kbd>
        </footer>
      </article>
      <article>
        <h4>FN skal tage stilling til dræberrobotter: Nye våben identificerer og dræber selv deres mål</h4>
        <div>
          Det går stærkt med at udvikle våben, som på egen hånd kan træffe dødbringende beslutninger. FN skal se på lovgivning, men det er en svær diskussion, siger forsker ved DIIS.Forestil dig himlen fuld af små militære droner, som gennemsøger et område, mens de leder efter én bestemt person. De kommunikerer konstant med hinanden og omsætter lynhurtigt store mængder af information. Forestil dig, at de finder personen og selv beslutter, hvornår han/hun skal slås ihjel.Eller forestil dig en kampvogn, som kører selv, selv afsøger terrænet for mål og selv beskyder målene.De to scenarier er hverken computerspil, film eller fjern fremtid. Det er nutidens teknologi inden for det, der hedder &quot;lethal autonomous weapon&quot; (på dansk: dødbringende autonome våben). Det amerikanske forsvar har allerede udviklet dronerne, og det russiske forsvar har kampvognen.Men til næste år skal FN diskutere brugen og udviklingen af lethal autonomous weapons, også bare kaldet killer robots eller dræberrobotter. Det besluttede FN-organet UN Convention on Certain Conventional Weapons fredag, skriverBuzzFeed.ADVERTISING inRead invented by TeadsI længere tid har kampagnen &quot;Campaign to Stop Killer Robots&quot; (kampagne for at stoppe dræberrobotter, red.) forsøgt at få FN's opmærksomhed på området. Bag kampagnen står en række NGO'er, herunder Humans Rights Watch.Johannes Lang er uddannet psykolog og forsker i psykologiens rolle i moderne krigsførelse ved Dansk Institut for Internationale Studier.Han forklarer, hvorfor den slags teknologi over hovedet bliver udvilket.»I krig er der hele tiden brug for, at man kan tænke hurtigere og reagere hurtigere. Meget af den teknologi, som er udviklet og taget i brug i krig får tingene til at gå så stærkt, at mennesker ikke kan følge med længere. Derfor udvikler man hele tiden teknologi, som man kan outsource hurtige og komplicerede beslutninger til,«siger han.Det er en svær diskussion, for der er både argumenter for og imod dræberrobotterne, forklarer han.»På den ene side kan de her intelligente systemer muligvis gøre, at vi vil se færre civile tab i krig. Mennesker er for langsomme, de kan blive trætte, og de kan blive følelsesmæssigt involveret, når der skal tages hurtige beslutninger. Det kan man komme til livs med disse teknologier, og man vil muligvis også kunne sende færre soldater i krig. Og så vil tilhængere af teknologierne sige, at der altid er en menneskelig beslutning &quot;in the loop&quot; - altså at systemerne ikke fungerer fuldstændig autonomt.«»Men et problem kan være, at når der skal tages så hurtige og så vigtige beslutninger, risikerer man, at mennesker ikke stoler på deres egen dømmekraft, eller at de ikke kan tage beslutningen hurtigt nok. Og så vælger de måske at tro på systemerne. Dermed bliver det de facto systemerne, der tager beslutningen,«siger Johannes Lang.Kunstig intelligens kan tage magten fra osDansk Institut for Internationale Studier afholdt i november måned et seminar om netop dræberrobotter. Og her argumenterede flere danske eksperter for, at problematikkerne ved de nye våben, vil kunne håndteres inden for allerede eksisterende international lov som fx. krigens love og folkeretten, fortæller Johannes Lang.»Andre, som fx. kampagnen Campaign to Stop Killer Robots, vil have, at man helt forbyder brugen af disse teknologier, mens der også er nogle, som mener, man bør stoppe udviklingen af teknologierne. Problemet er bare, at udviklingen af disse teknologier finder sted mange andre steder end i militære sammenhænge. Fx. i bilindustrien, hvor man at udvikle selvkørende biler, der bruger nogle af de samme teknologier,«siger Johannes Lang.UN Convention on Certain Conventional Weapons har tidligere forbudt bl.a. landminer, napalm og blændende lasere.Der udvikles hele tiden flere og flere våben, som kan arbejde mere og mere autonomt. Men de rejser etiske dilemmaer, som FN nu skal tage stilling til. Her er det et Phalanx Close-in Weapons System (CIWS), som er monteret på et amerikansk krigsskib. Phalanx er et avanceret, computerstyret anti-missil-system. Foto: US Navy.Der udvikles hele tiden flere og flere våben, som kan arbejde mere og mere autonomt. Men de rejser etiske dilemmaer, som FN nu skal tage stilling til. Her er det et Phalanx Close-in Weapons System (CIWS), som er monteret på et amerikansk krigsskib. Phalanx er et avanceret, computerstyret anti-missil-system. Foto: US Navy.
        </div>
        <footer>
          <em>Jyllands-posten.dk (Abonnementsområde)</em>
          &nbsp;·&nbsp; 2016-12-17
          &nbsp;·&nbsp; e6084ed9
          &nbsp;·&nbsp; #42
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.994</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.628</kbd>
        </footer>
      </article>
      <article>
        <h4>Videnskabsfolk advarer mod udvikling af dræberrobotter</h4>
        <div>
          København, fredagHvad skal vi gøre, hvis robotter ikke overholder reglerne for krigsførelse?, spørger professor.Verdenssamfundet bør skride ind og sætte en stopper for forskning i, hvad der populært går under betegnelsen dræberrobotter.Det mener over 1000 videnskabsfolk og erhvervsspidser, som beskæftiger sig med teknologi.I et åbent brev til en konference i Buenos Aires om kunstig intelligens advarer brevskriverne om, at udviklingen af militærrobotter er nået så langt, at selvstyrende dræberrobotter kan blive mulige &quot;inden for år, ikke årtier&quot;, skriver Politiken.I brevet betegnes selvstyrende våben som &quot;den tredje revolution inden for krigsførelse&quot; - efter først opfindelsen af krudt og siden atomvåben.Brevet advarer om, at hvis en stor militærmagt sætter turbo på udviklingen af våben med kunstig intelligens, &quot;så er et globalt våbenkapløb uundgåeligt&quot;.Underskriverne tæller kendte intellektuelle som fysikeren Stephen Hawking og filosoffen Noam Chomsky.De frygter, at selvstyrende våben let kan falde i de forkerte hænder, for når teknologien først findes, kan de fremstilles nemmere og billigere end for eksempel atomvåben.- Selvstyrende våben vil blive morgendagens Kalasjnikovs, skriver forskerne med henvisning til en type automatriffel, som er blevet særlig udbredt blandt militante og terrorister.Noel Sharkey, der er professor i robotteknologi ved University of Sheffield, er en del af en alliance, der arbejder for at få en FN-konvention, som forbyder brugen af avancerede militære robotter på verdensplan.- Man skal huske, at militære robotter er maskiner, programmeret af mennesker. Der findes også onde mennesker. Hvad skal vi gøre, hvis maskinerne ikke overholder reglerne for krigsførelse? Hvem er så ansvarlig?, spørger Sharkey.Det er imidlertid langtfra alle, der frygter udviklingen af dræberrobotter.- Robotter er rationelle, og jeg mener ikke, at det per automatik er problematisk at overlade drabsbeslutningen til en robot, siger Klaus Æ. Mogensen fra Instituttet for Fremtidsforskning til Politiken.- Vi har set masser af eksempler på, at den menneskelige bedømmelse af en situation i eksempelvis Iran og Irak ikke altid bliver foretaget på et rationelt grundlag. En robot træffer altid en rationel beslutning, fordi den ikke er bekymret for sit eget liv, siger han./ritzau/
        </div>
        <footer>
          <em>Ritzaus Bureau</em>
          &nbsp;·&nbsp; 2015-07-31
          &nbsp;·&nbsp; e52529e3
          &nbsp;·&nbsp; #43
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.981</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.816</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.591</kbd>
        </footer>
      </article>
      <article>
        <h4>FN vil regulere dræberrobotter, der selv finder og udsletter deres mål</h4>
        <div>
          Hightechvåben, der selv identificerer deres mål og selv beslutter, om de skal udslettes, venter lige om hjørnet.De såkaldte dræberrobotter er ikke længere noget, der kun hører Arnold Schwarzeneggers læderjakke-klædte &quot;Terminator&quot;-filmfigur til. I mange lande forskes der på livet løs i den banebrydende teknologi, der dog samtidig rejser store etiske problemer.I den forløbne uge har dræberrobotterne været på dagsordenen ved et FN-møde i Genève. Hensigten er at etablere et sæt principper, der regulerer udviklingen af dræberrobotter på fremtidens slagmark. Danmark deltog for første gang.En dræberrobot er et såkaldt autonomt våben, som selv udpeger sit mål og selv afgør, om målet skal slås ihjel eller udslettes - uden menneskelig indblanding. Sådanne våben findes, så vidt vides, ikke endnu, men det vil kun være et spørgsmål om tid, siger internationale eksperter.De har optalt 381 forskellige slags våben, som delvis tænker selv, men altså stadig i et vist omfang påvirkes af et menneske i den anden ende.En drone er et eksempel. Den finder sit mål, men det er stadig en soldat, der udløser det dræbende missil mod målet.12 lande er ifølge eksperter i gang med at udvikle krigsrobotter med alle de store militærmagter i spidsen.Foreløbig handler debatten meget om at definere konkret, hvad man skal forstå ved dræberrobotter for at kunne arbejde videre med at få dem underlagt internationale regulativer.»Autonomt« våben»Det er helt afgørende med en sådan afklaring af definitioner for at kunne etablere robuste og gennemsigtige reguleringer af området. Alle lande har forpligtet sig til at fastholde et element af menneskelig kontrol med våbnene, men hvad vil det sige? Forskningen går lige nu så hurtigt, at der er risiko for, at lande kan komme i konflikt med disse våben,« siger seniorforsker Robin May Schott fra DIIS, Dansk Institut for Internationale Studier.Hun mener, at definitionen på en dræberrobot skal indeholde to dele: Den skal selv kunne udpege sit mål og selv udløse et angreb - uden menneskelig indflydelse.»Det er typisk sådan, at de lande, der har en stor militær kapacitet, med USA i spidsen, ikke er interesseret i, at aftalerne er for forpligtende.Omvendt med militært svage lande,« siger Robin May Schott.USA, der er længst fremme med forskningen, har forpligtet sig til, at der i hvert fald frem til 2022 altid vil være menneskelig kontrol over alle slags våben, men igen er det et definitionsspørgsmål, påpeger hun.I Genève fastholdt flere lande, at selve programmeringen af våbnene sikrer en menneskelig kontrol, men den tilgang er stærkt omdiskuteret.21 lande har underskrevet en opfordring til at forbyde sådanne våben, og en international ngo-kampagne &quot;Stop Killer Robots&quot; har stor gennemslagskraft. Også Tesla-grundlæggeren Elon Musk og den nu afdøde fysiker Stephen Hawking har været fremtrædende kritikere.De beskriver dræberrobotterne som krigsførelsens tredje revolution efter opfindelsen af krudtet og udviklingen af atombomben.De peger på, at autonome våben ikke kan programmeres til at overholde krigens love, og at det vil være etisk forkasteligt at overlade spørgsmålet om liv og død til en maskine, uden at et menneske er med inde over.Krig industrialiseres»Dræberrobotterne vil blive masseødelæggelsesvåben og rene terrorvåben, som terrorister og bøllestater vil bruge.Én programmør og en 3Dprinter vil kunne præstere det samme som en hel hær af soldater. Krig vil blive industrialiseret.Disse våben kan dræbe 24/ 7, og de kan dræbe hurtigere, end mennesker kan nå at forsvare sig selv,« siger professor i kunstig intelligens Toby Walsh til The Guardian.Han er en af de skarpeste internationale kritikere af udviklingen af krigsrobotter.Danmark deltog for første gang i ekspertmødet i Genève og lægger sammen med EU vægt på nødvendigheden af, at »den potentielle udvikling og brug af sådanne våbensystemer lever op til international humanitær folkeret og menneskerettighederne,« oplyser Udenrigsministeriet.Til efteråret vil FN-mødet begynde at diskutere forslag til egentlige reguleringer.joern.mikkelsen@jp.dk Fakta: AUTONOME VÅBEN Uberørt af menneskerFlere lande forsker intenst i autonome våben. Fuldt selvkørende våben findes, så vidt vides, ikke endnu, men 381 våbentyper, der kommer tæt på, er registreret.Alle lande forsikrer officielt, at de fortsat vil lade mennesker have den endelig afgørelse, når våbnet skal affyres.Men det lægger op til et slagsmål om, hvad »menneskelig ind-flydelse« vil sige.En ekspertgruppe under FN forsøger at få hold om området.Danmark er nu med.
        </div>
        <footer>
          <em>Jyllands-Posten</em>
          &nbsp;·&nbsp; 2018-04-15
          &nbsp;·&nbsp; e6b44ae4
          &nbsp;·&nbsp; #44
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.729</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.625</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.621</kbd>
        </footer>
      </article>
      <article>
        <h4>Er tryghed stadig vigtig?</h4>
        <div>
          Autonome robotter/droner er udstyret med kunstig intelligens (AI), der tænker langt hurtigere end mennesker. Kunstig intelligens kan selv udvikle sin intelligens. Således har robotter kunnet udvikle et andet sprog til kommunikation, da menneskets sprog var for langsomt.I krig er hurtige beslutninger noget, man kan vinde en krig med. Derfor er det fristende at overlade krigens beslutninger til superhurtige dræberrobotter, men det vil betyde, at en atomkrig lettere vil kunne starte ved en fejl. Derfor kom og hør vort gadeteater om autonome dræberrobotter på FN's fredsdag den 21. september klokken 17.00 og klokken 17.30 i Heerups Have ved Hotel Britannia i Esbjerg.
        </div>
        <footer>
          <em>Jv.dk (Abonnementsområde)</em>
          &nbsp;·&nbsp; 2018-09-18
          &nbsp;·&nbsp; e6e708d6
          &nbsp;·&nbsp; #45
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.978</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.596</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.566</kbd>
        </footer>
      </article>
      <article>
        <h4>INDBLIK: Inden længe behøver mennesker ikke selv at udkæmpe deres krige</h4>
        <div>
          De bliver aldrig bange, trætte eller sultne. I modsætning til soldater af kød og blod kan våben, som tænker selv, udløser sig selv og selv beslutter at slå ihjel - uberørt af menneskehånd - blive ved og ved. De adlyder altid, og de misser kun sjældent deres mål.Såkaldt autonome våben - killer robots - rykker stadigt tættere på at blive virkelighed.Men udviklingen er forbundet med så store etiske udfordringer, at mange forsøger at få den reguleret nærmere.Siden menneskene opfandt de første våben at bruge mod hinanden, har kampen på liv og død fjernet sig stadigt mere fra den direkte udmåling af fysisk styrke. Selv en drone, der flyver tusindvis af kilometer, før den affyrer et missil, bliver styret af et menneske i den anden ende, om end pr. joystick, og er ret beset kun en teknologisk videreudvikling af gammeldags kanoner og raketter.Med udviklingen af selvstændige dræbermaskiner med kunstig intelligens går våbenteknologien et stort skridt videre: Disse våben vil selv kunne afgøre, hvor og hvornår nogen må dø. Det har altid været et stort spørgsmål, hvor menneskeligheden er i krig, og hvor bizart det egentlig er at lave regler for, hvordan krigen må føres. Men nu er mennesket på nippet til at blive skrevet helt ud af krigen.»Mange tænker nok straks på &quot;Terminator&quot; og Arnold Schwarzenegger, men faktisk var end ikke han fuldt autonom. Han vidste f. eks. ikke, hvordan Sarah Connor (kvinden, der skal reddes i filmen, red.) så ud. De våben, vi taler om her, ved alt og kan alt selv,« siger seniorforsker Gary John Schaub Jr., Center for Militære Studier under Københavns Universitet.En moralsk grænse overskridesHan publicerede tidligere på året en rapport om emnet, som forsøgte at definere, hvornår våben kan siges at tænke og agere selvstændigt, og beskrive den bagvedliggende, kunstige intelligens. Men den fokuserede også på de store etiske udfordringer.Den internationale ngo-kampagne »Stop Killer Robots« formulerer det direkte: »At overlade spørgsmålet om liv og død til maskiner overskrider en grundlæggende moralsk grænse. Autonome maskiner mangler den menneskelige dømmekraft og evnen til at forstå alle sammenhænge. Disse egenskaber er nødvendige for at træffe komplicerede etiske valg på slagmarken, skelne mellem soldater og civile og afveje proportionaliteten i et angreb.« Af samme grund krænker dræbermaskiner folkeretten, påpeger kampagnen. Den verdensberømte fysiker Stephen Hawking advarer sammen med superiværksætteren Elon Musk i et åbent brev også om de store risici og kræver et forbud: »Det er oplagt, hvor denne udvikling ender: Autonome våben vil blive morgendagens Kalasjnikov-geværer, allestedsnærværende og billige for alle førende militærmagter at masseproducere. Det vil kun være et spørgsmål om tid, før de havner på sortbørsen og falder i hænderne på terrorister, diktatorer og krigsherrer.« Også FN har fået øjnene op for udfordringen.I tre år har en særlig komité arbejdet med emnet ved FN i Genève. I forrige uge var den samlet igen. I første omgang handler det om at definere, hvad en autonom dræbermaskine er. Dernæst følger debatten om en regulering, måske et forbud. Men der er lang vej igen. Interessemodsætningerne er store mellem de førende militærmagter.Ikke alle er lige opsatte på en regulering. Og det er en våbenteknologisk udvikling, som det er svært at sætte rammer for.»Mennesket har til alle tider automatiseret sine handlinger mere og mere, også militært.For at forsvare sine soldater, for at øge effektiviteten, for at spare ressourcer. Ultimativt fører det til, at maskinen erstatter mennesket,« siger Gary John Schaub Jr.En del våbentyper, der bruges i dag, er ganske tæt på at være autonome, men er alligevel i sidste ende afhængige af menneskelig påvirkning, hvad enten det er selve affyringen, målsøgningen eller programmeringen.Et krydsermissil finder selv vej, men er programmeret på forhånd. En drone finder sit mål, men dens missil udløses af et menneske, om end meget langt væk.Intelligente våben i DanmarkOgså det danske forsvar råder over sådanne halvautonome våben. Både luftvåbnet og søværnet har ifølge rapporten fra Center for Militære Studier flere missiltyper, der falder ind under denne kategori. Aegis-missilforsvaret, der udgør rygraden i Natos forsvar mod ballistiske missiler, kan automatisk opdage fjendtlige missiler og skyde dem ned.»Hvordan vil denne autonomi ændre krigens førelse? Og hvilke etiske og juridiske problemer giver det? Den diskussion må vi forberede os på. Det handler om at sikre, at menneskene fastholder kontrollen over våbnene,« sagde Vincent Boulanin fra det svenske fredsforskningsinstitut Sipri forleden til det tyske ZDF.Han blev suppleret af ærkebiskop Ivan Jurkovic, der er Vatikanets repræsentant i FN-komitéen: »Vi står foran en meget dramatisk udvikling, som vil præge det 21. århundrede.Fuldt automatiske våben er uforenelige med kristne værdier og anfægter selve menneskeligheden.« 21 lande har foreløbig opfordret til et forbud mod dræbermaskiner. Danmark er ikke med. Tilhængerne af at gå videre med teknologien findes især hos de store våbenproducenter.De påpeger, at maskinerne redder menneskeliv og gør livet lettere for soldaterne ved grænsekontrol, antiterror, beskyttelse af konvojer m. m.Halvautonome våben har været indsat i flere krige, ofte med forfærdende konsekvenser. I den første Golf-krig skød Patriotmissiler amerikanske og britiske fly ned, og heller ikke det amerikanske drone-program lever op til egne målsætninger om altid at identificere ofrene.»Teknologisk er vi ret tæt på autonome våben. Allerede nu kunne man gøre et Tomahawk-krydsermissil helt selvstændigt.Men politisk er der et stykke vej endnu. Problemerne er ved at gå op for de fleste,« siger Gary John Schaub Jr., der mener, at det er på høje tid, at også den danske regering systematiserer sine overvejelser.»Snart bliver pizzaen bragt ud med drone i København. Der mangler i den grad retningslinjer for denne vigtige udvikling af våbenteknologien,« tilføjer han.Lande som USA, Storbritannien, Israel og Sydkorea har alle avancerede programmer for autonome våben og har i varierende grad forpligtet sig til, at der altid vil være en menneskelig dimension i håndteringen af de intelligente våben. Men disse løfter er ifølge ngo-folkene ikke konkretiseret. Pentagon meddelte i 2012, at der altid vil være mennesker med ind over i de følgende 10 år, altså til 2022.»I sidste ende er man tilbage ved spørgsmålet om, hvorvidt det er mere ædelt at slå ihjel i nærkamp, soldat mod soldat, end via en drone i 10 kilometers højde. At krigen har sine egne love, har altid været underligt.Og er det altid rigtigt, at en dum menneskelig hjerne altid skal have forrang over selv den mest intelligente maskine? Det handler vel om, hvad formålet er med at slå ihjel,« siger Gary John Schaub Jr.joern.mikkelsen@jp.dk Fakta: VÅBENTEKNOLOGI Kunstig intelligensMed FN i spidsen er mange aktører ved at få øjnene op for, at våbenteknologien står foran et kvantespring. Introduktionen af såkaldte &quot;killer robots&quot; - autonome dræbermaskiner - er lige om hjørnet. De kan selv  nde og uskadeliggøre deres mål, uden at mennesker er med i processen.En international kampagne for et forbud mod disse våben spiller en afgørende rolle i debatten.Men også FN er gået ind i den og har i de seneste tre år haft en særlig komité - Convention on Conventional Weapons (CCW) - siddende til at diskutere ikke mindst de etiske udfordringer ved, at maskiner kan agere helt selvstændigt.
        </div>
        <footer>
          <em>Jyllands-Posten</em>
          &nbsp;·&nbsp; 2017-11-22
          &nbsp;·&nbsp; e6834219
          &nbsp;·&nbsp; #46
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.927</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.833</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.619</kbd>
        </footer>
      </article>
      <article>
        <h4>Dronen - den fattige mands krydsermissil</h4>
        <div>
          I Mellemøstens virvar af krige og konflikter er dronen blevet den lille mands krydsermissil.Militser, klaner, terrororganisationer og fejlslagne stater kan med ganske få tekniske og økonomiske midler nu slå igen mod højteknologiske militærmagter, som de tidligere var helt forsvarsløse mod.En drone er nem at bygge. Det rulles for tiden også op i Københavns Byret, hvor tre mænd står tiltalt for at have indkøbt avanceret droneudstyr til Islamisk Stat i Syrien.Dronen er billig og kan være svær at opdage på en radar. Men den kan sprede død og ødelæggelse, og den forrykker magtbalancen mellem etablerede militære systemer og fattige oprørsbevægelser.»Der er en blodig ironi i det. USA lancerede sit droneprogram for at få ram på terrorister.Men nu får man selv dronerne tilbage i hovedet. De store magter har mistet deres monopol på at bruge droner,« siger seniorforsker Lars Erslev Andersen, Dansk Institut for Internationale Studier.Det er endnu uafklaret, om det virkelig var droner, affyret af houthi-militsen i Yemen, der ramte Saudi-Arabiens to største olieanlæg i weekenden og lammede 10 pct.af kongedømmets olieproduktion. Houthierne siger selv, at de afsendte 10 droner.Men internationale eksperter tvivler trods alt på, at oprørsmilitsen råder over så avanceret droneteknologi.Men dronen som nyt våben har været i høj kurs i Mellemøsten i de senere år. Igen og igen rapporteres om droner, der har været sat ind i større eller mindre militære aktioner. Dronerne er hurtigt blevet en del af våbenarsenalet selv hos de mindste og fattigste militser. Tilfældige eksempler fra det seneste halve år: N I Irak kastede Islamisk Stat sprængladninger ned fra meget små droner, som man kan bygge med materialer for få penge.N I Syrien lykkedes det oprørsstyrker at ødelægge dele af den russiske luftbase ved Latakia, selv om den er beskyttet af det topmoderne antimissilsystem S-400.N En israelsk kamphelikopter skød en drone ned, som menes afsendt af iranske revolutionsgardister fra Libanon.N Islamisk Stat har i flere propagandafilm pralet med, hvor farlige dens droner er.N Houthi-oprørere brugte i maj droner til et angreb på saudiske olierørledninger.Droner er svære at opdage på radarNogle af dronerne er ikke meget større end modelfly. De flyver lavt og langsomt og har en begrænset rækkevidde, men kan være svære at opdage på en radar. De programmeres problemfrit via gps eller fjernstyres pr. joystick og er altså ikke afhængige af satellitter, som styrer de store militærmagters droner.Ifølge militære eksperter koster det måske kun op til 150.000 kr. at bygge en drone, der kan fremføre våben eller sprængladninger over længere afstande. Da mange af de komponenter, der indgår i bygningen af en drone, er civile, er det næsten umuligt at blokere salget af dem.»Dronerne er et ekstra værktøj for terrorister og fattige stater, som ellers ikke kunne svare igen i eller fra luften. De er et meget effektivt våben mod enkeltpersoner og bestemte mindre mål. Men de kan jo ikke bruges til at bekæmpe en stat som sådan,« siger major Karsten Marrup, Forsvarsakademiet.Han finder det logisk, at dronen har kunnet udvikles som et nyt våben for oprørsbevægelser og terrorister: »Den teknologi, der udvikles af de store lande, kommer tilbage til dem igen, når den bliver kommerciel. Det monopol på brug af droner, som USA oprindelig havde, er væk.«.Stormagternes drone-monopol er vækDet er også holdningen hos en af USA's førende Iran-kendere, Gary Sick, der har siddet i flere præsidenters nationale sikkerhedsråd.De store militærmagter er ikke længere ene om at ramme mål via droner.USA må nu finde sig i at blive ramt med droner, hvor man tidligere under krigen mod terror var urørlige fra luften: »Er tiden for énvejssmerten forbi? Den kunne sikkert ikke opretholdes i det lange løb. Når andre begynder at kunne håndtere den ret billige dronekrigsførelse, udfordres idéen om, at USA og dets allierede har totalt luftherredømme. Teknologien til krydsermissiler er mere kompliceret, men også dét er kun et spørgsmål om tid,« skriver Gary Sick på sin blog.Selve idéen om ubemandede fly opstod i USA i 1990' erne. De er billige i drift og produktion, der er ingen piloter, der bliver trætte eller kan blive dræbt, og de er ukomplicerede at føre frem. I starten blev de kun brugt til rekognoscering. En amerikansk drone blev første gang sat ind over Bosnien i 1995 i krigen på Balkan, hvor den hjalp Natos styrker på jorden.Amerikanske droner havde al-Qaeda-chefen Osama bin Laden på kornet flere gange, men på det tidspunkt var dronerne endnu ikke udstyret med missiler. Under præsident George W. Bush begyndte det egentlige bevæbnede droneprogram, men det var under Barack Obama, at dronen som et nyt, højteknologisk våben for alvor slog igennem.Nogle af de amerikanske droner er efterhånden lige så store som civile passagerfly.Den drone, som Iran i juli skød ned over Den Persiske Golf, havde et vingefang som en A320-airbus. De opererer over enorme afstande og medbringer store, højteknologiske missiler. Andre droner, f. eks. af Predatorklassen, er knap så store, men også dødbringende.De kan veje 600 kg og klassificeres som en mindre drone.Utallige terrorchefer er blevet likvideretUtallige er de terrorchefer i Afghanistan og Irak, der er blevet dræbt af en drone, herunder al-Qaeda-lederen Anwar al-Awlaki, som den danske PET-agent Morten Storm var med til at udpege i Yemen. Det særlige ved al-Awlaki var, at han blev den første amerikanske statsborger, som en præsident gav ordre til at slå ihjel med en drone.I dag har over 100 lande egne militære droneprogrammer - og så altså også alle mulige andre grupper og bevægelser, om end af en mere begrænset størrelse og kapacitet.»Sådan som dronerne er blevet udbredt i dag, smager Vesten virkelig sin egen medicin,« siger seniorforsker Lars Erslev Andersen.Major Karsten Marrup peger på, at selv om det viser sig at være houthi-militsen i Yemen, der står bag angrebene i Saudi-Arabien, er der ikke tale om droner i normal forstand.»En typisk drone flyver afsted, afleverer sin våbenlast og vender hjem igen. I Saudi-Arabien er der i givet fald tale om en kamikazedrone, som flyver sig selv ind i målet, ligesom et missil. Den gængse opfattelse af en drone er, at den fortrinsvis styres pr.fjernstyring. Her se det ud, som om våbnet var forprogrammeret på samme måde som et krydsermissil,« siger han.Ikke droner, men avancerede våbenSpørgsmålet er, hvorfor det saudiske luftforsvar ikke har evnet at skyde dronerne eller missilerne ned, hvor de end kom fra: Irak, Yemen eller måske ligefrem Iran.Saudi-Arabien har investeret meget i sit luftforsvar, og selv om en del er koncentreret om hovedstaden Riyadh, er olieanlæggene også beskyttet militært, bl. a. af amerikanske Patriot-batterier.»Det vidner om, at ligegyldig hvad der ramte raffinaderierne, så var det ikke hjemmelavede droner, der blev styret frem mod målet. Det tyder på meget avancerede våben,« siger major Karsten Marrup.At dronen er et nyt militært våben, som mange kan få fingre i og bruge efter forgodtbefindende, viser også forskningen i, hvordan man kan gardere sig mod droner. Laserlys, jamming af radiofrekvenser, store net foruden opsættelse af flokke af rovfugle er blandt de afværgemetoder, der prøves af, forklarer han.At en lufthavn ved London for nylig måtte lukkes ned to gange på grund af et par civile droner, der kom for tæt på, siger alt om, hvor sårbare højt udviklede samfund er over for dronen. Forleden var den gal igen, da den radikale britiske miljøgruppe Extinction Rebellion truede med endnu en droneaktion mod Heathrow Lufthavn. Gruppens ledere blev arresteret.»Dronen er blevet et anarkistisk våben.Den kan bruges til mange ting og er svær at få under kontrol,« siger Lars Erslev Andersen.Fakta: DRONER SOM VÅBENI mange lande forskes der i kunstig intelligens i militært øjemed. Udvikling af droner indgår, men dronerne opererer endnu ikke selvstændigt.De programmeres eller styres af et menneske.USA satte sin første drone op i midten af 1990' erne over Balkan under krigen i Bosnien.I mange år blev de kun brugt til rekognoscering. Under præsident Obama blev droner, bevæbnet med missiler, taget massivt i anvendelse.I krigene i Afghanistan og Irak blev der sat droner ind i masser af aktioner mod terrorledere.
        </div>
        <footer>
          <em>Jyllands-Posten</em>
          &nbsp;·&nbsp; 2019-09-20
          &nbsp;·&nbsp; e759b8c0
          &nbsp;·&nbsp; #47
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.761</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.645</kbd>
        </footer>
      </article>
      <article>
        <h4>Forskere vil bruge droner til fugletællinger</h4>
        <div>
          Droner kan være mindre forstyrrende for fugle, der ruger i kolonier, end hvis fugletællere går rundt på jorden og skræmmer fuglene på vingerne, påpeger Thomas Eske Holm, seniorrådgiver ved Institut for Bioscience.Han har sammen med kolleger gennemført forsøg i 2018 på adskillige jyske lokaliteter. Biologerne konstaterer, at de ynglende fugle oftest bliver på rederne, selv om der flyver en drone hen over dem.- Droner har nået et stadie, hvor de er billige. De har fået bedre software, bedre kompas og gps og er meget nemme at bruge, så vi kan styre dem til at flyve automatisk i eksempelvis 20 meters højde.- Med en lille drone til 12.000 kroner kan vi kortlægge et relativt stort område og få ét sammenhængende foto, siger Thomas Eske Holm.Sammenligninger mellem traditionelle tællinger og dronetællinger viser også, at overvågning med drone ofte giver mere nøjagtige tal.Det gælder ikke mindst, hvor alternativet er at tælle fuglene i kolonien på afstand gennem kikkert.En droneoptælling af måger på øen Langli i Vadehavet gav således et dobbelt så højt antal - omkring 19.000 - som en manuel opgørelse fra to erfarne fugletællere.- Og vi er helt sikre på, at dronens tal er rigtige. Ved traditionelle tællinger kan man miste overblikket over, hvad man har talt og ikke talt - eller fuglene går pludselig i luften, siger Thomas Eske Holm.Brug af droner kan også i mange tilfælde spare arbejdstimer og penge.Der mangler dog at blive udviklet en algoritme, der automatisk identificerer og tæller fuglene på dronefotos. Herved kan der spares mange timer, som ellers bruges på manuelt at tælle de enkelte arter på billeder./Ritzau/
        </div>
        <footer>
          <em>Kristeligt-Dagblad.dk</em>
          &nbsp;·&nbsp; 2019-03-24
          &nbsp;·&nbsp; e720fd21
          &nbsp;·&nbsp; #48
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.963</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.851</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.682</kbd>
        </footer>
      </article>
      <article>
        <h4>Brugen af selvflyvende politidroner med AI breder sig i USA</h4>
        <div>
          Borgerne bør være kritiske over for det amerikanske politis brug af droner, mener borgerrettighedsgruppen American Civil Liberties Union.Politiet i den sydcaliforniske by Chula Vista har taget selvflyvende droner med den seneste teknologi i brug for at håndhæve loven, mens også andre politiafdelinger har lanceret droneprogrammer. Den stigende brug af droner vækker dog også bekymringer om øget overvågning, skriver The New York TimesFlere politiafdelinger i landet har brugt droner i flere år, men det har hovedsageligt foregået på den måde, at dronen er blevet kørt ud til et gerningssted, hvorefter en betjent har styret dronen manuelt.Men droner kan gøre hverdagen meget nemmere for politiet, der i stedet for at bruge store summer på helikoptere og piloter kan slippe langt billigere ved at anvende droner. Den seneste teknologi bruger kunstig intelligens til at gøre dronerne selvflyvende og dermed også mere attraktive for politiet. Teknologien minder om den, der også anvendes i selvkørende biler.I den sydcaliforniske by Chula Vista bruger politiet de autonome droner til at reagere på akutte situationer. Når de modtager et nødopkald, giver en betjent dronen en lokation, som den selv flyver hen til og vender tilbage fra.For nylig modtog politiet i Chula Vista en melding om, at der lå en bil på hovedet i en udtørret flod. Her sendte politiet en drone fra Silicon Valley-virksomheden Skydio af sted. Dronen fløj selv hen på stedet og ned til bilen.»En almindelig drone ville med garanti være styrtet nu,«  fortæller politibetjenten James Horst til The New York Times, da han fremviser en video af dronen, som flyver ned mod den udtørrede flod og inspicerer bilens indre helt tæt på.Op mod 15 gange om dagen sender politiet i Chula Vista en drone af sted. Det har indtil videre betydet mere end 4.100 droneflyvninger, siden politiafdelingen lancerede droneprogrammet for to år siden. Dronerne kan også sættes til automatisk at forfølge en person eller et køretøj.Flere steder i landet har politiet lanceret lignende droneprogrammer. Derudover samarbejder flere politiafdelinger med virksomheden Shield AI, der har udviklet en drone, som uden pilot kan flyve ind i en bygning og undersøge den i både lys og mørke.Flere droneproducenter, heriblandt Skydio og kinesiske DJI, arbejder på at udvikle lignende teknologier til deres droner, skriver New York Times.Øget overvågningIfølge Jay Stanley, der er politisk analytiker i borgerrettighedsgruppen American Civil Liberties Union, så bør borgere stille sig kritiske over for politiafdelingernes droneprogrammer. Han mener, at behovet for at beskytte privatlivets fred stiger i takt med, at flere politistyrker tager dronerne til sig.For jo mere politiet bruger dronerne, desto flere videooptagelser af borgernes færden i byerne optages og opbevares der, hvilket kan medføre, at borgere må opgive enhver tanke om at have et privatliv, så snart de træder ud ad døren og ud på gaden, siger han til The New York Times.»Droner kan bruges til at efterforske forbrydelser. Men de er også sensorer, som selv kan frembringe lovovertrædelser,«  siger han og tilføjer, at dronerne kan bruges på måder, som er ude trit med de sociale normer.Han påpeger, at dronerne kan bruges til at identificere personer, som eksempelvis deltager i demonstrationer. Ifølge Chula Vistas politi har de dog eksempelvis ikke brugt droner til at flyve over de seneste måneders Black Lives Matter-demonstrationer, fordi deres egne politikker forbyder den brug.Politiet i Chula Vista skal ikke have tilladelse af myndighederne for at udvide brugen af droner, men har løbende underrettet borgerne om, hvad dronerne bruges til, fortæller politiafdelingen til New York Times.
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2020-12-12
          &nbsp;·&nbsp; e808695d
          &nbsp;·&nbsp; #49
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.709</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.632</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.595</kbd>
        </footer>
      </article>
    </main>
  </body>
</html>
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Infomedia Articles</title>
    <style type="text/css">
/*!
 * Pico.css v1.3.3 (https://picocss.com)
 * Copyright 2019-2021 - Licensed under MIT
 */:root{--font-family:system-ui,-apple-system,"Segoe UI","Roboto","Ubuntu","Cantarell","Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";--line-height:1.5;--font-weight:400;--font-size:16px;--border-radius:.25rem;--border-width:1px;--outline-width:3px;--spacing:1rem;--typography-spacing-vertical:1.5rem;--block-spacing-vertical:calc(var(--spacing) * 2);--block-spacing-horizontal:var(--spacing);--grid-spacing-vertical:0;--grid-spacing-horizontal:var(--spacing);--form-element-spacing-vertical:.75rem;--form-element-spacing-horizontal:1rem;--transition:.2s ease-in-out}@media (min-width:576px){:root{--font-size:17px}}@media (min-width:768px){:root{--font-size:18px}}@media (min-width:992px){:root{--font-size:19px}}@media (min-width:1200px){:root{--font-size:20px}}@media (min-width:576px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 2.5)}}@media (min-width:768px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 3)}}@media (min-width:992px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 3.5)}}@media (min-width:1200px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 4)}}@media (min-width:576px){article{--block-spacing-horizontal:calc(var(--spacing) * 1.25)}}@media (min-width:768px){article{--block-spacing-horizontal:calc(var(--spacing) * 1.5)}}@media (min-width:992px){article{--block-spacing-horizontal:calc(var(--spacing) * 1.75)}}@media (min-width:1200px){article{--block-spacing-horizontal:calc(var(--spacing) * 2)}}a{--text-decoration:none}a.contrast,a.secondary{--text-decoration:underline}small{--font-size:0.875em}h1,h2,h3,h4,h5,h6{--font-weight:700}h1{--font-size:2rem;--typography-spacing-vertical:3rem}h2{--font-size:1.75rem;--typography-spacing-vertical:2.625rem}h3{--font-size:1.5rem;--typography-spacing-vertical:2.25rem}h4{--font-size:1.25rem;--typography-spacing-vertical:1.874rem}h5{--font-size:1.125rem;--typography-spacing-vertical:1.6875rem}[type=checkbox],[type=radio]{--border-width:2px}[type=checkbox][role=switch]{--border-width:3px}thead td,thead th{--border-width:3px}:not(thead)>*>td{--font-size:0.875em}code,kbd,pre,samp{--font-family:"Menlo","Consolas","Roboto Mono","Ubuntu Monospace","Noto Mono","Oxygen Mono","Liberation Mono",monospace,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji"}kbd{--font-weight:bolder}:root:not([data-theme=dark]),[data-theme=light]{color-scheme:light;--background-color:#FFF;--color:#415462;--h1-color:#1b2832;--h2-color:#23333e;--h3-color:#2c3d49;--h4-color:#374956;--h5-color:#415462;--h6-color:#4d606d;--muted-color:#73828c;--muted-border-color:#edf0f3;--primary:#1095c1;--primary-hover:#08769b;--primary-focus:rgba(16,149,193,0.125);--primary-inverse:#FFF;--secondary:#596b78;--secondary-hover:#415462;--secondary-focus:rgba(89,107,120,0.125);--secondary-inverse:#FFF;--contrast:#1b2832;--contrast-hover:#000;--contrast-focus:rgba(89,107,120,0.125);--contrast-inverse:#FFF;--mark-background-color:#fff2ca;--mark-color:#543a25;--ins-color:#388E3C;--del-color:#C62828;--blockquote-border-color:var(--muted-border-color);--blockquote-footer-color:var(--muted-color);--button-box-shadow:0 0 0 rgba(0,0,0,0);--button-hover-box-shadow:0 0 0 rgba(0,0,0,0);--form-element-background-color:transparent;--form-element-border-color:#a2afb9;--form-element-color:var(--color);--form-element-placeholder-color:var(--muted-color);--form-element-active-background-color:transparent;--form-element-active-border-color:var(--primary);--form-element-focus-color:var(--primary-focus);--form-element-disabled-background-color:#d5dce2;--form-element-disabled-border-color:#a2afb9;--form-element-disabled-opacity:.5;--form-element-invalid-border-color:#C62828;--form-element-invalid-active-border-color:#B71C1C;--form-element-valid-border-color:#388E3C;--form-element-valid-active-border-color:#2E7D32;--switch-background-color:#bbc6ce;--switch-color:var(--primary-inverse);--switch-checked-background-color:var(--primary);--range-border-color:#d5dce2;--range-active-border-color:#bbc6ce;--range-thumb-border-color:var(--background-color);--range-thumb-color:var(--secondary);--range-thumb-hover-color:var(--secondary-hover);--range-thumb-active-color:var(--primary);--table-border-color:var(--muted-border-color);--table-row-stripped-background-color:#f6f8f9;--code-background-color:#edf0f3;--code-color:var(--muted-color);--code-kbd-background-color:var(--contrast);--code-kbd-color:var(--contrast-inverse);--code-tag-color:#b34d80;--code-property-color:#3d888f;--code-value-color:#998866;--code-comment-color:#a2afb9;--accordion-border-color:var(--muted-border-color);--accordion-close-summary-color:var(--color);--accordion-open-summary-color:var(--muted-color);--card-background-color:var(--background-color);--card-border-color:var(--muted-border-color);--card-box-shadow:0 0.125rem 1rem rgba(27,40,50,0.04),0 0.125rem 2rem rgba(27,40,50,0.08),0 0 0 0.0625rem rgba(27,40,50,0.024);--card-sectionning-background-color:#fafbfc;--progress-background-color:#d5dce2;--progress-color:var(--primary);--loading-spinner-opacity:.5;--tooltip-background-color:var(--contrast);--tooltip-color:var(--contrast-inverse);--icon-chevron:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");--icon-date:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");--icon-time:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");--icon-search:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");--icon-checkbox:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-minus:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");--icon-valid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(56, 142, 60, 0.999)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-invalid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(198, 40, 40, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E")}@media only screen and (prefers-color-scheme:dark){:root:not([data-theme=light]){color-scheme:dark;--background-color:#11191f;--color:#bbc6ce;--h1-color:#edf0f3;--h2-color:#e1e6ea;--h3-color:#d5dce2;--h4-color:#c8d1d8;--h5-color:#bbc6ce;--h6-color:#aebbc3;--muted-color:#73828c;--muted-border-color:#1f2d38;--primary:#1095c1;--primary-hover:#1ab3e6;--primary-focus:rgba(16,149,193,0.25);--primary-inverse:#FFF;--secondary:#596b78;--secondary-hover:#73828c;--secondary-focus:rgba(115,130,140,0.25);--secondary-inverse:#FFF;--contrast:#edf0f3;--contrast-hover:#FFF;--contrast-focus:rgba(115,130,140,0.25);--contrast-inverse:#000;--mark-background-color:#d0c284;--mark-color:#11191f;--ins-color:#388E3C;--del-color:#C62828;--blockquote-border-color:var(--muted-border-color);--blockquote-footer-color:var(--muted-color);--button-box-shadow:0 0 0 rgba(0,0,0,0);--button-hover-box-shadow:0 0 0 rgba(0,0,0,0);--form-element-background-color:#11191f;--form-element-border-color:#374956;--form-element-color:var(--color);--form-element-placeholder-color:var(--muted-color);--form-element-active-background-color:var(--form-element-background-color);--form-element-active-border-color:var(--primary);--form-element-focus-color:var(--primary-focus);--form-element-disabled-background-color:#2c3d49;--form-element-disabled-border-color:#415462;--form-element-disabled-opacity:.5;--form-element-invalid-border-color:#B71C1C;--form-element-invalid-active-border-color:#C62828;--form-element-valid-border-color:#2E7D32;--form-element-valid-active-border-color:#388E3C;--switch-background-color:#374956;--switch-color:var(--primary-inverse);--switch-checked-background-color:var(--primary);--range-border-color:#23333e;--range-active-border-color:#2c3d49;--range-thumb-border-color:var(--background-color);--range-thumb-color:var(--secondary);--range-thumb-hover-color:var(--secondary-hover);--range-thumb-active-color:var(--primary);--table-border-color:var(--muted-border-color);--table-row-stripped-background-color:rgba(115,130,140,0.05);--code-background-color:#17232c;--code-color:var(--muted-color);--code-kbd-background-color:var(--contrast);--code-kbd-color:var(--contrast-inverse);--code-tag-color:#a65980;--code-property-color:#599fa6;--code-value-color:#8c8473;--code-comment-color:#4d606d;--accordion-border-color:var(--muted-border-color);--accordion-active-summary-color:var(--primary);--accordion-close-summary-color:var(--color);--accordion-open-summary-color:var(--muted-color);--card-background-color:#141e25;--card-border-color:#11191f;--card-box-shadow:0 0.125rem 1rem rgba(0,0,0,0.06),0 0.125rem 2rem rgba(0,0,0,0.12),0 0 0 0.0625rem rgba(0,0,0,0.036);--card-sectionning-background-color:#17232c;--progress-background-color:#23333e;--progress-color:var(--primary);--loading-spinner-opacity:.5;--tooltip-background-color:var(--contrast);--tooltip-color:var(--contrast-inverse);--icon-chevron:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");--icon-date:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");--icon-time:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");--icon-search:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");--icon-checkbox:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-minus:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");--icon-valid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(46, 125, 50, 0.999)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-invalid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(183, 28, 28, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E")}}[data-theme=dark]{color-scheme:dark;--background-color:#11191f;--color:#bbc6ce;--h1-color:#edf0f3;--h2-color:#e1e6ea;--h3-color:#d5dce2;--h4-color:#c8d1d8;--h5-color:#bbc6ce;--h6-color:#aebbc3;--muted-color:#73828c;--muted-border-color:#1f2d38;--primary:#1095c1;--primary-hover:#1ab3e6;--primary-focus:rgba(16,149,193,0.25);--primary-inverse:#FFF;--secondary:#596b78;--secondary-hover:#73828c;--secondary-focus:rgba(115,130,140,0.25);--secondary-inverse:#FFF;--contrast:#edf0f3;--contrast-hover:#FFF;--contrast-focus:rgba(115,130,140,0.25);--contrast-inverse:#000;--mark-background-color:#d0c284;--mark-color:#11191f;--ins-color:#388E3C;--del-color:#C62828;--blockquote-border-color:var(--muted-border-color);--blockquote-footer-color:var(--muted-color);--button-box-shadow:0 0 0 rgba(0,0,0,0);--button-hover-box-shadow:0 0 0 rgba(0,0,0,0);--form-element-background-color:#11191f;--form-element-border-color:#374956;--form-element-color:var(--color);--form-element-placeholder-color:var(--muted-color);--form-element-active-background-color:var(--form-element-background-color);--form-element-active-border-color:var(--primary);--form-element-focus-color:var(--primary-focus);--form-element-disabled-background-color:#2c3d49;--form-element-disabled-border-color:#415462;--form-element-disabled-opacity:.5;--form-element-invalid-border-color:#B71C1C;--form-element-invalid-active-border-color:#C62828;--form-element-valid-border-color:#2E7D32;--form-element-valid-active-border-color:#388E3C;--switch-background-color:#374956;--switch-color:var(--primary-inverse);--switch-checked-background-color:var(--primary);--range-border-color:#23333e;--range-active-border-color:#2c3d49;--range-thumb-border-color:var(--background-color);--range-thumb-color:var(--secondary);--range-thumb-hover-color:var(--secondary-hover);--range-thumb-active-color:var(--primary);--table-border-color:var(--muted-border-color);--table-row-stripped-background-color:rgba(115,130,140,0.05);--code-background-color:#17232c;--code-color:var(--muted-color);--code-kbd-background-color:var(--contrast);--code-kbd-color:var(--contrast-inverse);--code-tag-color:#a65980;--code-property-color:#599fa6;--code-value-color:#8c8473;--code-comment-color:#4d606d;--accordion-border-color:var(--muted-border-color);--accordion-active-summary-color:var(--primary);--accordion-close-summary-color:var(--color);--accordion-open-summary-color:var(--muted-color);--card-background-color:#141e25;--card-border-color:#11191f;--card-box-shadow:0 0.125rem 1rem rgba(0,0,0,0.06),0 0.125rem 2rem rgba(0,0,0,0.12),0 0 0 0.0625rem rgba(0,0,0,0.036);--card-sectionning-background-color:#17232c;--progress-background-color:#23333e;--progress-color:var(--primary);--loading-spinner-opacity:.5;--tooltip-background-color:var(--contrast);--tooltip-color:var(--contrast-inverse);--icon-chevron:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");--icon-date:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");--icon-time:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");--icon-search:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");--icon-checkbox:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-minus:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");--icon-valid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(46, 125, 50, 0.999)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-invalid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(183, 28, 28, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E")}*,:after,:before{box-sizing:border-box}:after,:before{text-decoration:inherit;vertical-align:inherit}html{-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:rgba(0,0,0,0);-moz-tab-size:4;-ms-text-size-adjust:100%;background-color:var(--background-color);color:var(--color);font-family:var(--font-family);font-size:var(--font-size);font-weight:var(--font-weight);line-height:var(--line-height);text-rendering:optimizeLegibility;cursor:default}main{display:block}body{width:100%;margin:0}body>footer,body>header,body>main{width:100%;margin-right:auto;margin-left:auto;padding:var(--block-spacing-vertical) 0}.container,.container-fluid{width:100%;margin-right:auto;margin-left:auto;padding-right:var(--spacing);padding-left:var(--spacing)}@media (min-width:576px){.container{max-width:510px;padding-right:0;padding-left:0}}@media (min-width:768px){.container{max-width:700px}}@media (min-width:992px){.container{max-width:920px}}@media (min-width:1200px){.container{max-width:1130px}}section{margin-bottom:var(--block-spacing-vertical)}.grid{grid-column-gap:var(--grid-spacing-horizontal);grid-row-gap:var(--grid-spacing-vertical);display:grid;grid-template-columns:1fr;margin:0}@media (min-width:992px){.grid{grid-template-columns:repeat(auto-fit,minmax(0%,1fr))}}.grid>*{min-width:0}figure{display:block;margin:0;padding:0;overflow-x:auto}figure figcaption{padding:calc(var(--spacing) / 2) 0;color:var(--muted-color)}b,strong{font-weight:bolder}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-0.25em}sup{top:-0.5em}dl dl,dl ol,dl ul,ol dl,ul dl{margin:0}ol ol,ol ul,ul ol,ul ul{margin:0}address,blockquote,dl,figure,form,ol,p,pre,table,ul{margin-top:0;margin-bottom:var(--typography-spacing-vertical);color:var(--color);font-size:1rem;font-style:normal}a{--color:var(--primary);--background-color:transparent;outline:none;background-color:var(--background-color);color:var(--color);text-decoration:var(--text-decoration);transition:background-color var(--transition),color var(--transition),text-decoration var(--transition),box-shadow var(--transition)}a:active,a:focus,a:hover{--color:var(--primary-hover);--text-decoration:underline}a:focus{--background-color:var(--primary-focus)}a.secondary{--color:var(--secondary)}a.secondary:active,a.secondary:focus,a.secondary:hover{--color:var(--secondary-hover)}a.secondary:focus{--background-color:var(--secondary-focus)}a.contrast{--color:var(--contrast)}a.contrast:active,a.contrast:focus,a.contrast:hover{--color:var(--contrast-hover)}a.contrast:focus{--background-color:var(--contrast-focus)}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:var(--typography-spacing-vertical);color:var(--color);font-family:var(--font-family);font-size:var(--font-size);font-weight:var(--font-weight)}h1{--color:var(--h1-color)}h2{--color:var(--h2-color)}h3{--color:var(--h3-color)}h4{--color:var(--h4-color)}h5{--color:var(--h5-color)}h6{--color:var(--h6-color)}address~h1,address~h2,address~h3,address~h4,address~h5,address~h6,blockquote~h1,blockquote~h2,blockquote~h3,blockquote~h4,blockquote~h5,blockquote~h6,dl~h1,dl~h2,dl~h3,dl~h4,dl~h5,dl~h6,figure~h1,figure~h2,figure~h3,figure~h4,figure~h5,figure~h6,form~h1,form~h2,form~h3,form~h4,form~h5,form~h6,ol~h1,ol~h2,ol~h3,ol~h4,ol~h5,ol~h6,pre~h1,pre~h2,pre~h3,pre~h4,pre~h5,pre~h6,p~h1,p~h2,p~h3,p~h4,p~h5,p~h6,table~h1,table~h2,table~h3,table~h4,table~h5,table~h6,ul~h1,ul~h2,ul~h3,ul~h4,ul~h5,ul~h6{margin-top:var(--typography-spacing-vertical)}hgroup{margin-bottom:var(--typography-spacing-vertical)}hgroup>*{margin-bottom:0}hgroup>:last-child{--color:var(--muted-color);--font-weight:unset;font-family:unset;font-size:1rem}p{margin-bottom:var(--typography-spacing-vertical)}small{font-size:var(--font-size)}ol,ul{padding-left:var(--spacing)}ol li,ul li{margin-bottom:calc(var(--typography-spacing-vertical) / 4)}ul li{list-style:square}mark{padding:.125rem .25rem;background-color:var(--mark-background-color);color:var(--mark-color);vertical-align:middle}blockquote{display:block;margin:var(--typography-spacing-vertical) 0;padding:var(--spacing);border-left:0.25rem solid var(--blockquote-border-color)}blockquote footer{margin-top:calc(var(--typography-spacing-vertical) / 2);color:var(--blockquote-footer-color)}abbr[title]{border-bottom:1px dotted;text-decoration:none;cursor:help}ins{color:var(--ins-color);text-decoration:none}del{color:var(--del-color)}::selection{background-color:var(--primary-focus)}audio,canvas,iframe,img,svg,video{vertical-align:middle}audio,video{display:inline-block}audio:not([controls]){display:none;height:0}iframe{border-style:none}img{max-width:100%;height:auto;border-style:none}svg:not([fill]){fill:currentColor}svg:not(:root){overflow:hidden}button{margin:0;overflow:visible;font-family:inherit;text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{padding:0;border-style:none}button{display:block;width:100%;margin-bottom:var(--spacing)}a[role=button]{display:inline-block;text-decoration:none}a[role=button],button,input[type=button],input[type=reset],input[type=submit]{--background-color:var(--primary);--border-color:var(--primary);--color:var(--primary-inverse);--box-shadow:var(--button-box-shadow,0 0 0 rgba(0,0,0,0));padding:var(--form-element-spacing-vertical) var(--form-element-spacing-horizontal);border:var(--border-width) solid var(--border-color);border-radius:var(--border-radius);outline:none;background-color:var(--background-color);box-shadow:var(--box-shadow);color:var(--color);font-size:1rem;font-weight:var(--font-weight);line-height:var(--line-height);text-align:center;cursor:pointer;transition:background-color var(--transition),border-color var(--transition),color var(--transition),box-shadow var(--transition)}a[role=button]:active,a[role=button]:focus,a[role=button]:hover,button:active,button:focus,button:hover,input[type=button]:active,input[type=button]:focus,input[type=button]:hover,input[type=reset]:active,input[type=reset]:focus,input[type=reset]:hover,input[type=submit]:active,input[type=submit]:focus,input[type=submit]:hover{--background-color:var(--primary-hover);--border-color:var(--primary-hover);--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0))}a[role=button]:focus,button:focus,input[type=button]:focus,input[type=reset]:focus,input[type=submit]:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--primary-focus)}input[type=reset]{--background-color:var(--secondary);--border-color:var(--secondary);--color:var(--secondary-inverse);cursor:pointer}input[type=reset]:active,input[type=reset]:focus,input[type=reset]:hover{--background-color:var(--secondary-hover);--border-color:var(--secondary-hover)}input[type=reset]:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--secondary-focus)}a[role=button].secondary,button.secondary,input[type=button].secondary,input[type=reset].secondary,input[type=submit].secondary{--background-color:var(--secondary);--border-color:var(--secondary);--color:var(--secondary-inverse);cursor:pointer}a[role=button].secondary:active,a[role=button].secondary:focus,a[role=button].secondary:hover,button.secondary:active,button.secondary:focus,button.secondary:hover,input[type=button].secondary:active,input[type=button].secondary:focus,input[type=button].secondary:hover,input[type=reset].secondary:active,input[type=reset].secondary:focus,input[type=reset].secondary:hover,input[type=submit].secondary:active,input[type=submit].secondary:focus,input[type=submit].secondary:hover{--background-color:var(--secondary-hover);--border-color:var(--secondary-hover)}a[role=button].secondary:focus,button.secondary:focus,input[type=button].secondary:focus,input[type=reset].secondary:focus,input[type=submit].secondary:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--secondary-focus)}a[role=button].contrast,button.contrast,input[type=button].contrast,input[type=reset].contrast,input[type=submit].contrast{--background-color:var(--contrast);--border-color:var(--contrast);--color:var(--contrast-inverse)}a[role=button].contrast:active,a[role=button].contrast:focus,a[role=button].contrast:hover,button.contrast:active,button.contrast:focus,button.contrast:hover,input[type=button].contrast:active,input[type=button].contrast:focus,input[type=button].contrast:hover,input[type=reset].contrast:active,input[type=reset].contrast:focus,input[type=reset].contrast:hover,input[type=submit].contrast:active,input[type=submit].contrast:focus,input[type=submit].contrast:hover{--background-color:var(--contrast-hover);--border-color:var(--contrast-hover)}a[role=button].contrast:focus,button.contrast:focus,input[type=button].contrast:focus,input[type=reset].contrast:focus,input[type=submit].contrast:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--contrast-focus)}a[role=button].outline,button.outline,input[type=button].outline,input[type=reset].outline,input[type=submit].outline{--background-color:transparent;--color:var(--primary)}a[role=button].outline:active,a[role=button].outline:focus,a[role=button].outline:hover,button.outline:active,button.outline:focus,button.outline:hover,input[type=button].outline:active,input[type=button].outline:focus,input[type=button].outline:hover,input[type=reset].outline:active,input[type=reset].outline:focus,input[type=reset].outline:hover,input[type=submit].outline:active,input[type=submit].outline:focus,input[type=submit].outline:hover{--background-color:transparent;--color:var(--primary-hover)}a[role=button].outline.secondary,button.outline.secondary,input[type=button].outline.secondary,input[type=reset].outline.secondary,input[type=submit].outline.secondary{--color:var(--secondary)}a[role=button].outline.secondary:active,a[role=button].outline.secondary:focus,a[role=button].outline.secondary:hover,button.outline.secondary:active,button.outline.secondary:focus,button.outline.secondary:hover,input[type=button].outline.secondary:active,input[type=button].outline.secondary:focus,input[type=button].outline.secondary:hover,input[type=reset].outline.secondary:active,input[type=reset].outline.secondary:focus,input[type=reset].outline.secondary:hover,input[type=submit].outline.secondary:active,input[type=submit].outline.secondary:focus,input[type=submit].outline.secondary:hover{--color:var(--secondary-hover)}a[role=button].outline.contrast,button.outline.contrast,input[type=button].outline.contrast,input[type=reset].outline.contrast,input[type=submit].outline.contrast{--color:var(--contrast)}a[role=button].outline.contrast:active,a[role=button].outline.contrast:focus,a[role=button].outline.contrast:hover,button.outline.contrast:active,button.outline.contrast:focus,button.outline.contrast:hover,input[type=button].outline.contrast:active,input[type=button].outline.contrast:focus,input[type=button].outline.contrast:hover,input[type=reset].outline.contrast:active,input[type=reset].outline.contrast:focus,input[type=reset].outline.contrast:hover,input[type=submit].outline.contrast:active,input[type=submit].outline.contrast:focus,input[type=submit].outline.contrast:hover{--color:var(--contrast-hover)}a[role=button][disabled],button[disabled],input[type=button][disabled],input[type=reset][disabled],input[type=submit][disabled]{opacity:.5;pointer-events:none}input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:1rem;letter-spacing:inherit;line-height:var(--line-height)}input{overflow:visible}select{text-transform:none}legend{max-width:100%;padding:0;color:inherit;white-space:normal}textarea{overflow:auto}[type=checkbox],[type=radio]{padding:0}::-webkit-inner-spin-button,::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}::-moz-focus-inner{padding:0;border-style:none}:-moz-focusring{outline:none}:-moz-ui-invalid{box-shadow:none}::-ms-expand{display:none}[type=file],[type=range]{padding:0;border-width:0}input:not([type=checkbox]):not([type=radio]):not([type=range]){height:calc((1rem * var(--line-height)) + (var(--form-element-spacing-vertical) * 2) + (var(--border-width) * 2))}fieldset{margin:0;margin-bottom:var(--spacing);padding:0;border:0}fieldset legend,label{display:block;margin-bottom:calc(var(--spacing) / 4);vertical-align:middle}input:not([type=checkbox]):not([type=radio]),select,textarea{display:block;width:100%}input:not([type=checkbox]):not([type=radio]):not([type=range]):not([type=file]),select,textarea{-webkit-appearance:none;-moz-appearance:none;appearance:none;padding:var(--form-element-spacing-vertical) var(--form-element-spacing-horizontal);vertical-align:middle}input,select,textarea{--background-color:var(--form-element-background-color);--border-color:var(--form-element-border-color);--color:var(--form-element-color);--box-shadow:none;border:var(--border-width) solid var(--border-color);border-radius:var(--border-radius);outline:none;background-color:var(--background-color);box-shadow:var(--box-shadow);color:var(--color);font-weight:var(--font-weight);transition:background-color var(--transition),border-color var(--transition),color var(--transition),box-shadow var(--transition)}input:not([type=submit]):not([type=button]):not([type=reset]):not([type=checkbox]):not([type=radio]):not([readonly]):active,input:not([type=submit]):not([type=button]):not([type=reset]):not([type=checkbox]):not([type=radio]):not([readonly]):focus,select:active,select:focus,textarea:active,textarea:focus{--background-color:var(--form-element-active-background-color)}input:not([type=submit]):not([type=button]):not([type=reset]):not([role=switch]):not([readonly]):active,input:not([type=submit]):not([type=button]):not([type=reset]):not([role=switch]):not([readonly]):focus,select:active,select:focus,textarea:active,textarea:focus{--border-color:var(--form-element-active-border-color)}input:not([type=submit]):not([type=button]):not([type=reset]):not([type=range]):not([type=file]):not([readonly]):focus,select:focus,textarea:focus{--box-shadow:0 0 0 var(--outline-width) var(--form-element-focus-color)}input:not([type=submit]):not([type=button]):not([type=reset])[disabled],select[disabled],textarea[disabled]{--background-color:var(--form-element-disabled-background-color);--border-color:var(--form-element-disabled-border-color);opacity:var(--form-element-disabled-opacity)}input[aria-invalid],select[aria-invalid],textarea[aria-invalid]{padding-right:2rem;background-position:center right .75rem;background-repeat:no-repeat;background-size:1rem auto}input[aria-invalid=false],select[aria-invalid=false],textarea[aria-invalid=false]{--border-color:var(--form-element-valid-border-color);background-image:var(--icon-valid)}input[aria-invalid=false]:active,input[aria-invalid=false]:focus,select[aria-invalid=false]:active,select[aria-invalid=false]:focus,textarea[aria-invalid=false]:active,textarea[aria-invalid=false]:focus{--border-color:var(--form-element-valid-active-border-color)!important}input[aria-invalid=true],select[aria-invalid=true],textarea[aria-invalid=true]{--border-color:var(--form-element-invalid-border-color);background-image:var(--icon-invalid)}input[aria-invalid=true]:active,input[aria-invalid=true]:focus,select[aria-invalid=true]:active,select[aria-invalid=true]:focus,textarea[aria-invalid=true]:active,textarea[aria-invalid=true]:focus{--border-color:var(--form-element-invalid-active-border-color)!important}input::-webkit-input-placeholder,input::placeholder,select:invalid,textarea::-webkit-input-placeholder,textarea::placeholder{color:var(--form-element-placeholder-color);opacity:1}input:not([type=checkbox]):not([type=radio]),select,textarea{margin-bottom:var(--spacing)}select::-ms-expand{border:0;background-color:transparent}select:not([multiple]):not([size]){padding-right:calc(var(--form-element-spacing-horizontal) + 1.5rem);background-image:var(--icon-chevron);background-position:center right .75rem;background-repeat:no-repeat;background-size:1rem auto}input+small,select+small,textarea+small{display:block;width:100%;margin-top:calc(var(--spacing) * -0.75);margin-bottom:var(--spacing);color:var(--muted-color)}label>input,label>select,label>textarea{margin-top:calc(var(--spacing) / 4)}[type=checkbox],[type=radio]{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:inline-block;width:1.25em;height:1.25em;margin-top:-.125em;margin-right:.375em;border-width:var(--border-width);vertical-align:middle;cursor:pointer}[type=checkbox]::-ms-check,[type=radio]::-ms-check{display:none}[type=checkbox]:checked,[type=checkbox]:checked:active,[type=checkbox]:checked:focus,[type=radio]:checked,[type=radio]:checked:active,[type=radio]:checked:focus{--background-color:var(--primary);--border-color:var(--primary);background-image:var(--icon-checkbox);background-position:center;background-repeat:no-repeat;background-size:.75em auto}[type=checkbox]~label,[type=radio]~label{display:inline-block;margin-right:.375em;margin-bottom:0;cursor:pointer}[type=checkbox]:indeterminate{--background-color:var(--primary);--border-color:var(--primary);background-image:var(--icon-minus);background-position:center;background-repeat:no-repeat;background-size:.75em auto}[type=radio]{border-radius:50%}[type=radio]:checked,[type=radio]:checked:active,[type=radio]:checked:focus{--background-color:var(--primary-inverse);border-width:.35em;background-image:none}[type=checkbox][role=switch]{--background-color:var(--switch-background-color);--border-color:var(--switch-background-color);--color:var(--switch-color);width:2.25em;height:1.25em;border:var(--border-width) solid var(--border-color);border-radius:1.25em;background-color:var(--background-color);line-height:1.25em}[type=checkbox][role=switch]:focus{--background-color:var(--switch-background-color);--border-color:var(--switch-background-color)}[type=checkbox][role=switch]:checked{--background-color:var(--switch-checked-background-color);--border-color:var(--switch-checked-background-color)}[type=checkbox][role=switch]:before{display:block;width:calc(1.25em - (var(--border-width) * 2));height:100%;border-radius:50%;background-color:var(--color);content:'';transition:margin 0.1s ease-in-out}[type=checkbox][role=switch]:checked{background-image:none}[type=checkbox][role=switch]:checked:before{margin-right:0;margin-left:calc(1.125em - var(--border-width))}[type=color]::-webkit-color-swatch-wrapper{padding:0}[type=color]::-moz-focus-inner{padding:0}[type=color]::-webkit-color-swatch{border:none;border-radius:calc(var(--border-radius) / 2)}[type=color]::-moz-color-swatch{border:none;border-radius:calc(var(--border-radius) / 2)}[type=date],[type=datetime-local],[type=month],[type=time],[type=week]{background-image:var(--icon-date);background-position:center right .75rem;background-repeat:no-repeat;background-size:1rem auto}[type=date]::-webkit-calendar-picker-indicator,[type=datetime-local]::-webkit-calendar-picker-indicator,[type=month]::-webkit-calendar-picker-indicator,[type=time]::-webkit-calendar-picker-indicator,[type=week]::-webkit-calendar-picker-indicator{opacity:0}[type=time]{background-image:var(--icon-time)}[type=file]{--color:var(--muted-color);padding:calc(var(--form-element-spacing-vertical)/2) 0;border:none;border-radius:0;background:none}[type=file]::-webkit-file-upload-button{--background-color:var(--secondary);--border-color:var(--secondary);--color:var(--secondary-inverse);margin-right:calc(var(--spacing) / 2);padding:calc(var(--form-element-spacing-vertical) / 2) calc(var(--form-element-spacing-horizontal) / 2);border:var(--border-width) solid var(--border-color);border-radius:var(--border-radius);outline:none;background-color:var(--background-color);box-shadow:var(--box-shadow);color:var(--color);font-size:1rem;font-weight:var(--font-weight);line-height:var(--line-height);text-align:center;cursor:pointer;transition:background-color var(--transition),border-color var(--transition),color var(--transition),box-shadow var(--transition)}[type=file]:active,[type=file]:focus,[type=file]:hover{--color:var(--color);border:none;background:none}[type=file]:active::-webkit-file-upload-button,[type=file]:focus::-webkit-file-upload-button,[type=file]:hover::-webkit-file-upload-button{--background-color:var(--secondary-hover);--border-color:var(--secondary-hover)}[type=range]{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:block;width:100%;height:1.25rem;background:transparent}[type=range]::-webkit-slider-runnable-track{width:100%;height:0.25rem;border-radius:var(--border-radius);background-color:var(--range-border-color);transition:background-color var(--transition),box-shadow var(--transition)}[type=range]::-moz-range-track{width:100%;height:0.25rem;border-radius:var(--border-radius);background-color:var(--range-border-color);transition:background-color var(--transition),box-shadow var(--transition)}[type=range]::-ms-track{width:100%;height:0.25rem;border-radius:var(--border-radius);background-color:var(--range-border-color);transition:background-color var(--transition),box-shadow var(--transition)}[type=range]::-ms-fill-lower{background-color:var(--border-radius)}[type=range]::-webkit-slider-thumb{-webkit-appearance:none;width:1.25rem;height:1.25rem;margin-top:-0.5rem;border:2px solid var(--range-thumb-border-color);border-radius:50%;background-color:var(--range-thumb-color);cursor:pointer;transition:background-color var(--transition),transform var(--transition)}[type=range]::-moz-range-thumb{-webkit-appearance:none;width:1.25rem;height:1.25rem;margin-top:-0.5rem;border:2px solid var(--range-thumb-border-color);border-radius:50%;background-color:var(--range-thumb-color);cursor:pointer;transition:background-color var(--transition),transform var(--transition)}[type=range]::-ms-thumb{-webkit-appearance:none;width:1.25rem;height:1.25rem;margin-top:-0.5rem;border:2px solid var(--range-thumb-border-color);border-radius:50%;background-color:var(--range-thumb-color);cursor:pointer;transition:background-color var(--transition),transform var(--transition)}[type=range]:focus,[type=range]:hover{--range-border-color:var(--range-active-border-color);--range-thumb-color:var(--range-thumb-hover-color)}[type=range]:active{--range-thumb-color:var(--range-thumb-active-color)}[type=range]:active::-webkit-slider-thumb{transform:scale(1.25)}[type=range]:active::-moz-range-thumb{transform:scale(1.25)}[type=range]:active::-ms-thumb{transform:scale(1.25)}[type=search]{border-radius:5rem;padding-left:calc(var(--form-element-spacing-horizontal) + 1.75rem)!important;background-image:var(--icon-search);background-position:center left 1.125rem;background-repeat:no-repeat;background-size:1rem auto}[type=search]::-webkit-search-cancel-button{-webkit-appearance:none;display:none}table{width:100%;border-color:inherit;border-collapse:collapse;border-spacing:0;text-indent:0}td,th{padding:calc(var(--spacing) / 2) var(--spacing);border-bottom:var(--border-width) solid var(--table-border-color);color:var(--color);font-size:var(--font-size);font-weight:var(--font-weight);text-align:left}tr{background-color:var(--background-color)}table[role=grid] tbody tr:nth-child(odd){--background-color:var(--table-row-stripped-background-color)}code,kbd,pre,samp{font-family:var(--font-family);font-size:.875rem}pre{-ms-overflow-style:scrollbar;overflow:auto}code,kbd,pre{background:var(--code-background-color);color:var(--code-color);font-weight:var(--font-weight);line-height:initial}code,kbd{display:inline-block;padding:.375rem .5rem;border-radius:var(--border-radius)}pre{display:block;margin-bottom:var(--spacing);padding:var(--spacing);overflow-x:auto;background:var(--code-background-color)}pre>code{display:block;padding:0;background:transparent;font-size:14px;line-height:var(--line-height)}code b{color:var(--code-tag-color);font-weight:var(--font-weight)}code i{color:var(--code-property-color);font-style:normal}code u{color:var(--code-value-color);text-decoration:none}code em{color:var(--code-comment-color);font-style:normal}kbd{background-color:var(--code-kbd-background-color);color:var(--code-kbd-color);vertical-align:middle}hr{box-sizing:content-box;height:0;overflow:visible;border:none;border-top:1px solid var(--muted-border-color)}[hidden],template{display:none}dialog{display:block;position:absolute;right:0;left:0;width:-moz-fit-content;width:-webkit-fit-content;width:fit-content;height:-moz-fit-content;height:-webkit-fit-content;height:fit-content;margin:auto;padding:1em;border:solid;background-color:white;color:black}dialog:not([open]){display:none}canvas{display:inline-block}details{display:block;margin-bottom:var(--spacing);padding-bottom:calc(var(--spacing) / 2);border-bottom:var(--border-width) solid var(--accordion-border-color)}details summary{color:var(--accordion-close-summary-color);line-height:1rem;list-style-type:none;list-style-type:none;cursor:pointer;transition:color var(--transition)}details summary::-webkit-details-marker{display:none}details summary::marker{display:none}details summary::-moz-list-bullet{list-style-type:none}details summary:after{display:inline-block;width:1rem;height:1rem;float:right;transform:rotate(-90deg);background-image:var(--icon-chevron);background-position:center;background-repeat:no-repeat;background-size:1rem auto;content:'';transition:transform var(--transition)}details summary:focus{outline:none;color:var(--accordion-active-summary-color)}details summary~*{margin-top:calc(var(--spacing) / 2)}details summary~*~*{margin-top:0}details[open]>summary{margin-bottom:calc(var(--spacing) / 4)}details[open]>summary:not(:focus){color:var(--accordion-open-summary-color)}details[open]>summary:after{transform:rotate(0)}article{margin:var(--block-spacing-vertical) 0;padding:var(--block-spacing-vertical) var(--block-spacing-horizontal);overflow:hidden;border-radius:var(--border-radius);background:var(--card-background-color);box-shadow:var(--card-box-shadow)}article>footer,article>header,article>pre{margin-right:calc(var(--block-spacing-horizontal) * -1);margin-left:calc(var(--block-spacing-horizontal) * -1);padding:calc(var(--block-spacing-vertical) / 1.5) var(--block-spacing-horizontal);background-color:var(--card-sectionning-background-color)}article>header{margin-top:calc(var(--block-spacing-vertical) * -1);margin-bottom:var(--block-spacing-vertical);border-bottom:var(--border-width) solid var(--card-border-color)}article>footer,article>pre{margin-top:var(--block-spacing-vertical);margin-bottom:calc(var(--block-spacing-vertical) * -1);border-top:var(--border-width) solid var(--card-border-color)}nav,nav ul{display:flex}nav{justify-content:space-between}nav ol,nav ul{align-items:center;margin-bottom:0;padding:0;list-style:none}nav ol:first-of-type,nav ul:first-of-type{margin-left:calc(var(--spacing) * -0.5)}nav ol:last-of-type,nav ul:last-of-type{margin-right:calc(var(--spacing) * -0.5)}nav li{display:inline-block;margin:0;padding:var(--spacing) calc(var(--spacing) / 2)}nav li>*,nav li>input:not([type=checkbox]):not([type=radio]){margin-bottom:0}nav a{display:block;margin:calc(var(--spacing) * -1) calc(var(--spacing) * -0.5);padding:var(--spacing) calc(var(--spacing) / 2);border-radius:var(--border-radius);text-decoration:none}nav a:active,nav a:focus,nav a:hover{text-decoration:none}aside li,aside nav,aside ol,aside ul{display:block}aside li{padding:calc(var(--spacing) / 2)}aside li a{margin:calc(var(--spacing) * -0.5);padding:calc(var(--spacing) / 2)}progress{display:inline-block;vertical-align:baseline}progress{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:inline-block;width:100%;height:.5rem;margin-bottom:calc(var(--spacing) / 2);overflow:hidden;border:0;border-radius:var(--border-radius);background-color:var(--progress-background-color);color:var(--progress-color)}progress::-webkit-progress-bar{border-radius:var(--border-radius);background:transparent}progress[value]::-webkit-progress-value{background-color:var(--progress-color)}progress::-moz-progress-bar{background-color:var(--progress-color)}@media (prefers-reduced-motion:no-preference){progress:indeterminate{background:var(--progress-background-color) linear-gradient(to right,var(--progress-color) 30%,var(--progress-background-color) 30%) top left/150% 150% no-repeat;animation:progressIndeterminate 1s linear infinite}progress:indeterminate[value]::-webkit-progress-value{background-color:transparent}progress:indeterminate::-moz-progress-bar{background-color:transparent}}@keyframes progressIndeterminate{0%{background-position:200% 0}to{background-position:-200% 0}}[aria-busy=true]{cursor:progress}[aria-busy=true]:not(input):not(select):not(textarea):before{display:inline-block;width:1em;height:1em;border:0.1875em solid currentColor;border-radius:1em;border-right-color:transparent;vertical-align:text-bottom;vertical-align:-.125em;animation:spinner 0.75s linear infinite;content:'';opacity:var(--loading-spinner-opacity)}[aria-busy=true]:not(input):not(select):not(textarea):not(:empty):before{margin-right:calc(var(--spacing) / 2)}[aria-busy=true]:not(input):not(select):not(textarea):empty{text-align:center}a[aria-busy=true],button[aria-busy=true],input[type=button][aria-busy=true],input[type=reset][aria-busy=true],input[type=submit][aria-busy=true]{pointer-events:none}@keyframes spinner{to{transform:rotate(360deg)}}[data-tooltip]{position:relative}[data-tooltip]:not(a):not(button):not(input){border-bottom:1px dotted;text-decoration:none;cursor:help}[data-tooltip]:after,[data-tooltip]:before{display:block;z-index:99;position:absolute;bottom:100%;left:50%;padding:.25rem .5rem;overflow:hidden;transform:translate(-50%,-0.25rem);border-radius:var(--border-radius);background:var(--tooltip-background-color);color:var(--tooltip-color);font-size:.875rem;font-style:normal;font-weight:var(--font-weight);text-decoration:none;text-overflow:ellipsis;white-space:nowrap;content:attr(data-tooltip);opacity:0;pointer-events:none}[data-tooltip]:after{padding:0;transform:translate(-50%,0rem);border-top:.3rem solid;border-right:.3rem solid transparent;border-left:.3rem solid transparent;border-radius:0;background-color:transparent;color:var(--tooltip-background-color);content:''}[data-tooltip]:focus:after,[data-tooltip]:focus:before,[data-tooltip]:hover:after,[data-tooltip]:hover:before{opacity:1;animation-name:slide;animation-duration:.2s}[data-tooltip]:focus:after,[data-tooltip]:hover:after{animation-name:slideCaret}@keyframes slide{0%{transform:translate(-50%,0.75rem);opacity:0}to{transform:translate(-50%,-0.25rem);opacity:1}}@keyframes slideCaret{0%{opacity:0}50%{transform:translate(-50%,-0.25rem);opacity:0}to{transform:translate(-50%,0rem);opacity:1}}[aria-controls]{cursor:pointer}[aria-disabled=true],[disabled]{cursor:not-allowed}[aria-hidden=false][hidden]{display:initial}[aria-hidden=false][hidden]:not(:focus){clip:rect(0,0,0,0);position:absolute}[tabindex],a,area,button,input,label,select,summary,textarea{-ms-touch-action:manipulation}@media (prefers-reduced-motion:reduce){:not([aria-busy=true]),:not([aria-busy=true]):after,:not([aria-busy=true]):before{background-attachment:initial!important;animation-duration:1ms!important;animation-delay:-1ms!important;animation-iteration-count:1!important;scroll-behavior:auto!important;transition-delay:0s!important;transition-duration:0s!important}}
    </style>
    <style type="text/css">
      article div {
        font-size: 1.15em;
        line-height: 1.6em;
      }
    </style>
  </head>
  <body style="background-color: #f9fafb;">
    <main class="container">
      <nav>
        <ul>
          <li><a href="../index.html"> Topic list</a></li>
        </ul>
      </nav>
      <!-- <h1>Infomedia Articles Selection: 50 articles</h1> -->
      <h1>H_0_130 <kbd>H_0_130</kbd></h1>
      <h3>Words (top 25)</h3>
      <div style="margin:0px -12px">
        <span style="font-size:11.32pt; padding:0px 12px"><strong>uniform</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>militret</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>drbe</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>defense</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>militr</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>krig</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>soldater</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>vben</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fly</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>flyve</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>autonome</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>vbenkaplb</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>flyvende</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>krudtet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>airbus</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>droneteknologi</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>droner</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>autonom</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>selvflyvende</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dronen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>affyre</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>missil</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>civile</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>tirig</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>blstempler</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>pawel</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>blodig</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>piloter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>diis</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>laws</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>forbud</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>forsvarsminister</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>flde</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>army</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>afghanistan</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>vingerne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>magtanvendelse</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>krigsmaskiner</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>drberrobotterne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>slagmarken</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>krigsfrelse</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>landminer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>killer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sheffield</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>pentagon</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ubemandet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>noel</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>gary</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fn</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>forprogrammeret</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>operere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>flight</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>atomvben</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>defence</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>afsides</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>landjorden</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>militre</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>militrt</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>soldaterne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>radioaktivitet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>stormagterne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>forsvar</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>mangerigt</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>bevbnede</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>jr.</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>darpa</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>robotudvikling</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>autonomt</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>afsmeltning</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>libyske</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>flyets</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>piloterne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>flyvningen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>pilotens</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ddbringende</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>affyres</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>reef</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>armeret</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>krudt</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>shinzo</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>missiler</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>flden</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>civil</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fjendens</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>vbensystemer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>drberrobotter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fjendtlige</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>vbentyper</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>baltiske</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>f-16</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>pilot</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>piloten</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>lockheed</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>combat</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>vbensystem</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>navy</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>bevbnet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fjender</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>missioner</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>luftrummet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>bomber</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>militrs</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>luftangreb</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>hackes</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>natos</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>aserbajdsjan</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>wales</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>meters</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>galde</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>operatr</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fjenden</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kvadratkilometer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>overvlde</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ubde</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>aspen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>forsvarsministerium</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>hangarskibe</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>bemandede</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>eisenhower</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>vbnede</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>committee</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ubemandede</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>pentagons</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>resolut</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>genve</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>pansrede</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>krigszoner</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sprkkerne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sydkoreansk</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>formation</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>modificeres</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>drone</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sydkoreanske</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>selvtnkende</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>diktatorer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>noam</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>aegis</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>flyproducent</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>passagerfly</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>droneangreb</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>pandoras</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>stillehavet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>jage</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>isenkram</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>autonomi</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>forsvarskommandoen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>flytrafikken</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>associeres</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>cummings</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kampfly</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>jagerpilot</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>luftvben</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>f-35</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>udviklingsprogram</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ddelig</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>nabolag</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ske</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>drberrobot</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>soldat</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>krigsrobotter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>militrmagter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>vbnene</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>krigens</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>massedelggelsesvben</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>toby</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>walsh</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>humanitr</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>folkeret</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kampdroner</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>brevet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>svrme</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ai-vben</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>rdsler</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>stealth</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>forsvarsakademiet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>robots-</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>drber-robotter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>rens</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>invaderer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>menneskehnd</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sydkoreas</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>aftrkkeren</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>despoter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fuglene</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>miner</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dji</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ehang</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>jedi</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>jagerfly</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>hangarskib</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>forsvarsforliget</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>exo-skeletter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>flokke</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>svrmen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>svrm</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>drb</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>vista</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>nedkmpe</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>tanks</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>grshopper</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>tyrkisk</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>affyret</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>chomsky</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kunstgdning</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>russel</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>works</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>direktiv</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>iben</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>videnskabsteori</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>campaign</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dronerne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>helikopter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>protestbrev</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>topniveau</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>underskrivere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fn-rapport</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>selvstyrende</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>drbes</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>khalifa</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>balkan</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>rekognoscering</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>krigene</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>forsvarssystemer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>gennemtnke</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>luftforsvar</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>wallace</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>summende</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>laugesen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>droneteknologien</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>stormagternes</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>styrtdykker</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>erklringen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>drbermaskiner</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fjernstyres</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sea</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>forvolde</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>admiral</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>forsvarsministeriet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sfolk</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>helikoptere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>vbenindustrien</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>jackie</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>bae</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ddeligt</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>krigsskibe</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>havbunden</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>civilt</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>weapons</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kamprobotter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>medunderskrivere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>militrmagt</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>opskaleret</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kaist</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>vbenproducent</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>hanwha</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>schaub</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kampvogne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>laservben</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>hin-yan</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>affyring</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>lethal</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>robotik</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>krigsteknologi</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>warfare</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dronens</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dronernes</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>lokaliteter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fjernstyrede</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>egenhndigt</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fredelige</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>talepapir</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>konventionen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>beslutningskden</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>semi-autonome</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>schmitt</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>mger</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>luftfart</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>springende</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>phalanx</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>nedskyde</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>weapon</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>willum</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>forsvarsministeriums</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ciws</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>skibets</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ballistiske</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>vestskov</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>robotvben</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>boykotten</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>traktat</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>bestand</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>lorenz</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dronevirksomheden</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>biologerne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sikkerhedsteknologi</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>nogles</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>command</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>oberst</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>rumforskning</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>underskriverne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sharkey</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>svrmene</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>uskadeliggre</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>formere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>aviation</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>affyrede</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ledningerne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>korrosion</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>emad</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ebeid</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dronecenter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ledningen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>hjspndingsledninger</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>luftledninger</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>hca</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>airport</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kablerne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>omsonst</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>propeller</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fjernbetjente</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>unmanned</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>reaper</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kampflyet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ucav'er</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ringsmose</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>aboulafia</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>teal</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dronepiloter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>flyvevben</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>manvredygtighed</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>forsvars</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>vehicles</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>udtnker</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>gaarn</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>skrinlagt</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>maskingevr</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>soldaten</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>faldskrm</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>svve</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>luftrum</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>overvgnings-og</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>radarsystemer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>testomrde</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fodboldbane</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>uas</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>synsvidde</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>skakspil</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>defekter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>trafik-</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>haahr</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>tllinger</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>hunter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>northrop</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>grumman</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dronesvrme</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>3.100</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>tilintetgre</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>missilerne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>karlsson</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>eagle</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>randy</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>smitsomme</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>basen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>bombet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>google-ansatte</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>strandene</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>affyrer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>hiroshima</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>luftfarten</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>landinger</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>vadehavet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>militrteknologi</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>landing</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>missilet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>flyves</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>agenturer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>krigsfrsel</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>udkmpe</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>elefanterne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>autonomien</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>trafikstyrelsen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>forskerkredse</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>miljproblemer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>arms</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sstjerner</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>indkommende</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>cour-harbo</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>trykluft</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>scharre</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>gletsjeren</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>svrnet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>rogers</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>mellemstlig</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>folkeretten</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>boeings</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>koralrevet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>inspektionen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>google-medarbejdere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>hornet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kampvognen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>tordenvejr</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>eurofighter</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sjettegenerations</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>danadynamics</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>thwaites-gletsjeren</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>tornekroner</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>dunbabin</strong>&nbsp;<span style="font-size:.5em">1</span></span>
      </div>
      <br><br>
      <h3>Articles (top 50)</h3>
      Query:
      <pre>SELECT * FROM articles WHERE articles.dupeKeep=1 AND articles.sizeKeep=1 ORDER BY H_0_130 DESC LIMIT 50</pre>
      <article>
        <h4>Bliver kunstig intelligens et massedelggelsesvben?</h4>
        <div>
          I 2016 lykkedes det for frste gang en AI-computer at nedkmpe en menneskelig kampflypilot i simulatorvelser i det amerikanske luftvbens centrale forskningslaboratorium i Ohio. Illustration: University of CincinnatiForskere advarer om, at kamprobotter med kunstig intelligens vil opskalere krig til i et hidtil uset omfang. Men det er forkert at kategorisere autonome vben som massedelggelsesvben, siger forfatteren til den frste danske rapport om fnomenet.Det sprgsml, vi m stille os selv, lyder: Hvilke skridt kan vi tage for at forhindre en militr konkurrence, hvis udfald bliver katastrofalt for alle parter? Sdan ld advarslen mod en frygtindgydende ny vbenteknologi i et historisk manifest, hvis medunderskrivere omfattede nogle af de mest anerkendte forskere inden for udviklingen af selv samme teknologi. Dengang, i juli 1955, handlede advarslen om atombomben i et manifest fra 11 videnskabsmnd anfrt af Bertrand Russell og Albert Einstein.Seks rtier senere lyder advarslen mod en ny vbenteknologi under hastig udvikling ikke meget anderledes.Det afgrende sprgsml for menneskeheden er i dag, hvorvidt man skal indlede eller forhindre et globalt AI-vbenkaplb. Hvis en given stor militrmagt skubber p udviklingen af vben med kunstig intelligens, er et globalt vbenkaplb stort set uundgeligt. Advarslen mod mod at anvende kunstig intelligens til militre forml er formuleret i et bent brev til FN fra 2015, hvis medunderskrivere nok engang omfatter forskere inden for selv samme teknologi. Nrmere bestemt 3.963 forskere inden for robotter og kunstig intelligens, foruden 22.396 medunderskrivere, der omfatter prominente navne som Stephen Hawking, Elon Musk, Apples Steve Wozniak og professor Noam Chomsky.Krig i et hidtil uset omfangOg sprger man en af specialisterne bag advarslen fra 2015, skal autonome vben ligesom atombomben kategoriseres som et massedelggelsesvben. Han hedder Toby Walsh og er professor i kunstig intelligens ved New South Wales University og formand for organisationen AI Access Foundation, som har til forml at udbrede forkningsresultater indenfor kunstig intelligens.Verdenssamfundet br betragte autonome vben som massedelggelsesvben og ikke mindst fje dem til listen over disse. For en enkelt programmr vil kunne forvolde skader, som tidligere krvede en hel hr. Krig bliver opskaleret i et hidtil uset omfang, fortalte Toby Walsh for f dage siden til Ingeniren i en artikel om regulering af autonome vben.Han er ogs en af de 50 forskere bag den boykot, der i sidste uge fik det sydkoreanske universitet KAIST til at opgive et samarbejde med den sydkoreanske vbenproducent Hanwha Systems om et laboratorium til udvikling af autonome vben optimeret med kunstig intelligens.Ikke massedelggelsesvbenSprger man derimod forfatteren til den frste danske videnskabelige rapport om autonome vben, rammer Toby Walshs og andre bekymrede fagfolks bestrbelser p at f kategoriseret autonome vben som massedelggelsesvben ved siden af.Problemet er, at disse systemer slet ikke er massedelggelsesvben, siger Gary Schaub, seniorforsker ved Center for Militre Studier p Kbenhavns Universitet. Han offentliggjorde i 2016 en rapport om behovet for retningslinjer for anvendelsen af autonome vben.Massedelggelsesvben er per definition ikke diskriminerende i deres delggelser. Det er den massedelggelse, der gr dem unikke. Autonome vben er ikke udiskriminerende. De autonome vben, der bliver udviklet i den nre fremtid, vil vre ligesom de konventionelle vben, der anvendes i dag - kampvogne, kampfly, missiler, fregatter og ubde - bare med en maskine som beslutningstager som aflser for et menneske, siger Gay Schaub.Han vurderer dog, ligsom en rkke andre forskere, som Ingeniren har talt med til de seneste dages artikler, at det er ndvendigt at opstille retningslinjer for, hvordan den menneskelige kontrol med autonome vbensystemer skal foreg.Nr der i FN foretages officielle diskussioner om mulige restriktioner p autonome vbensystemer, som det skete i Genve i sidste uge, sker det indtil videre med udgangspunkt i, at autonome vbensystemer ikke er massedelggelsesvben, nemlig med henblik p en mulig opdatering af FN's konvention om srlige konventionelle vben. Den har til forml at forbyde eller begrnse brugen af vben, som anses for at vre undigt skadevoldende eller for at ramme i flng, ssom landminer, lureminer, brandvben og blindende laservben, hvorimod listen af massedelggelsevben i dag kun omfatter kemiske, biologiske, radioaktive og nukleare vben.Er slet ikke vbenArbejdet med at opstille juridiske rammer for autonome vbensystemer bliver vanskeliggjort af, at selve vbendelen af systemerne nppe kommer til at adskille sig fra konventionelle vbentyper som missiler og projektiler.En forskningsartikel bragt i ICRC-s internationale forskningstidsskrift i 2012 konkluderede p den baggrund, at autonome vbensystemer end ikke er vben, men at de alene er kendetegnet ved en srlig anvendelse af konventionelle vben. Forfatteren til rapporten, Hin-Yan Liu, er i dag professor ved Juridisk Institut p Kbenhavns Universitet.Den afgrende forskel p autonome vbensystemer og andre vben er, at autonome vbensystemer ikke er vben. Vben er redskaber til at beg vold, som krver en operatr. Det problematiske ved autonome vbensystemer er derfor ikke selve vbnet, men den operatr, der betjener det. Det bliver benlyst, nr man tager i betragtning, at autonome vbensystemer med al sandsynlighed kommer til at benytte sig af eksisterende, konventionelle vbentyper, siger Hin-Yan Liu.Fuldt autonome vbensystemer, der selv udvlger og angriber deres ml, anvendes endnu ikke i nogen lande. I Danmark benytter Forsvaret i dag delvist autonome vben i form af skaldte fire and forget-missiler, som efter affyring selv kan finde frem til deres ml.Sidste uges diskussioner i FN bestod af det andet mde i en mellemstatslige ekspertgruppe med regeringsreprsentanter, som FN besluttede at oprette i 2016, og som skal diskutere bde de teknologiske, militre, juridiske og etiske implikationer ved at udvikle autonome vben. Den skaldte Group of Governmental Experts on Lethal Autonomous Weapons Systems fortstter diskussionerne ved sit nste mde i august i r.
        </div>
        <footer>
          <em>Ing.dk (Ingeniren)</em>
          &nbsp;&nbsp; 2018-04-17
          &nbsp;&nbsp; e6b5158a
          &nbsp;&nbsp; #0
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.983</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.546</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.583</kbd>
        </footer>
      </article>
      <article>
        <h4>Note</h4>
        <div>
          Stealth - det usynlige vben, Zulu 20.00: I en nr fremtid har den amerikanske flde udviklet et ubemandet jagerfly, der styres af en kunstig intelligens. Flyet bliver sendt til et hangarskib i Stillehavet for at lre kampteknik af piloterne om bord. Men da computeren begynder at flge sine egne ordrer, er det op til de tre elitepiloter at stoppe den, fr den indleder en atomkrig... 
        </div>
        <footer>
          <em>Ekstra Bladet</em>
          &nbsp;&nbsp; 2016-10-28
          &nbsp;&nbsp; e5f27eb8
          &nbsp;&nbsp; #1
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.94</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.941</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.577</kbd>
        </footer>
      </article>
      <article>
        <h4>Note</h4>
        <div>
          Stealth, TV 2 22.30: I en nr fremtid har flden udviklet et ubemandet jagerfly, styret af en kunstig intelligens. Flyet bliver sendt til Stillehavet, s piloterne om bord kan give flyet lektioner i kampteknik. Men da computeren begynder at flge sine egne ordrer, m de tre elitepiloter stoppe den.
        </div>
        <footer>
          <em>Ekstra Bladet</em>
          &nbsp;&nbsp; 2018-01-19
          &nbsp;&nbsp; e695427a
          &nbsp;&nbsp; #2
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.948</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.936</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.564</kbd>
        </footer>
      </article>
      <article>
        <h4>1.000 forskere efterlyser forbud mod intelligente drberrobotter</h4>
        <div>
          1.000 forskere i kunstig intelligens har skrevet under p et bent brev, der rder FN til at forbyde brug og udvikling af autonome vbensystemer. Udvikling af vben, der kan fungere uden menneskelig indblanding, kan sammenlignes med opfindelsen af atomvben, mener underskriverne, som blandt andet tller Stephen Hawking, Elon Musk og Googles researchchef Peter Norvig. Forskerne frygter, at autonome vben i sidste ende vil kunne bruges af terrorister eller af diktatorer til at undertrykke befolkningen.
        </div>
        <footer>
          <em>Ing.dk (Ingeniren)</em>
          &nbsp;&nbsp; 2015-07-29
          &nbsp;&nbsp; e5243077
          &nbsp;&nbsp; #3
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.965</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.618</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.53</kbd>
        </footer>
      </article>
      <article>
        <h4>Internationale forskere boykotter universitet af frygt for kaplb om drberrobotter</h4>
        <div>
          Flankeret af 50 kolleger forsger den internationalt anerkendte AI-ekspert Toby Walsh at stoppe universiteterne i at vre med til at accelere udviklingen af fuldt autonome vben. Illustration: Nanna SkytteOver 50 af klodens frende forskere inden for kunstig intelligens og robotudvikling skrinlgger alt samarbejde med sydkoreansk universitet, der samarbejder med vbenproducent.Af 4. apr 2018 kl. 16:02De drmmer om at bremse eller endnu bedre helt at stoppe kaplbet om udviklingen af fuldt automatiserede vben optimeret og drevet af kunstig intelligens.Et opsigtsvkkende skridt er nu taget i den kamp. Over 50 af klodens frende forskere indenfor kunstig intelligens(AI) og robotudvikling fra 30 forskellige lande tager i en flles udtalelse skarp afstand fra Sydkoreas topuniversitet, KAIST.Forskerne stopper alt samarbejde med universitet p ubestemt tid, fordi KAIST i samarbejde med den sydkoreanske vbenproducent Hanwha Systems har oprettet et laboratorium til udvikling af autonome vben optimeret med kunstig intelligens.Gruppen vil frst ophve boykottet, nr KAIST forsikrer, at laboratoriet vil afholde sig fra at udvikle vben, som kan fungere 100 procent autonomt. Der skal alts fortsat vre et menneske, som i et eller andet omfang kontrollerer de vben, som KAIST og Hanwha Systems udtnker, krver forskerne.Udviklingen indenfor AI og autonome vben gr i en potentiel farlig retning med dette her. Det er vores pligt at tage stilling og forsge at gre beslutningstagerne opmrksomme p konsekvenserne, siger en af de 50 medunderskrivere p boykotten, Thomas Bolander til Ingeniren.Han er ph.d. og lektor i logik og kunstig intelligens ved DTU Compute og pointerer, at der er mange ubekendte faktorer ved Hanwha Systems- universitets-laboratorium.I sydkoreansk presse har KAIST udlagt samarbejdet, som om der blot er tale om et AI-assisteret navigationssystem til Hanwha Systems- tanks eller missiler.Blstempler vben-kaplbUanset om det er tilfldet, betoner Thomas Bolander, at forskernes afstandtagen br ses i en strre kontekst.I udmeldingen, som er forfattet af en af verdens mest fremtrdende AI-forskere, professor Toby Walsh fra New South Wales University, fremhves risikoen for, at KAIST blstempler og stter turbo p kaplbet om udviklingen af autonome vben. Vel at mrke p et tidspunkt, hvor vi stadig kmper med at begribe potentialet ved AI.Hvis udviklet, vil autonome vben vre den tredje revolution inden for krigsfrelse. Krig vil blive sat i gang hurtigere og i en skala strre end nogensinde fr. Despoter og tyraner kan bruge disse vben mod uskyldige og fjerne alle former for etiske begrnsninger. Denne Pandoras ske vil vre svr at lukke, hvis den bnes, skriver de 50 forskere i fllesudmeldingen, hvor de opfordrer KAIST til at koncentrere deres AI-forskning om at fremme fredelige forml.Hanwha Systems er kendt herhjemme, idet selskabets artilleri-system K9 Thunder var en af kandidaterne, da det danske forsvar for r tilbage bnede op for en udbudsrunde om nyt artilleri.Internationalt set har Hanwha Systems vakt opsigt, idet selskabet producerer klyngebomber til trods for, at en FN-konvention forbyder fremstillingen og brugen af denne type vben.Sydkoreas signatur mangler p denne konvention, hvorfor der juridisk set ikke er noget at udstte p KAIST-s samarbejde med Hanwha Systems.
        </div>
        <footer>
          <em>Ing.dk (Ingeniren)</em>
          &nbsp;&nbsp; 2018-04-04
          &nbsp;&nbsp; e6b0dc39
          &nbsp;&nbsp; #4
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.964</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.564</kbd>
        </footer>
      </article>
      <article>
        <h4>Forskere boykotter universitet af frygt for kaplb om drberrobotter</h4>
        <div>
          De drmmer om at bremse eller endnu bedre helt stoppe kaplbet om udviklingen af fuldt automatiserede vben optimeret og drevet af kunstig intelligens.Et opsigtsvkkende skridt er nu taget i den kamp. 55 af klodens frende forskere inden for kunstig intelligens (AI) eller robotudvikling fra 30 lande tager i en flles udtalelse skarpt afstand fra Sydkoreas topuniversitet, KAIST.Forskerne stopper alt samarbejde med universitetet p ubestemt tid, fordi KAIST i samarbejde med den sydkoreanske vbenproducent Hanwha Systems har oprettet et laboratorium til udvikling af autonome vben med kunstig intelligens.Gruppen vil frst ophve boykotten, nr KAIST forsikrer, at laboratoriet ikke vil udvikle vben, som kan fungere 100 procent autonomt.Der skal alts fortsat vre et menneske, som i et eller andet omfang kontrollerer de vben, som KAIST og Hanwha Systems udtnker.Udviklingen inden for AI og autonome vben gr i en potentielt farlig retning med det her. Det er vores pligt at tage stilling og forsge at gre beslutningstagerne opmrksomme p konsekvenserne, siger en af de 55 underskrivere p boykotten, Thomas Bolander.Han er ph. d. og lektor i logik og kunstig intelligens ved DTU Compute og pointerer, at der er mange ubekendte faktorer ved Hanwha Systems' universitets-laboratorium.I sydkoreansk presse har KAIST udlagt samarbejdet, som om der blot er tale om et AI-assisteret navigationssystem til Hanwha Systems' tanks eller missiler. Uanset om det er tilfldet eller ej, betoner Thomas Bolander, at forskernes afstandtagen br ses i en strre kontekst.Blstempler vben-kaplbI udmeldingen, som er forfattet af en af verdens mest fremtrdende AI-forskere, professor Toby Walsh fra New South Wales University, fremhves risikoen for, at KAIST blstempler og stter turbo p kaplbet om udviklingen af autonome vben. Vel at mrke p et tidspunkt, hvor vi stadig kmper med at begribe potentialet ved AI.Hvis udviklet, vil autonome vben vre den tredje revolution inden for krigsfrelse. Krig vil blive sat i gang hurtigere og i en skala strre end nogensinde fr. Despoter og tyraner kan bruge disse vben mod uskyldige og fjerne alle former for etiske begrnsninger. Denne Pandoras ske vil vre svr at lukke, hvis den bnes, skriver de 55 forskere i fllesudmeldingen.Autonome vben er ikke forbudt af FN - i frste omgang af den grund, at FN's 123 medlemslande aldrig har drftet dem. Det sker dog p mandag efter tre rs pres fra Toby Walsh.Han plderer for, at AI til vben skal defineres som massedelggelsesvben i FN-systemet. Et forbud, som 22 FN-lande allerede sttter.Tidligere havde man brug for en hel hr for at fre krig. Du skulle overtale folk til at kmpe, uddanne dem, give dem mad, udstyr og ln. Det behver man ikke med AI, der gr det muligt at skalere krigsfrelse p en mde, som vi aldrig har set fr, sagde Toby Walsh sidste r i et interview med Ingeniren.Her betegnede han sig selv som vrende pessimistisk optimist. For ingen kan forudsige den teknologiske fremtid, der er produktet af AI.Vi forbd ikke kemi og vil heller ikke forbyde AI. Vi forbd brugen af kemiske vben, og jeg hber, vi kan forbyde brugen af AI-vben, understreger Toby Walsh.
        </div>
        <footer>
          <em>Ingeniren</em>
          &nbsp;&nbsp; 2018-04-06
          &nbsp;&nbsp; e6b17e79
          &nbsp;&nbsp; #5
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.993</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.565</kbd>
        </footer>
      </article>
      <article>
        <h4>Har de selvstyrende kamprobotter allerede vundet krigen?</h4>
        <div>
          I luftrummet over et amerikansk militrt testomrde, der ligner en mellemstlig by, svver en lille drone kaldet Bendner, imens dens regner p, hvilke personer nr en moske den skal sende hjem til deres skaber.Dronen med seks svirrende rotorer er en billig, nrmest kedelig en af slagsen. Ja, alts, hvis vi ser bort fra dronens software. Den bestr af det amerikanske militrs mest avancerede kunstige intelligens, som skal gre dronen i stand til p egen hnd at opsge, identificere og eliminere fjendtlige enheder.Da Pentagons hemmelighedsfulde udviklingsenhed Darpa sidste sommer demonstrerede en ubevbnet udgave af den autonome drone, havde Bendner sommetider svrt ved at skelne mellem trnet p moskeen og en bevbnet mand. Andre gange udpegede dronen iflge Darpa resolut de rigtige ml.Et andet sted p kloden, ved en storstilet russisk militrmesse sidste r, erklrede vbenproducenten Kalashnikov, at firmaets kunder inden for den nrmeste fremtid kan kbe en srlig serie af landbaserede kamprobotter. Med firmaets legendariske 69 r gamle stormgevrsteknik i hnden og p baggrund af neurale netvrk er robotterne i stand til egenhndigt at identificere ml, trffe beslutninger og trykke p aftrkkeren, lover Kalashnikov.Den tredje krigsrevolutionDette er blot to eksempler p noget af det nyeste militre isenkram, som offentligheden har fet indblik i. To eksempler, som mske ikke fremstr srligt frygtindgydende sammenlignet med moderne ballistiske missiler og hjenergilasere.Men nr de to eksempler fra USA og Rusland skiller sig ud, hnger det heller ikke sammen med, hvad der rent faktisk bliver affyret. Det handler om, hvem der bestemmer, hvornr der skal trykkes p aftrkkeren.I begge tilflde er den beslutning udlagt til en kunstig intelligens (AI): et softwareprogram, som efterligner et eller flere aspekter af den menneskelige intelligens ssom analyse, logik eller udvikling p baggrund af fejl.Kunstig intelligens er i dag s veludviklet, at AI-eksperterne over en bred kam mener, at vi nu befinder os i begyndelsen af den tredje revolution inden for krigsfrelse: Frst kom krudtet, dernst atombomben og nu et system, der midt i krigens tge formr at tnke og reagere mangefold hurtigere end menneskehjernen.Frste officielle mder i FN Inden for de seneste to uger har flere forskere og programmrer plderet for aldrig at gre krigsrobotter komplet autonome. Eller endnu bedre: at vi helt stter udviklingen af krigsteknologi med AI p pause.Blandt de bekymrede fagfolk er professor Toby Walsh fra New South Wales University, en af verdens mest fremtrdende AI-forskere og talsmand for 50 frende AI-forskere bag en boykot af det prominente sydkoreanske universitet KAIST.Universitetet har indget et samarbejde om AI med en sydkoreansk vbenproducent, der fremstiller klyngebomber, som FN's krigskonvention ellers har bandlyst brugen af.Vi br betragte autonome vben som massedelggelsesvben og ikke mindst fje dem til listen over disse. For en enkelt programmr vil kunne forvolde skader, som tidligere fordrede en helt hr.Krig bliver opskaleret i et hidtil uset omfang, siger Toby Walsh til Ingeniren.Han befinder sig i Genve, hvor FN i denne uge for frste gang har indkaldt medlemslandene til officielle diskussioner, der kan afgre de autonome vbens fremtid.F dage efter forskerboykotten af KAIST blev et..FORTSTTES P SIDE 4-5... protestbrev fra 3.100 Googleansatte lkket. De bnfalder itmastodontens verste chef, Sundar Pichai, om at skrotte projekt Maven: et samarbejde med Pentagon om at benytte Googles AI-mnstergenkendelse til at forbedre droners evne til at udpege trusler.Ikke i nrheden af definition Men et forbud mod autonome vben systemer p slagmarken krver, at FN's medlemslande rent faktisk kan blive enige om, hvad man gerne vil forbyde.Vi er ikke i nrheden af en defi-nition, som er tilstrkkeligt holdbar og afgrnset til at kunne danne grundlag for et juridisk forbud. Problemet er, at autonomi i modstning til eksempelvis miner, klyngebomber eller kemikalier ikke er en hndgribelig ting med bestemte fysiske egenskaber, siger Iben Yde, ph. d. i folkeret og juridisk rdgiver for Forsvars kommandoen. Hun skrev for to r siden sin afhandling ved Aarhus Universitet om regulering af autonome vben.Ugens mderkke i Genve udgr den forelbige kulmination p, at FN siden 2014 har afholdt multilaterale mder om autonome vben.Og man har alts siddet i fire r uden at komme i nrheden af en definition af autonome vben. I mandags startede det frste af to rlige mder om autonome vbensystemer i FN-regi og her er det tungeste punkt p dagsordenen stadigvk, at vi skal finde en solid og retvisende arbejdsdefinition, som alle parter kan enes om, siger Iben Yde.Alle de mest gngse definitioner af autonome vben tager udgangspunkt i det amerikanske forsvarsministeriums direktiv 3000.09 fra 2014. Her defineres et autonomt vben ved, at det efter aktivering ikke er underlagt menneskelig kontrol.Problemet med den definition er, at den dkker en lang rkke allerede anvendte miner, torpedoer og missiler, der selv kan angribe specifikke ml eller mltyper uden menneskelig indblanding. Derfor har det amerikanske forsvarsministerium undtaget en masse vbensystemer fra direktivet.S man famler sig frem og retter opmrksomheden mod vbensystemer, som ikke er underlagt menneskelig kontrol efter affyring, men det omfatter i princippet en rkke eksisterende vbentyper, der ikke betragtes som ulovlige, siger Iben Yde.Derfor vil man i FN f ufatteligt svrt ved at f alle stater til at enes om en definition. For der vil i alle tilflde vre lande, hvis vbensystemer bliver ramt af definitioner s brede som dem, der er p bordet lige nu. Og de vil sandsynligvis ikke g med til at begrnse deres rderum yderligere, siger Iben Yde.Vi fr aldrig alle medHos Center for Militre Studier p Kbenhavns Universitet vurderer seniorforsker Gary Schaub, at et internationalt forbud mod bevbnet AI aldrig kommer til at se dagens lys.Ikke alene vil verdens supermagter ikke tilslutte sig et forbud.Mange andre stater vil ogs se autonomi som en oplagt mulighed for at skyde genvej til et militrt topniveau, siger Gary Schaub.Han er forfatter til den frste danske rapport om autonome vben, som blev udgivet i 2016. Han vurderer ligesom Iben Yde, at selv en flles definition af autonome vben har lange udsigter.Isr fordi kapaciteten til at behandle og distribuere data gradvis ndrer det, der kan defineres som autonomt. Fra en enkelt enhed som en kampvogn eller en drone til et netvrk af enheder, der hver for sig ikke er autonome, men som i fllesskab kan blive det, siger Gary Schaub.Meningsfuld kontrolDerfor er man i FN nu ogs begyndt at kigge i retning af, hvordan man bedst muligt kan tjle kamprobotterne.Fagtermen er meningsfuld menneskelig kontrol, og den har inden for de seneste r vundet indpas i den akademiske debat om autonome vben.Frem for et forbud giver det mening at diskutere, hvordan vi kan indrette kontrollen med autonome systemer, s vi sikrer os, at vbnene bliver brugt inden for de regler, som vi allerede har i blandt andet Genvekonventionerne.Og nu ser det endelig ud til, at man begynder at kigge mere den vej i FN, siger Iben Yde.Et eksempel kunne vre en drone, som er forprogrammeret til at afsge et omrde og angribe eventuelle ml p egen hnd. En kapacitet, som str hjt p flere landes militre nskelister.Hvis dronen bare skal finde fjender, bliver det meget svrt. For det er svrt for et vbensystem at skelne mellem en kombattant og en civil. Man kan derimod stte dronen til specifikt at finde pansrede kretjer eller radarsystemer, som kan identificeres p baggrund af objektive kriterier ssom strrelse, vgt eller termisk profil, og som er lovlige ml iflge folkeretten, siger Iben Yde.S det er min vurdering, at den slags systemer bedst kan anvendes p meget stramt afgrnsede mltyper. Det kan godt gres uden menneskelig overvgning, men man bliver ndt til at have en mekanisme, s det autonome system beder om en menneskelig revurdering af opgaven, hvis mlet afviger fra, hvad det er programmeret til at ramme. For eksempel hvis der dukker civile op i mlomrdet, siger Iben Yde.En mske urealistisk opgave Samtlige tilhngere af et forbud mod autonome vben, som Ingeniren har talt med, medgiver, at de er p en mske urealistisk opgave.For professor ved Lancaster University Lucy Suchman, som forsker i designet af autonome vbensystemer og er medlem af International Committee for Robot Arms Control, er det imidlertid afgrende, at verdenssamfundet ikke accepterer et eskalerende AI-vbenkaplb.Hun peger p, at FN's medlemslande tidligere er blevet enige om et forbud mod landminer, kemiske vben og atomvben. Og selvom disse forbud bliver brudt og omget, har de alligevel en vigtig funktion.De har skabt en norm, der har begrnset brugen af disse vben.Det er altafgrende at gre det samme med AI-vben, siger hun.TRE EKSEMPLER P AUTONOME VBENAEGIS COMBAT SYSTEM Kampsystemet Aegis, som udgr it-rygraden i Natos ballistiske missilforsvar, kan selv identificere og nedskyde fjendtlige ballistiske missiler.Nr Aegis er koblet sammen med et Phalanx-nrforsvarssystem med maskinkanon, kan det ogs nedskyde fjendtlige fly. Den menneskelige operatr kan som udgangspunkt underkende systemets beslutning om at angribe, men Aegis kan ogs fungere i casualty mode, hvor det antager, at operatren er forhindret i at betjene systemet, og derfor selv trffer beslutning om at skyde.SGR-A1Sydkoreanske Samsungs intelligente vagttrn SGR-A1 bevogter i dag den demilitariserede zone mellem Nord-og Sydkorea. SGR-A1 kan selv identificere ml inden for 3,2 kilometer og kan enten reagere med en hj alarm, ikkedrbende gummikugler, et 5.56 x 45 maskingevr eller en granatkaster. Et lignende system i form af det israelske SentryTech er placeret langs grnsen til Gazastriben.SEA HUNTERSea Hunter fra Pentagons udviklingsenhed Darpa er udviklet til autonom ubdsjagt og elektronisk krigsfrelse.Det ubemandede skib scanner havet under sig, og finder den et ml, kan den selv udpege fjendens mest srbare punkter og indlede et angreb.Dog kan den ikke foretage angreb uden grnt lys fra et menneske. Sea Hunter har netop afsluttet et torigt testforlb og er principielt klar til operativ tjeneste.
        </div>
        <footer>
          <em>Ingeniren</em>
          &nbsp;&nbsp; 2018-04-13
          &nbsp;&nbsp; e6b379ee
          &nbsp;&nbsp; #6
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.965</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.618</kbd>
        </footer>
      </article>
      <article>
        <h4>Har de selvstyrende kamprobotter allerede vundet krigen?</h4>
        <div>
          Regulering af vben styret af kunstig intelligens kuldsejler, fordi teknologien i sig selv ikke er et vben. Imens fortstter det globale vbenkaplb, hvor autonome krigssystemer selv udvlger og eliminerer ml.I luftrummet over et amerikansk militrt testomrde, der ligner en mellemstlig by, svver en lille drone kaldet Bendner, imens den regner p, hvilke personer nr en moske den skal sende hjem til deres skaber.Dronen med seks svirrende rotorer er en billig, nrmest kedelig en af slagsen. Ja, alts, hvis vi ser bort fra dronens software. Den bestr af det amerikanske militrs mest avancerede kunstige intelligens, som skal gre dronen i stand til p egen hnd at opsge, identificere og eliminere fjendtlige enheder.Da Pentagons hemmelighedsfulde udviklingsenhed Darpa sidste sommer demonstrerede en ubevbnet udgave af den autonome drone, havde Bendner sommetider svrt ved at skelne mellem trnet p moskeen og en bevbnet mand. Andre gange udpegede dronen iflge Darpa resolut de rigtige ml.Et andet sted p kloden, ved en storstilet russisk militrmesse sidste r, erklrede vbenproducenten Kalashnikov, at firmaets kunder inden for den nrmeste fremtid kan kbe en srlig serie af landbaserede kamprobotter. Med firmaets legendariske 69 r gamle stormgevrsteknik i hnden og p baggrund af neurale netvrk er robotterne i stand til egenhndigt at identificere ml, trffe beslutninger og trykke p aftrkkeren, lover Kalashnikov.Den tredje krigsrevolutionDette er blot to eksempler p noget af det nyeste militre isenkram, som offentligheden har fet indblik i. To eksempler, som mske ikke fremstr srligt frygtindgydende sammenlignet med moderne ballistiske missiler og hjenergilasere.Men nr de to eksempler fra USA og Rusland skiller sig ud, hnger det heller ikke sammen med, hvad der rent faktisk bliver affyret. Det handler om, hvem der bestemmer, hvornr der skal trykkes p aftrkkeren.I begge tilflde er den beslutning udlagt til en kunstig intelligens (AI): et softwareprogram, som efterligner et eller flere aspekter af den menneskelige intelligens ssom analyse, logik eller udvikling p baggrund af fejl.Kunstig intelligens er i dag s veludviklet, at AI-eksperterne over en bred kam mener, at vi nu befinder os i begyndelsen af den tredje revolution inden for krigsfrelse: Frst kom krudtet, dernst atombomben og nu et system, der midt i krigens tge formr at tnke og reagere mangefold hurtigere end menneskehjernen.Frste officielle mder i FNInden for de seneste to uger har flere forskere og programmrer plderet for aldrig at gre krigsrobotter komplet autonome. Eller endnu bedre, at vi helt stter udviklingen af krigsteknologi med AI p pause.Blandt de bekymrede fagfolk er professor Toby Walsh fra New South Wales University, en af verdens mest fremtrdende AI-forskere og talsmand for 50 frende AI-forskere bag en boykot af det prominente sydkoreanske universitet KAIST.Universitetet har indget et samarbejde om AI med en sydkoreansk vbenproducent, der fremstiller klyngebomber, som FN-s krigskonvention ellers har bandlyst brugen af.Vi br betragte autonome vben som massedelggelsesvben og ikke mindst fje dem til listen over disse. For en enkelt programmr vil kunne forvolde skader, som tidligere fordrede en helt hr. Krig bliver opskaleret i et hidtil uset omfang, siger Toby Walsh til Ingeniren.Han befinder sig i Genve, hvor FN i denne uge for frste gang har indkaldt medlemslandene til officielle diskussioner, der kan afgre de autonome vbens fremtid.F dage efter forskerboykotten af KAIST blev et protestbrev fra 3.100 Google-ansatte lkket. De ansatte bnfalder it- mastodontens verste chef, Sundar Pichai, om at skrotte projekt Maven: et samarbejde med Pentagon om at benytte Googles AI-mnstergenkendelse til at forbedre droners evne til at udpege trusler.Ikke i nrheden af definitionMen et forbud mod autonome vbensystemer p slagmarken krver, at FN-s medlemslande rent faktisk kan blive enige om, hvad man gerne vil forbyde.Vi er ikke i nrheden af en definition, som er tilstrkkeligt holdbar og afgrnset til at kunne danne grundlag for et juridisk forbud. Problemet er, at autonomi i modstning til eksempelvis miner, klyngebomber eller kemikalier ikke er en hndgribelig ting med bestemte fysiske egenskaber, siger Iben Yde, ph.d. i folkeret og juridisk rdgiver for Forsvarskommandoen. Hun skrev for to r siden sin afhandling ved Aarhus Universitet om regulering af autonome vben.Ugens mderkke i Genve udgr den forelbige kulmination p, at FN siden 2014 har afholdt multilaterale mder om autonome vben.Og man har alts siddet i fire r uden at komme i nrheden af en definition af autonome vben. I mandags startede det frste af to rlige mder om autonome vbensystemer i FN-regi, og her er det tungeste punkt p dagsordenen stadigvk, at vi skal finde en solid og retvisende arbejdsdefinition, som alle parter kan enes om, siger Iben Yde.Alle de mest gngse definitioner af autonome vben tager udgangspunkt i det amerikanske forsvarsministeriums direktiv 3000.09 fra 2014. Her defineres et autonomt vben ved, at det efter aktivering ikke er underlagt menneskelig kontrol. Problemet med den definition er, at den dkker en lang rkke allerede anvendte miner, torpedoer og missiler, der selv kan angribe specifikke ml eller mltyper uden menneskelig indblanding. Derfor har det amerikanske forsvarsministerium undtaget en masse vbensystemer fra direktivet.S man famler sig frem og retter opmrksomheden mod vbensystemer, som ikke er underlagt menneskelig kontrol efter affyring, men det omfatter i princippet en rkke eksisterende vbentyper, der ikke betragtes som ulovlige, siger Iben Yde.Derfor vil man i FN f ufatteligt svrt ved at f alle stater til at enes om en definition. For der vil i alle tilflde vre lande, hvis vbensystemer bliver ramt af definitioner s brede som dem, der er p bordet lige nu. Og de vil sandsynligvis ikke g med til at begrnse deres rderum yderligere, siger Iben Yde.Vi fr aldrig alle medHos Center for Militre Studier p Kbenhavns Universitet vurderer seniorforsker Gary Schaub, at et internationalt forbud mod bevbnet AI aldrig kommer til at se dagens lys.Ikke alene vil verdens supermagter ikke tilslutte sig et forbud. Mange andre stater vil ogs se autonomi som en oplagt mulighed for at skyde genvej til et militrt topniveau, siger Gary Schaub.Han er forfatter til den frste danske rapport om autonome vben, som blev udgivet i 2016. Han vurderer ligesom Iben Yde, at selv en flles definition af autonome vben har lange udsigter.Isr fordi kapaciteten til at behandle og distribuere data gradvis ndrer det, der kan defineres som autonomt. Fra en enkelt enhed som en kampvogn eller en drone til et netvrk af enheder, der hver for sig ikke er autonome, men som i fllesskab kan blive det, siger Gary Schaub.Meningsfuld kontrolDerfor er man i FN nu ogs begyndt at kigge i retning af, hvordan man bedst muligt kan tjle kamprobotterne. Fagtermen er meningsfuld menneskelig kontrol, og den har inden for de seneste r vundet indpas i den akademiske debat om autonome vben.Frem for et forbud giver det mening at diskutere, hvordan vi kan indrette kontrollen med autonome systemer, s vi sikrer os, at vbnene bliver brugt inden for de regler, som vi allerede har i blandt andet Genvekonventionerne. Og nu ser det endelig ud til, at man begynder at kigge mere den vej i FN, siger Iben Yde.Et eksempel kunne vre en drone, som er forprogrammeret til at afsge et omrde og angribe eventuelle ml p egen hnd. En kapacitet, som str hjt p flere landes militre nskelister.Hvis dronen bare skal finde fjender, bliver det meget svrt. For det er svrt for et vbensystem at skelne mellem en kombattant og en civil. Man kan derimod stte dronen til specifikt at finde pansrede kretjer eller radarsystemer, som kan identificeres p baggrund af objektive kriterier ssom strrelse, vgt eller termisk profil, og som er lovlige ml iflge folkeretten, siger Iben Yde.S det er min vurdering, at den slags systemer bedst kan anvendes p meget stramt afgrnsede mltyper. Det kan godt gres uden menneskelig overvgning, men man bliver ndt til at have en mekanisme, s det autonome system beder om en menneskelig revurdering af opgaven, hvis mlet afviger fra, hvad det er programmeret til at ramme. For eksempel hvis der dukker civile op i mlomrdet, siger hun.
        </div>
        <footer>
          <em>Ing.dk (Ingeniren)</em>
          &nbsp;&nbsp; 2018-04-13
          &nbsp;&nbsp; e6b3c82f
          &nbsp;&nbsp; #7
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.909</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.618</kbd>
        </footer>
      </article>
      <article>
        <h4>TILHRER FREMTIDENS LUFTRUM KAMPFLY ELLER DRONER?</h4>
        <div>
          Alt imens valget af Danmarks nste kampfly nrmer sig, undergr markedet for militre droner en rivende udvikling, der bner mulighed for, at fjernbetjente droner inden lnge bliver tilstrkkeligt avancerede til at kunne erstatte bemandede kampfly.Antallet af militre droner p verdensplan er eksploderet efter terrorangrebene i New York og Washington i september 2001, og droner overtager stadigt flere traditionelle kampflyopgaver, herunder bevbnede operationer som luftsttte og luft-til-jord-angreb.Et kendt eksempel er Natos brug af luftmagt i Afghanistan, hvor fem procent af alle amerikanske og britiske luftangreb i 2011 blev udfrt af droner. Allerede i januar 2013 var andelen oppe p 23 procent, viser en rapport fra Forsvarsakademiet fra samme r.Og bestrbelserne p at udvikle kampdroner, der kan overtage traditionelle kampflyopgaver, fortstter med uformindsket styrke. Sidste r gennemfrte US Navy for frste gang operationer med en kombination af kampfly og den hangarskibsbaserede drone X-47B. Den er det nyeste medlem af den skaldte UCAV-klasse (Unmanned Combat Aerial Vehicle), som ogs omfatter kampdronerne i det amerikanske luftvbens Hunter-Killer-program, MQ-9 Reaper og MQ-1 Predator.Udviklingen har affdt diskussioner om de bemandede kampflys fremtid i USA, hvor Pentagon og Lockheed Martin i jeblikket udvikler femtegenerations kampflyet F-35. Ogs herhjemme, hvor forsvarsforligskredsen inden lnge skal vlge F-35, F/ A-18 eller Euro-fighter som aflseren for Flyvevbnets F-16, har politikere og debattrer rejst sprgsmlet om, hvorvidt Danmarks strste forsvarsinvestering til dato br g til bemandede fly, der risikerer at blive forldede inden for deres 30-rige levetid.Ingeniren har derfor spurgt fem af de frende specialister i militr luftfart i Danmark, USA, Canada og Storbritannien, om det er sandsynligt, at kampdroner bliver avancerede nok til at erstatte bemandede kampfly inden for levetiden af Danmarks nste kampfly.Mangler situationsoverblikSamtlige eksperter svarer, at kampfly ikke inden for de nste 15 til 20 r vil mde nogen seris konkurrence fra droner. Flertallet vurderer ogs, at bemandede kampfly stadig om 30 r vil vre overlegne p en rkke afgrende parametre.Den afgrende taktiske forskel mellem UCAV'er og kampfly er iflge de fleste eksperter det situationsoverblik, skaldt situational awareness, der flger med kampflypiloters udsyn p op til 360 grader samt informationer fra pilotens vrige sanser - kontra drone piloters begrnsede, kamerabaserede udsyn.Lektor ved Center for War Studies p Syddansk Universitet Jens Ringsmose, som str bag Forsvarsakademiets rapport om droner fra 2013, konkluderer ligefrem, at en drone aldrig vil kunne operere lige s effektivt som et bemandet kampfly - uanset antallet af sensorer og kvaliteten af satellitforbindelsen mellem operatr og drone.Der er nogle faktorer, der tilsiger, at droner aldrig vil kunne helt det samme som de konventionelle kampfly. Det er blandt andet situational awareness - det forhold, at man som pilot er til stede og har det fulde udsyn, siger han til Ingeniren.Samme melding lyder fra Richard Aboulafia, der er vicedirektr i analysevirksomheden Teal Group og rdgiver inden for militr luftfart.Han vurderer, at UCAV'er som X-47B har stort potentiale inden for konventionel krig, hvor mlene er let identificerbare, og operationerne handler om at nedkmpe alle fjendtlige stillinger hurtigst muligt.Men internationale operationer handler i dag mere om at hndhve flyveforbudszoner eller gennemfre afgrnsede angreb mod autoritre regimer, oprrsstyrker eller pirater. Her er situationsoverblik afgrende, og der er lange udsigter til, at sensorer og datalinks kan levere det forndne overblik for dronepiloter, siger han.Jeg tror derfor ikke p, at UCAV'er vil tage rollen som kampfly fra bemandede fly inden for de nste rtier, siger Richard Aboulafia til Ingeniren.Usikker besparelseEt hyppigt argument for at satse p droner er, at de udgr et billigere alternativ til bemandede kampfly, hvad angr bde anskaffelsespris, brndstofforbrug og pilotuddannelser.Der er gjort enkelte forsg p systematisk at sammenligne omkostninger for droner og bemandede kampfly, men sammenligningen er vanskelig, idet de ikke kan lse de samme typer af opgaver. Resultaterne er heller ikke entydige, men de indikerer, at dronerne generelt er en anelse billigere end kampfly. Det skal imidlertid holdes op imod, at kampfly kan udfre langt flere opgavetyper end droner, skriver Jens Ringsmose i Forsvarsakademiets dronerapport fra 2013.P den ene side viser erfaringerne fra Irak, Afghanistan og Libyen, at droner kan udfre kampflyopgaver som overvgning og rekognoscering billigere i omrder med lav lufttrussel. Men der vil g mange r, fr droner kan hndhve et magtmonopol i luften eller operere i omrder med mere end ' meget lav' eller ' ingen' trussel mod fly, konkluderer Jens Ringsmose. Derfor er indsttelsen af droner stadig afhngig af, at kampfly i forvejen har etableret luftherredmme i missionsomrdet.Kampfly er eksempelvis svrere bevbnet end UCAV'er, hvilket gr kampflyene i stand til at lse et bredere spektrum af opgaver. Iflge en opgrelse fra det amerikanske luftvben er Reaper-droner i stand til at bre maksimalt to af de laserstyrede bomber GBU-38 eller GBU-12 p hver 500 pund, svarende til 227 kilo, sammen med fire mindre AGM-114 Hellfire-missiler. Til sammenligning er F-16 i stand til at medbringe to 2.000-punds bomber sammen med to AIM-9 Side windermissiler og to AIM-120 AMRAAM-missiler.Oven i anskaffelsesprisen for UCAV'er kommer ogs hje omkostninger til logistik og bemanding. I 2011 konkluderede den amerikanske kongres' budgetkontor, at droner sammenfattende ikke har indfriet de hje forventninger til besparelser, selv om anskaffelsesprisen er lavere for droner end for kampfly. Det skyldes ikke mindst, at besparelsen bliver udlignet eller reduceret af hje udgifter til dronernes logistikog stttestruktur.Et eksempel er, at Natos drift af de store RQ-4 Global Hawks krver mindst 100 rsvrk per drone i fredstid, hvilket Jens Ringsmose sammenligner med, at det danske flyvevben opererer med 15 til 25 rsvrk per F-16 i fredstid.En rapport fra det britiske forsvarsministerium konkluderede ogs i 2011, at der ikke er udsigt til betydelige besparelser ved kampdroner, idet priserne p de strste UCAV'er vil vokse hurtigere end priserne p kampfly i de kommende r. Prisen p X-47B, som endnu er omkring 10 r fra produktionsfasen, er stadig ukendt, men den bliver iflge Jens Ringsmose sandsynligvis ikke meget lavere end prisen p et F-35, eftersom en kampdrone krver nogenlunde samme skrog, motorer, sensorer, pilot-interface og software som et kampfly. Derudover krver alle strre droner ekstraomkostninger i form af adgang til satellitkommunikation og beskyttet bndbredde. Dermed bortfalder det konomiske rationale bag UCAV'erne, konkluderer Jens Ringsmose.Ringe manvredygtighed og reaktionstidDronerne halter ogs stadig efter de bemandede kampfly, hvad angr fart og manvredygtighed. Det amerikanske forsvars MQ-9 Reaper prsterer en topfart p 440 km/ h og kan manvrere med en tyngdepvirkning p 2 g. F-16 prsterer til sammenligning 2.000 km/ h og trkker op til 9 g. Samtidig er eksisterende UCAV'er lette at opdage med selv mindre avancerede radarer. For en modstander med bare et minimum af antiluftskyts eller kampflykapacitet er UCAV'er derfor lette at nedkmpe, konkluderer Jens Ringsmose sammen med lektor Anders Henriksen fra Det Juridiske Fakultet ved Kbenhavns Universitet i en anden rapport om droner fra Dansk Institut for Internationale Studier fra 2013.Mange brancheanalytikere forventer imidlertid, at fremtidige droner vil kunne foretage manvrer, der ikke ville vre mulige med et menneske om bord. Af samme rsag vurderer Michael Byers, professor ved University of British Columbia og forfatter til en rkke bger om forsvarspolitik, som den eneste af de fem eksperter, Ingeniren har talt med, at droner vil overfldiggre bemandede kampfly inden for nste kampflygenerations levetid.Droneteknologi kan inden lnge gre kampfly til en forldet platform, eftersom menneskets evne til at modst g-krfter udgr den primre begrnsning p kampflys manvredygtighed. Udviklingens hastighed er naturligvis usikker, men ser vi p droneudviklingen de seneste 30 r, virker det sandsynligt, at de tilbagevrende teknologiske forhindringer kan overvindes inden for en tilsvarende periode, siger Michael Byers.UCAV'er har imidlertid et andet afgrende handicap: De bliver styret via satellitkommunikation. Det betyder, at de reagerer p kommandoer med mellem 1,2 og 2 sekunders forsinkelse. Samtidig gr datalinkforbindelsen jvnligt tabt. UCAV'er som Predator og Reaper slr automatisk ind p en forprogrammeret rute, nr forbindelsen afbrydes, hvilket ikke har store konsekvenser i Afghanistan, hvor Nato har det fulde luftherredmme, siger Jens Ringsmose. Men i mdet med kampfly eller missilforsvarssystemer overlever en drone ikke med en forsinket reaktionstid p et par sekunder eller ved at sl ind p en forprogrammeret kurs, hvis satellitforbindelsen ryger.Dronerne skal stadig styres via satellit, og det giver et timelapse p mindst 1,2 sekunder. Hvis en drone bliver involveret i en dogfight med et kampfly, er det derfor klart, at dronen er ilde stedt, siger han.Wingman for kampflySamme melding lyder fra Elizabeth Quintana, seniorforsker og direktr for Military Sciences Department ved den britiske forsvarstnketank Royal United Services Institute.Det er udelukket, at fjernbetjente fly vil erstatte kampfly i luft-til-luftkamp eller i afvisningsberedskab. UCAV'er er ikke tilstrkkeligt manvredygtige til at konkurrere med kampfly, og selv hvis de var, er over et sekunds forsinkelse mellem operatrinput og respons tilstrkkeligt lang tid til, at de bliver skudt ned, fr de kan n at reagere, siger hun.Det forhold kan ndre sig i takt med, at luftkampe p grund af get radar-og missilrkkevidde bevger sig vk fra de kendte dogfights.F-35 markedsfres eksempelvis som et kampfly, der kan lave skaldte over-the-horizon-angreb. Luftkampe over store afstande stiller imidlertid nye krav til UCAV'ernes datalink, siger George Petrolekas, forsker ved Canadian Global Affairs Institute, tidligere oberst og rdgiver for Nato angende ISAF-missionerne.Det er helt udelukket, at droner med forsinket reaktionstid kan vinde dogfights. Hvis luftkampe derimod foregr uden visuel kontakt, og dogfights bliver en mindre benyttet taktik, kan UCAV'er naturligvis godt bruges til at affyre missiler, hvis de har radarkapacitet til at lse p fjendtlige fly. Men det krver til gengld en enorm dataudveksling, idet vi stadig skal have et menneske til at trykke p aftrkkeren, srligt i omrder med mange civile, siger George Petrolekas.Forligskredsens valg af nyt kampfly skal senest vre p plads i forret 2016. Imens barsler US Navy med planer om at udvikle en ny hangarskibsbaseret UCAV p strrelse med et F-14 Tomcat, som skal vre i stand til at bre AMRAAM-missiler og dermed til at angribe kampfly. Eftersom de forndne sensorer og algoritmer til at udmanvrere kampflyene endnu er uden for rkkevidde, tiltnker US Navy dog kun den nye UCAV en rolle som wingman for bemandede kampfly.En X-47B-drone i luften over hangarskibet USS George H. W. Bush under en velse i Atlanterhavet. X-47B er et eksempel p den klasse af skaldte Unmanned Combat Aerial Vehicles (UCAV), som har frt til debat om fremtiden for bemandede kampfly.Jeg tror ikke p, at UCAV'er vil tage rollen som kampfly fra bemandede fly inden for de nste rtier.RICHARD ABOULAFIA, VICEDIREKTR, ANALYSEVIRKSOMHEDEN TEAL GROUP Ser vi p droneudviklingen de seneste 30 r, virker det sandsynligt, at de tilbagevrende teknologiske forhindringer kan overvindes inden for en tilsvarende periode.MICHAEL BYERS, PROFESSOR, UNIVERSITY OF BRITISH COLUMBIA.KAMPDRONERBedst egnet til konventionel krig med let identificerbare ml. Krver luftherredmme i missionsomrdet, etableret af kampfly.-Kamerabaseret, begrnset situationsoverblik. -Reagerer p ' pilotens' kommandoer med en forsinkelse p 1,2 til 2 sekunder grundet satellitlink.KAMPFLY Egnet til bl. a. hndhvelse af flyveforbudszoner, angreb mod autoritre regimer, oprrsstyrker eller pirater.+ 360 graders overblik fra pilotens syn og vrige sanser. + Piloten kan reagere uden forsinkelse. F-16 Topfart: 2.000 km/ h Tyngdepvirkning: op til 9 g Vben: to 2.000-punds bomber, to AIM-9 Sidewindermissiler og to AIM-120 AMRAAM-missiler. MQ-9 REAPER Topfart: 440 km/ h Tyngdepvirkning: hjst 2 g Vben: hjst to laserstyrede GBU-38-eller GBU-12-bomber p hver 500 pund, samt fire mindre AGM-114 Hellfiremissiler.
        </div>
        <footer>
          <em>Ingeniren</em>
          &nbsp;&nbsp; 2015-12-18
          &nbsp;&nbsp; e56b0c0a
          &nbsp;&nbsp; #8
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.736</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.618</kbd>
        </footer>
      </article>
      <article>
        <h4>Lapper sig selv sammen: S vanvittigt er fremtidens kampfly</h4>
        <div>
          Kampfly, der kan reparere sig selv i luften. 3D-printere om bord p flyene, der kan printe sm droner ud og kaste dem direkte ind i luftkamp mod fjendtlige fly. Det lyder mske som fjern fremtid, men det kan meget vel blive virkelighed om bare 15-20 r.Ledende forskere og opfindere i det amerikanske forsvars tophemmelige forskningsenhed Darpa er get i gang med at sl de frste streger til det, der skal blive USA-s nste avancerede kampfly omkring r 2030.Samtidig undersger flere af verdens strste vbenproducenter, hvad der kan opfindes af nye teknologier. For dem handler det om at vre frst med det vben eller den teknologi, som USA bare m have med p sine nye fly.For Darpa og det amerikanske forsvar arbejder ikke blot med at udvikle et sjette-generations fly   men hele to: F/A-XX Next Generation Air Dominance fighter til flden og F-X Next Generation Tactical Aircraft til flyvevbenet.Lukker lynhurtigt skudhullerBritiske Bae Systems har tnkt nogle af de vildeste tanker. De pusler med med iden om, at kampflyene reparerer sig selv og forestiller sig, at flyet er bygget af nanorr i kulfiber. Inde i rrene er en letvgtsvske, som siver ud og lynhurtigt lukker skudhuller.Teknologien skal gre det muligt for flyene at fortstte kampen, selv om de bliver ramt og flyskroget gennemhulles. Dermed bliver fremtidens kampfly i stand til at angribe fjender i situationer, hvor nutidens fly ikke har en chance.Den store amerikanske flyproducent har leveret flere bud p hvordan fremtidens kampfly til US Navy kunne se ud. (Foto: Boeing)Iden med 3D-printere om bord p flyene kommer ogs fra Bae Systems. De sm droner kan printes og spyttes ud af bunden af flyet, hvis det brnder p. S kan de hjlpe med at g til angreb p en srlig genstridig fjende. Hvis der er mange fjendtlige ml i bde luften og p jorden, skal dronerne kaste sig over hvert sit ml, mens piloten i flyet koncentrerer sig om luftkamp med andre fly. Bagefter kan dronerne enten selv-destruere eller returnere til basen og genbruges. Nu er de jo printet ...Et kobbel af dronerEksperterne regner ikke med, at droner fuldstndig skal overtage kampflyets opgaver. I hvert fald ikke i denne omgang. Men Darpa leger med tanken om et helt kobbel af droner, som styres af en operatr p jorden eller fra et bemandet fly.Dronerne skal overvge situationen og sende anbefalinger tilbage til operatren om, hvad der br gres. Han kan s vlge at flge dronernes anbefalinger, afvise dem eller bede dronerne indsamle flere informationer.Dronerne kan vre selvstndige enheder, som selv flyver eller styres ud i krigszonen. Men dronerne kan ogs vre en del af flyet, s flyet kan dele sig i tre dele, der flyver videre hver for sig. Det kan vre en drone, der bliver til tre. Det kan ogs vre et fly, der bliver til to droner og et bemandet fly.Det bemandede fly udfrer s en krvende bombemission eller lignende, mens dronerne afpatruljerer luftrummet og holder fjenderne p afstand. Nr turen gr hjemad, samles de tre enheder og flyver tilbage som en enhed.Kunstig intelligensDe Georg Gearls-typer, som er get i gang med at omstte de vilde fantasier til virkelighed, mener, at der ogs i den nste generation af kampfly skal vre plads til en pilot   hvis den konkrete mission krver det. Er det en srlig farlig mission, hvor der skal bombes langt inde i fjendeland, kan det mske vre bedre at sende flyet af sted ubemandet.Er der derimod udsigt til luftkamp med fjendtlige fly, eller er der tale om en srlig avanceret mission, kan man vlge at bemande flyet.I takt med at nye kampfly bliver mere og mere avancerede og kan flere og flere ting, tager arbejdsopgaverne opmrksomheden vk fra selve flyvningen. En computer-copilot er derfor ogs p nskesedlen til det nye kampfly. Med kunstig intelligens skal flyet vre i stand til -selv- at tage sig af den mere rutineprget flyvning.Computer-copiloten kan styre flyet i formation med ubemandede fly, der styres fra jorden.Strle af energiFremtidens kampfly fr nye vbentyper. En af dem kunne vre en koncentreret strle af energi, som sendes mod fjendtlige missiler og fly med lysets hastighed og med stor prcision. En anden mulighed kunne vre store, langtrkkende missiler.Dermed kan flyet bedre helt undg at komme inden for skudhold for fjenden. I bedste fald har det affyret sine missiler, inden fjenden overhovedet har opdaget flyet.Den store amerikanske flyproducent har leveret flere bud p hvordan fremtidens kampfly til US Navy kunne se ud. (Foto: Boeing)Missilerne vil dog krve mere plads i flyets bug og under vingerne. Flere eksperter forudser derfor, at fremtidens kampfly bliver strre end i dag. Mere i retning af et stort, strategisk bombefly end de sm og lette manvredygtige fly. Et strre fly vil have plads til en strre radar og strre brndstoftanke. Dermed kan flyet starte lngere vk fra kamppladsen uden at lufttanke.Uden halerorDe tre store amerikanske producenter af militrt isenkram, Boeing, Lockheed Martin og Northrop Grumman grubler ogs over, hvordan nste generations kampfly skal se ud.Northrop Grumman arbejder med tanken om et supersonisk kampfly uden det traditionelle haleror   en lsning man kender fra bombeflyet B-2.Boeing og Lockheed Martin har ogs sat deres tophemmelige srlige udviklingsafdelinger, Phantom Works og Skunkworks, i sving. Det er her, de frste streger til mange af bde historiens og nutidens kampfly er blevet slet.Isr Skunk Works har igen og igen leveret nye banebrydende flytyper. Det var her, man i 1960-erne udviklede CIA-s spion-fly SR-71 Blackbird, der den dag i dag har rekorden som verdens hurtigste fly med en hastighed p 3529,6 kilometer i timen.Hvis det bli'r ndvendigt...Det amerikanske flyvevben, US Air Force, og den amerikanske flde, US Navy, fr i disse r de helt nye F-35 Lightning II Joint Strike Fighter-kampfly, som verdens strste vbenproducent, Lockheed Martin, har udviklet.Det skaldte femte-generations kampfly skal de kommende r erstatte en stribe ldre fly i det amerikanske forsvar, men Darpa har allerede tidligere i r fet de frste millioner til at starte udviklingen af nye sjette-generations kampfly. Det skete, inden F-35 overhovedet har vret i krig og luftkamp.Et fly, der er vsentligt strre end de kampfly vi kender i dag. Det er buddet p fremtidens kampfly fra Lockheed Martin, der ogs str bag F-16 og F-35. (Foto: Lockheed Martin.)Men opfindelse og udvikling af nye kampfly tager mange r. Ikke mindst fordi de helst skal kunne holde sig p vingerne i 30 r eller mere. Flyene skal vre s avancerede som muligt, s USA kan klare sig mod de bedste og nyeste kinesiske kampfly   hvis det en dag bliver ndvendigt.
        </div>
        <footer>
          <em>EkstraBladet.dk/Ekstra</em>
          &nbsp;&nbsp; 2015-07-25
          &nbsp;&nbsp; e5232a50
          &nbsp;&nbsp; #9
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.891</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.744</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.661</kbd>
        </footer>
      </article>
      <article>
        <h4>Selvstyrende drberrobotter udlser global bekymring, protester og boykot</h4>
        <div>
          Google-ansatte protesterer mod krigsprojekt med det amerikanske forsvar, og forskere opfordrer til boykot af sydkoreansk universitet, der udvikler intelligente krigsmaskiner.En solbrillebrende og lderjakkekldt Arnold Schwarzenegger vandrer mlrettet gennem politistationens snvre gange, mens han sender byger af bly mod de sageslse betjente, der str mellem ham og hans ml: Sarah Connor. Ingen samvittighed, ingen mdehold, kun kold kalkule: Find, drb.Da -Terminator--filmen kom ud i 1984, var ideen om en drberrobot, som den T-800 Model 101 Arnold Schwarzenegger portrtterede, ren science fiction. Og selv om menneskemaskiner p to ben med moderigtige lderjakker og drberinstinkt formentlig stadig ligger langt ude i fremtiden, er der ikke lngere tvivl om, at drberrobotterne er p vej.USA, Kina, Rusland, Israel og England frer an i udviklingen af mere eller mindre selvstyrende krigsmaskiner. Droner, jagerfly, tanks og ubde med potentiale til at delgge og sl ihjel uafhngigt af deres menneskelige opfindere.Udviklingen vkker stor bekymring verden over, og derfor mdes mere end 80 lande og adskillige interesseorganisationer i denne uge i Genve til FN-s konference om konventionelle vben for at diskutere ddelige selvstyrende vben - de skaldte drberrobotter.Debatten om drberrobotter har taget fart de senere r. Forskere, eksperter og techikoner anfrt af prominente navne som Elon Musk og den nu afdde Stephen Hawking har flere gange offentligt efterspurgt et forbud mod at udvikle og bruge selvstyrende krigsrobotter.Senest opfordrede mere end 50 forskere i kunstig intelligens til boykot af det sydkoreanske universitet Kaist, fordi universitetet samarbejder med en sydkoreansk virksomhed om at udvikle vbensystemer med kunstig intelligens.Og i onsdags kunne avisen The New York Times prsentere et internt brev sendt af flere end 3.000 Google-ansatte til Googles verste chef, Sundar Pichai. I brevet tryglede de ansatte direktren om at annullere Googles aftale om at udvikle intelligente overvgnings- og mludvlgelsessystemer for det amerikanske forsvar.At skabe denne teknologi til at hjlpe den amerikanske regering med militr overvgning - med potentielt ddelige konsekvenser - er ikke acceptabelt , skrev de ansatte i brevet.Moral og sikkerhedEn af deltagerne ved FN-mdet i denne uge er roboteksperten Noel Sharkey. Ud over at vre professor emeritus i robotteknologi ved University of Sheffield har han som talsmand for kampagnen -Stop Killer Robots- i revis kmpet for et FN-forbud mod selvstyrende krigsrobotter.Vi bliver ndt til at f et internationalt forbud mod udviklingen og brugen af selvstyrende krigsrobotter, inden de bliver taget i brug , siger Noel Sharkey.Det er isr to ting, der bekymrer de kritikere, der kalder udviklingen af intelligente drbermaskiner for den tredje store vbenrevolution. Den frste var brugen af krudt, den anden opfindelsen af atomvben.
        </div>
        <footer>
          <em>Politiken.dk</em>
          &nbsp;&nbsp; 2018-04-09
          &nbsp;&nbsp; e6b243ca
          &nbsp;&nbsp; #10
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.713</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.514</kbd>
        </footer>
      </article>
      <article>
        <h4>Google-ansatte til chefen: Stop vben med kunstig intelligens</h4>
        <div>
          IT-gigantens verste chef Sundar Pichai bryder med selskabets motto, hvder over tretusinde Google-medarbejdere. Illustration: Maurizio PesceI et protestbrev bnfalder over 3.100 ansatte deres chef om at annullere en opgave for Pentagon om at udvikle en visuel overvgningsmaskine med AI beregnet til dronekrig.Af 6. apr 2018 kl. 10:37Kre Sundar, Vi mener ikke, at Google br vre indblandet i krigsindustrien. Derfor beder vi om, at Project Maven bliver aflyst, og at Google udfrdiger, offentliggr og hndhver en klar politik om, at hverken Google eller dets leverandrer nogensinde vil bygge krigsteknologi. Sdan lyder indledningen i et brev, der cirkulerer rundt hos Googles ansatte. Modtageren er it-mastodontens verste chef, Sundar Pichai.Kontroversen om projektet ved navn Maven glder en kontrakt for Pentagon vedrrende en skaldt -AI surveillance engine- beregnet til droner anvendt af USA-s forsvar.Kontrakten er fortrolig, s det konkrete indhold kender alts kun Google og Pentagon. Men ud fra brevet fremgr det, at der er tale om brugen af kunstig intelligens i et overvgningsprogram installeret i droner, s disse hurtigere kan overvge kretjer og andre objekter, flge deres bevgelser og rapportere tilbage til USA-s forsvarsministerium.Bde Diane Greene, som str i spidsen for Googles afdeling for cloud-infrastruktur, samt Sundar Pichai har nu internt og i offentligheden forsvaret arbejdet for Pentagon med afst i, at Project Maven grundlggende ikke er offensivt. Ydermere vil Google og Pentagon afst fra at udvikle autonome vbensystemer, der kan skyde uden en menneskelig operatr.Det argument er prellet af p de kritiske Google-medarbejdere, som har svrt ved at se kontrakten harmonere med selskabet motto om 'don-t be evil'.I en tid med voksende bekymringer over AI, som er fordomsfuld og bevbnet, kmper Google allerede med at opretholde offentlighedens tillid. Ved at indg denne kontrakt kommer vi i selskab med foretagender som Palantir, Raytheon og General Dynamics, lyder det i protestbrevet.Du kan lse hele protestbrevet fra de 3.100 Google-ansatte her i New York Times.Forskere protesterer ogsGoogle-protestbrevet s i vrigt dagens lys samme tidspunkt som et andet protestbrev om kampvben med kunstig intelligens. Det brev stammer fra over 50 af klodens frende forskere inden for kunstig intelligens (AI) og robotudvikling fra 30 forskellige lande.I en flles udtalelse tager de skarp afstand fra Sydkoreas topuniversitet, KAIST. Forskerne stopper alt samarbejde med universitet p ubestemt tid, fordi KAIST i samarbejde med den sydkoreanske vbenproducent Hanwha Systems har oprettet et laboratorium til udvikling af autonome vben optimeret med kunstig intelligens.Gruppen vil frst ophve boykotten, nr KAIST forsikrer, at laboratoriet vil afholde sig fra at udvikle vben, som kan fungere 100 procent autonomt. Der skal alts fortsat vre et menneske, som i et eller andet omfang kontrollerer de vben, som KAIST og Hanwha Systems udtnker, krver forskerne.Udviklingen inden for AI og autonome vben gr i en potentiel farlig retning med dette her. Det er vores pligt at tage stilling og forsge at gre beslutningstagerne opmrksomme p konsekvenserne, siger en af de 50 medunderskrivere p boykotten, Thomas Bolander, til Ingeniren.Han er ph.d. og lektor i logik og kunstig intelligens ved DTU Compute og pointerer, at der er mange ubekendte faktorer ved Hanwha Systems- universitets-laboratorium.I sydkoreansk presse har KAIST udlagt samarbejdet, som om der blot er tale om et AI-assisteret navigationssystem til Hanwha Systems- tanks eller missiler.Blstempler vben-kaplbUanset om det er tilfldet eller ej, betoner Thomas Bolander, at forskernes afstandtagen br ses i en strre kontekst.I udmeldingen, som er forfattet af en af verdens mest fremtrdende AI-forskere, professor Toby Walsh fra New South Wales University, fremhves risikoen for, at KAIST blstempler og stter turbo p kaplbet om udviklingen af autonome vben. Vel at mrke p et tidspunkt, hvor vi stadig kmper med at begribe potentialet ved AI.Hvis det bliver udvikler udviklet, vil autonome vben vre den tredje revolution inden for krigsfrelse. Krig vil blive sat i gang hurtigere og i strre skala end nogensinde fr. Despoter og tyranner kan bruge disse vben mod uskyldige og fjerne alle former for etiske begrnsninger. Denne Pandoras ske vil vre svr at lukke, hvis den bnes, skriver de 50 forskere i fllesudmeldingen, hvor de opfordrer KAIST til at koncentrere deres AI-forskning om at fremme fredelige forml.
        </div>
        <footer>
          <em>Ing.dk (Ingeniren)</em>
          &nbsp;&nbsp; 2018-04-06
          &nbsp;&nbsp; e6b18579
          &nbsp;&nbsp; #11
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.763</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.56</kbd>
        </footer>
      </article>
      <article>
        <h4>Dronen mod kampvognen. Hvem vinder fremtidens krige?</h4>
        <div>
          Det er blevet svrere at beskytte kampvogne og kanoner p jorden mod billige, men hjteknologiske droner. Selv sm stater har dem nu. Krigsfrelse skal tnkes p en ny mde, siger eksperter. Det ligner et computerspil, men er blodig alvor. En kampvogn str p jorden og bliver filmet fra en drone. S rammer missilet med kirurgisk prcision. Eksplosion, slrede billeder, udslettelse. Normalt har det vret stormagterne, der har sendt billederne af deres hjteknologiske militroperationer ud til verdensoffentligheden. Budskabet har vret klart og til skrk og advarsel: Se, hvad vi kan. Men dronen er ved at vre hvermandseje. Den er blevet s billig i drift og let at hndtere, at selv mindre og ret fattige stater nu rder over hightechdroner, som kan udslette ml p jorden. Seneste eksempel er de hrde kampe mellem Armenien og Aserbajdsjan om enklaven Nagorno-Karabakh, hvor der lige nu er en skrbelig vbenhvile. Begge parter har offentliggjort videoer, der hvdes at vise fjendtlige kampvogne, der bliver ramt af missiler, affyret fra droner. Man kan nok godt g ud fra, at ogs stormagterne har fulgt nje med i, hvordan krigen i Nagorno-Karabakh er blevet frt med bl.a. droner,  siger adjunkt Andreas Graae fra Institut for Militr Teknologi ved Forsvarsakademiet. Militre analytikere sprger i disse r sig selv, om dronerne er ved at tage livet af tunge, traditionelle vben p landjorden som kampvogne, pansrede mandskabsvogne og artilleri. Ogs i Nagorno-Karabakh har det vist sig, hvor svrt det er at forsvare sig mod droner. Det er en offentlig hemmelighed, at Tyrkiet har forsynet Aserbajdsjan med droner af typen Bayraktar TB2. Tyrkiet er i de senere r blevet en regulr dronestormagt. Hvis radarsystemer og luftforsvaret kan sttes ud af spillet, kan man ret nemt ramme kampvogne og andre pansrede kretjer med droner. De er simpelthen ikke konstrueret til at modst angreb oppefra, men mest fra siden,  forklarer Andreas Graae. Aserbajdsjan indsatte allerede i kampe mod Armenien i 2016 droner og har siden kbt stort ind, ogs i Israel. Det drejer sig bl.a. om en nyudviklet israelsk drone, der kan bruges som sit eget missil, en slags kamikazedrone, der flyver sig selv ind i sit ml. Som fugleflokke eller bisvrme kan man sende s mange droner ind, som ovenikbet kan operere autonomt, at det alene i kraft af antallet kan vre svrt at forsvare sig p landjorden. Andreas Graae, adjunkt, Forsvarsakademiet Denne type drone blev formentlig ogs brugt i det storstilede angreb, som den ellers ludfattige Houthi-milits i Yemen sidste r rettede mod to olieraffinaderier i Saudi-Arabien. Her blev det tydeligt, at dronen ogs er blevet den fattige mands krydsermissil. Major Karsten Marrup, Forsvarsakademiet, peger p, at indsttelsen af droner har frt til, at luftrummet over de pansrede styrker p landjorden ikke lngere er sikret, og at de dermed er blevet mere srbare. Med kamikazedroner - fjernstyrede bomber - er det ikke lngere nok at sl modstanderens luftstyrker ud. Truslen om luftangreb kommer nu flere steder fra. Behovet for luftforsvar har dermed ndret sig. Teknologien og systemerne til forsvar mod droner er i hastig udvikling, men de skal ogs implementeres i vores mde at operere p, inden vi igen kan sige, at vi er nogenlunde sikre,  siger Karsten Marrup, der dermed understreger, at hele den klassiske mde at fre krig p er under forandring. Svrme af droner Det er svrt at gardere sig mod droner. Isr nr de afsendes i store mngder i en skaldt svrmstrategi. Som fugleflokke eller bisvrme kan man sende s mange droner ind, som ovenikbet kan operere autonomt, at det alene i kraft af antallet kan vre svrt at forsvare sig p landjorden. Det vil helt klart stille krav om ndringer i den klassiske krigsfrelse,  siger adjunkt Andreas Graae. Lige nu forskes der p livet ls i forsvar mod droner. Det handler om elektronisk forsvar af alle slags: laservben, elektromagnetisk strling, mikroblger, jamming, hacking. Droner som vben I mange lande forskes der i kunstig intelligens i militrt jemed. Udvikling af droner indgr, men dronerne opererer endnu ikke helt autonomt. De programmeres eller styres af et menneske. USA satte sin frste drone op i midten af 1990'erne over Balkan under krigen i Bosnien. I mange r blev de kun brugt til rekognoscering. Under prsident Barack Obama blev droner bevbnet med missiler taget massivt i anvendelse. Den amerikanske Reaper-drone har et vingefang som en airbus . Men den findes i alle strrelser. I krigene i Afghanistan og Irak blev der sat droner ind i masser af aktioner mod terrorledere. Dronernes teknologi er blevet lbende forbedret. Oprindelig var de meget store og tunge. Nu er de blevet mindre og mere mobile. De er hjeffektive, udstyret med prcisionstyrede, mlsgende missiler, men stadig meget billige, forklarer Andreas Graae. De kan vende tilbage til basen, tanke op igen og holde sig p vingerne, s lnge det nskes. Ingen pilot bliver trt og skal udskiftes. Og s indgr dronens optagelser af fjendens delagte vben i den lbende propagandakrig. Sdan har det ogs netop vret i Nagorno-Karabakh. Det sender et signal bde til fjenden og til hjemmefronten. Kampvogne skal beskyttes Kampvognen som vben gr dog stadig blandt de fleste militrfolk for at vre et uhyre slagkraftigt og fleksibelt vben, der ikke gr af mode i overmorgen. Men den skal bruges p en anden mde, efter at dronen har revolutioneret noget af krigsfrelsen. Der er ingen tvivl om, at taktikken for brug af kampvogne m udvikles, hvis de skal overleve i det lange lb. Elektronisk jamming af radar- og dronesignaler og dermed gre fjenden blind er n mde. Desuden skal kampvognen beskyttes med bedre luftforsvar,  siger en militr analytiker til nyhedsbureauet Al Jazeera. De tider er forbi, da Sovjetunionen under Den Kolde Krig havde 40.000 kampvogne klar til at rulle hen over Vesteuropa. Heller ikke historiens strste kampvognslag ved Kursk i august 1943 mellem Nazityskland og Den Rde Hr med 8.000 kampvogne vil formentlig nogensinde gentage sig. I bde USA og Storbritannien pgr lige nu intense debatter i militre kredse om at satse mindre p kampvogne og andre tunge, pansrede vbentyper og mere p hightechvben. Holland har nsten helt opgivet sine kampvogne. Det amerikanske marinekorps har oplyst, at det vil skre sin faste bestand af kampvogne ned og satse mere p get fleksibilitet og lettere vben til at udkmpe fremtidens hjteknologiske krige. Farvel til kampvognen I en rapport, offentliggjort i august, bestilt af marinekorpset selv, flder de militre eksperter en hrd dom over kampvognen. Der er tilstrkkeligt med dokumentation for, at kampvognen trods sin lange og hderkronede historie i mange krige operationelt ikke lngere matcher de trusler, som vi (i marinekorpset) fremover vil blive udsat for,  sagde korpsets chef, David Berger, ved fremlggelsen af rapporten. Det er ikke det samme, som at marinekorpset vil afskrive kampvognen helt. Men den vil blive nedprioriteret, tilfjede han. Ogs USA's almindelige hr vil stadig bruge kampvogne. I Mellemsten har kampvogne og pansrede kretjer haft svrt ved at st distancen over for prcisionsangreb og mngden af droner og diverse overvgningssystemer p slagmarken,  skrev det amerikanske forsvars eget blad, Stars and Stripes, for nylig i en leder. Den britiske hrchef Mark Carleton-Smith sagde i en tale, at kampvognen vil spille en mindre rolle i fremtidens krige: Hovedtruslen er ikke lngere missiler og kampvogne. Det er militariseringen af alle de elementer i globaliseringen, som ellers har gjort os rige og sikre: mobiliteten, nr det glder varer, mennesker, data og tanker.  100 kampvogne delagt Professor Michael Clarke, King's College i London, ser en klar linje: At lgge for megen vgt p tung pansring af sine militre styrker ses mere og mere som et udtryk for en gammeldags mde at tnke p i en tid, som er ved at rinde ud - for alle andre end lige netop supermagten USA,  siger han til BBC. Militre planlggere over hele verden har nrstuderet et storstilet tyrkisk angreb med droner i det nordlige Syrien i februar. Op mod 100 syriske kampvogne og andre kretjer blev delagt, da Tyrkiet hvnede et angreb fra regeringsstyrker p tyrkiske stillinger. De syriske styrker forekom prisgivet over for denne hjteknologiske krigsfrelse. Ogs i Libyen har tyrkiske droner fet krigslykken til at vende. Oprrsstyrkerne var ved at indtage hovedstaden Tripoli, men da Tyrkiet tidligere p ret forsynede den FN-anerkendte regering med droner, blev oprrsgeneralen Khalifa Haftar drevet stp igen. For major Karsten Marrup handler det om at finde konkrete svar p den nye udfordring: Jeg tror p ingen mde, at dronerne har taget livet af kampvognen og andre tunge vben. Men de har ndret vores mde at tnke luftforsvar p.  Vil du have vores bedste Indblik-artikler direkte i din indbakke? Tilmeld dig gratis og f de fem nyeste artikler fra Jyllands-Postens Indblik-sektion hver dag kl. 16 - klik her, st flueben og indtast din mailadresse
        </div>
        <footer>
          <em>Jyllands-posten.dk (Abonnementsomrde)</em>
          &nbsp;&nbsp; 2020-10-18
          &nbsp;&nbsp; e7f2015f
          &nbsp;&nbsp; #12
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.875</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.562</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.646</kbd>
        </footer>
      </article>
      <article>
        <h4>Videnskabsmnd i oprb: St en stopper for drberrobotter</h4>
        <div>
          Over 1.000 videnskabsfolk og frende erhvervsledere advarer i et flles brev om konsekvenserne, hvis ikke der sttes en stopper for forskningen i drberrobotter.Der br sttes en stopper for forskningen i drberrobotter, ellers str verden over for uoverskuelige konsekvenser.Sdan lyder advarslen fra over 1.000 videnskabsfolk og erhvervsspidser, skriver Politiken.P en konference om kunstig intelligens, der har fundet sted i denne uge, blev det bne brev fremsat.Anerkendte videnskabsmnd som Stephen Hawking og filosoffen Noam Chomsky er blandt underskriverne.Iflge brevet skulle udviklingen af kunstig intelligens i militrrobotter vre noget s langt, at selvstyrende drberrobotter kan se dagens lys i lbet af f r, skriver Politiken.De selvstyrende vben beskrives i brevet som den tredje revolution inden for krigsfrelse, hvor krudt og atomvben udgjorde de to frste.Brevet advarer om, at et global vbenkaplb er uundgeligt, sfremt en stor militrmagt skulle beslutte sig for at stte turbo i udviklingen, iflge Politiken.En af folkene bag brevet er Noel Sharkey, en professor i robotteknologi ved University of Sheffield.Uden et forbud nu risikerer vi, at det her udvikler sig til en milliarddollarforretning, og s bliver det umuligt at stoppe, siger Noel Sharkey.Man skal huske, at militre robotter er maskiner programmeret af mennesker. Der findes ogs onde mennesker. Hvad skal vi gre, hvis maskinerne ikke overholder reglerne for krigsfrelse? Hvem er s ansvarlig? Er det programmren eller den, der gav ordren til at stte robotterne ind?, siger Sharkey.Folkene bag brevet er ligeledes bekymret for, hvad der vil ske, hvis teknologien falder i hnder p terrorister.
        </div>
        <footer>
          <em>Amtsavisen.dk (Randers Amtsavis) (Abonnementsomrde)</em>
          &nbsp;&nbsp; 2015-08-01
          &nbsp;&nbsp; e5253bb2
          &nbsp;&nbsp; #13
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.829</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.71</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.571</kbd>
        </footer>
      </article>
      <article>
        <h4>Robotterne vil f kontrol over aftrkkeren</h4>
        <div>
          Pentagon afviser, at USA vil overlade beslutningen om at drbe et menneske til robotter, men en rkke dokumenter peger p det modsatte. Et sprgsml om tid, fr kamprobotter bliver fuldt autonome, siger forskere.Da det amerikanske forsvarsministerium for f r siden formulerede sin politik angende autonome vben i Direktiv 3000.09, gjorde man t forhold srligt klart: Autonome vbens brug af ddelig magt skal vre underlagt menneskers kontrol.Pentagons standpunkt i det yderst kontroversielle sprgsml om fuldt autonome vben er siden blev gentaget af adskillige forsvarsspidser, senest i r af det amerikanske flyvevbens general Paul Selva, som under en tale i Washington proklamerede, at mennesker altid kommer til at vre in the loop hos det amerikanske forsvar. Men sprgsmlet er, hvor fasttmret et standpunkt det er.Politisk udsagn frem for forudsigelseDet tror jeg simpelthen ikke p. Der er jo et vbenkaplb i gang. S hvis en general siger, at vi beholder mennesket in the loop, s m det opfattes som et politisk udsagn om, hvor man er lige nu, frem for en forudsigelse om fremtiden. Det er han ikke i stand til at forudse med den hastighed, udviklingen har,siger Thomas Vestskov Terney, konsulent inden for digital strategi og ph.d. i kunstig intelligens.Og efter alt at dmme er det da ogs et sprgsml om, hvornr snarere end hvorvidt det amerikanske forsvarsministerium opgiver sit standpunkt. Pentagon og det amerikanske forsvar formulerer i en rkke offentligt tilgngelige dokumenter netop en konkret forventning om at anvende autonome vben uden menneskelig indblanding i fremtiden.-Gradvis reduktion af kontrol-I den omfattende 25-rsplan Unmanned Systems Integrated Roadmap FY2011-2036 skriver det amerikanske forsvarsministerium, at man -forventer, at ubemandede systemer problemfrit vil operere side om side med bemandede systemer, med en gradvis reduktion af menneskelig kontrol i den ubemandede del af forsvaret-.Hos det amerikanske luftvben, der i rtier har anvendt fjernbetjente kampdroner, forventer man iflge den skaldte Unmanned Aircraft Systems Flight Plan 2009-2047, at -fremskridt inden for kunstig intelligens vil gre det muligt for systemer at bestemme og udfre kamphandlinger inden for de juridiske og politiske rammer uden at behve input fra mennesker-.Specifikt om vbensystemer til landjorden beskriver det amerikanske forsvar tilsvarende i sin Unmanned Ground Systems Roadmap en igangvrende indsats for at ge selvstndigheden for UGV-er (Unmanned Ground Vehicles). Med et aktuelt ml om overvget autonomi, kendt som human on the loop, men med et endeligt ml om fuld autonomi.Taler med to tungerHeller ikke Mikkel Willum Johansen, adjunkt og lektor i videnskabsteori ved Kbenhavns Universitet, kber udmeldingen fra den amerikanske forsvarstop.Nr en amerikansk general melder ud, at man ikke vil lade robotter trykke p aftrkkeren, taler militret med to tunger. P den ene side melder man en politisk grnse ud, mens man samtidig stter gang i den teknologiske udvikling, der skal muliggre netop den type robotter. S man kan stte sprgsmlstegn ved, hvor trovrdig den udmelding er,siger Mikkel Willum Johansen.Som Ingeniren tidligere har skrevet, anvender USA allerede i dag vbensystemer med kapaciteten til fuld autonomi, men under opsyn, s mennesker har mulighed for at gribe ind. Med andre ord human on the loop.Selvskydende i 'casualty mode'F.eks. kan kampsystemet Aegis, som udgr it-rygraden i Natos ballistiske missilforsvar, selv identificere og nedskyde fjendtlige ballistiske missiler. Nr Aegis er koblet sammen med et Phalanx CIWS-nrforsvarssystem, kan det ogs nedskyde fjendtlige fly.Den menneskelige operatr kan som udgangspunkt underkende systemets beslutning om at angribe, men Aegis kan ogs fungere i casualty mode, hvor det antager, at operatren er forhindret i at betjene systemet, og derfor selv trffer beslutning om at skyde.Min frygt er, at man bevger sig ud p en glidebane. For hvis man en dag fravlger at bruge et vbensystem, som kunne have forsvaret et antal amerikanske soldater, som i stedet blev drbt af Islamisk Stat, s bliver det i et indenrigspolitisk perspektiv svrt for politikerne at insistere p, at vi stadig skal have et menneske ind over beslutningen. Vi ved fra historien, at der ikke skal mange bodybags til, for at den politiske vind vender,siger Thomas Vestskov Terney.For langsom med tjrede robotterMilitrforskere som Michael N. Schmitt og Jeffrey S. Thurnher, som netop har publiceret en artikel om kunstig intelligens i Harvard National Security Journal, peger ogs p risikoen for, at amerikanske styrker sakker bagud p slagmarken, hvis Pentagon ikke slipper tjlerne p sine kamprobotter.Efterhnden som lande som Kina og Rusland ogs udvikler autonome vben, kan tempoet p slagmarken blive s hjt, at mennesker ikke lngere kan flge med. Og med et tjret vbensystem vil man uvgerligt trffe sine beslutninger langsommere end en fjende med et fuldt autonomt vbensystem. Derfor kan de operationelle realiteter tvinge USA til at forkaste sin praksis med at beholde et menneske i beslutningskden, skriver de.Davrende forskningschef Werner Dahm fra det amerikanske luftvben sagde tilbage i 2010, at det teknologisk har vret muligt at lade robotter foretage autonome angreb i lang tid. Og at mennesket inden 2030 vil vre blevet kamppladsens svageste led.
        </div>
        <footer>
          <em>Ing.dk (Ingeniren)</em>
          &nbsp;&nbsp; 2016-10-30
          &nbsp;&nbsp; e5f349cf
          &nbsp;&nbsp; #14
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.704</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.512</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.592</kbd>
        </footer>
      </article>
      <article>
        <h4>Fr Danmarks valg af nyt kampfly: Nste generation spger allerede i kulissen</h4>
        <div>
          Northrop Grumman har i december offentliggjort denne visualisering af sit bud p nste generation af kampfly. Flyet har laservben i form af en solid-state-hjenergilaser, der fungerer med stor njagtighed og lysets hastighed, men ger flyets infrarde synlighed. Bagudvinklede vinger som p Northrops bombefly B-2 reducerer luftmodstanden og mindsker effekten af chokblger ved overlydshastighed.Femtegenerations kampflyet F-35 er stadig langtfra frdigudviklet, men tre kampflyproducenter arbejder allerede nu p sjette generation, som Pentagon vil have p vingerne i 2030.7. feb 2016 kl. 12:00Herhjemme handler det om femte generation eller fjerde generation: Nr kredsen af partier bag forsvarsforliget snart skal vlge nye kampfly, skal vi s g efter F-35, som markerer et teknologispring men stadig oplever udviklingsproblemer? Eller skal vi satse p et velafprvet fjerdegenerations kampfly som F/A-18 Super Hornet eller Eurofighter?I udviklingsafdelingerne hos en lille hndfuld internationale forsvarsvirksomheder har blikket derimod lnge vret rettet mod sjette generation af kampfly, som efter planen skal g p vingerne for det amerikanske forsvar omkring 2030.Senest har Northrop Grumman, som str bag bombeflyet B-2 Spirit og i dag er underleverandr p bde F-35 og Super Hornet, for f uger siden offentliggjort sin visualisering af et bud p et sjettegenerations kampfly, der prsterer lngere rkkevidde, laservben og modstandskraft mod elektronisk krigsfrelse.Inden for de seneste r har ogs Boeing og Lockheed Martin offentliggjort deres bud p sjette generation som opvarmning til, at Pentagon skyder et udbud i gang.Producenterne er meget bevidste om, at de nuvrende budgetplaner for forsvaret kun vil tillade to centrale kampfly at overleve i det kommende rti. Derfor er alle tre producenter ivrige efter at gre opmrksom p deres muligheder, siger Richard Aboulafia, vicedirektr i analysevirksomheden Teal Group og rdgiver inden for militr luftfart.Et sprgsml om stealthDet amerikanske forsvarsministerium udsendte allerede i 2012 det indledende udbudsmateriale til kampflyproducenter, og US Air Force er i samarbejde med US Navy lige nu i gang med at kortlgge producenternes bud p et sjettegenerations kampfly. Pentagon overvejer angiveligt bde bemandede, ubemandede og valgfrit bemandede kampfly.Mens US Air Force og US Navy indledningsvis samarbejder om indkbet, bliver der tale om to adskilte programmer, der har til forml at erstatte forskellige kampfly. Flyvevbnets F-X-program skal erstatte fjerdegenerations kampflyet F-15 Eagle og femtegenerations kampflyet F-22 Raptor, mens svrnets FA-XX-program skal levere en aflser for fjerdegenerations kampflyet F/A-18 Super Hornet. Det amerikanske forsvarsministerium har, belrt af designkompromiserne og fordyrelserne i flleskampflyet F-35, valgt at holde de to nye kampflyprogrammer adskilt p trods af overlappende egenskaber.Boeings nyeste bud p et sjettegenerations kampfly er dette koncept fra 2013. Flyet kan enten flyves med pilot eller fjernstyres. Pentagon har endnu ikke lagt sig fast p sprgsmlet om bemanding. To motorer ger flyets motorkraft og minimerer konsekvensen af et motorstop. Fravr af haleror og dermed vertikale flader bidrager til flyets begrnsede radarsynlighed.US Air Force og US Navy har da ogs forskellige forventninger til hver deres nste kampflygeneration. Den mest markante forskel ligger formentlig i tiltroen til stealth-teknologi. Hos US Air Force er overbevisningen, at radarusynlighed fortsat er en central kampflyteknologi, og general Herbert Carlisle meldte sidste r ud, at stealth ogs bliver en ngleegenskab for fremtidige kampflygenerationer. Begejstringen hos US Navy er derimod afmlt, og admiral Jonathan Greenert har meldt ud, at stealth-teknologi formentlig er overvurderet og ikke i fremtiden kan holde kampfly skjult for ny radarteknologi.Iflge Mark Gunzinger, seniorforsker ved den Washington-baserede tnketank CSBA og tidligere rdgiver for det amerikanske forsvarsministerium og luftvben, vil reduceret radarsynlighed vre en ndvendighed for fremtidige kampfly.Vores vurdering er, at fremtidige systemer til luftdominans, bemandede svel som ubemandede, skal kunne operere i strkt beskyttede miljer. Det stiller krav om den seneste stealth-teknologi og avancerede selvforsvarssystemer, for eksempel i form af laservben, siger han til Ingeniren.Justerbare motorerFlere krav til den nye kampflygeneration gr igen hos bde US Navy og US Air Force. For begge vrn bliver der tale om store krav til datalinks, der kan gre det muligt at dele store datamngder med andre kampfly. Begge vrn har ogs luftet ambitioner om kunstig intelligens, som i praksis formentlig vil tage form af avanceret pilotunderstttelse i stil med den aktuelle fusionering af forskellige sensorinput, som i dag er at finde i F-35.US Air Force og US Navy samarbejder ogs om en flles motorlsning. En af mulighederne p tegnebrttet er en motor med justerbart bypassforhold, der kan tilpasses til den optimale effekt ved forskellige hastigheder og hjder, hvilket skal give flyene bedre acceleration og ikke mindst lngere rkkevidde.Eksempelvis et system, der fungerer som en turbojetmotor med reduceret bypass ved overlydsflyvning, og som en turbofanmotor med hj bypass ved lavere cruisehastigheder. Motorproducenterne General Electric og Pratt &amp; Whitney arbejder begge p skaldte adaptive cycle-motorsystemer.CybermodstandEn ngleegenskab i Northrop Grummans vision for et sjettegenerations kampfly er cyber resiliency, modstandsdygtighed over for cyberangreb. Efterhnden som elektronisk krigsfrelse spiller en stadigt strre rolle, forestiller selskabet sig ikke at kunne afvrge samtlige forsg p cyberangreb, men i stedet at gre nye kampfly i stand til at registrere angreb og minimere skaden, inspireret af hvide blodlegemer.Menneskekroppen er s modtagelig for infektioner, at tanken om at blokere angreb er urealistisk. Sprgsmlet er snarere, hvordan din krop reagerer, nr du er inficeret. Hvide blodlegemer er et utroligt system, der angriber og forsger at kontrollere infektioner p en mde, der forhindrer dem i at skade kroppen. Systemerne i 2030 vil vre udstyret med noget lignende, sagde Tom Vice, direktr for Northrop Grummans luftfartsdivision, til Defense News tidligere p ret.
        </div>
        <footer>
          <em>Ing.dk (Ingeniren)</em>
          &nbsp;&nbsp; 2016-02-07
          &nbsp;&nbsp; e58da6a8
          &nbsp;&nbsp; #15
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.784</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.626</kbd>
        </footer>
      </article>
      <article>
        <h4>Tusindvis af eksperter opfordrer til bandlysning af kunstig intelligens i vbenudvikling</h4>
        <div>
          I et bent brev advarer eksperter i kunstig intelligens og robotter imod at starte et nyt vbenkaplb.Af Daniel McClane Tirsdag, 28. juli 2015 - 10:25Kunstig intelligens teknologi har net et niveau, hvor det inden for f r vil kunne introduceres i krigsfrelse, og der str rigtig meget p spil.Sdan indledes et bent brev , som netop er blevet offentliggjort p en international konference om kunstig intelligens i Buenos Aires i Argentina. Det skriver The Guardian .Eksperterne advarer mod de humanitre konsekvenser ved at introducere kunstig intelligens i militret. Blandt underskriverne p brevet er Teslas Elon Musk, Apples Steve Wozniak, Dennis Hassabis fra Google, Stephen Hawking og mere end tusind andre eksperter.Det drejer sig om robotter, der kan finde og angribe ml uden menneskelig styring. Eksempelvis selvstndige quadrokoptere, der blot er programmeret med nogle kriterier for mlsgning.Autonome vben er blevet beskrevet som den tredje revolution inden for krigsfrelse efter krudt og atomvben. Og imens forfatterne bag brevet er enige i, at de autonome vben kan forbedre arbejdsvilkrene for nogle soldater, er de bekymrede for, at det vil ge villigheden til at starte vbnede konflikter og dermed resultere i flere tab af menneskeliv.Desuden kan de autonome vben foranledige et vbenkaplb, som overstiger, hvad vi oplevede med atomvben, da de nye vben ikke krver srlige materialer som beriget uran til atombomber, og dermed vil teknologien vre svrere at overvge globalt.Opfordringen i brevet er, at man laver et totalt FN-forbud mod kunstig intelligens i militrt isenkram.Der eksisterer flere NGO-er som lobbyer imod brugen af autonome vben, bl.a. -Stop Killer Robots- som siden 2012 har arbejdet for et globalt forbud.Elon Musk og Stephen Hawking har tidligere udtalt, at generel kunstig intelligens er den strste eksterne trussel mod menneskehedens eksistens. Dette brev slutter dog af med at sige, at kunstig intelligens kan have mange gode anvendelser i andre aspekter af vores hverdag.Ved en FN konference om samme emne tidligere i r, udtalte den britiske regering sig imod et forbud p autonome vben.Via: The Guardian
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2015-07-28
          &nbsp;&nbsp; e523db6f
          &nbsp;&nbsp; #16
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.867</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.598</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.561</kbd>
        </footer>
      </article>
      <article>
        <h4>Kunstig intelligens er genvej til militre muskler</h4>
        <div>
          get brug af autonome vben og AI forventes at kunne dmme op for, at 17 procent af de militre ddsfald skyldes friendly fire. Alts at en hrenhed kommer til at skyde deres egne i kampens hede.Selvstyrende krigsmaskiner vil udligne styrkeforholdet mellem de forskellige nationer og destabilisere den militre magtbalance, vurderer AI-forskere.Guatemala, Costa Rica, Irak, Panama, Uganda, Palstina og s videre.Et udvalg af de 22 lande, som til dato har underskrevet et FN-forbud om fuldstndigt at bandlyse brugen af autonome vben. Om end ogs et udvalg af lande, som nppe fr en general fra nogen strre vestlige nationer til at ryste i sine camouflagefarvede army-bukser.Men nr kunstig intelligens bliver blandet ind i den militre magtbalance, br store hre frygte sm landes enheder i langt strre grad.Det er en overset pointe og ikke mindst en ekstra grund til, at militre svrvgtere ssom USA, Rusland eller Storbritannien tillige br bakke op om et forbud mod autonome vben.Det mener professor Toby Walsh fra New South Wales University, en af verdens mest fremtrdende AI-forskere og talsmand for sammenslutningen af forskere imod autonome vben.Dette er vben, som vil destabilisere den nuvrende magtbalance. Du behver ikke vre en supermagt for at opbygge en skrmmende hr p baggrund af autonome vben, siger Toby Walsh.Pentagon er da ogs udmrket klar over udgifterne til krudt, kugler og kunstig intelligens anvendt i krigszoner. Men det har alts hidtil ikke afholdt USA fra at sttte op om indskrnkninger i de forskelle grader af autonomi ved AI-vben.Da FN-s medlemslande og AI-eksperter mdtes i Genve i begyndelsen af mneden for at drfte autonome vben, havde USA ligefrem travlt med at ppege fordele ved autonome vben.Eksempelvis at AI kraftigt vil kunne reducere antallet af civile ofte i vbnede konflikter. rsagen er ofte uprcis styring af bomber, fordi vi mennesker nu engang er unjagtige og har vanskeligt ved at holde hovedet koldt i en glohed konflikt.Meget, meget billigereEn motivationsfaktor for USA-s positive udlgninger af autonome vben med avanceret AI kan vre, at AI kraftigt vil kunne reducere udgifterne til at fre krig, og USA er en af klodens mest aktive nationer i konflikter.Et estimat fra en militr tnketank har tidligere anslet, at det eksempelvis koster mindst 2,1 millioner kroner blot at optrne en Navy Seal-soldat. Et moderne Patriot-missil opereret af en antiballistisk robot fs for 18,5 millioner kroner. En autonom drone lber op i omkring 12.370 kroner. Blandt andet takket vre det faktum, at udgifterne til AI i hj grad allerede er blevet afholdt af offentlig universitetsforskning.Samme regnestykke skver oprrsgruppe eller andre nationers generaler ogs til, understreger Toby Walsh.USA og Rusland br i hj grad vre opmrksomme p, at autonome vben ikke vil gre dem strkere, men gre forholdet til deres modstandere mere jvnbyrdigt, siger han.Doping med dataUdviklingen indenfor kunstig intelligens er i dag s fremskreden, at vbenproducenter og nationer ssom USA, Israel, Storbritannien og Sydkorea alle rder over skibe eller artillerisystemer baseret p det, man kunne kalde for militr machine learning.Uden menneskelig indflydelse er maskinerne i stand til at opsge og egenhndigt trffe en beslutning om et ddeligt angreb. Indtil videre er mennesket bevaret i den beslutningskde.Gary Schaub, seniorforsker ved Center for Militre Studier p Kbenhavns Universitet, offentliggjorde i 2016 en rapport om behovet for retningslinjer ved anvendelse af autonome vben. Han mener ligesom Toby Walsh, at en udbredelse af autonome vben vil udligne forskellene mellem krigsaktive nationer. Og en traktat eller forbud tvivler han p har nogen gang p jord, selv i det tilflde, hvor selvstyrende krigsmaskiner kan defineres tilstrkkeligt prcist til en international traktat:Ikke alene vil verdens supermagter ikke tilslutte sig et forbud, men mange stater, der higer efter mere indflydelse, vil opfatte autonomi som en oplagt mulighed for at skyde genvej til et militrt topniveau, siger Gary Schaub.En sdan stat kan vre Kina. Riget i Midten har lnge flt sig underkuet i forhold til Rusland og USA's militre teknologi. Kina har vgret sig ved Pentagons stadig mere offensive politik i dette rhundrede for kernevben og oversiske missiler.Lg dertil, at Kina isr er ngstelig for at blive taget p sengen ved ikke at opdage et angreb i tide.I relation til Rusland og USA har Kina lnge vret oppe mod en a-vben-asymmetri. I modstning hertil udgr AI og autonomi et potentiale, som p langt sigt lader Beijing forstyrre Washingtons traditionelle styrker, siger Lora Saalman, fellow ved Stockholm International Peace Research Institute (SIPRI) og professor fra Tsinghua Universitys afdeling for internationale relationer, til
        </div>
        <footer>
          <em>Ing.dk (Ingeniren)</em>
          &nbsp;&nbsp; 2018-04-26
          &nbsp;&nbsp; e6ba20ae
          &nbsp;&nbsp; #17
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.661</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.576</kbd>
        </footer>
      </article>
      <article>
        <h4>Robotterne vil f kontrol over aftrkkeren</h4>
        <div>
          Da det amerikanske forsvarsministerium for f r siden formulerede sin politik angende autonome vben i Direktiv 3000.09, gjorde man t forhold srligt klart: Autonome vbens brug af ddelig magt skal vre underlagt menneskers kontrol.Pentagons standpunkt i det yderst kontroversielle sprgsml om fuldt autonome vben er siden blev gentaget af adskillige forsvarsspidser, senest i r af det amerikanske flyvevbens general Paul Selva, som under en tale i Washington proklamerede, at mennesker altid kommer til at vre in the loop hos det amerikanske forsvar. Men sprgsmlet er, hvor fasttmret et standpunkt det er.Det tror jeg simpelthen ikke p.Der er jo et vbenkaplb i gang. S hvis en general siger, at vi beholder mennesket in the loop, s m det opfattes som et politisk udsagn om, hvor man er lige nu, frem for en forudsigelse om fremtiden. Det er han ikke i stand til at forudse med den hastighed, udviklingen har, siger Thomas Vestskov Terney, konsulent inden for digital strategi og ph. d. i kunstig intelligens.Og efter alt at dmme er det da ogs et sprgsml om, hvornr snarere end hvorvidt det amerikanske forsvarsministerium opgiver sit standpunkt.Pentagon og det amerikanske forsvar formulerer i en rkke offentligt tilgngelige dokumenter netop en konkret forventning om at anvende autonome vben uden menneskelig indblanding i fremtiden.' Gradvis reduktion af kontrol'I den omfattende 25-rsplan Unmanned Systems Integrated Roadmap FY2011-2036 skriver det amerikanske forsvarsministerium, at man ' forventer, at ubemandede systemer problemfrit vil operere side om side med bemandede systemer, med en gradvis reduktion af menneskelig kontrol i den ubemandede del af forsvaret'.Hos det amerikanske luftvben, der i rtier har anvendt fjernbetjente kampdroner, forventer man iflge den skaldte Unmanned Aircraft Systems Flight Plan 2009-2047, at ' fremskridt inden for kunstig intelligens vil gre det muligt for systemer at bestemme og udfre kamphandlinger inden for de juridiske og politiske rammer uden at behve input fra mennesker'.Specifikt om vbensystemer til landjorden beskriver det amerikanske forsvar tilsvarende i sin Unmanned Ground Systems Roadmap en igangvrende indsats for at ge selvstndigheden for UGV'er (Unmanned Ground Vehicles). Med et aktuelt ml om overvget autonomi, kendt som human on the loop, men med et endeligt ml om fuld autonomi.Heller ikke Mikkel Willum Johansen, adjunkt og lektor i videnskabsteori ved Kbenhavns Universitet, kber udmeldingen fra den amerikanske forsvarstop.Nr en amerikansk general melder ud, at man ikke vil lade robotter trykke p aftrkkeren, taler militret med to tunger. P den ene side melder man en politisk grnse ud, mens man samtidig stter gang i den teknologiske udvikling, der skal muliggre netop den type robotter.S man kan stte sprgsmlstegn ved, hvor trovrdig den udmelding er, siger Mikkel Willum Johansen.Som Ingeniren tidligere har skrevet, anvender USA allerede i dag vbensystemer med kapaciteten til fuld autonomi, men under opsyn, s mennesker har mulighed for at gribe ind. Med andre ord human on the loop.F. eks. kan kampsystemet Aegis, som udgr it-rygraden i Natos ballistiske missilforsvar, selv identificere og nedskyde fjendtlige ballistiske missiler. Nr Aegis er koblet sammen med et Phalanx CIWS-nrforsvarssystem, kan det ogs nedskyde fjendtlige fly.Den menneskelige operatr kan som udgangspunkt underkende systemets beslutning om at angribe, men Aegis kan ogs fungere i casualty mode, hvor det antager, at operatren er forhindret i at betjene systemet, og derfor selv trffer beslutning om at skyde.Min frygt er, at man bevger sig ud p en glidebane. For hvis man en dag fravlger at bruge et vbensystem, som kunne have forsvaret et antal amerikanske soldater, som i stedet blev drbt af Islamisk Stat, s bliver det i et indenrigspolitisk perspektiv svrt for politikerne at insistere p, at vi stadig skal have et menneske ind over beslutningen.Vi ved fra historien, at der ikke skal mange bodybags til, for at den politiske vind vender, siger Thomas Vestskov Terney.For langsom med tjrede robotter Militrforskere som Michael N.Schmitt og Jeffrey S. Thurnher, som netop har publiceret en artikel om kunstig intelligens i Harvard National Security Journal, peger ogs p risikoen for, at amerikanske styrker sakker bagud p slagmarken, hvis Pentagon ikke slipper tjlerne p sine kamprobotter.Efterhnden som lande som Kina og Rusland ogs udvikler autonome vben, kan tempoet p slagmarken blive s hjt, at mennesker ikke lngere kan flge med. Og med et tjret vbensystem vil man uvgerligt trffe sine beslutninger langsommere end en fjende med et fuldt autonomt vbensystem. Derfor kan de operationelle realiteter tvinge USA til at forkaste sin praksis med at beholde et menneske i beslutningskden, skriver de.Davrende forskningschef Werner Dahm fra det amerikanske luftvben sagde tilbage i 2010, at det teknologisk har vret muligt at lade robotter foretage autonome angreb i lang tid. Og at mennesket inden 2030 vil vre blevet kamppladsens svageste led. j.GRADER AF AUTONOMIAutonomi benyttes om flere grader af selvstndighed, hvor mennesket har strre eller mindre vgt i beslutningskden.En bredt anvendt model definerer tre grader af selvbestemmelse i vbensystemer: Humanintheloop Mennesker er en integreret del af beslutningskden og har fuld kontrol over systemet.Humanontheloop Mennesker betragter beslutningskden og har mulighed for at gribe ind i systemet.Humanoutoftheloop Mennesker er uden indflydelse p beslutningskden. Autonome vben beskrives som krigsfrelsens tredje revolution efter frst krudtet og s atomvben.Ingeniren ser i en serie p de stadigt mere intelligente kamprobotter.Ls blandt andet: Kamprobotternes akilleshl er uforudsigelighed ing.dk/ 187503 Hvornr er krigsrobotter autonome? ing.dk/ 187619.13. RHUNDREDE LandminerBrugt som skaldte area denial-vben siden Song-dynastiet i Kina. Betegnes af nogle som fuldt autonome vben, hvilket dog ikke flugter med de mest udbredte definitioner af fuldt autonome vben, som indebrer, at vbnet kan vlge mellem forskellige handlingsmuligheder.Efter den definition er landminer snarere automatiske.1920' ERNE Ubemandede kretjerSkaldte UGV'er (Unmanned Ground Vehicle) har eksisteret siden 1920' erne, og de fleste er fortsat fjernstyrede, mens flere nyere versioner, som de amerikanske Swords, er delvist autonome. Israels Guardium og USA's Crusher kan bde fjernbetjenes og indstilles til at operere autonomt, dog med menneskelig overvgning.ANDEN VERDENSKRIG Fire and forgetFire and forget-missiler er guidede missiler, der selv finder og angriber det ml, som piloten har udpeget. De frste kom frem under Anden Verdenskrig, og kategorien omfatter i dag bl. a. de udbredte lasereller radarstyrede Sidewinder-, Amraam-og Hellfire-missiler. Missilerne kan dermed betegnes som semi-autonome vben. De nye Brimstone-luft-til-jord-missiler fremhves ofte som srligt selvstndige, idet de kan affyres i en generel retning, selv finde et ml og identificere mlets mest srbare punkt.1950' ERNE Kunstig intelligensKunstig intelligens (Artificial Intelligence/ AI) udgr forudstningen for udviklingen af autonome vben. Forskningsfeltet opstod i 1950' erne, og i dag findes kunstig intelligens i et utal af vbensystemer.3.000 specialister i robotter advarede sidste r FN om, at udviklingen kan lbe lbsk, og at kunstig intelligens i sidste ende kan udgre en trussel mod menneskeheden.1970' ERNE CIWSNrforsvarssystemer eller CIWS (Close-In Weapon System) har vret anvendt p krigsskibe siden de russiske AK-630 i 1970' erne. CIWS kan automatisk nedskyde fjendtlige missiler, bde og fly, men krver grnt lys fra et menneske for at angribe. Det kan dermed betegnes som et semi-autonomt vbensystem.00' ERNE Fuzzy logicFuzzy logic - lringsalgoritmer, hvor mlet ikke er eksakte vrdier, men hvor man kombinerer de bedste erfaringer med regelst for at n den bedst mulige version af et givent regelst - benyttes i dag i flysimulatorer og vil i de kommende r formentlig brede sig til mange anvendelser, eksempelvis droner.I 2016 lykkedes det for frste gang en AI-computer baseret p fuzzy logic at nedkmpe en menneskelig kampflypilot i simulatorvelser i det amerikanske luftvbens centrale forskningslaboratorium i Ohio.
        </div>
        <footer>
          <em>Ingeniren</em>
          &nbsp;&nbsp; 2016-10-28
          &nbsp;&nbsp; e5f2918e
          &nbsp;&nbsp; #18
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.812</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.557</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.596</kbd>
        </footer>
      </article>
      <article>
        <h4>TV 2 kl. 22.30 Stealth</h4>
        <div>
          I en nr fremtid har flden udviklet et ubemandet jagerfly, styret af en kunstig intelligens.Flyet bliver sendt til Stillehavet, for at piloterne om bord kan give flyet lektioner i kampteknik. Men da computeren begynder at flge sine egne ordrer, m de tre elitepiloter stoppe den, fr den indleder en atomkrig.
        </div>
        <footer>
          <em>rhus Stiftstidende</em>
          &nbsp;&nbsp; 2018-01-19
          &nbsp;&nbsp; e695321c
          &nbsp;&nbsp; #19
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.944</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.711</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.614</kbd>
        </footer>
      </article>
      <article>
        <h4>Ny rapport: Danmark mangler politik for autonome vben</h4>
        <div>
          Danmark rder allerede i dag over delvist autonome vben i form af Harpoon Block II-antiskibsmissiler. Her affyret fra sttteskibet Esbern Snare under en velse i Norge sidste sommer. (Foto: Forsvaret)Intelligente vbensystemer vinder hastigt frem og betegnes som tredje revolution inden for krigsfrelse. Men selv om Forsvaret allerede rder over autonome vben, mangler danske politikere at forholde sig til, hvordan Danmark skal anvende dem. Ny rapport om problemet lander i dag.24. feb 2017 kl. 09:01Frst kom krudtet, s kom atomvben, og nu str robotterne klar til at indtage slagmarken. Autonome vben beskrives som den tredje revolution inden for krigsfrelse, og med de sofistikerede nye vbensystemer flger en lang rkke etiske og juridiske dilemmaer.Men modsat lande som USA og Storbritannien har Danmark ingen politik for anvendelsen af autonome vben. Det er konklusionen i en rapport fra Center for Militre Studier ved Kbenhavns Universitet, som offentliggres i dag.Der er flere grunde til, at danske beslutningstagere burde vre i gang med at adressere dette problem allerede nu. Militret har generelt meget distinkte ansvarskder, s hvis en soldat gr noget galt i Afghanistan eller Irak, har den overordnede officer et ansvar. Vi mangler en tilsvarende model, nr soldaten erstattes af en maskine med evnen til at handle autonomt,siger Gary Schaub Jr., seniorforsker ved Center for Militre Studier og rapportens ene forfatter.Det er den frste rapport om autonome vben i en dansk kontekst. Den er samtidig udarbejdet som en del af Center for Militre Studiers myndighedsbetjening og lander derfor p skrivebordet hos forsvarsminister Claus Hjort Frederiksen (V) og hos partierne bag forsvarsforliget, som skal forhandles p plads inden rets udgang.Allerede i DanmarkBehovet for retningslinjer bliver ikke mindre presserende af, at det danske forsvar i forvejen rder over adskillige vbensystemer med autonome funktioner. Det viser en opgrelse, som Center for Militre Studier har lavet i forbindelse med den nye rapport.Svrnet benytter Harpoon Block II-antiskibsmissiler, ESSM-luftforsvarsmissiller og MU90-letvgts-antiubdstorpedoer, mens Flyvevbnet rder over luft til luft-missilet AIM-120 AMRAAM og luft til jord-missilet AGM 65 Maverick. Det er skaldte fire and forget-systemer, som skal affyres af mennesker, men som efter affyring er mlsgende og kan finde frem til deres ml, selv om de er uden for affyringssystemets synsfelt. Missilerne kan ogs foretage undvigemanvrer over for mlets beskyttelsessystemer.Danmark har rent faktisk allerede autonome vbensystemer efter den amerikanske definition. Og allerede i 1982 har autonome vben skabt problemer for danske beslutningstagere,siger Gary Schaub Jr. med henvisning til det Harpoon-missil, som utilsigtet blev affyret fra en dansk fregat og ramte et sommerhusomrde i Nordvestsjlland, hvor det eksploderede og totalskadede flere sommerhuse.Sagen blev kontroversiel, fordi der netop ikke var etableret nogen proces for at fastsl ansvaret for episoder med den slags vben. Det er et eksempel p, at det ikke er godt nok at udelade en fast praksis og i stedet frst finde p den, nr problemerne opstr. Man bliver ndt til at gennemtnke den slags problemstillinger mere effektivt,siger han.Juridisk ingenmandslandFuldt autonome vbensystemer, der udvlger og angriber deres ml uden menneskelig indblanding, anvendes ikke i dag. Men det amerikanske forsvar formulerer i en rkke offentligt tilgngelige dokumenter en forventning om at anvende fuldt autonome vben i fremtiden. Derfor efterlyste eksperter i kunstig intelligens allerede i efterret i Ingeniren danske retningslinjer for autonome vben. Blandt dem er Thomas Vestskov Terney, konsulent inden for digital strategi og ph.d. i kunstig intelligens. Og konsekvenserne kan blive alvorlige, hvis danske politikere ikke lytter til indstillingen i den nye rapport, advarer han.Konsekvensen vil vre, at vi stter os selv uden for indflydelse. Der er ingen tvivl om, at de fuldt autonome vben kommer, og hvis vi ikke selv tager aktivt stilling til sagen, s kommer andre til at foretage den stillingtagen for os. Det bliver enten vores allierede eller vores modstandere,siger Thomas Vestskov Terney.Samtidig kan vi ikke placere ansvaret, hvis noget gr galt. Er det operatrens ansvar? Er det producentens? Vi er lige nu i et juridisk ingenmandsland. Og hvis vi ikke etablerer nogle rammer for anvendelsen, kommer vi uafvrgeligt til at st med problemer. Bekymringen er naturligvis, at udviklerne overser noget. En vsentlig faktor, som gr, at systemet reagerer anderledes, end vi havde tnkt os,siger han.Frste skridtForfatterne bag den nye rapport foreslr konkret at oprette en tvrministeriel arbejdsgruppe med reprsentanter fra Forsvarsministeriet, Justitsministeriet, Udenrigsministeriet, Forsvarskommandoen og Forsvarets Efterretningstjeneste, der skal belyse implikationerne ved autonome vben, ligesom det har vret tilfldet med cyberkrigsfrsel.Arbejdsgruppen skal blandt andet evaluere argumenterne for, hvorvidt det skal vre dansk politik 1) at understtte anvendelsen og udviklingen af autonome vbensystemer i det danske forsvar, den danske forsvarsindustri og hos danske allierede, 2) at tillade, at allierede landes autonome vben udstationeres p eller passerer igennem dansk territorium, og 3) at deltage i militre operationer, hvor autonome vben anvendes.Teknologien er utvivlsomt p vej, og det er vsentligt at have en dansk politik p plads, ikke blot for Danmarks egen brug af autonome vben, men ogs hvordan vi hndterer allieredes brug af teknologien. USA-s frerposition p omrdet vil skabe alvorlige sprgsml om, hvorvidt Danmark vil deltage i operationer med autonome vben eller tillade dem i dansk luftrum eller farvand,siger Gary Schaub Jr.Samtidig skal arbejdsgruppen foresl en kommandostruktur, der skal sikre den forndne kontrol med og ansvarsplacering for vbensystemerne. Endelig foreslr rapporten en permanent arbejdsgruppe inden for Forsvarskommandoen, som skal sikre, at nyanskaffelser af autonome vben foregr i overensstemmelse med dansk lov og med Genvekonventionen.Ingeniren har bedt forsvarsminister Claus Hjort Frederiksen om at kommentere udspillet i den nye rapport, men det har ikke vret muligt at tale med ministeren.
        </div>
        <footer>
          <em>Ing.dk (Ingeniren)</em>
          &nbsp;&nbsp; 2017-02-24
          &nbsp;&nbsp; e6210acd
          &nbsp;&nbsp; #20
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.649</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.609</kbd>
        </footer>
      </article>
      <article>
        <h4>Kampen om den nste kampflygeneration er i gang</h4>
        <div>
          Herhjemme handler det om femte generation eller fjerde generation: Nr kredsen af partier bag forsvarsforliget snart skal vlge nye kampfly, skal vi s g efter F35, som markerer et teknologispring men stadig oplever udviklingsproblemer? Eller skal vi satse p et velafprvet fjerdegenerations kampfly som F/ A18 Super Hornet eller Eurofighter? I udviklingsafdelingerne hos en lille hndfuld internationale forsvarsvirksomheder har blikket derimod lnge vret rettet mod sjette generation af kampfly, som efter planen skal g p vingerne for det amerikanske forsvar omkring 2030.Senest har Northrop Grumman, som str bag bombeflyet B2 Spirit og i dag er underleverandr p bde F35 og Super Hornet, for f uger siden offentliggjort sin visualisering af et bud p et sjettegenerations kampfly, der prsterer lngere rkkevidde, laservben og modstandskraft mod elektronisk krigsfrelse.Inden for de seneste r har ogs Boeing og Lockheed Martin offentliggjort deres bud p sjette generation som opvarmning til, at Pentagon skyder et udbud i gang.Producenterne er meget bevidste om, at de nuvrende budgetplaner for forsvaret kun vil tillade to centrale kampfly at overleve i det kommende rti. Derfor er alle tre producenter ivrige efter at gre opmrksom p deres muligheder, siger Richard Aboulafia, vice direktr i analysevirksomheden Teal Group og rdgiver inden for militr luftfart.Et sprgsml om stealthDet amerikanske forsvarsministerium udsendte allerede i 2012 det indledende udbudsmateriale til kampflyproducenter, og US Air Force er i samarbejde med US Navy lige nu i gang med at kortlgge producenternes bud p et sjettegenerations kampfly. Pentagon overvejer angiveligt bde bemandede, ubemandede og valgfrit bemandede kampfly.Mens US Air Force og US Navy indledningsvis samarbejder om indkbet, bliver der tale om to adskilte programmer, der har til forml at erstatte forskellige kampfly.Flyvevbnets FXprogram skal erstatte fjerdegenerations kampflyet F15 Eagle og femtegenerations kampflyet F22 Raptor, mens svrnets FAXXprogram skal levere en aflser for fjerdegenerations kampflyet F/ A18 Super Hornet.Det amerikanske forsvarsministerium har, belrt af designkompromiserne og fordyrelserne i flleskampflyet F35, valgt at holde de to nye kampflyprogrammer adskilt p trods af overlappende egenskaber.US Air Force og US Navy har da ogs forskellige forventninger til hver deres nste kampflygeneration.Den mest markante forskel ligger formentlig i tiltroen til stealthteknologi.Hos US Air Force er overbevisningen, at radarusynlighed fortsat er en central kampflyteknologi, og general Herbert Carlisle meldte sidste r ud, at stealth ogs bliver en ngleegenskab for fremtidige kampflygenerationer.Begejstringen hos US Navy er derimod afmlt, og admiral Jonathan Green ert har meldt ud, at stealthteknologi formentlig er overvurderet og ikke i fremtiden kan holde kampfly skjult for ny radarteknologi.Iflge Mark Gunzinger, seniorforsker ved den Washingtonbaserede tnketank CSBA og tidligere rdgiver for det amerikanske forsvarsministerium og luftvben, vil reduceret radarsynlighed vre en ndvendighed for fremtidige kampfly.Vores vurdering er, at fremtidige systemer til luftdominans, bemandede svel som ubemandede, skal kunne operere i strkt beskyttede miljer. Det stiller krav om den seneste stealthteknologi og avancerede selvforsvarssystemer, for eksempel i form af laservben, siger han til Ingeniren.Justerbare motorerFlere krav til den nye kampflygeneration gr igen hos bde US Navy og US Air Force. For begge vrn bliver der tale om store krav til datalinks, der kan gre det muligt at dele store datamngder med andre kampfly. Begge vrn har ogs luftet ambitioner om kunstig intelligens, som i praksis formentlig vil tage form af avanceret pilotunderstttelse i stil med den aktuelle fusionering af forskellige sensorinput, som i dag er at finde i F35.US Air Force og US Navy samarbejder ogs om en flles motorlsning.En af mulighederne p tegnebrttet er en motor med justerbart bypassforhold, der kan tilpasses til den optimale effekt ved forskellige hastigheder og hjder, hvilket skal give flyene bedre acceleration og ikke mindst lngere rkkevidde.Eksempelvis et system, der fungerer som en turbojetmotor med reduceret bypass ved overlydsflyvning, og som en turbofanmotor med hj bypass ved lavere cruisehastigheder.Motorproducenterne General Electric og Pratt &amp; Whitney arbejder begge p skaldte adaptive cyclemotorsystemer.CybermodstandEn ngleegenskab i Northrop Grummans vision for et sjettegenerations kampfly er cyber resiliency, modstandsdygtighed over for cyberangreb.Efterhnden som elektronisk krigsfrelse spiller en stadigt strre rolle, forestiller selskabet sig ikke at kunne afvrge samtlige forsg p cyberangreb, men i stedet at gre nye kampfly i stand til at registrere angreb og minimere skaden, inspireret af hvide blodlegemer.Menneskekroppen er s modtagelig for infektioner, at tanken om at blokere angreb er urealistisk.Sprgsmlet er snarere, hvordan din krop reagerer, nr du er inficeret.Hvide blodlegemer er et utroligt system, der angriber og forsger at kontrollere infektioner p en mde, der forhindrer dem i at skade kroppen.Systemerne i 2030 vil vre udstyret med noget lignende, sagde Tom Vice, direktr for Northrop Grummans luftfartsdivision, til Defense News tidligere p ret.get rkkeviddeDet nyligt offentliggjorte design fra Northrop Grumman er halelst og minder i udformningen om selskabets nye kampdrone X47B, men med et frontparti, der minder mere om Lockheed Martins F35.Northrop Grumman satser p et usdvanligt stort kampfly, der kan rumme meget brndstof og dermed prstere get rkkevidde. Netop den begrnsede brndstofmngde i F35 er blevet kritiseret, og som forsvarsmediet Defense News skrev i januar, kan flyets begrnsede rkkevidde i tilflde af en konflikt med Kina tvinge de amerikanske hangarfly inden for rkkevidde af de kinesiske DF21 og DF26 ' carrier killer' mellemdistanceraketter.Ogs Mark Gunzinger fremhver strrelse og rkkevidde som en afgrende forskel mellem femte og sjette generation af kampfly: Jeg er faktisk ikke glad for udtrykket sjettegenerations kampfly, eftersom det antyder, at de kommende fly vil ligne de kampfly, vi kender i dag. Men hvis de nye fly skal kunne undertrykke fjendtlige kampfly og missilsystemer over store afstande og i lngere perioder, skal de muligvis vre meget strre end kampfly i dag og bevbnet med store mngder missiler samt en laser til brug mod jordml og luftml.get rkkevidde krver en strre platform, som muligvis m vre mindre manvredygtig end nuvrende kampfly, siger han.HjenergilasereNetop lasere gr igen i de tre producenters ambitioner for fremtidens kampfly. Air Force Research Laboratory har udsendt udbudsmateriale for et laservben til bevbning af nste generation af kampfly. Herunder en hjenergilaser, der bde kan anvendes mod jordml og mod andre kampfly, og som kan affyres fra op til 20 kilometers hjde og ved en fart p op til Mach 2,5.Hjenergilasere til fly undergr for tiden en rivende udvikling, og som Ingeniren skrev i januar, tester Pentagon og vbenproducenten General Atomics i jeblikket en laser p 150 kW med henblik p at bevbne de store ildstttefly AC130.Ideen med hjenergilasere til kampfly er dels at beskytte mod fjendtlige missiler og kampfly. Laservbens njagtighed bner imidlertid ogs op for offensiv anvendelse, for eksempel lufttiljordangreb mod specifikke kretjer eller enkeltpersoner.En vigtig egenskab for sjettegenerations kampfly er at vende tilbage til den samme hastighed og killing power, som F22 har, og som F35 ganske enkelt mangler. Derudover er der utrolig mange muligheder og stadig meget f visheder. Ud over laservben og fjernbetjening omfatter mulighederne sensorintegrerede intelligente overflader, bedre datafusion og bedre muligheder for samarbejde med andre forsvarssystemer, siger Richard Aboulafia.Pentagon kalkulerer iflge sit budget for 2015 med at fljte et egentligt indkbsprogram i gang i 2018. j.Hvis de nye fly skal kunne undertrykke fjendtlige kampfly og missilsystemer over store afstande og i lngere perioder, skal de muligvis vre meget strre end kampfly i dag.Mark Gunzinger, seniorforsker, tnketanken CSBA.BOEINGS nyeste bud p et sjettegenerations kampfly er dette koncept fra 2013.Flyet kan enten flyves med pilot eller fjernstyres. Pentagon har endnu ikke lagt sig fast p sprgsmlet om bemanding.To motorer ger flyets motorkraft og minimerer konsekvensen af et motorstop.Fravr af haleror og dermed vertikale flader bidrager til flyets begrnsede radarsynlighed. LOCKHEED MARTIN har som den eneste af de tre producenter fastholdt haleror i sit tidlige bud p et kampflydesign.Flyet har multispektral stealth, hvilket reducerer radarsynlighed i flere frekvensbnd. P nuvrende F-35 virker stealth fortrinsvis mellem 8 og 12 GHz.Det har selvhelende egenskaber pga. de flydende epoxymaterialer, der forsegler brud p skroget.Flyet har ' get hastighed', hvilket ikke er yderligere specificeret, men som iflge Lockheed krver nye gennembrud inden for fremdrift og generatorer.NORTHROP GRUMMAN har i december offentliggjort denne visualisering af sit bud p nste generation af kampfly.Flyet har laservben i form af en solid-state-hjenergilaser, der fungerer med stor njagtighed og lysets hastighed, men ger flyets infrarde synlighed.Bagudvinklede vinger som p Northrops bombefly B-2 reducerer luftmodstanden og mindsker effekten af chokblger ved overlydshastighed.
        </div>
        <footer>
          <em>Ingeniren</em>
          &nbsp;&nbsp; 2016-02-05
          &nbsp;&nbsp; e58a8cfb
          &nbsp;&nbsp; #21
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.601</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.627</kbd>
        </footer>
      </article>
      <article>
        <h4>Forskere: Danmark nler med politik for autonome vben</h4>
        <div>
          Amerikanske skibe affyrer de samme mlsgende ESSM-luftmlsmissiler, som det danske forsvar rder over. Missilerne falder iflge en ny rapport indenfor betegnelsen delvist autonome vben. Foto: United States NavyLande som USA og Storbritannien har vedtaget bestemmelser om ikke at overlade beslutninger om ddelig magt til robotter. Det har Danmark ikke, selv om det danske forsvar rder over flere delvist autonome vben.Mens industrien er i fuld gang med at udvikle sofistikerede vbensystemer, der kan udvlge og uskadeliggre deres ml uden menneskelig indblanding, vokser gruppen af bekymrede forskere og fagfolk, som advarer mod at overlade aftrkkeren til maskiner.Ogs i det danske forsvar har vbensystemer med strre eller mindre grad af selvbestemmelse gjort deres indtog. Men hvor lande som USA og Storbritannien har vedtaget direktiver om, at autonome vbens brug af ddelig magt skal vre underlagt menneskers kontrol, har Danmark ingen nedfldet politik p omrdet. Det er p hje tid, at danske poiltikere forholder sig til, hvordan forsvaret skal benytte autonome vben fremover, siger to eksperter i kunstig intelligens.Autonome vben er jo noget, der helt benlyst er p vej. Dermed bliver man ndt til at tage stilling fra politisk hold. For mig at se er der ingen vej udenom: Man kan ikke bare lade det vre op til en given indkbsafdeling eller operativ chef, hvordan Forsvaret bruger den slags teknologi. Og med den udvikling, vi i jeblikket ser inden for kunstig intelligens, er det nu, de danske politikere skal tage stilling,siger Thomas Vestskov Terney, konsulent inden for digital strategi og ph.d. i kunstig intelligens.Vbensystemer i DanmarkFuldt autonome vbensystemer, der udvlger deres ml og foretager angreb uden nogen form for menneskelig indblanding, anvendes stadig ikke af nogen lande, heller ikke Danmark. Men Danmark rder ligesom mange andre lande over en rkke vbensystemer med bestemte autonome funktioner eller med mulighed for autonom anvendelse, skaldte semiautonome systemer.Iflge Forsvarsministeriets Materiel- og Indkbsstyrelse drejer det sig i dag alene om to systemer, og kun i Svrnet: Nrforsvarssystemet til krigsskibe Millennium CIWS (Close-In Weapon Systems) og luftforsvarsmissillerne Evolved Seasparrow Missile System (ESSM).'Flyverstaben rder ikke over sdanne systemer. Svrnet rder over Close in Weapon Systems (CIWS) og missilsystemer, som godt nok har autonome funktionaliteter, men de er ikke implementeret i Svrnet. Det kan dog implementeres hvis vi nsker det,'skriver pressechef Ren Gyldensten fra FMI i en email til Ingeniren.Millennium CIWS beskytter med en 35 mm maskinkanon de danske fregatter mod fjendtlige missiler og fly. Systemet kan selv identificere og flge sine ml, men en menneskelig operatr trffer beslutningen om at bne ild mod potentielle trusler. ESSM-missilerne er mlsgende og kan i slutfasen af flyvningen forflge deres ml med en indbygget radar. Nr de to vbensystemerns autonome funktioner ikke er implementeret i Danmark, er det iflge FMI-s Ren Gyldensten 'alene af den grund, at der ikke er operative krav desangende'.'Vi har ikke en formuleret politik for autonome vbensystemer,'skriver han.Flere vben p listenMen sprger man forskere p omrdet, der definerer vben med autonome funktioner lidt bredere end Forsvarsministeriet, rder det danske forsvar over flere end de to vbensystemer, der lever op til definitionen:Militrforsker Heather Roff fra Arizona State University sammensatte tidligere p ret et register over autonome eller semiautonome vben p verdensplan, og p listen finder man en rkke skaldte fire and forget -missiler, som ogs Danmark rder over. Det er guidede missiler, der efter affyring selv finder deres ml uden behov for styring fra en ildledelsesradar, og som derfor kan ramme deres ml, selv om det er uden for affyringssystemets synsfelt. P listen finder man Flyvevbenets missiler AMRAAM og Sidewinder samt Svrnets Harpoon.Det er helt oplagt, at der er brug for at tage diskussionen om, hvor langt vi vil g i den militre udnyttelse af teknologien. Et eksempel p en tydelig grnse er jo princippet om human in the loop. Men man kunne ogs opstille andre grnser, for eksempel defensiv frem for offensiv brug af vbensystemerne,siger Mikkel Willum Johansen, adjunkt og lektor i videnskabsteori ved Kbenhavns Universitet.Status i andre landeBde Storbritannien og USA har nedfldede politikker p omrdet om netop human in the loop. Det britiske forsvarsministerium skriver i den skaldte Joint Doctrine Note fra 2011, at Storbritannien -aktuelt ikke har nogen intentioner om at udvikle systemer, der kan operere uden menneskelig indblanding i vbenets kommando- og kontrolkde-. Og det amerikanske forsvarsministerium skriver i Direktiv 3000.09 fra 2012, at anvendelsen af autonome vben krver -passende niveauer af menneskelig kontrol over magtanvendelse-.USA og Storbritannien hrer vel at mrke begge til den lille gruppe af lande, der selv udvikler autonome vben, og de to lande rder over vbensystemer med vsentlig hjere grader af autonomi end Danmark. Ingen andre lande har p samme mde nedfldede direktiver p omrdet, men Frankrig bekendtgjorde ved UNHCR's samling i 2013, at det franske forsvar -ikke besidder eller har ikke til hensigt at erhverve robotstyrede vbensystemer med kapacitet til at affyre uafhngigt af mennesker-. Lignende tilkendegivelser kom fra lande som Tyskland, Sverige, Mexico og Japan under FN's konvent om autonome vben i Genve i 2014.Ingenirens ville gerne have talt med forsvarsminister Peter Christensen (V) om sagen, men det har ikke vret muligt. I stedet har ministeriets presseafdeling sendt en skriftlig kommentar, som ikke direkte forholder sig til de to eksperters efterlysning af en dansk politik om autonome vben.'Det er relevant at flge udviklingen p omrdet. Danmarks muligheder for at flge udviklingen p omrdet omfatter blandt andet Nato-samarbejdet, hvor autonome vbensystemer, som militr kapacitet, flges i Nato-sammenhng i Allied Command Transformation,'skriver pressemedarbejder Andreas Reckeweg Godfrey.
        </div>
        <footer>
          <em>Ing.dk (Ingeniren)</em>
          &nbsp;&nbsp; 2016-11-07
          &nbsp;&nbsp; e5f638a9
          &nbsp;&nbsp; #22
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.602</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.574</kbd>
        </footer>
      </article>
      <article>
        <h4>Fremtidens luftrum tilhrer dronesvrmene</h4>
        <div>
          Dronesvrme kommer til at vende op og ned p fremtidens krigsfrelse. Svrmene bringer selv de bedst beskyttede militre ml i fare.Da det amerikanske svrn for fem r siden slap otte sm kamikazedroner ls mod en af sine destroyere i en rkke computersimulerede angreb, var resultatet ildevarslende.Destroyere ligger hjt p listen over strategiske ml og er blandt de bedst beskyttede militre fartjer. Ikke desto mindre kommer skibets avancerede forsvarssystemer til kort over for de sm lavteknologiske droner med improviserede sprnghoveder:De amerikanske destroyere er udstyret til elektronisk krigsfrelse, men skibets AN/SLQ-32-jammere er designet til at beskytte mod krydsermissiler, s de er ikke i stand til at afbryde smdroner uden betydelige opgraderinger. Dronesvrmen benytter ikke infrard mlsgning, s den bider heller ikke p de afledninger i form af brndende magnesiumstave, skaldte flares, som skibet affyrer.Dronerne bliver p grund af deres lave radarsignatur frst opdaget af skibets forsvarssystemer med 15 sekunders varsel, hvilket bringer dem for tt p skibet til at affyre skibets letvgtskanon eller luftforsvarsmissiler, og skibets to manuelt betjente 25 mm maskingevrer er ikke i stand til at ramme s sm ml.Det bedste bud p beskyttelse mod de sm droner er derfor skibets to nrforsvarssystemer. De bestr af to radarstyrede revolverkanoner, som affyrer 4.500 skud i minuttet, og de udgr normalt et krigsskibs sidste forsvarslinje mod fjendtlige missiler. Men selv revolverkanonernes rkkevidde p 1,47 km bliver reduceret mod dronerne, som er meget mindre end antiskibsmissiler.Resultat af de i alt 500 opstillede scenarier er derfor, at fire af de otte droner slipper igennem skibets forsvarssystemer. Selv da forskerne bag rapporten afprvede en rkke scenarier, hvor de amerikanske destroyere fr opgraderet deres forsvarssystemer for flere milliarder dollars, slipper mindst n af dronerne igennem til skibet med sin sprngladning.ndrer billedetMed andre ord m styrker verden over indstille sig p, at nogle af de bedst beskyttede militre ml bliver srbare p en helt anden mde end tidligere.Dronesvrme er formentlig den mest effektive mde at benytte militre droner, ogs nr vi ser p den teknologiske udvikling om 20 r. Det handler ganske enkelt om at overvlde fjendens forsvar, siger Gary Schaub Jr, seniorforsker ved Center for Militre Studier p Kbenhavns Universitet. Han er forfatter til en rkke videnskabelige rapporter om kampfly og senest den frste danske rapport om autonome vben, som blev udgivet tidligere p ret.Det vil frst og fremmest vre stationre eller langsomme ml som militrbaser og krigsskibe, der er srbare for angreb med dronesvrme. Det skyldes, at dronerne er langsomme og har begrnset rkkevidde. Derfor kommer de ogs til at arbejde sammen med strre fartjer, der som en slags moderskibe kan sende en dronesvrm afsted, siger han.Netop dette s vi et eksempel p tidligere i r, da det amerikanske forsvar sendte en svrm af sm Perdix-droner afsted fra tre kampfly, hvorefter dronerne autonomt gennemfrte en rkke simple trningsopgaver.Kunstig intelligens bliver afgrendeBlandt de kendte eksempler er ogs det amerikanske svrns projekt Locust (Low-Cost UAV Swarming Technology), som siden 2015 har flyvetestet dronesvrme p op til 30 enheder, beregnet til at angribe svrt bevbnede ml. Svrmene bestr af de sm Coyote-droner, der er 0,9 meter lange, har en vgt p bare 5,9 kg og et vingespnd p halvanden meter.Man behver rent faktisk ikke at spejde srligt langt ud i fremtiden, for de fleste af komponenterne er allerede p plads, platforme, agilitet, drivkraft, kommunikationssystemer, sensorer, processorer og kontrolalgoritmer, siger Randall Steeb, senioringenir ved den amerikanske forsvarstnketank RAND Corporation, til Ingeniren.Nogle meget specifikke egenskaber er naturligvis stadig under udvikling, men alle de grundlggende egenskaber er p plads nu. Hvis vi ser p den gngse definition af militr swarming, forstet som mange samtidige angreb fra flere retninger mod en strre modstander, kan det godt gres med de eksisterende teknologier, siger han.Bevbnede smdroner som Coyote er stadig delvist autonome, hvilket indebrer, at svrmen styres kollektivt af n dronepilot. De individuelle droner i svrmen selv er i stand til at flyve i formation og skifte placering, hvis en af dronerne bliver delagt. Men efterhnden vil dronepiloternes rolle aftage, og fremtidens dronesvrme vil operere med en hj grad af autonomi. Dermed hnger den teknologiske udvikling inden for dronesvrme ulseligt sammen med udviklingen indenfor kunstig intelligens.Efter min mening har fjernstyring en meget begrnset fremtid inden for swarming, ud over at definere opgaver og eventuelt gribe ind og afblse angreb, for eksempel i tilflde af risiko for civile tab, siger Randall Steeb.Fjernstyring krver langtrkkende kommunikation, hvilket medfrer meget lang responstid og bner srbarheder for elektronisk krigsfrelse eller jamming. Kunstig intelligens er nglen til at indfri det fulde militre potentiale af swarming, siger han.Ingen luftkampeEftersom dronesvrme er srligt velegnede til at uskadeliggre svrt bevogtede militre ml, kan de ogs meget vel udgre et alternativ til de store kampdroner som MQ-9 Reaper og MQ-1 Predator, som i dag spiller en central rolle i amerikanske luftangreb i verdens konfliktomrder. De store droner er langsomme, har en hj radarsignatur og begrnsede muligheder for at beskytte sig, s de er i praksis henvist til at operere i omrder, hvor kampfly i forvejen har etableret luftherredmmet.Derimod vil dronesvrme nppe nogensinde kunne indg i skaldte dogfights i luften, eftersom de med al sandsynlighed ogs fremover vil vre for langsomme til at kunne konkurrere med kampfly.De sm droner er ganske enkelt for langsomme. Hvis dronesvrme skal have nogen anvendelse mod kampfly, bliver det mest sandsynligt i nrheden af deres lufthavne. Hvis man har de forndne oplysninger om, hvor fjendens kampfly letter og lander, kan man jo sende en sky af sm droner op foran kampflyene og hbe p, at en af dem rammer flyet, siger Center for Militre Studiers Gary Schaub Jr.Han peger p, at en ubevbnet hobbydrone for f mneder siden var tt p at nedbringe et af de hjteknologiske femtegenerationskampfly F-22 i USA.Kina lurer i kulissenUSA er ikke alene p banen, nr det kommer til udviklingen af bevbnede dronesvrme.For f mneder siden satte det statsejede China Electronics Technology Group Corporation (CETC) rekord inden for flyvetest af dronesvrme, da selskabet sendte en svrm p 119 droner p vingerne. Og Kina er iflge CETC-s egne udmeldinger p niveau med USA, hvad angr udviklingen af teknologi til dronesvrme.Om de kinesiske meldinger er korrekte eller ej er vanskeligt at vurdere. Men iflge offentliggjorte beretninger fra Pentagon vil det kinesiske forsvar frem til 2023 investere over 10 milliarder dollars i at bygge over 41.000 sm og store droner til bde overvgning og kampoperationer. Til sammenligning rder det amerikanske forsvar i dag over godt og vel 7.000 droner. Og amerikanske Defense Science Board, som rdgiver det amerikanske forsvarsministerium, vurderede for fire r siden, at kinesiske investeringer i droneteknologi indenfor de kommende rtier vil overg de amerikanske.Potentialet for militre dronesvrme begrnser sig imidlertid ikke til angrebsvben, vurderer Randall Steeb.Der er ingen grund til at begrnse anvendelsen af dronesvrme til angreb   selv om der foregr megen udvikling inden for sm kampdroner og meget sm svvevben, s som Spike, Pyros og guidede mortergranater foruden kamikazesystemer som Switchblade. Swarming kan ogs bruges til overvgning, efterretninger, afskrkkelse, kommunikationsnetvrk, endda logistik, med mange sm fartjer, der bevger sig ligesom fiskestimer, der skilles og samles for at minimere tab, siger senioringeniren fra RAND Corporation.Mens det amerikanske svrn i jeblikket arbejder p de motorlse og ubevbnede Cicada-droner, der kan bruges til overvgningsopgaver svel som til vejrmlinger, valgte det britiske forsvar sidste r at udskrive en konkurrence for at finde bud p, hvordan svrme p op til 20 mikrodroner kan bruges til at jamme fjendtlige kommunikationslinjer, flge bestemte individer og rekognoscere.
        </div>
        <footer>
          <em>Ing.dk (Ingeniren)</em>
          &nbsp;&nbsp; 2017-10-22
          &nbsp;&nbsp; e677fe5c
          &nbsp;&nbsp; #23
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.704</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.628</kbd>
        </footer>
      </article>
      <article>
        <h4>Forbud mod kamprobotter krver en katastrofe</h4>
        <div>
          Nr AI styrer fingeren p aftrkkeren, er der efter meget at dmme frre civile ofre i bevbnede konflikter, men et dilemma er, hvornr og hvordan en militr AI vurderes som vrende raffineret nok til at blive anvendt. Illustration: Yacobchuk /Big StockUdbredelsen af autonome kamprobotter p slagmarken tegner til at blive afgjort af i hvor hj grad vi accepterer antallet af civile tab drbt af algoritmer og AI.Det afgrende sprgsml for menneskeheden er i dag, hvorvidt man skal indlede eller forhindre et globalt AI-vbenkaplb. Sdan ld det for to r siden i et protestbrev til FN, i hvilket 3.963 forskere og fagfolk advarede mod at bevbne kunstig intelligens. Brevet affdte international opmrksomhed, ikke mindst p grund af de prominente medunderskrivere som Stephen Hawking, Elon Musk, Apples Steve Wozniak og professor Noam Chomsky.Hvis en given stor militrmagt skubber p udviklingen af vben med kunstig intelligens, er et globalt vbenkaplb stort set uundgeligt, og slutmlet for den teknologiske kurs er indlysende: Autonome vben bliver morgendagens Kalashnikov, skrev de.Rde Kors og Human Rights Watch fulgte op og opfordrede til helt at forbyde al udvikling og anvendelse af fuldt autonome vben.Nu har regeringsreprsentanterne for FN-s medlemslande for frste gang drftet det, der er af de bekymrede fagfolk betegnes som den tredje revolution af krigsfrelse: Anvendelsen af krigsmaskiner, som p baggrund af kunstig intelligens (AI) egenhndigt kan afgre, hvornr der skal skydes for at drbe.Og vil landene og isr de nationale militre stormagter s flge op p forskernes advarsler?Nppe.Rusland skldte ud, USA fremhvede fordeleIngeniren har gennemget oplg og talepapirer fra det just overstede mde i Genve. Her advarede Kina om, at et forbud mod AI i selvstyrende krigsmaskiner ikke mtte forplumre den overordnede udvikling og implementering af AI i almindelige fredelige forml.Rusland harcelerede over, at nogle medlemslande var forvirrede over forskellen p autonome og semi-autonome vben. Rusland havde desuden travlt med at pointere, at de ikke nsker at overlade fingeren p aftrkkeren til en AI-s beslutningskde, men ppegede samtidig, at en sdan beslutning stadig vil kunne spores tilbage til et menneske.Man glemmer, at de maskinens automatiserede funktioner til at identificere og ramme ml er afgjort af et menneske gennem algoritme, ld det i Ruslands talepapir.I et seks sider langt talepapir, prsenteret under mderne i Genve, opstillede USA lutter fordele ved at anvende autonome vben. AI vil markant kunne reducere antallet af civile ofre, som er langt i overtal i de vbnede konflikter. De dr iflge den amerikanske delegation typisk, fordi bomber affyres for uprcist, fordi vi mennesker nu en gang er uprcise og sommetider har vanskeligt ved at holde hovedet koldt.Mange AI-forskere har svrt ved at f denne argumentation til at g op, om end de samtidig peger p et paradoks, som mske ligefrem kan dmme op for brugen af fuldt autonome kamprobotter i klodens militre brndpunkter. For fidusen ved selvlrende algoritmer, alts programmer, der lrer uafhngigt af de data, de kan indsamle, er, at teknologien konstant forbedrer udfrelsen af opgaven.S hvis en autonom bevbnet drone for alvor skal blive bedre til at vre fleksibel, men samtidig forudsigelig nok til at operere sikkert i en kaotisk krigszone gennem en selvlrende algoritme, fordrer det en menneskelig afvejning af et acceptabelt udviklingsstadium, fr det autonome system bliver sluppet ls p slagmarken egenhndigt.Alts en afvejning af, hvornr AI kan udnyttes i sin fulde udstrkning i krig.Inden for militariseret machine learning betyder det, at politiske, militre og industrielle ledere skal specificere, hvor mange civile ddsfald der vil blive opfattet som acceptable, fr AI-en betragtes som vrende raffineret nok, siger professor Peter Lee, direktr for Security and Risk Research ved University of Portsmouth,
        </div>
        <footer>
          <em>Ing.dk (Ingeniren)</em>
          &nbsp;&nbsp; 2018-04-19
          &nbsp;&nbsp; e6b7e651
          &nbsp;&nbsp; #24
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.882</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.625</kbd>
        </footer>
      </article>
      <article>
        <h4>Droner med kunstig intelligens jagtede militssoldater i den libyske borgerkrig</h4>
        <div>
          ISTANBUL Modstandernes soldater blev under den libyske borgerkrig jagtet af selvstyrende droner, og det var med til at vende krigslykken for den FN-stttede regering i Tripoli.Det fremgr af en FN-rapport, der indikerer, at det er det frste kendte eksempel p autonome vben, som er blevet indsat i en aktiv kampsituation og selv har kunnet afgre, hvem der skulle drbes.De tyrkiskfremstillede droner var bl. a. udstyret med ansigtsgenkendelsesteknologi.De blev indsat af den libyske samlingsregering for at drive styrker loyale til den russisk-stttede krigsherre Marshal Khalifa Haftar ud af den libyske hovedstad. Da de begyndte at trkke sig, blev de forfulgt af dronerne. De var i stand til at fortstte missionen selv, efter at de havde bevget sig uden for rkkevidde af en styregruppe.Logistikkonvojer og soldaterne p tilbagetog blev jagtet og angrebet af de ubemandede kampdroner eller autonome vbensystemer ssom STM Kargu-2, fastslr den 548 sider lange rapport fra marts.STM Kargu-2 er en henvisning til en knap 7 kg tung tyrkisk drone, som kan fungere i svrme p op mod 20 droner med henblik p at overvlde modstanderen. Producenten, STM, beskriver det som en propeldrevet angrebsdrone, der kan bruges autonomt eller styres manuelt.De ddbringende autonome vbensystemer var programmeret til at angribe ml uden behov for dataforbindelse mellem operatren og ammunition, fortstter rapporten, der er udarbejdet af et panel af uafhngige eksperter.Den siger dog ikke noget om, hvorvidt dronerne havde succes med at ramme deres ml.Droner er blevet udnyttet som et militrt vben i mere end et rti. USA's tidligere prsident Barack Obama brugte det isr i kampen mod terror, og hans aflser, Donald Trump, udvidede brugen af det i Afrika.Lande som Kina, Rusland og Israel har ogs en flde af droner. Men brugen af intelligente droner i Libyen udstreger, hvor hurtigt teknologien breder sig, og det stiller nye krav til nationale forsvarssystemer.Angriber i svrme Det betyder, at der skal tnkes p en ny mde. Det amerikanske luftvben er f. eks.ved at gennemtnke hele sin mde at operere p, s det kan forsvare sig mod droner.De er billige og mere tilgngelige end kampfly som F-35 og vil i fremtiden formentlig blive brugt til at angribe i svrme, siger Peter Viggo Jakobsen, lektor ved Forsvarsakademiet.Det leverede Tyrkiet i februar 2020 et eksempel p. Styrker fra det syriske regime marcherede med russisk sttte frem mod byen Idlib, som kontrolleres af en oprrsgruppe med tyrkisk sttte. Da et luftangreb drbte flere end 30 tyrkiske soldater, ivrksatte Tyrkiet en offensiv, som inkluderede droner.Dronerne, der blev brugt, var den ligeledes tyrkisk-fremstillede TB2 fra selskabet Baykar. Den larmer ikke srligt meget og er svr at opdage p en radar. De blev hngende i luften i timer, indtil de fandt sprkkerne i modstanderens luftforsvar. Fordi dronerne er relativt billige, kunne forsvaret tage strre risici.Hvis du mister en, to eller tre, er det lige meget, s lnge andre droner rammer mlet, siger Ismail Demir, leder af det statslige kontrolorgan for Tyrkiets vbenindustri, til Wall Street Journal.Da Tyrkiet i 2020 gede sin militre sttte til den libyske regering, brugte den erfaringerne fra Idlib til at forfine taktikken.Senere p ret hjalp tyrkiske droner ogs styrker i Aserbajdsjan med at genvinde kontrollen over dele af Nagorno-Karabakh, som i mere end to rtier har vret i hnderne p russisk-stttede armeniere.Droner er ogs blevet brugt af iransk-stttede grupper i Irak og Yemen til at angribe Saudi-Arabien. De er blevet brugt af Islamisk Stat, der kbte dronedele og selv samlede dem. I 2019 blev tre mnd i Danmark kendt skyldige i at have kbt dele til droner og sende dem til terrorgruppen i Syrien.Det er bl. a. muligt, fordi Kina er blevet en stor eksportr til Mellemsten og Afrika.Mindst 10 lande, ssom Nigeria og De Forenede Arabiske Emirater, har brugt kinesiskproducerede droner til at angribe fjender, vurderer forsvarsanalytikere til Wall Street Journal.Det indikerer alt sammen, at droner er i gang med fundamentalt at ndre p, hvordan lande frer krig.ndrer hele spillet Det har konsekvenser, som ndrer hele spillet, advarede den britiske forsvarsminister, Ben Wallace, i en tale i juli 2020 med henvisning til de tyrkiske droneangreb mod Idlib.I langt de fleste tilflde er der dog tale om droner, som styres af mennesker, med indbyggede kameraer. Men rapporten fra FN indikerer, at kampen om at regulere autonome vbensystemer med kunstig intelligens er ved at blive tabt.Den Internationale Rde Kors Komit appellerede i sidste mned til verdenssamfundet om at lave internationale regler p omrdet, herunder et generelt forbud mod at bruge dem mod mennesker.USA's prsident, Joe Biden, har forud for et besg i Europa, hvor han bl. a. skal deltage i et Nato-topmde, ogs advaret mod truslen fra ny teknologi.I takt med at nye teknologier ndrer vores verden p en fundamental mde, udstiller srbarheder mod angreb fra afpresningssoftware og skaber trusler ssom en indgribende kunstig intelligens-drevet overvgning, m verdens demokratier g sammen for at sikre, at vores vrdier regulerer brugen og udviklingen af dem - ikke autokratiske interesser, skrev han i weekenden i et indlg i avisen Washington Post.heidi.plougsgaard@jp.dk Det har konsekvenser, som ndrer hele spillet.BEN WALLACE, STORBRITANNIENS FORSVARSMINISTER I EN TALE I 2020.Fakta: DRONER SOM VBENI mange lande forskes der i kunstig intelligens i militrt jemed. Udvikling af droner indgr, men droner er typisk ikke i stand til at operere autonomt, men programmeres eller styres af et menneske.USA satte sin frste drone op i midten af 1990' erne over Balkan under krigen i Bosnien. I mange r blev de kun brugt til rekognoscering. Under prsident Barack Obama blev droner, bevbnet med missiler, taget massivt i anvendelse.I krigene i Afghanistan og Irak blev der sat droner ind i masser af aktioner mod terrorledere. I januar 2020 brugte davrende prsident Trump et droneangreb til at drbe general Qassem Soleimani, lederen af Quds-styrken i Irans revolutionsgarde.USA har lnge vret tilbageholdende med at slge sine mest avancerede modeller - selv til allierede. Men som reaktion p droneeksporten fra Kina og andre producenter bldte Trump-regeringen i juli 2020 op p reglerne.
        </div>
        <footer>
          <em>Jyllands-Posten</em>
          &nbsp;&nbsp; 2021-06-08
          &nbsp;&nbsp; e84d6210
          &nbsp;&nbsp; #25
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.561</kbd>
            <kbd data-tooltip="Cyberwarfare &amp; geopolitics">L10_CYBERW&nbsp;0.522</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.622</kbd>
        </footer>
      </article>
      <article>
        <h4>Robotvben vlger selv deres ofre</h4>
        <div>
          P en klar efterrsdag sidste r ud for det sydlige Californiens kyst affyrede et Air Force B-1-bombefly et forsgsmissil, der kan vre et varsel om fremtidens krigsfrelse.Piloterne om bord p flyet styrede til at begynde med missilet, men da det var net halvvejs til mlet, afbrd det kommunikationen med piloterne. Alene og uden menneskelig styring besluttede missilet, hvilket af de tre skibe det skulle angribe.Det sgte ned til en hjde lige over havets overflade og ramte et ubemandet fragtskib p 260 fod.Der bruges stadig mere software til at fre krig. I dag kan bevbnede droner fjernstyres af piloter, der sidder tusinder af kilometer fra krigsskuepladsen og stirrer ind i en skrm. Men iflge nogle forskere har vbenproducenterne nu krydset en grnse og bevget sig ud i et terrn fuldt af faldgruber: De udvikler vben, der bruger kunstig intelligens i stedet for instrukser fra mennesker til at beslutte, hvad der skal angribes, og hvem der skal drbes.I takt med at disse vben bliver mere intelligente og raffinerede, bliver de iflge kritikere stadig vanskeligere for mennesker at styre - og forsvare sig imod. Den store prcision kan redde civile liv, men kritikerne ppeger, at vben uden menneskelig styring kan ge sandsynligheden for krig - det bliver lige s nemt som at trykke p en knap.Ogs Norge bruger dronerStorbritannien, Israel og Norge bruger allerede missiler og droner, der gennemfrer angreb p fjendens radaranlg, kampvogne og skibe uden direkte menneskelig styring. Nr disse skaldte autonome vben er blevet affyret, bruger de kunstig intelligens og sensorer til at udvlge ml og angribe.Briternes ' fyr og glem-missiler' af typen Brimstone kan for eksempel selv skelne mellem kampvogne og biler og busser, ligesom de kan jage ml i et p forhnd de-fineret omrde, uden at mennesker blander sig.Der er vben med endnu mere avanceret selvstyring p tegnebrttet, men detaljerne om dem holdes som regel hemmelige.Der forgr allerede et vbenkaplb inden for autonome vben, siger Steve Omohundru, der arbejder med kunstig intelligens p forskningscentret Self-Aware Systems i Palo Alto i Californien. De er i stand til at reagere hurtigere, mere effektivt og mindre forudsigeligt.FN nsker forbudBekymringen for et robotvbenkaplb var en af grundene til, at reprsentanter for et dusin lande i denne uge mdtes i Genve for at drfte, om der skal indfres begrnsning p denne type vben ved hjlp af FN's konvention om srlige vben.Christof Heyns, FN's srlige rapportr om vilkrlige henrettelser uden forudgende rettergang, krvede sidste r et forbud mod at udvikle disse vben.Det amerikanske forsvarsministerium har udsendt et direktiv, der krver tilladelse fra hjt niveau til at udvikle vben, der kan drbe uden menneskelig styring.Men den hurtige teknologiske udvikling har iflge nogle forskere allerede gjort direktivet forldet.Det, der optager os, er, hvordan angrebsmlene bliver udvalgt, og isr, hvem der udvlger dem, siger Peter Asaro, medstifter og nstformand for International Committee for Robot Arms Control, en gruppe forskere, der nsker restriktioner p brug af militre robotter.Er det mennesker, der har udpeget mlene? Eller beslutter disse systemer selv, hvad mlet er?. Vbenproducenter i USA var de frste, der udviklede avancerede autonome vben.En tidlig udgave af krydsermissilet Tomahawk var i stand til selv at jage sovjetiske skibe p havet uden direkte menneskelig styring. Vbnet blev taget ud af brug i begyndelsen af 1990' erne, efter at der var blevet indget en atomvbenaftale med Rusland.Ramte indisk skibTilbage i 1988 afprvede den amerikanske flde et Harpoon-missil, der anvendte en tidlig form for selvstyringsteknologi. Missilet forvekslede et indisk fragtskib med sit ml. Harpoon-missilet, der ikke var armeret med et sprnghoved, slog ned p fragtskibets bro og drbte et bestningsmedlem.Trods ulykken blev Harpoon en fast bestanddel af fldens arsenal, og det er stadig meget brugt.I de seneste r er kunstig intelligens begyndt at erstatte menneskets beslutninger p en rkke omrder, herunder hurtig aktiehandel, lgelig diagnosticering og sgar i selvkrende biler. Men det er teknologiske fremskridt p tre konkrete felter, der har banet vej for vben, som reelt er selvstyrende.Nye typer af radarer, laser og infrarde sensorer har gjort missiler og droner bedre til at beregne deres position og orientering.' Maskinsyn', der minder om menneskets syn, identificerer mnstre i billeder og hjlper vbnene med at udpege vigtige ml. Disse detaljerede sensordata fortolkes hurtigt af kunstig intelligens og stter missilet eller dronen i stand til selv at foretage en analyse i luften.Det missil, der blev testet ud for Californiens kyst, et langtrkkende antiskibsmissil, udvikles af Lockheed Martin for luftvbnet og flden. Det er beregnet til at flyve hundreder af kilometer og selv manvrere uden om radarsystemer uden radiokontakt med menneskelige operatrer.Direktiv med reglerI et direktiv fra 2012 trak det amerikanske forsvarsministerium en grnse mellem halvautonome vben, hvis ml udvlges af mennesker, og helautonome vben, der kan jage og angribe ml uden at modtage konkrete instrukser om det.Fremtidens vben, hedder det i direktivet, skal konstrueres sledes, at militre beslutningstagere og operatrer har mulighed for i et passende omfang at udve menneskelig dmmekraft i forbindelse med magtudvelse. Alligevel hvder forsvarsministeriet, at det nye antiskibsmissil kun er halvautonomt, og at mennesker er tilstrkkeligt reprsenteret i dets beslutninger om at angribe og drbe. Men hverken hos Defense Advanced Research Projects, der oprindelig udviklede missilet, eller hos producenten, Lockheed Martin, nsker man at kommentere, hvordan vbnet udvlger ml. Det er fortrolige oplysninger, lyder det begge steder.Det vil operere autonomt, nr det sger efter fjendens flde, siger Mark A. Gubrud, der er medlem af International Committee for Robot Arms Control og tidligt advarede mod skaldte intelligente vben. Det her er ganske avancerede sager, som jeg vil kalde kunstig intelligens, der er uden for menneskelig kontrol, siger han.Paul Scharre, en vbenspecialist, der i sin tid var med til at skrive forsvarsministeriets direktiv, siger: Det er relevant at sprge, om det her gr over stregen. Nogle eksperter i vbenkontrol siger, at det er for vagt, nr forsvarsministeriet kun krver menneskelig kontrol i passende omfang over disse vben, og at det er med til at fremskynde udviklingen af nye systemer, der automatiserer drab.Christof Heyns fra FN siger, at lande med avancerede vben br indvilge i at begrnse sig til vbensystemer, der har vsentlig menneskelig kontrol over udvlgelse af og angreb p ml. Det skal svare til den rolle, en militr leder har over for sine soldater, siger Christof Heyns.Og det er ikke tilstrkkeligt med systemer, der giver mennesker mulighed for at omstde computerens beslutninger, tilfjer han. Vben, der trffer egne beslutninger, opererer s hurtigt, at det inden lnge kan blive svrt for menneskelige operatrer at flge med.Ramte otte kampvogne p en gang Norge har planer om at udstyre sin flde af kampfly med Joint Striker-missilet, der uden instrukser fra mennesker kan jage, udpege og angribe et ml. Modstandere af missilet kalder det en drberrobot.Militranalytikere som Paul Scharre siger, at automatiserede vben er et fremskridt, fordi de kan resultere i frre massedrab og civile tab. Den slags vben begr ikke krigsforbrydelser, siger han.16. september 2011 affyrede britiske kampfly for eksempel 24 Brimstone-missiler mod en gruppe libyske kampvogne, der beskd civile. Mindst otte af kampvognene blev iflge en militr talsmand delagt p en gang, hvilket reddede mange civiles liv. Det ville nemlig have vret vanskeligt for menneskelige operatrer at koordinere svrmen af missiler lige s prcist.Bedre og mere intelligente vben er en god ting, hvis de begrnser civile tab og vilkrlige drab, siger han.Oversttelse: Tonny Pedersen.udland@pol.dk Det er relevant at sprge, om det her gr over stregen Paul Scharre, militranalytiker.
        </div>
        <footer>
          <em>Politiken</em>
          &nbsp;&nbsp; 2014-11-15
          &nbsp;&nbsp; e4ac89a3
          &nbsp;&nbsp; #26
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.99</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.664</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.615</kbd>
        </footer>
      </article>
      <article>
        <h4>Google-ansatte vil stoppe militrt samarbejde</h4>
        <div>
          Tusinder af Google-ansatte mener ikke, at firmaet skal associeres med krig.Google har givet Pentagon lov til at bruge noget af deres teknologi til et militrt projekt. Foto: Mark Lennihan/ APAnne FilbertGoogle har givet det amerikanske forsvar lov til at bruge firmaets billedeteknologi til deres militre projekt, der gr under navnet &quot;Maven&quot;. Projekt Maven involverer brug af kunstig intelligens for at kunne forbedre prcisionen af militre droneangreb.Det skriver.De ansatte i Google er dog ikke srligt venligtstillede over for beslutningen om at hjlpe det amerikanske militr med at fre krig. Det skriver de i et bent brev til Googles administrerende direktr, Sundar Pichai.Vi mener, at Google ikke skal vre medvirkende til at fre krig. Netop derfor beder vi om, at projekt Maven bliver droppet, og at Google udarbejder en klar politik om, at hverken Google eller Googles samarbejdspartnere nogensinde vil producere krigsteknologi, skriver de ansatte.
        </div>
        <footer>
          <em>Jyllands-posten.dk</em>
          &nbsp;&nbsp; 2018-04-05
          &nbsp;&nbsp; e6b1428c
          &nbsp;&nbsp; #27
          <br>
          <br>
            <kbd data-tooltip="Tech industry &amp; regulation">L02_BIGTEC&nbsp;0.745</kbd>
            <kbd data-tooltip="EU regulation of big tech">L10_EUREGU&nbsp;0.505</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.569</kbd>
        </footer>
      </article>
      <article>
        <h4>Kamprobotterne kommer</h4>
        <div>
          Den 145 ton tunge ubdsjger glider gennem vandet og scanner havet under sig uden et eneste bestningsmedlem om bord. Finder den et ml, kan Sea Hunter, som det amerikanske forsvars hemmelighedsfulde udviklingsenhed Darpa slap ls sidste r, selv udpege fjendens mest srbare punkter og indlede et angreb. Det m den bare ikke uden grnt lys fra et menneske.Ikke endnu, i hvert fald.USA's politik for autonome vben er formuleret i direktiv 3000.09, som krver, at ddelig magtanvendelse er underlagt passende niveauer af menneskelig vurdering. Det betyder i praksis, at det amerikanske forsvar ikke lader autonome vben angribe uden et menneske in the loop. Det har vret et centralt dogme lige s lnge, som hjteknologiske droner, missilforsvarssystemer og kanontrne har vret udstyret med kunstig intelligens (AI).Men direktiv 3000.09 udlber i r. USA's regering under prsident Donald Trump skal i nste mned tage stilling til, hvordan det amerikanske forsvars regler for anvendelse af kamp robotter skal se ud fremover. Men uanset hvordan det nste femrige direktiv falder ud, er det et sprgsml om tid, fr mennesker overlader kontrollen med aftrkkeren til maskinerne, vurderer Richard Aboulafia, vicedirektr i analysevirksomheden Teal Group og rdgiver inden for militr luftfart: KAMPDRONEN X-47B kan selv lette fra og lande p hangarskibe og kan modificeres til at foretage autonome angreb. Foto: Northrop Grumman Rent faktisk tror jeg, det er uundgeligt, at AInden slipper ud af flasken. Men forhbentlig under begrnsede forhold og omstndigheder, siger han til Ingeniren.I lbet af de nste 30 r vil udviklingen inden for autonomi og kunstig intelligens gradvist gre vbensystemer mere ddbringende.Det kan gre verden til et mere usikkert sted. Heldigvis tager teknologiske gennembrud som AI altid lngere tid at udvikle end forventet.S mske vil menneskeheden n at udvikle de ndvendige betingelser, retningslinjer og endda spredningskontrol for at forhindre de vrste scenarier, siger Richard Aboulafia.Pentagons 2036-plan En rkke offentligt tilgngelige dokumenter viser en konkret forventning hos det amerikanske..krav om menneskelig kontrol over autonome systemer, og fokus er p hastighed, antal og prprogrammerede handlinger. Det vil sandsynligvis affde en hurtigere proces med at f dronesvrme i kamp end hos lande, der arbejder under den vestlige doktrin, siger Peter Roberts.Iflge folkeretsforskere som Michael N. Schmitt og Jeffrey S.Thurnher, der sidste r offentliggjorde en artikel om kunstig intelligens i Harvard National Security Journal, kan udviklingen i andre lande ganske enkelt tvinge Pentagon til at slippe tjlerne p kamprobotter.Med den forventede udvikling i Kina og Rusland kan tempoet p slagmarken blive s hjt, at hverken mennesker eller et tjlet vbensystem kan flge med, skriver de to forskere i artiklen, som Ingeniren ogs omtalte sidste r.... forsvarsministerium om at anvende autonome vben uden menneskelig indblanding inden for en tidsramme p 20 r. Pentagon skriver i sin 25rsplan ' Unmanned Systems Integrated Roadmap 20112036', at man forventer, at ubemandede systemer problemfrit vil operere side om side med bemandede systemer, med en gradvis reduktion af menneskelig kontrol i den ubemandede del af forsvaret. Srligt det amerikanske luftvben har ambitioner p omrdet.US Air Force forventer iflge sin egen ' Unmanned Aircraft Systems Flight Plan 20092047', at kunstig intelligens vil gre det muligt for autonome systemer at bestemme og udfre kamphandlinger uden input fra mennesker. Og her forventer Michael Byers, professor ved University of British Columbia og forfatter til en rkke bger om forsvarspolitik, at droner vil overfldiggre bemandede kampfly inden for levetiden af femtegenerationskampfly som F35.Blandt de nyeste eksempler er amerikanske Northrop Grummans X47B, som selv kan lette fra og lande p hangarskibe og kan modificeres til at foretage autonome angreb.Luftkamp vil nsten med sikkerhed blive autonom, kontrolleret af en form for kunstig intelligens, hvilket rejser nogle vanskelige sprgsml om kontrol og juridisk ansvar, siger Michael Byers til Ingeniren.Derfor bliver udviklingen ogs mdt med stor bekymring fra mange sider, herunder fra specialister i robotter og kunstig intelligens. Det skabte overskrifter verden over, da 3.100 forskere og fagfolk i et bent brev til FN i 2015 advarede mod at bevbne kunstig intelligens. Ikke mindst p grund af de prominente medunderskrivere som Stephen Hawking, Elon Musk, Apples Steve Wozniak og professor Noam Chomsky.Det afgrende sprgsml for menneskeheden er i dag, hvorvidt man skal indlede eller forhindre et globalt AIvbenkaplb.Hvis en given stor militrmagt skubber p udviklingen af vben med kunstig intelligens, er et globalt vbenkaplb stort set uundgeligt, og slutmlet for den teknologiske kurs er indlysende: Autonome vben bliver morgendagens Kalashnikov. () Det vil kun vre et sprgsml om tid, fr vbnene dukker op p det sorte marked og i hnderne p terrorister, diktatorer med nsker om bedre kontrol med befolkningen eller krigsherrer med nsker om etnisk udrensning. Autonome vben er ideelle til opgaver som mord, destabilisering af stater, undertrykkelse af borgere og drab p en bestemt etnisk gruppe, skriver de bekymrede fagfolk, mens Rde Kors og Human Rights Watch opfordrer til helt at forbyde al udvikling og anvendelse af fuldt autonome vben.Skrbelig amerikansk fringHvis USA og andre vestlige lande i de kommende r holder fast i en restriktiv politik for autonome vben, kan lande som Rusland og Kina meget vel overtage frerpositionen p omrdet, siger Peter Roberts, seniorforsker og institutleder ved det anerkendte Royal United Services Institute for Defence and Security Studies i London.Den amerikanskledede vestlige doktrin forudser forelbig ikke, at mennesket tages ud af loopet. Her er fokus p et samarbejde mellem mennesker og maskiner p slagmarken. Den tilgang bygger p monitorering, kontrol og styring af alle handlinger udfrt af autonome systemer. Den strste styrke bliver dermed at kombinere maskinernes kapacitet med den menneskelige evne til at tnke uden for binre, reaktionsbaserede beslutninger og dermed tilfre list og uforudsigelighed, siger han og peger p dronesvrme som eksempel.I kontrast dertil stiller den stlige doktrin - russiske, iranske og kinesiske militre skoler - ingen.Hvad gr Danmark?Hvis det amerikanske forsvar, enten af egen drift eller tvunget af de operationelle realiteter, gr i retning af mere autonome vbensystemer, rejser det ogs en rkke principielle sprgsml for allierede som Danmark. Og de danske politikere burde allerede nu vre i gang med at formulere en politik p omrdet.Det var konklusionen i den frste danske rapport om anvendelsen af autonome vben, som Center for Militre Studier ved Kbenhavns Universitet offentliggjorde i februar.Ud over selve sprgsmlet om at anvende autonome vben i det danske forsvar bliver det ndvendigt at formulere en politik for, hvorvidt allierede styrkers autonome vben m udstationeres p eller passere igennem dansk territorium, og hvorvidt danske styrker m deltage i militre operationer med autonome vben, konkluderer Center for Militre Studier.Forslaget om en dansk politik p omrdet blev imidlertid her i Ingeniren skudt til hjrne af forsvarsminister Claus Hjort Frederiksen (V), som i frste omgang vil flge med i det internationale arbejde p omrdet. Det foregr blandt andet i regi af Nato, der lige nu undersger rammerne for fremtidige internationale operationer.Det danske forsvar rder i forvejen over delvist autonome vben i form af missiler og torpedoer af typen fire and forget, som efter affyring selv kan finde frem til deres ml.Det drejer sig om ESSMluftforsvarsmissiller, Harpoon Block IIantiskibsmissiler, MU90antiubdstorpedoer, luft til luftmissilet AIM120 AMRAAM og luft til jordmissilet AGM 65 Maverick.Ud over USA er det i dag kun Storbritannien, der har en formuleret politik om anvendelsen af autonome vben. Storbritannien producerer vel at mrke selv autonome vben, og bestemmelsen i det britiske forsvarsministeriums skaldte ' Joint Doctrine Note' fra 2011 er lige s lst formuleret som det amerikanske direktiv, idet Storbritannien aktuelt ikke har nogen intentioner om at udvikle systemer, der kan operere uden menneskelig indblanding i vbnets kommandoog kontrolkde. FN besluttede sidste r at oprette den indtil videre eneste mellemstatslige ekspertgruppe med regeringsreprsentanter, der skal diskutere bde de teknologiske, militre, juridiske og etiske implikationer ved at udvikle autonome vben.Den skaldte Group of Governmental Experts on Lethal Autonomous Weapons Systems har sit frste mde i Genve midten af nste mned. j.Luftkamp vil nsten med sikkerhed blive autonom, kontrolleret af en form for kunstig intelligens, hvilket rejser nogle vanskelige sprgsml om kontrol og juridisk ansvar.Michael Byers, professor, University of British Columbia.Ingeniren og ing.dk ser i dag og i nste uge nrmere p de teknologiske udviklinger og udfordringer, der kommer til at forme slagmarken i lbet af de kommende rtier.Dette er frste artikel i serien.
        </div>
        <footer>
          <em>Ingeniren</em>
          &nbsp;&nbsp; 2017-10-06
          &nbsp;&nbsp; e6728638
          &nbsp;&nbsp; #28
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.688</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.555</kbd>
        </footer>
      </article>
      <article>
        <h4>Verdens klogeste hoveder advarer: Autonome vben vil blive morgendagens kalasjnikover</h4>
        <div>
          Lad dig ikke narre af, at denne artikel starter med et sci-fi billede fra filmen Terminator - snart vil vi se rigtige drber-robotter p alverdens slagmarker, hvis vi ikke passer p, mener en rkke af mnd, hvis evne til at se ind i fremtiden overgr de flestes.Fysikeren Stephen Hawking, SpaceX/Tesla-bossen Elon Musk og over 1000 andre af verdens frende eksperter i kunstig intelligens (AI) og robotforskning har underskrevet et brev, hvori de foreslr et forbud mod robot-krig.I brevet advares mod potentialet for voldsom destruktion ved brug af &quot;autonome vben&quot;. Sagt med andre ord: Robotter, der drber p egen hnd vil kunne stte verden i flammer.Hvis n af de strste militrmagter kommer foran i udviklingen af AI-vben, vil et globalt vbenkaplb vre nsten uundgeligt (...)Autonomous Weapons: an Open Letter from AI &amp; Robotics ResearchersBrevet, som mandag den 27. juli blev prsenteret under konferencen International Joint Conference on Artificial Intelligence i Buenos Aires, Argentina, advarede specifikt mod et &quot;AI-vbenkaplb&quot; mellem verdens frende militrmagter. I brevet str:&quot;Kunstig intelligens (AI-teknologi) er net et punkt, hvor implementeringen af sdanne systemer er - praktisk, hvis ikke lovligt - gennemfrlige inden for f r, ikke rtier, og der er meget p spil: Autonome vben er blevet beskrevet som den tredje revolution inden for krigsfrelse, efter krudt og atomvben.&quot;Forskerne argumenterer ikke idealistisk for at stoppe al hjteknologisk krigsfrelse, men vil srge for, at sdanne vben altid bliver udlst af mennesker. Forskernes fokus er sledes p vben, der egenhndigt kan sge og finde ml ud fra forudbestemte kriterier - i modstning til guidede missiler og fjernstyrede droner, hvis brug indbefatter, at mennesker beslutter, hvem de vil ramme.Heraf flger konklusionen, at ingen af verdens strste militrmagter br begynde en jagt p udviklingen af autonome vben. I brevet str:&quot;Hvis n af de strste militrmagter kommer foran i udviklingen af AI-vben, vil et globalt vbenkaplb vre nsten uundgeligt, og slutpunktet p denne teknologiske bane er benlyst: Autonome vben vil blive morgendagens kalasjnikover.&quot;Udover at brevet er underskrevet af Stephen Hawking og Elon Musk, s er der ogs indsamlet signaturer fra Apples med-grundlgger Steve Wozniak, chefen for Googles Deepmind-afdeling, Demis Hassabis, professor Noam Chomsky og Googles research-leder Peter Norvig.Slutteligt str der i brevet:&quot;Vi tror, at AI har stort potentiale til at gavne menneskeheden p mange mder, og mlet br vre at gre dette. At starte et AI-vbenkaplb er en drlig id og br blive prventivt forhindret med et forbud mod autonome vben, der er uden for meningsfuld, menneskelig kontrol.&quot;
        </div>
        <footer>
          <em>Jp.dk (Jyllands-Posten) (Abonnementsomrde)</em>
          &nbsp;&nbsp; 2015-07-28
          &nbsp;&nbsp; e5240286
          &nbsp;&nbsp; #29
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.972</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.662</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.529</kbd>
        </footer>
      </article>
      <article>
        <h4>Militre svrvgtere ruster sig til krig p kunstig intelligens</h4>
        <div>
          USA har f kvababbelser over kunstig intelligens i kamprobotter, Rusland sklder ud p nrmest alle for at misforst autonomi i kamprobotter, og Kina kmper mest af alt for at beskytte sine AI-ambitioner.Stormagterne ser stort potentiale i autonome vbensystemer, der kan gre tempoet p slagmarken s hjt, at mennesker ikke kan flge med. FN har netop afsluttet en uges debat uden at blive enige om restriktioner.Mngden af krudt og kugler var engang udslagsgivende for, hvem der sejrede eller betalte den ultimative pris p slagmarken. Trumfkortet fremover tegner til at blive kredslb og kunstig intelligens.Det indikerer sidste uges FN-diskussioner i Genve. En mellemstatslig ekspertgruppe og regeringsreprsentanter drftede for frste gang officielt det, der bliver betegnet som den tredje revolution inden for krigsfrelse: anvendelsen af krigsmaskiner, som p baggrund af kunstig intelligens (AI) egenhndigt kan afgre, hvornr der skal skydes for at drbe.Blandt oplgsholderne var en rkke forskere, der advarede om at overlade aftrkkeren til kunstig intelligens. Anvendelsen af selvstyrende krigsmaskiner risikerer iflge forskerne at bryde Genvekonventionens regler om beskyttelse af civilbefolkning i krigstid, fordi AI p nuvrende tidspunkt er uforudsigelig.Teknisk set mangler autonome vben de ndvendige komponenter til, at vi kan vre sikre p, at de er i stand til at udvise proportionalitet for at opfylde en opgave i en konflikt. Desuden er deres opfrsel uforudsigelig, srligt i scenarier, hvor flere forskellige AI-er interagerer, ld det fra Lucy Suchman, professor ved Lancaster University, da Ingeniren talte med hende forud for mderne i Genve.USA-s politik for autonome vben er formuleret i direktiv 3000.09, som krver, at ddelig magtanvendelse er underlagt passende niveauer af menneskelig vurdering , men direktivet udlb egentlig sidste r. USA-s fremtidige anvendelse af kamprobotter skal derfor revurderes under prsident Donald Trump.I et seks sider langt talepapir fra Genve opstiller USA lutter fordele ved at anvende autonome vben.Frem for at forsge at stigmatisere eller bandlyse teknologier, der er p vej inden for autonome vbensystemer, br nationerne hellere opfordre til innovation, der fremmer formlet med konventionen, ld det fra USA-s reprsentant.Aftrkkeren bliver programmeretLande som USA, Israel, Storbritannien og Sydkorea rder allerede i dag over skibe eller artillerisystemer baseret p det, man kunne kalde militr machine learning. Uden menneskelig indflydelse er de i stand til at opstve fjender og indlede angreb. Indtil videre skal mennesket dog stadig give grnt lys i beslutningskden.Ruslands prsident, Vladimir Putin, erklrede sidste r, at dn, som formr at vre toneangivende inden for AI, vil styre verden.I Genve fremfrte Rusland dog, at de ikke agter at anvende fuldstndig autonome krigsmaskiner. Men Rusland kritiserede samtidig, at FN-bestrbelserne p at regulere brugen af autonome vben med AI efter Ruslands opfattelse er p vej til ogs at gre brugen af bevbnede droner mindre automatisk af misforstet frygt for og forvirring over at afgive for megen menneskelig medbestemmelse.Man glemmer, at maskiners automatiserede funktioner til at identificere og ramme ml er afgjort af et menneske gennem algoritmer, fremfrte Rusland.Herhjemme lyder samme pointe fra Iben Yde, ph.d. i folkeret og juridisk rdgiver for Forsvarskommandoen. Hun skrev for to r siden sin afhandling om regulering af autonome vben.Den eneste forskel fra konventionelle vben er, at den menneskelige kontrol bliver forskudt fra realtid til at ligge i programmeringsfasen, siger hun til Ingeniren.Iflge Rusland forplumrer mange lande drftelserne, fordi de ikke forstr forskellene p autonome og semi-autonome vben ssom en lang rkke eksisterende mlsgende missiler. Ruslands udsendte understregede derfor, at det er en misforstelse, at fuldt selvstyrende kamprobotter allerede bliver anvendt i militre brndpunkter, og at diskussionen om et forbud bygger p spekulative diskussioner lsrevet fra realiteterne .AI-kaplb tager tilIkke overraskende samtykkede Kina, som tegner til at indtage AI-frertrjen.Iflge folkeretsforskere som Michael N. Schmitt og Jeffrey S. Thurnher, der for f r siden offentliggjorde en artikel om kunstig intelligens i Harvard National Security Journal, kan den forventede udvikling i Kina og Rusland gre tempoet p slagmarken s hjt, at mennesker ikke kan flge med, hvorfor udviklingen ganske enkelt kan tvinge USA til at slippe tjlerne p kamprobotter.Kina ser brugen af AI som ndvendig for at opretholde konomisk vkst, s mulige FN-restriktioner kan stkke landets ambitise AI-agenda.Kina tror, at pvirkningen fra nye teknologier fortjener objektive, upartiske og fyldestgrende diskussioner. Indtil sdanne diskussioner er foretaget, br der ikke indgs nogle prmisser eller forudindtagne resultater, som kan obstruere udviklingen af AI-teknologi, sagde Kinas reprsentant.FN-regeringsreprsentanterne nede ikke til enighed om noget forbud. Gruppen mdes igen i august, men iflge mange af de forskere, som Ingeniren har talt med om sagen, har et forbud mod autonome vben lange udsigter. Kinesiske Hin-Yan Liu har tidligere skrevet artikler om autonome vbensystemer i internationale forskningstidsskrifter og er i dag professor ved Juridisk Institut p Kbenhavns Universitet.Jeg ser absolut ingen chancer for et proaktivt forbud, omend jeg gerne s det, siger han.Verden bliver formentlig ndt til at opleve et afgrende jeblik, der destillerer alle de frygtelige ting, autonome vben legemliggr. Og p en mde, som er relaterbar for offentligheden. Hvis der bliver indfrt et forbud, bliver det p baggrund af en frygtelig ugerning beget af autonome vbensystemer. Jeg hber inderligt, at jeg tager fejl, men mennesker er tilbjelige til frst at lre af deres fejltrin, siger Hin-Yan Liu.
        </div>
        <footer>
          <em>Ing.dk (Ingeniren)</em>
          &nbsp;&nbsp; 2018-04-22
          &nbsp;&nbsp; e6b8b1b1
          &nbsp;&nbsp; #30
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.721</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.604</kbd>
        </footer>
      </article>
      <article>
        <h4>Konvention skal spnde ben for ny drberrobot</h4>
        <div>
          Stop drberrobotterne'. Det er navnet p en international kampagne mod vben, der - uden at mennesker rrer s meget som en knap - kan lokalisere og drbe uvidende fjender.De skaldte drberrobotter er nste skridt i vbenudviklingen efter droner, de ubemandede, fjernstyrede kampfly, som USA i stigende grad gr brug af i blandt andet Yemen og Pakistan.En robot kan ikke skelne mellem civile og kombattanter.Vi har set det rod, droner har skabt, selv nr mennesker styrer dem. Robotter vil beg mange flere fejl, siger Noel Sharkey, professor i robotter og kunstig intelligens p Sheffield University i England.Han str i spidsen for kampagnen ' Stop the Killer Robots', der arbejder for et internationalt forbud, inden teknologien er frdigudviklet. Med sig har han blandt andet organisationen Human Rights Watch og den amerikanske aktivist Jody Williams, der fik Nobels Fredspris for sin kamp mod landminer, samt en rkke internationale organisationer. Mlet er en konvention p lige fod med dem, der forbyder klyngebomber og landminer.Vi vil have et forbud, fr udviklingen nr et punkt, hvor der ikke er nogen vej tilbage, siger Noel Sharkey, der mener, at teknologien vil ligge klar inden slutningen af dette rti. Han frygter derfor, at vbenteknologien nr at udvikle sig s hurtigt, at den overhaler krigens regler indenom, herunder de skaldte rules of engagement og Genvekonventionen.S snart t land har knkket koden, vil de vre overalt, siger han.Nyt vbenkaplb blandt stormagterne Det amerikanske militr tester i jeblikket det ubemandede X-47B, der foruden at flyve hurtigere end lydens hastighed kan lette fra hangarskibe, udfre missioner og lande igen uden menneskelig hjlp undervejs. Ogs England, Rusland og Kina poster mange penge i udviklingen af ubemandede militrfly.Der er et vbenkaplb i gang. Der er stor konkurrence og ekstremt mange penge involveret, siger Noel Sharkey.Herhjemme har Sren Pind, udenrigsordfrer for Venstre, vret blandt de mest kritiske rster i dronedebatten. Han tror ikke p et forbud - hverken mod de eksisterende eller fremtidige droner.Vi bliver ndt til at acceptere, at der hele tiden udvikles nye teknologier. Kunstig intelligens kommer til at indg i alle parametre af vores hverdag, herunder ogs vbenindustrien. Det handler om, at vi skal anvende det forsvarligt og i overensstemmelse med vores kultur, siger Sren Pind.Kampagnen mod drberrobotterne ventes at g i luften for alvor i april, hvor aktivistgruppen bringer sagen for Storbritanniens parlament.Jeg bryder mig ikke om at drbe mennesker generelt, men det her er et skridt for langt, s her vil vi trkke en streg i sandet, siger Noel Sharkey og sender en opfordring p tvrs af Vesterhavet.Vi skal have stoppet det her, og vi vil gerne have Danmark med ind i kampen, slutter han.rasmus.raun@pol.dk Vi har set det rod, droner har skabt, selv nr mennesker styrer dem.Robotter vil beg mange flere fejl Noel Sharkey.
        </div>
        <footer>
          <em>Politiken</em>
          &nbsp;&nbsp; 2013-02-27
          &nbsp;&nbsp; e3acc54c
          &nbsp;&nbsp; #31
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.786</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.571</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.617</kbd>
        </footer>
      </article>
      <article>
        <h4>Det store ubesvarede sprgsml: Hvornr er krigsrobotter autonome?</h4>
        <div>
          Phalanx p de amerikanske krigsskibe kan automatisk registrere og nedskyde fjendtlige missiler, men er systemet af den grund autonomt? Foto: RaytheonImens et hastigt voksende antal stadig mere sofistikerede robotter melder sig ved fronten, intensiveres advarslerne mod at overlade beslutninger om militr magt til maskiner. Men uklarheder om definitionen p autonome vben forvrnger debatten.20. okt 2016 kl. 05:38Kunstig intelligens har net et punkt, hvor indsttelsen af systemer, der uden menneskelig indblanding er i stand til at udsge og eliminere personer p baggrund af en bestemte kriterier, bliver mulig indenfor f r. Ikke rtier. Sdan ld advarslen fra over 3.000 specialister i robotter og kunstig intelligens i et bent brev til FN sidste r. Og indsatsen er iflge de bekymrede fagfolk hj: Autonome vben er blevet beskrevet som den tredje revolution af krigsfrelse, efter krudt og atomvben.Men hvad taler vi om, nr vi taler om autonomi inden for militre systemer, der kan sl ihjel?Det amerikanske forsvarsministerium offentliggjorde for f r siden Direktiv 3000.09, der definerer et selvstndigt vbensystem sledes: Et vben, der, nr det er aktiveret, kan vlge at angribe ml uden yderligere indgriben fra en menneskelig operatr. Den definition omfatter autonome vbensystemer under opsyn, som tillader mennesker at stoppe systemet, men som ogs kan angribe ml uden menneskelig input efter aktivering.I den akronymglade forsvarssektor bruger man betegnelsen LAWS, lethal autonomous weapon systems. Det er systemer, som kan registrere, spore og angribe en person eller en genstand uden menneskelig indblanding. Et eksempel i trd med de bekymrede fagfolks advarsel kunne vre en bevbnet drone med software til ansigtsgenkendelse, som er i stand til at finde og eliminere registrerede terrorister, forklarer Mikkel Willum Johansen, adjunkt og lektor i videnskabsteori ved Kbenhavns Universitet.Vi er ret tt p den forndne teknologi til sdan et system, idet vi efterhnden har de forskellige komponenter: Vi har billedgenkendelsessoftware, vi har frerlse biler med effektiv navigation, og vi har bevbnede droner. Det er p algoritmerne, vi halter efter: Robotterne skal kunne fungere forudsigeligt og sikkert, uden at vi kan komme i kontakt med dem,siger han.En vsentlig skelnen er, at vbensystemer underlagt faste regler, der ikke tillader nogen afvigelser, er automatiserede, ikke autonome. Det ppeger det amerikanske forsvarsministeriums ekspertkomit Defense Science Board i en ny rapport om perspektiverne for autonome vben. For at kunne betegnes som autonomt skal et system have evnen til selvstndigt at indkredse og vlge mellem forskellige handlemuligheder for at opn sit ml, baseret p sin viden og forstelse af verden, sig selv og situationen, skriver Defense Science Board. Derfor giver det for mange vbensystemers vedkommende mening at tale om enkelte autonome funktioner eller semi-autonome systemer, snarere end egentlige autonome systemer.Hvorfor er det vigtigt?Efterhnden som udviklingen af intelligente og autonome vbensystemer tager til, mder udviklingen stadig mere intensiv modstand. Blandt de mangerige kritikere er Stephen Hawking, der ligesom Elon Musk, Apples Steve Wozniak og professor Noam Chomsky er blandt medunderskriverne p sidste rs advarsel fra de mange fagfolk. Ikke mindst har organisationen Human Rights Watch advaret mod autonome vben i rapporten Losing Humanity: The Case against Killer Robots.Det kan der vre god grund til. Som Ingeniren skrev for f dage siden, forstr vi stadig ikke til fulde maskinernes rsonnement, og manglen p forudsigelighed kan blive afgrende for, at mennesker aldrig kommer til at overlade beslutningen om at anvende militr magt til autonome robotter med kunstig intelligens. Det er vurderingen fra topfolk i det amerikanske forsvar, fra rdgiverne i Defense Science Board og fra flere danske specialister, som Ingeniren har talt med.Debatten forplumres imidlertid af forskellige opfattelser af, hvad et autonomt vbensystem er.-Nylige erklringer fra fremtrdende forskere og teknologer forsger at udbrede iden om alvorlige konsekvenser p grund af den hastige implementering af kunstig intelligens og autonome robotter. Nogle af de offentliggjorte udsagn er omhyggelig med at benytte prciseringen fuldt autonome vben, men den skelnen kan let g tabt i kommunikation. Potentialet for en modreaktion mod anvendelse af ikke-ddelige og semi-autonome systemer til militr brug kan derfor vokse,- skriver Defense Science Board i sin rapport om autonomi.Tilsvarende argumenterer de to militrforskere Michael N. Schmitt og Jeffrey S. Thurnher iHarvard National Security Journal for, at debatten om fuldt autonome vbensystemer m holdes adskilt fra vben med ringere grader af autonomi. Og ppeger, at Human Rights Watch i sin rapport alene foreslr at forbyde fuldt autonome vbensystemer. Ikke mindst i medierne bliver autonome vbensystemer omtalt som en ensartet gruppe af systemer med samme st af risici. Herunder ogs danske medier, hvor advarslen fra Stephen Hawking og de bekymrede fagfolk blev citeret bredt sidste r.Den offentlige debat er   ogs p dette omrde   temmelig uprcis. Man er ndt til at skelne mellem fuld og delvis autonomi,siger professor Henrik Gordon Petersen, som forsker i anvendt robotteknologi ved Kbenhavns Universitet.Hvad er s ikke et autonomt vben?Et eksempel p et automatiserede eller delvis autonome systemer, som kun aktiveres under i forvejen fastsatte omstndigheder, er nrforsvarssystemer til krigsskibe, skaldte CIWS (Close-In Weapon Systems). Nrforsvarssystemer beskytter mod indgende missiler ved hjlp af en radarstyret maskinkanon og betegnes som et krigsskibs sidste forsvarslinje, hvis fjendtlige missiler slipper forbi skibets luftforsvarsmissiler. CIWS-systemet Phalanx findes i dag p de fleste amerikanske krigsskibe, mens de danske skibe af Absalon-klassen og Iver Huitfeldt-klassen er udstyret med det skaldte Millennium-system.Nrforsvarssystemer kan bde styres fra operationsrummet og sttes til at reagere selv, hvis de registrerer indgende missiler. Kendetegnende for systemerne er, at de udelukkende bruges til forsvar, og at de er stationre. Systemet angriber ikke uden menneskelig indblanding luftml, der ikke udgr en direkte trussel mod skibet.Sdanne semi-autonome vbensystemer betegnes ogs som systemer med human-in-the-loop og har lnge vret udbredte. Gruppen omfatter ogs en lang rkke fire and forget -vben, som de udbredte missiler Sidewinder, Amraam, Helffire og de nye Brimstone, der efter affyring selv finder og angriber det ml, som en operatr eller kampflypilot har udpeget.Fuldt autonome vbensystemer, der selv udvlger deres ml, betegnes som human-out-of-the-loop. Det er den slags systemer, Human Rights Watch specifikt advarer imod, og de anvendes ikke i dag.Allerede i spilDet betyder ikke, at vbensystemer med kapaciteten til fuld autonomi ikke findes. De anvendes allerede i flere sammenhnge, men de benyttes udelukkende under opsyn, skaldt human-on-the-loop, hvor mennesker har mulighed for at gribe ind i systemets operationer. Et eksempel er Natos ballistiske missilforsvar, hvori det sbaserede kampsystem Aegis, som binder missilforsvarets radarer og missilbatterier sammen, er i stand til at identificere indgende ballistiske missiler og affyre interceptormissiler for at stoppe dem. Men kampsystemets menneskelige operatrer kan vetoe systemets beslutning om at angribe. Tilsvarende er de amerikanske Patriot-batterier og det israelske Iron Dome missilforsvar i stand til at nedskyde missiler uden menneskelig indblanding, men benyttes under menneskeligt opsyn.-Den eneste substantielle forskel mellem disse og fuldt autonome systemer er, at operationerne nje overvges af et menneske, der kan tilsidestte systemets beslutninger,- konstaterer Michael N. Schmitt og Jeffrey S. Thurnher i Harvard National Security Journal.Tilsvarende er en rkke militre systemer med kunstig intelligens under udvikling med henblik p enten human-in-the-loop eller human-on-the-loop, men med de teknologiske forudstninger for at agere selvstndigt. Det amerikanske forsvar har i flere r testfljet den avancerede skibsbaserede drone X-47B, som ved egen hjlp kan lette fra og lande p hangarskibe. Det britiske forsvar udvikler stealth-dronen Taranis, som kan identificere og angribe ml, hvis operatren giver grnt lys.-Selv om disse systemer endnu ikke er designet til at foretage autonome angreb, er det ikke svrt at forestille sig, hvordan sdanne teknologier kan modificeres til at understtte fuldt autonom mlsgning,- skriver Schmitt og Thurnher, som begge er professorer ved United States Naval War College.Nogenlunde samme vurdering lyder fra Henrik Gordon Petersen, om end fuldt autonome vbensystemer har lange udsigter.Man vil i praksis oftest indfre forhndsgivne regler. For eksempel, at en robot kan agere fuldt autonomt indenfor et givent omrde. Eller at systemet under fuld autonomi kan lede efter mlet, men at der ikke kan skydes uden en operatrs tilladelse,siger han.Jeg mener godt, at man i hvert fald i teorien kan forestille sig et fuldstndigt autonomt vbensystem. Med den nuvrende viden om kunstig intelligens og autonomi finder jeg det dog urealistisk at civiliserede lande ville kunne finde p at indfre et sdant system,siger Henrik Gordon Petersen.Fuld autonomi betyder ikke fuld autonomiI sagens natur er heller ikke et vbensystem, der lever op til nrvrende kriterier for fuld autonomi, helt fritaget for menneskelig indblanding. Det ppeger bde Schmitt og Thurnher i deres artikel og Defense Science Board i sin rapport. Systemets udvikler eller operatr bliver som minimum ndt til at programmere det til at operere indenfor bestemte parametre, og operatren trffer den overordnede beslutningen om at indstte systemet i en given operation. Et selvlrende vbensystem bliver trnet af mennesker til et bestemt spektrum af operationer, selvom det ogs kan fortstte med at tilegne sig nye kompetencer under selve operationen.P nuvrende tidspunkt glder for stort set al kunstig intelligens, at det krver masser af menneskelig arbejdskraft. Ved maskinindlring skal man stadigvk i stort omfang bruge data, hvor mennesker har vret involveret i at sortere og kategorisere disse data. Derudover stter menneskerne de overordnede rammer for, hvad systemet skal bruges til, uanset om det er billedgenkendelse, flykontrol, eller brtspil,siger Thomas Vestskov Terney, konsulent inden for digital strategi og ph.d. i kunstig intelligens.Vi er stadig dr, hvor systemerne er virkelig gode under forudstning af, at vi definerer en s snver opgave, at det er muligt for systemet selv at afgre, om det kommer i ml eller ej. Desto mere kompleks den opgave bliver, desto svre er det for systemet at fungere autonomt,siger Thomas Vestskov Terney.
        </div>
        <footer>
          <em>Ing.dk (Ingeniren)</em>
          &nbsp;&nbsp; 2016-10-20
          &nbsp;&nbsp; e5ef6d55
          &nbsp;&nbsp; #32
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.941</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.59</kbd>
        </footer>
      </article>
      <article>
        <h4>Droner med kunstig intelligens jagtede militssoldater i den libyske borgerkrig</h4>
        <div>
          Avancerede tyrkiske droner, der blev brugt i den libyske borgerkrig, fandt selv deres ml, iflge en FN-rapport. Det er formentlig det frste kendte eksempel p brugen af autonome vben i aktiv krigsfrelse.Jyllands-Postens korrespondentISTANBULModstandernes soldater blev under den libyske borgerkrig jagtet af selvstyrende droner, og det var med til at vende krigslykken for den FN-stttede regering i Tripoli.Det fremgr af en FN-rapport, der indikerer, at det er det frste kendte eksempel p autonome vben, som er blevet indsat i en aktiv kampsituation og selv har kunnet afgre, hvem der skulle drbes.De tyrkiskfremstillede droner var bl.a. udstyret med ansigtsgenkendelsesteknologi. De blev indsat af den libyske samlingsregering for at drive styrker loyale til den russisk-stttede krigsherre Marshal Khalifa Haftar ud af den libyske hovedstad. Da de begyndte at trkke sig, blev de forfulgt af dronerne. De var i stand til at fortstte missionen selv, efter at de havde bevget sig uden for rkkevidde af en styregruppe.Logistikkonvojer og soldaterne p tilbagetog blev jagtet og angrebet af de ubemandede kampdroner eller autonome vbensystemer ssom STM Kargu-2,  fastslr den 548 sider lange rapport fra marts.STM Kargu-2 er en henvisning til en knap 7 kg tung tyrkisk drone, som kan fungere i svrme p op mod 20 droner med henblik p at overvlde modstanderen. Producenten, STM, beskriver det som en propeldrevet angrebsdrone, der kan bruges autonomt eller styres manuelt.De ddbringende autonome vbensystemer var programmeret til at angribe ml uden behov for dataforbindelse mellem operatren og ammunition,  fortstter rapporten, der er udarbejdet af et panel af uafhngige eksperter.Den siger dog ikke noget om, hvorvidt dronerne havde succes med at ramme deres ml.Droner som vbenI mange lande forskes der i kunstig intelligens i militrt jemed. Udvikling af droner indgr, men droner er typisk ikke i stand til at operere autonomt, men programmeres eller styres af et menneske.USA satte sin frste drone op i midten af 1990'erne over Balkan under krigen i Bosnien. I mange r blev de kun brugt til rekognoscering. Under prsident Barack Obama blev droner, bevbnet med missiler, taget massivt i anvendelse.I krigene i Afghanistan og Irak blev der sat droner ind i masser af aktioner mod terrorledere. I januar 2020 brugte davrende prsident Trump et droneangreb til at drbe general Qassem Soleimani, lederen af Quds-styrken i Irans revolutionsgarde.USA har lnge vret tilbageholdende med at slge sine mest avancerede modeller - selv til allierede. Men som reaktion p droneeksporten fra Kina og andre producenter bldte Trump-regeringen i juli 2020 op p reglerne. Bl.a. solgte USA i januar 18 MQ-9-droner til De Forenede Arabiske Emirater for knap 3 mia. dollars.Droner er blevet udnyttet som et militrt vben i mere end et rti. USA's tidligere prsident Barack Obama brugte det isr i kampen mod terror, og hans aflser, Donald Trump, udvidede brugen af det i Afrika. Lande som Kina, Rusland og Israel har ogs en flde af droner. Men brugen af intelligente droner i Libyen udstreger, hvor hurtigt teknologien breder sig, og det stiller nye krav til nationale forsvarssystemer.Angriber i svrmeDet betyder, at der skal tnkes p en ny mde. Det amerikanske luftvben er f.eks. ved at gennemtnke hele sin mde at operere p, s det kan forsvare sig mod droner. De er billige og mere tilgngelige end kampfly som F-35 og vil i fremtiden formentlig blive brugt til at angribe i svrme,  siger Peter Viggo Jakobsen, lektor ved Forsvarsakademiet.Det leverede Tyrkiet i februar 2020 et eksempel p. Styrker fra det syriske regime marcherede med russisk sttte frem mod byen Idlib, som kontrolleres af en oprrsgruppe med tyrkisk sttte. Da et luftangreb drbte flere end 30 tyrkiske soldater, ivrksatte Tyrkiet en offensiv, som inkluderede droner.Dronerne, der blev brugt, var den ligeledes tyrkisk-fremstillede TB2 fra selskabet Baykar. Den larmer ikke srligt meget og er svr at opdage p en radar. De blev hngende i luften i timer, indtil de fandt sprkkerne i modstanderens luftforsvar. Fordi dronerne er relativt billige, kunne forsvaret tage strre risici.Hvis du mister en, to eller tre, er det lige meget, s lnge andre droner rammer mlet,  siger Ismail Demir, leder af det statslige kontrolorgan for Tyrkiets vbenindustri, til Wall Street Journal.Det har konsekvenser, som ndrer hele spillet.Ben Wallace, Storbritanniens forsvarsminister i en tale i 2020Da Tyrkiet i 2020 gede sin militre sttte til den libyske regering, brugte den erfaringerne fra Idlib til at forfine taktikken.Senere p ret hjalp tyrkiske droner ogs styrker i Aserbajdsjan med at genvinde kontrollen over dele af Nagorno-Karabakh, som i mere end to rtier har vret i hnderne p russisk-stttede armeniere.Droner er ogs blevet brugt af iransk-stttede grupper i Irak og Yemen til at angribe Saudi-Arabien. De er blevet brugt af Islamisk Stat, der kbte dronedele og selv samlede dem. I 2019 blev tre mnd i Danmark kendt skyldige i at have kbt dele til droner og sende dem til terrorgruppen i Syrien.Det er bl.a. muligt, fordi Kina er blevet en stor eksportr til Mellemsten og Afrika. Mindst 10 lande, ssom Nigeria og De Forenede Arabiske Emirater, har brugt kinesisk-producerede droner til at angribe fjender, vurderer forsvarsanalytikere til Wall Street Journal.Det indikerer alt sammen, at droner er i gang med fundamentalt at ndre p, hvordan lande frer krig.ndrer hele spilletDet har konsekvenser, som ndrer hele spillet,  advarede den britiske forsvarsminister, Ben Wallace, i en tale i juli 2020 med henvisning til de tyrkiske droneangreb mod Idlib.Droner er relativt lette at producere sammenlignet med andre vbentyper, og regionale stormagter kan bruge dem uafhngigt at USA, Rusland eller Kina. For Tyrkiets prsident, Recep Tayyip Erdogan, har det betydet get indflydelse i regionen.Hvis Tyrkiet kan producere dem, kan Israel, Sydkorea og en rkke andre lande ogs. Det viser, hvor hurtigt teknologien spreder sig,  siger Peter Viggo Jacobsen, som ppeger, at det i jeblikket ikke er noget, det danske forsvar har et vrn mod.I langt de fleste tilflde er der dog tale om droner, som styres af mennesker, med indbyggede kameraer. Men rapporten fra FN indikerer, at kampen om at regulere autonome vbensystemer med kunstig intelligens er ved at blive tabt.Den Internationale Rde Kors Komit appellerede i sidste mned til verdenssamfundet om at lave internationale regler p omrdet, herunder et generelt forbud mod at bruge dem mod mennesker.USA's prsident, Joe Biden, har forud for et besg i Europa, hvor han bl.a. skal deltage i et Nato-topmde, ogs advaret mod truslen fra ny teknologi.I takt med at nye teknologier ndrer vores verden p en fundamental mde, udstiller srbarheder mod angreb fra afpresningssoftware og skaber trusler ssom en indgribende kunstig intelligens-drevet overvgning, m verdens demokratier g sammen for at sikre, at vores vrdier regulerer brugen og udviklingen af dem - ikke autokratiske interesser,  skrev han i weekenden i et indlg i avisen Washington Post.Vil du have vores bedste Indblik-artikler direkte i din indbakke? Tilmeld dig gratis og f de fem nyeste artikler fra Jyllands-Postens Indblik-sektion hver dag kl. 16 - klik her, st flueben og indtast din mailadresse
        </div>
        <footer>
          <em>Jyllands-posten.dk</em>
          &nbsp;&nbsp; 2021-06-08
          &nbsp;&nbsp; e84d8a05
          &nbsp;&nbsp; #33
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.536</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.616</kbd>
        </footer>
      </article>
      <article>
        <h4>FN: Autonom kamikaze-drone kan for frste gang have angrebet et menneske</h4>
        <div>
          Dronerne menes at have vret brugt i konflikten mellem rivaliserende militre grupper i den Den Libyske Borgerkrig.Ddbringende og fuldt autonome kamikaze-droner med en eksplosiv ladning kan for frste gang have vret brugt til at angribe mennesker. Hndelsen, som fandt sted under den libyske borgerkrig sidste r, kan vre den frste af sin slags.Det skriver nyhedsmediet New Scientist efter at vre kommet i besiddelse af en ekspertrapport fra FN's Sikkerhedsrd.Mens de fulde detaljer om hndelsen, der fandt sted i Libyen, ikke er frigivet, og det er uklart, om der er nogen tilskadekomne, s antyder hndelsen, at det mske allerede er for sent med den internationale indsats for at forbyde ddbringende autonome vben, inden de tages i anvendelse,  skriver nyhedsmediet.Hndelsen fandt sted i marts 2020. Her skulle en den tyrkisk producerede Kargu-2 quadcopter iflge FN-rapporten af sig selv have jagtet et menneskeligt ml under en konflikt mellem Libyens regeringstropper og den militre udbryderfraktion Libyan National Army anfrt af desertren Khalifa Haftar.Artiklen fortstter under videoen:Flere droner opererede under konflikten i fuldt autonom tilstand med hj effektivitet , som ikke krver nogen som helst menneskelig kontrol, fremgr det af FN-rapporten, hvor der blandt andet str:De ddbringende autonome vbensystemer var programmeret til at angribe ml uden at krve dataforbindelse mellem operatren og vben: I virkeligheden er det en 'affyr, glem og find'-kapacitet. Iflge New Scientist antyder FN-rapporten, at en af dronerne jagtede en soldat under tilbagetrkning.Organisation vil have internationalt forbud mod drberrobotter Det er sandsynligvis frste gang, en drone har angrebet mennesker uden at have fet instruktioner p at gre det, fremgr det af FN-rapporten. Det samme vurderer sikkerhedseksperten, Zak Kellenborn, der specialiserer sig inden for ubemandede vbensystemer og droner, over for New Scientist. Han stiller sprgsmlene:Hvor skrbeligt er systemet til objektgenkendelse? Hvor ofte tager det fejl af ml? Hndelsen viser, at der er et presserende og vigtigt  behov for at diskutere en potentiel regulering af autonome vben, lyder det fra sikkerhedseksperten Jack Watling fra den britiske tnketank inden for forsvar og sikkerhed, Royal United Services Institute (RUSI) til New Scientist.Organisationen Humans Right Watch advarede i august under kampagnen 'Campaign to Stop Killer Robots' om, at autonome drberrobotter  med kunstig intelligens udgr en trussel mod vores civilisation.At fjerne menneskelig kontrol fra anvendelsen af magt betragtes nu bredt som en alvorlig trussel mod menneskeheden, der ligesom klimaforandringer fortjener multilateral handling,  ld det fra Mary Wareham, der er koordinator for kampagnen.En international forbudstraktat er en eneste effektive mde at tackle de alvorlige udfordringer, som fuldt autonome vben rejser,  ld det fra hende i forbindelse med udgivelsen af en rapport , som gennemgr 97 landes stillingtagen til sprgsmlet om vbensystemer, der kan angribe uden menneskelig kontrol.30 lande nsker iflge rapporten fuldstndig at forbyde fuldt autonome vbensystemer.
        </div>
        <footer>
          <em>Ing.dk (Ingeniren)</em>
          &nbsp;&nbsp; 2021-05-31
          &nbsp;&nbsp; e84a47cb
          &nbsp;&nbsp; #34
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.763</kbd>
            <kbd data-tooltip="Cyberwarfare &amp; geopolitics">L10_CYBERW&nbsp;0.651</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.599</kbd>
        </footer>
      </article>
      <article>
        <h4>Udviklere advarer om fremtidens robotkrigsmaskiner</h4>
        <div>
          Udsigterne til fremtidens krigsfrelse fr robotudviklere til at advare FN.Frende robotudviklere er skrmte over fremtidens muligheder for krigsfrelse med kunstig intelligens.Fremtidens krigsteknologi kan lbe fra os, hvis ikke vi bremser den hastige udvikling inden for robotteknologi.Sdan lyder en opsigtsvkkende advarsel fra nutidens robotudviklere i et bent brev til FN.I brevet opfordrer i alt 116 specialister fra 26 forskellige lande mod udviklingen inden for automatiserede vben, skriver den engelske avis The Guardian.- Nr de frst er udviklet, vil ddelige automatiske vben muliggre at armerede konflikter kan blive kmpet i hidtil uset skala, og i tidsforlb der er hurtigere, end mennesker kan begribe.- Det kan vre vben, som tyranner og terrorister bruger mod uskyldige befolkninger, og vben der kan hackes til at opfre sig p unskede mder, lyder det i brevet.Her advarer udviklerne ogs mod, at tiden er nu, hvis der skal handles.- Vi har ikke lang tid til at handle. Nr frst denne Pandoras ske er bnet, vil den vre svr at lukke, lyder det i brevet.Blandt underskriverne af brevet er Teslas topchef, Elon Musk, og Mustafa Suleyma, der har udviklet teknologi inden for kunstig intelligens, som er kbt af Google.Brevet udgives mandag, samme dag som en international konference om kunstig intelligens afholdes i Melbourne i Australien.Medunderskriverne af brevet opfordrer til, at de &quot;moralsk forkerte vben&quot; skal tilfjes til FN's liste over ulovlige vben.En liste der ogs inkluderer kemiske vben og vben med bevist blindende lasere.Eksperter har tidligere advaret mod, at udviklingen inden for kunstig intelligens er net et punkt, hvor det kan bruges i vben inden for f r.Droner er et eksempel p en del af udviklingen inden for automatiserede vben, som specialisterne advarer mod.
        </div>
        <footer>
          <em>Folkebladetlemvig.dk (Lemvig Folkeblad)</em>
          &nbsp;&nbsp; 2017-08-20
          &nbsp;&nbsp; e6612bbb
          &nbsp;&nbsp; #35
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.983</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.716</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.594</kbd>
        </footer>
      </article>
      <article>
        <h4>Forskere slr alarm over drberrobotter</h4>
        <div>
          Forskere boykotter sydkoreansk universitet, der vil lave drberrobotter.Det sydkoreanske universitet Korea Advanced Insitute of Science and Technology (KAIST har tidligere produceret harmlse robotter, der var designet til at efterligne menneskers kropssprog. Foto: APAnne FilbertMere end 50 af verdens frende forskere inden for kunstig intelligens har underskrevet et brev, der eftersprger et boykot af det sydkoreanske universitet Korea Advanced Insitute of Science and Technology (KAIST) og universitetets samarbejdspartner Hanwha System.Grundet til forskernes boykot er, at de frygter, at KAIST er er ved at udarbejde autonomiserede kampvben i samarbejde med forsvarproducenten Hanwha Systems.Og det er iflge forskerne etisk forkert, at udvikle robotter, der kun har til forml at fre krig. Det siger Toby Walsh fra The University og New South Wales, der har organiseret boykotten til The Guardian.En af de ting, man frygter allermest ved de skaldte drberrobotter er, om de ville kunne skelne ven fra fjende. En anden er robotternes prcision.Vbenproducenten Hanwha, der samarbejder med det sydkoreanske universitet, har tidligere skabt urre i diplomatiske situationer. Firmaet producerer blandt andet en form for klyngeammunition, der er banndlyst i 120 lande under en international traktat. Sydkorea, Rusland, USA og Kina har ikke underskrevet traktaten.KAIST siger dog selv til The Guardian, at de ikke har nogen intentioner om at producere ddelige vben. Universitetets prsident, Sung-Chul Shin forsiker om, at der p universitetet er fokus p menneskerettigheder og etik.Et andet sydkoreansk firma Dodaam Systems producerer dog allerede en fuldt autonom &quot;kamprobot&quot;.Robotten kan opdage ml p op til tre kilometers afstand, og virksomhedens kunder inkluderer lande som De Forenede Arabiske Emirater og Qatar. Dodaam System forsikrer dog om, at robotten ikke kan udfre et ddeligt angreb uden menneskelig aktivering.
        </div>
        <footer>
          <em>Jyllands-posten.dk</em>
          &nbsp;&nbsp; 2018-04-05
          &nbsp;&nbsp; e6b12e23
          &nbsp;&nbsp; #36
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.777</kbd>
            <kbd data-tooltip="AI &amp; innovation">L05_INNOAI&nbsp;0.554</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.54</kbd>
        </footer>
      </article>
      <article>
        <h4>Protester og boykot forud for FN-mde om selvstyrende drberrobotter</h4>
        <div>
          En solbrillebrende og lderjakkekldt Arnold Schwarzenegger vandrer mlrettet gennem politistationens snvre gange, mens han sender byger af bly mod de sageslse betjente, der str mellem ham og hans ml: Sarah Connor.Ingen samvittighed, ingen mdehold, kun kold kalkule: Find, drb.Da ' Terminator'-filmen kom ud i 1984, var ideen om en drberrobot, som den T-800 Model 101 Arnold Schwarzenegger portrtterede, ren science fiction. Og selv om menneskemaskiner p to ben med moderigtige lderjakker og drberinstinkt formentlig stadig ligger langt ude i fremtiden, er der ikke lngere tvivl om, at drberrobotterne er p vej.USA, Kina, Rusland, Israel og England frer an i udviklingen af mere eller mindre selvstyrende krigsmaskiner. Droner, jagerfly, tanks og ubde med potentiale til at delgge og sl ihjel uafhngigt af deres menneskelige opfindere.Udviklingen vkker stor bekymring verden over, og derfor mdes mere end 80 lande og adskillige interesseorganisationer i denne uge i Genve til FN's konference om konventionelle vben for at diskutere ddelige selvstyrende vben - de skaldte drberrobotter.Debatten om drberrobotter har taget fart de senere r. Forskere, eksperter og techikoner anfrt af prominente navne som Elon Musk og den nu afdde Stephen Hawking har flere gange offentligt efterspurgt et forbud mod at udvikle og bruge selvstyrende krigsrobotter.Senest opfordrede mere end 50 forskere i kunstig intelligens til boykot af det sydkoreanske universitet Kaist, fordi universitetet samarbejder med en sydkoreansk virksomhed om at udvikle vbensystemer med kunstig intelligens.Og i onsdags kunne avisen The New York Times prsentere et internt brev sendt af flere end 3.000 Google-ansatte til Googles verste chef, Sundar Pichai. I brevet tryglede de ansatte direktren om at annullere Googles aftale om at udvikle intelligente overvgnings-og mludvlgelsessystemer for det amerikanske forsvar.At skabe denne teknologi til at hjlpe den amerikanske regering med militr overvgning - med potentielt ddelige konsekvenser - er ikke acceptabelt, skrev de ansatte i brevet.Moral og sikkerhedEn af deltagerne ved FN-mdet i denne uge er roboteksperten Noel Sharkey. Ud over at vre professor emeritus i robotteknologi ved University of Sheffield har han som talsmand for kampagnen ' Stop Killer Robots' i revis kmpet for et FNforbud mod selvstyrende krigsrobotter.Vi bliver ndt til at f et internationalt forbud mod udviklingen og brugen af selvstyrende krigsrobotter, inden de bliver taget i brug, siger Noel Sharkey.Det er isr to ting, der bekymrer de kritikere, der kalder udviklingen af intelligente drbermaskiner for den tredje store vbenrevolution. Den frste var brugen af krudt, den anden opfindelsen af atomvben.Det frste kritikpunkt er det moralske.At robotter selvstndigt kan tage beslutninger om, hvorvidt et menneske skal d eller leve, er helt basalt moralsk forkert, mener Noel Sharkey. Robotter hverken kan eller skal vurdere, hvornr mlet helliger midlet i komplekse og uforudsigelige militre situationer.Der er ikke nogen algoritme til at udregne, om det eksempelvis er vrd at drbe Osama Bin Laden, hvis det ogs koster 25 gamle damer eller 10 sm brn livet.Det er ikke scenarier, man kan forudsige, det krver en erfaren befalingsmand p stedet at trffe den slags beslutninger, siger Noel Sharkey.Den anden store bekymring handler om global sikkerhed. Kritikerne frygter, at udviklingen af drberrobotter risikerer at ende i et selvdestruktivt vbenkaplb, hvor store nationer konkurrerer om hurtigst at udvikle nye og endnu mere destruktive robotter. Samtidig risikerer de sofistikerede vben ogs at ende i hnderne p skruppellse diktatorer og terrorister, hvor de kan volde stor delggelse.Men det mske vrst tnkelige scenario er, at et selvstyrende vbensystem kan starte en unsket konflikt, fordi det trffer valg p baggrund af dets programmering og ikke har et menneskes nuancerede overvejelser.Der findes mange eksempler p, at man har undget, at konflikter er udbrudt eller eskaleret, fordi mennesker med fingeren p aftrkkeren er get imod deres trning og ordrer og har udvist mdehold. Det kan man ikke forvente, at en forudprogrammeret robot vil gre, advarer Noel Sharkey.Drberrobot eller krigsmaskineNr det i lyset af den slags argumenter stadig er svrt at blive enig om, hvordan udviklingen og brugen af krigsrobotter skal reguleres, er det blandt andet, fordi der er stor uenighed om, hvordan en drberrobot skal defineres.Alle de vigtigste robotudviklende nationer siger, at de heller ikke nsker selvstyrende krigsrobotter. Men hvis man kigger p, hvordan de enkelte lande defi-nerer, hvad det vil sige at vre ' selvstyrende', bliver billedet mere mudret, siger Robin May Schott, der forsker i krigsrobotter ved Dansk Institut for Internationale Studier.S fr vi kan f en robust international lovgivning om, hvordan de her vben m udvikles og bruges, skal vi blive enige om, hvordan de defineres. De fleste nationer argumenterer med USA i spidsen for, at en krigsmaskine ikke er selvstyrende, s lnge et menneske har betydelig kontrol over den, heller ikke selv om den selv kan identificere og angribe et ml. Men hvad er ' betydelig menneskekontrol'? Krver det meget snvre parametre for, hvad der kan angribes og under hvilke forhold? Eller er det nok med blot brede missionsbetegnelser, som ' drb alle mnd, der brer trklde og vben' eller ' skyd p enhver, der prver at krydse grnsen'? Vi foreslr i stedet, at et ddeligt selvstyrende vben defineres som en maskine, der p egen hnd kan foretage de to afgrende krigsfunktioner: identificere og angribe ml, siger Robin May Schott, der har forsket i netop definitionssprgsmlet sammen med sine kollegaer Johannes Lang og Rens Van Munster.Med andre ord er der tale om en drberrobot, hvis et vben ikke har brug for et menneskes je ved sigtekornet eller et menneskes finger p aftrkkeren.Af de mere end 80 nationer, der deltager i mderne i Genve i denne uge, gr 22 ind for et totalt forbud af drberrobotter ud fra denne definition. De fleste af disse er udviklingslande, som formentlig vil vre blandt de sidste, der fr fingrene i den avancerede vbenteknologi.Der vil ikke blive truffet nogen endelige beslutninger om regulering i denne uge, men planen er, at der skal formuleres forslag til tiltag, som der s skal forhandles om nr nationerne mdes igen senere i 2018. Den danske regering deltager ikke i diskussionerne.jeppe.valeur@pol.dk Fakta: FAKTA DrberrobotterFlere lande arbejder p at udvikle mere eller mindre selvstyrende vben og krigsrobotter.USA arbejder blandt andet p ubde, fly og svrme af droner, der selvstndigt kan udpege angrebsml.Israels grnser beskyttes allerede af ubemandede kretjer og droner, som hele tiden bliver mere selvstyrende.Rusland arbejder p at udvikle og serieproducere verdens mest avancerede selvstyrende tank.
        </div>
        <footer>
          <em>Politiken</em>
          &nbsp;&nbsp; 2018-04-09
          &nbsp;&nbsp; e6b2222d
          &nbsp;&nbsp; #37
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.777</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.58</kbd>
        </footer>
      </article>
      <article>
        <h4>Autonome droner giver krigens regler kamp til stregen</h4>
        <div>
          Eksperter advarer om nye intelligente vbensystemer, der gr det svrt at placere ansvaret, nr byer bliver bombet. Vi er ved at krydse en grnse, lyder det.Menneskets synlige tilstedevrelse p slagmarken er ikke det eneste, som er ved at forsvinde i takt med fremmarchen af droner. Eksperter verden over advarer ogs om, at nye vbensystemer gr, at menneskelige beslutninger i disse r bliver overtaget af software.I FN opfordrer den srlige rapportr p omrdet, Christof Heyns, til et stop for udvikling af de intelligente vbensystemer, og amerikanske militranalytikere udtrykker i medierne bekymring over, hvad de kalder et 'vbenkaplb i autonome vbensystemer'. Herhjemme flger forskere ogs udviklingen med bekymrede miner, for robotterne befinder sig i en voksende juridisk grzone i forhold til den humanitre folkeret, der regulerer, hvad man m - og ikke m - i krig.For hvornr handler et system s meget p egen hnd, at det kan betegnes som autonomt? Det er det centrale juridiske sprgsml, mener ph.d.-stipendiat ved Juridisk Institut p Aarhus Universitet Iben Yde, hvis afhandling netop omhandler legaliteten af autonome vbensystemer.Hvor hj grad af 'selvbestemmelse' skal der vre, fr de falder i denne her kategori af problematiske vben? Jeg har siddet tre r med min afhandling nu, og jeg er ikke i stand til at stte det skel, siger hun.I dag er de intelligente vbensystemer allerede vidt udbredt - de kommer isr fra amerikanske producenter, men ogs Storbritannien, Norge og Israel har systemerne eller er i fuld gang med udviklingen. Lockheed Martin har udviklet anti-skibsmissilet LRASM, der af Human Rights Watch og medlemmer af den internationale komit for robotvben (ICRAC) betegnes som en forlber for fuldt automatiserede vben.LRASM udvlger selv sit ml og beregner sin egen rute uden om antiluftskyts. US Navy har ogs ssat hurtigtgende, selvstyrende speedbde, der ved brug af software-arkitekturen CARACaS (Control Architecture for Robotic Agent Command and Sensing) kan koordinere deres bevgelser, omringe og p sigt tilintetgre fldefartjer, der kommer for tt p krigsskibe.Israel str bag antiradar-vbnet Harpy. Harpy er en to meter lang drone, der bliver affyret fra et militrt kretj og flger en forprogrammeret rute, mens den scanner jorden under sig for fjendtlige radarsystemer - parat til at angribe.Fra det jeblik, Harpy er sendt af sted, er den ikke under menneskelig kontrol. Hvis en radar p jorden bliver aktiveret, opfanger dronen signalet og forsger at matche signalet med en database med godkendte ml. Er der match, styrtdykker dronen og indleder sit kamikazeangreb.Men sprgsmlet for jurister - isr i USA, hvor man bryster sig af, at ethvert angreb er funderet i en klar juridisk formulering - er, om et fuldgyldigt autonomt vbensystem kan operere lovligt under gldende international ret.For som professor i menneskerettigheder og FN's srlige rapportr Christof Heyns slog fast i maj sidste r, risikerer vi at 'ende p den forkerte side af grnsen, og til den tid er det meget svrt at vende tilbage. Hvis der nogensinde er et oplagt tidspunkt at regulere og stoppe disse vben p, er det nu', som han sagde under et FN-mde i Genve.Det er dog ikke utnkeligt, at et fuldstndigt autonomt vbensystem kan operere lovligt under gldende international ret, mener Iben Yde. Hun ppeger dog, at teknologien endnu ikke er tilstrkkelig til at foretage de ndvendige nuancerede menneskelignende skn.Men hvis et vbensystem i fremtiden selv selv skal st for mludpegning og beslutninger om angreb, skal det kunne opretholde to helt grundlggende principper for at leve op til kravene for militre angreb under den humanitre folkeret, forklarer hun.P trods af slagmarkens brutale virkelighed foreskriver krigens regler nemlig, at militre handlinger i mindst muligt omfang skal g ud over civile, uanset hvem eller hvad der trykker p aftrkkeren, og det reguleres i henholdsvis 'distinktionsprincippet' og 'proportionalitetsprincippet'.Hvis autonome vbensystemer kan handle i overenstemmelse med de to brende principper, er vbensystemerne ogs lovlige at bruge i krig, lyder Iben Ydes vurdering.Civile m ikke vre direkte ml for et militrt angreb, og distinktionsprincippet foreskriver derfor, at et automatiseret vben skal vre i stand til at skelne militre ml fra civile, inden det angriber.Men det krver en 'situationsfornemmelse', der omtrent er p hjde med menneskers, og der har vi endnu lang vej, fr vi nr det teknologiske niveau med kunstig intelligens, siger Iben Yde.For det andet skal systemerne ogs kunne tage stilling til den mere moralsk flydende problemstilling, der ligger i at overholde proportionalitetsprincippet, hvor unskede civile tab skal holdes op mod angrebets strategiske fordel.Men selv om civile ikke m vre direkte ml, bner folkeretten for en accept af civile ddsfald. De skal bare vre proportionelle med den militre strategiske fordel ved at angribe.Den afvejning er ogs vanskelig for mennesker, der jo heller ikke har en fast standard for, hvad der er rigtigt at gre i sdan en situation, siger Iben Yde.I dag findes der ingen regulering eller juridisk definition af autonome vbensystemer under de internationale love. Begrebet autonomi kan nemlig defineres s snvert, at udfaldet af systemets egne beslutninger nrmest er forudsigeligt.Flere eksisterende amerikanske droner kan allerede indstilles til at operere autonomt, men p grund af vbenproducenternes hemmelighedskrmmeri str det ikke klart, om dronerne eksempelvis er i stand til selv at udpege ml og tage beslutning om angreb.Men hvis dronerne besidder disse egenskaber, vurderer Iben Yde, at det under ekstremt skrpede omstndigheder ville vre lovligt at give dronen ret til selv at angribe p egen hnd.Hun forklarer, at en lang rkke forbehold ville gre sig gldende, ssom at dronen udelukkende m g efter materielle ml i afsides omrder, hvor der ingen risiko er for at ramme civile ml.Stram programmeringSom eksempel p et delvist selvbestemmende vbensystem nvner Iben Yde antiluftskyts-systemet Phalanx, som sidder p stort set alle britiske og amerikanske krigsskibe. Systemet kan sttes op til selv at detektere, spore og angribe indkommende missiler uden menneskelig indblanding.Systemet forsger bl.a. at tage radiokontakt for at sikre, at det ikke er et civilt fly, det er ved at skyde ned, og tager en lang rkke andre forbehold, inden det angriber.Et menneske kunne aldrig n at foretage s mange vurderinger p s kort tid, s jeg mener ikke, det er det, vi skal forbyde, siger Iben Yde, der som jurist ser en fremtid, hvor robotterne bliver stramt programmeret og holdt i kort snor.Det samme billede i krystalkuglen ser Thomas Bolander, der forsker i kunstig intelligens ved DTU.Som teknologien er i dag, skal du instruere robotten i alle de regler, den skal efterleve, men du skal ogs programmere samtlige undtagelser, som i kampens hede ofte beror p et subjektivt skn. Fjendens uniform er mske det, som for robotten definerer, hvad der m skydes p, og hvad der ikke m, men hvis et barn var kldt i fjendens uniform, ville et menneske mske ikke skyde, mens robotten i den situation ikke ville gre forskel, siger Thomas Bolander og fortstter:Det kan man selvflgelig tage forbehold for, men hvem kan garantere, at det program, man begynder at skrive, tager hjde for samtlige ting? Ved den ene yderlighed kan det betyde, at robotter udgr en stor risiko i forhold til at beg frygtelige fejl, eller ogs bliver de s forsigtige, at man kan diskutere, hvor interessante de s er at benytte, siger han.Han slr fast, at der endnu er meget lang vej, fr det bliver muligt at skabe fuldgyldige autonome systemer, der kan bruges i komplekse situationer, som krig ofte er, s drberrobotterne invaderer ikke slagmarken lige forelbigt.Dybest set forstr vi ikke, hvordan vi skal lave menneskelignende intelligens p en computer. Det er ikke engang sdan, at man kan sige, at vi er godt p vej, for det er en nd, vi simpelthen ikke har knkket endnu, siger Thomas Bolander.Er drberrobotter sikre?I FN har man diskuteret lovligheden af ddbringende autonome vbensystemer de seneste to r, men er endnu ikke net frem til, om de autonome droner skal p listen over vben, der er forbudte at anvende i krig.FN afholdt i maj et ekspertmde om emnet og inviterede blandt andre Paul Scharre, der leder et mangerigt forskningsprojekt, som skal kortlgge fremtidens krigsfrsel for den uafhngige organisation Center for a New American Security.Han arbejder p at finde ud af, hvilken rolle autonome robotter kommer til at spille i fremtidens krig, og mener, at vi i jeblikket str midt i en revolution inden for robotik - bde civil og militr - og det krver, at vi som verdenssamfund forholder os til perspektiverne i den nye teknologi.Mange vil hvde, at der ikke findes ddbringende autonome vbensystemer. Det er ikke sandt, nr man ser isoleret p funktionaliteten 'beslutning om udvlgelse af ml'. De er ikke i brug mange steder, men der er et lille antal systemer i brug i dag, som udfrer denne funktion, fortalte Poul Scharre til de officielle reprsentanter fra mere end 25 lande og nvnte blandt andet Harpy-systemet som eksempel.Under den kolde krig, forklarede han, var der automatiske detektionssystemer p begge sider, der ved flere lejligheder fejlagtigt troede, at et atomangreb var undervejs. Dengang var det indgreb fra mennesker i beslutningskden, der sikrede, at en global atomkrig ikke blev udlst.Der er et presserende behov for, at verdens nationer tnker over, hvordan man garanterer, at autonome vben er sikre og bruges p en sikker mde. Det er et ansvar, der phviler enhver stat, at garantere sin egen sikkerhed, men utilsigtet krig kan ikke komme nogen til gode, sagde Paul Scharre.Set fra den modsatte pol har selvbestemmende robotter ogs interessante perspektiver i forhold til at gre slagmarken mere human. Robotter handler aldrig p flelser og instinkter, og fortalere vil mene, at de kyniske robotter ikke vil vre i stand til at beg krigsforbrydelser.Den humanitre folkeret har primrt til forml at beskytte ofre for krig - og her menes primrt civile, der kan blive fanget i krydsilden. Hvis man kan lave autonome vbensystemer, som kan yde en bedre beskyttelse, s kan man argumentere for, at vi er moralsk og politisk forpligtede til at videreudvikle denne slags systemer, ville jeg mene, siger Iben Yde.Lockheed Martins LRASM-missil..Det israelske antiradar-vben Harpy..Antiluftskyts-systemet Phalanx..Luft-til-jord-missilet Brimstone opererer autonomt, nr frst det er affyret..Lockheed Martins LRASM-missil..Det israelske antiradar-vben Harpy..Antiluftskyts-systemet Phalanx..Luft-til-jord-missilet Brimstone opererer autonomt, nr frst det er affyret..
        </div>
        <footer>
          <em>Ing.dk (Ingeniren)</em>
          &nbsp;&nbsp; 2014-12-20
          &nbsp;&nbsp; e4bb32fa
          &nbsp;&nbsp; #38
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.984</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.631</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.64</kbd>
        </footer>
      </article>
      <article>
        <h4>AUTONOME DRONER UDFORDRER KRIGENS REGLER Nr vben bestemmer over liv og dd</h4>
        <div>
          Menneskets synlige tilstedevrelse p slagmarken er ikke det eneste, som er ved at forsvinde i takt med fremmarchen af droner. Eksperter verden over advarer ogs om, at nye vbensystemer gr, at menneskelige beslutninger i disse r bliver overtaget af software.I FN opfordrer den srlige rapportr p omrdet, Christof Heyns, til et stop for udvikling af de intelligente vbensystemer, og amerikanske militranalytikere udtrykker i medierne bekymring over, hvad de kalder et ' vbenkaplb i autonome vbensystemer'. Herhjemme flger forskere ogs udviklingen med bekymrede miner, for robotterne befinder sig i en voksende juridisk grzone i forhold til den humanitre folkeret, der regulerer, hvad man m - og ikke m - i krig.For hvornr handler et system s meget p egen hnd, at det kan betegnes som autonomt? Det er det centrale juridiske sprgsml, mener ph. d.-stipendiat ved Juridisk Institut p Aarhus Universitet Iben Yde, hvis afhandling netop omhandler legaliteten af autonome vbensystemer.Hvor hj grad af ' selvbestemmelse' skal der vre, fr de falder i denne her kategori af problematiske vben? Jeg har siddet tre r med min afhandling nu, og jeg er ikke i stand til at stte det skel, siger hun.I dag er de intelligente vbensystemer allerede vidt udbredt - de kommer isr fra amerikanske producenter, men ogs Storbritannien, Norge og Israel har systemerne eller er i fuld gang med udviklingen.Lockheed Martin har udviklet anti-skibsmissilet LRASM, der af Human Rights Watch og medlemmer af den internationale komit for robotvben (ICRAC) betegnes som en forlber for fuldt automatiserede vben.LRASM udvlger selv sit ml og beregner sin egen rute uden om antiluftskyts. US Navy har ogs ssat hurtigtgende, selvstyrende speedbde, der ved brug af software-arkitekturen CARACaS (Control Architecture for Robotic Agent Command and Sensing) kan koordinere deres bevgelser, omringe og p sigt tilintetgre fldefartjer, der kommer for tt p krigsskibe.Og endelig er der Israels antiradar-vben Harpy.Harpy er en to meter lang drone, der bliver affyret fra et militrt kretj og flger en forprogrammeret rute, mens den scanner jorden under sig for fjendtlige radarsystemer - parat til at angribe.Fra det jeblik, Harpy er sendt af sted, er den ikke under menneskelig kontrol. Hvis en radar p jorden bliver aktiveret, opfanger dronen signalet og forsger at matche signalet med en database med godkendte ml. Er der match, styrtdykker dronen og indleder sit kamikaze angreb.Men sprgsmlet for jurister - isr i USA, hvor man bryster sig af, at ethvert angreb er funderet i en klar juridisk formulering - er, om et fuldgyldigt autonomt vbensystem kan operere lovligt under gldende international ret.For som professor i menneskerettigheder og FN's srlige rapportr Christof Heyns slog fast i maj sidste r, risikerer vi at ' ende p den forkerte side af grnsen, og til den tid er det meget svrt at vende tilbage.Hvis der nogensinde er et oplagt tidspunkt at regulere og stoppe disse vben p, er det nu',..... som han sagde under et FNmde i Genve.Det er dog ikke utnkeligt, at et fuldstndigt autonomt vbensystem kan operere lovligt under gldende international ret, mener Iben Yde. Hun ppeger dog, at teknologien endnu ikke er tilstrkkelig til at foretage de ndvendige nuancerede menneskelignende skn.Men hvis et vbensystem i fremtiden selv selv skal st for mludpegning og beslutninger om angreb, skal det kunne opretholde to helt grundlggende principper for at leve op til kravene for militre angreb under den humanitre folkeret, forklarer hun.P trods af slagmarkens brutale virkelighed foreskriver krigens regler nemlig, at militre handlinger i mindst muligt omfang skal g ud over civile, uanset hvem eller hvad der trykker p aftrkkeren, og det reguleres i henholdsvis ' distinktionsprincippet' og ' proportionalitetsprincippet'.Hvis autonome vbensystemer kan handle i overenstemmelse med de to brende principper, er vbensystemerne ogs lovlige at bruge i krig, lyder Iben Ydes vurdering.Civile m ikke vre direkte ml for et militrt angreb, og distinktionsprincippet foreskriver derfor, at et automatiseret vben skal vre i stand til at skelne militre ml fra civile, inden det angriber.Men det krver en ' situationsfornemmelse', der omtrent er p hjde med menneskers, og der har vi endnu lang vej, fr vi nr det teknologiske niveau med kunstig intelligens, siger Iben Yde.For det andet skal systemerne ogs kunne tage stilling til den mere moralsk flydende problemstilling, der ligger i at overholde proportionalitetsprincippet, hvor unskede civile tab skal holdes op mod angrebets strategiske fordel.Men selv om civile ikke m vre direkte ml, bner folkeretten for en accept af civile ddsfald. De skal bare vre proportionelle med den militre strategiske fordel ved at angribe.Den afvejning er ogs vanskelig for mennesker, der jo heller ikke har en fast standard for, hvad der er rigtigt at gre i sdan en situation, siger Iben Yde.I dag findes der ingen regulering eller juridisk definition af autonome vbensystemer under de internationale love. Begrebet autonomi kan nemlig defineres s snvert, at udfaldet af systemets egne beslutninger nrmest er forudsigeligt.Flere eksisterende amerikanske droner kan allerede indstilles til at operere autonomt, men p grund af vbenproducenternes hemmelighedskrmmeri str det ikke klart, om dronerne eksempelvis er i stand til selv at udpege ml og tage beslutning om angreb.Men hvis dronerne besidder disse egenskaber, vurderer Iben Yde, at det under ekstremt skrpede omstndigheder ville vre lovligt at give dronen ret til selv at angribe p egen hnd.Hun forklarer, at en lang rkke forbehold ville gre sig gldende, ssom at dronen udelukkende m g efter materielle ml i afsides omrder, hvor der ingen risiko er for at ramme civile ml.Stram programmeringSom eksempel p et delvist selvbestemmende vbensystem nvner Iben Yde antiluftskyts-systemet Phalanx, som sidder p stort set alle britiske og amerikanske krigsskibe.Systemet kan sttes op til selv at detektere, spore og angribe indkommende missiler uden menneskelig indblanding.Systemet forsger bl. a. at tage radiokontakt for at sikre, at det ikke er et civilt fly, det er ved at skyde ned, og tager en lang rkke andre forbehold, inden det angriber.Et menneske kunne aldrig n at foretage s mange vurderinger p s kort tid, s jeg mener ikke, det er det, vi skal forbyde, siger Iben Yde, der som jurist ser en fremtid, hvor robotterne bliver stramt programmeret og holdt i kort snor.Det samme billede i krystalkuglen ser Thomas Bolander, der forsker i kunstig intelligens ved DTU.Som teknologien er i dag, skal du instruere robotten i alle de regler, den skal efterleve, men du skal ogs programmere samtlige undtagelser, som i kampens hede ofte beror p et subjektivt skn. Fjendens uniform er mske det, som for robotten de-finerer, hvad der m skydes p, og hvad der ikke m, men hvis et barn var kldt i fjendens uniform, ville et menneske mske ikke skyde, mens robotten i den situation ikke ville gre forskel, siger Thomas Bolander og fortstter: Det kan man selvflgelig tage forbehold for, men hvem kan garantere, at det program, man begynder at skrive, tager hjde for samtlige ting? Ved den ene yderlighed kan det betyde, at robotter udgr en stor risiko i forhold til at beg frygtelige fejl, eller ogs bliver de s forsigtige, at man kan diskutere, hvor interessante de s er at benytte, siger han.Han slr fast, at der endnu er meget lang vej, fr det bliver muligt at skabe fuldgyldige autonome systemer, der kan bruges i komplekse situationer, som krig ofte er, s drberrobotterne invaderer ikke slagmarken lige forelbigt.Dybest set forstr vi ikke, hvordan vi skal lave menneskelignende intelligens p en computer. Det er ikke engang sdan, at man kan sige, at vi er godt p vej, for det er en nd, vi simpelthen ikke har knkket endnu, siger Thomas Bolander.Er drberrobotter sikre?I FN har man diskuteret lovligheden af ddbringende autonome vbensystemer de seneste to r, men er endnu ikke net frem til, om de autonome droner skal p listen over vben, der er forbudte at anvende i krig.FN afholdt i maj et ekspertmde om emnet og inviterede blandt andre Paul Scharre, der leder et mangerigt forskningsprojekt, som skal kortlgge fremtidens krigsfrsel for den uafhngige organisation Center for a New American Security.Han arbejder p at finde ud af, hvilken rolle autonome robotter kommer til at spille i fremtidens krig, og mener, at vi i jeblikket str midt i en revolution inden for robotik - bde civil og militr - og det krver, at vi som verdenssamfund forholder os til perspektiverne i den nye teknologi.Mange vil hvde, at der ikke findes ddbringende autonome vbensystemer.Det er ikke sandt, nr man ser isoleret p funktionaliteten ' beslutning om udvlgelse af ml'.De er ikke i brug mange steder, men der er et lille antal systemer i brug i dag, som udfrer denne funktion, fortalte Poul Scharre til de officielle reprsentanter fra mere end 25 lande og nvnte blandt andet Harpysystemet som eksempel.Under den kolde krig, forklarede han, var der automatiske detektionssystemer p begge sider, der ved flere lejligheder fejlagtigt troede, at et atomangreb var undervejs. Dengang var det indgreb fra mennesker i beslutningskden, der sikrede, at en global atomkrig ikke blev udlst.Der er et presserende behov for, at verdens nationer tnker over, hvordan man garanterer, at autonome vben er sikre og bruges p en sikker mde. Det er et ansvar, der phviler enhver stat, at garantere sin egen sikkerhed, men utilsigtet krig kan ikke komme nogen til gode, sagde Paul Scharre.Set fra den modsatte pol har selvbestemmende robotter ogs interessante perspektiver i forhold til at gre slagmarken mere human.Robotter handler aldrig p flelser og instinkter, og fortalere vil mene, at de kyniske robotter ikke vil vre i stand til at beg krigsforbrydelser.Den humanitre folkeret har primrt til forml at beskytte ofre for krig - og her menes primrt civile, der kan blive fanget i krydsilden.Hvis man kan lave autonome vbensystemer, som kan yde en bedre beskyttelse, s kan man argumentere for, at vi er moralsk og politisk forpligtede til at videreudvikle denne slags systemer, ville jeg mene, siger Iben Yde.HARPYType: Anti-radar-drone Producent: Israeli Aerospace Industry Et to meter langt dronefly, der kan hnge i luftrummet over et missionsomrde og scanne efter fjendtlige radarprofiler. Hvis Harpy identificerer et ml, der eksisterer i dens database over godkendte ml, tager den selv beslutning om at angribe.Dronen styrtdykker mod mlet i et kamikaze-angreb og detonerer sin 35 kg tunge sprngladning umiddelbart inden nedslaget.LRASMType: Anti-skibsmissil Producent: Lockheed Martin Stadig under udvikling hos Lockheed Martin for det amerikanske militre forskningsinstitut Darpa.LRASM kan affyres p sikker afstand af fjendtlige skibe og er i stand til at ndre sin rute, hvis pludselige trusler skulle opst undervejs.Hvis mlet er en klynge af skibe, afgr missilet selv, hvilket skib det angriber.Missilet er svrt at opdage for fjendens radarsystemer, da det dykker ned under radarhjde, kort inden mlet rammes.PHALANXType: Nrforsvarssystem til skibe Producent: General Dynamics Et fuldautomatisk nrforsvarssystem, der sidder p strstedelen af bde den amerikanske og britiske flde.Systemet kan sttes op til automatisk at detektere, spore og nedskyde indkomne missiler og overfladetrusler.En lang rkke forbehold tages, inden vbnet affyres automatisk, ssom objektets fart og retning.BRIMSTONEType: Luft-til-jord-missil Producent: MBDA Missile Systems Et skaldt ' fire-and-forget'-missil, der opererer autonomt, nr frst det er affyret. Missilet identificerer selv et ml i den generelle retning, det er blevet affyret i. Brimstone kan identificere mlets mest srbare punkt, s det altid udretter strst mulig skade.Hvis missilerne affyres flere ad gangen i en salve, kommunikerer vbnene med hinanden og fordeler en angrebsrkkeflge, s de ikke alle rammer det samme ml. Hvis Brimstone ikke kan identi-ficere et oplagt ml, er det programmeret til at selvdestruere.GRADER AF AUTONOMIAutonomi er ikke en fast defineret strrelse, men snarere et spektrum, hvor mennesket er placeret i forskellige led i beslutningskden. Mange roboteksperter lner sig op ad en model, der definerer tre grader af selvbestemmelse i vbensystemer: ' Human-in-the-loop', hvor mennesker er en integreret del af beslutningskden og har fuld kontrol over systemet.' Human-on-the-loop', hvor mennesker betragter beslutningskden og har mulighed for at gribe ind i systemet.' Human-out-of-the-loop', hvor mennesker ikke har indflydelse p beslutningskden.
        </div>
        <footer>
          <em>Ingeniren</em>
          &nbsp;&nbsp; 2014-12-19
          &nbsp;&nbsp; e4ba8279
          &nbsp;&nbsp; #39
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.986</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.589</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.63</kbd>
        </footer>
      </article>
      <article>
        <h4>Her er det amerikanske militrs nye superfly</h4>
        <div>
          Et nyt krigsfly, som bliver styret af kunstig intelligens, er under udvikling.X 47 B bliver muligvis verdens frste ubemandede fly, der styret af kunstig intelligens frem for en operatr p landjorden.Det amerikanske militr tester i jeblikket X-47 B p havet.Hvis fremtids-flyet afslutter sine tests uden anmrkninger, bliver X-47 B det frste fly, som er i stand til at lande p et hangarskib uden hjlp.Uklare regler fra PentagonFlyet har vret under udvikling i fem r og er designet til at flyve ud p for-programmerede missioner.X-47 B er styret af en computer, som kan tnke selvstndigt og f.eks. selv ndre kurs.Pentagon har i sidste uge udsendt nye retningslinjer for, at det altid skal afgres af et menneske, nr en robot eller fly bner ild. Det er dog uklart, om X-47 B er inkluderet i den bekendtgrelse, skriver
        </div>
        <footer>
          <em>Jp.dk (Jyllands-Posten)</em>
          &nbsp;&nbsp; 2012-12-03
          &nbsp;&nbsp; e38c26c3
          &nbsp;&nbsp; #40
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.824</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.883</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.644</kbd>
        </footer>
      </article>
      <article>
        <h4>Ritzau Plus: Drones4Safety's fem hovedml</h4>
        <div>
          Kbenhavn1. At udvikle en holdbar metode til automatisk optankning af droner p hjspndingsledninger og jernbanekabler.2. At gre inspektionen af infrastruktur som eksempelvis broer mere effektiv ved hjlp af kunstig intelligens.3. At form en drone til at levere fejlfri inspektion.4. At udvikle dronernes evne til at samarbejde internt i en svrm - som fugle i en flok.5. At opbygge en cloud-baseret lsning, som kan sikre, at dronerne kan navigere af sig selv.Kilde: SDU/ritzau/Se ogs grafikDenne nyhed m publiceres digitalt bag paywall fra d. 13/06/2020 20:00Denne nyhed publiceres ikke p NET-tjenesten
        </div>
        <footer>
          <em>Ritzaus Bureau</em>
          &nbsp;&nbsp; 2020-06-13
          &nbsp;&nbsp; e7c01a16
          &nbsp;&nbsp; #41
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.717</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.621</kbd>
        </footer>
      </article>
      <article>
        <h4>FN skal tage stilling til drberrobotter: Nye vben identificerer og drber selv deres ml</h4>
        <div>
          Det gr strkt med at udvikle vben, som p egen hnd kan trffe ddbringende beslutninger. FN skal se p lovgivning, men det er en svr diskussion, siger forsker ved DIIS.Forestil dig himlen fuld af sm militre droner, som gennemsger et omrde, mens de leder efter n bestemt person. De kommunikerer konstant med hinanden og omstter lynhurtigt store mngder af information. Forestil dig, at de finder personen og selv beslutter, hvornr han/hun skal sls ihjel.Eller forestil dig en kampvogn, som krer selv, selv afsger terrnet for ml og selv beskyder mlene.De to scenarier er hverken computerspil, film eller fjern fremtid. Det er nutidens teknologi inden for det, der hedder &quot;lethal autonomous weapon&quot; (p dansk: ddbringende autonome vben). Det amerikanske forsvar har allerede udviklet dronerne, og det russiske forsvar har kampvognen.Men til nste r skal FN diskutere brugen og udviklingen af lethal autonomous weapons, ogs bare kaldet killer robots eller drberrobotter. Det besluttede FN-organet UN Convention on Certain Conventional Weapons fredag, skriverBuzzFeed.ADVERTISING inRead invented by TeadsI lngere tid har kampagnen &quot;Campaign to Stop Killer Robots&quot; (kampagne for at stoppe drberrobotter, red.) forsgt at f FN's opmrksomhed p omrdet. Bag kampagnen str en rkke NGO'er, herunder Humans Rights Watch.Johannes Lang er uddannet psykolog og forsker i psykologiens rolle i moderne krigsfrelse ved Dansk Institut for Internationale Studier.Han forklarer, hvorfor den slags teknologi over hovedet bliver udvilket.I krig er der hele tiden brug for, at man kan tnke hurtigere og reagere hurtigere. Meget af den teknologi, som er udviklet og taget i brug i krig fr tingene til at g s strkt, at mennesker ikke kan flge med lngere. Derfor udvikler man hele tiden teknologi, som man kan outsource hurtige og komplicerede beslutninger til,siger han.Det er en svr diskussion, for der er bde argumenter for og imod drberrobotterne, forklarer han.P den ene side kan de her intelligente systemer muligvis gre, at vi vil se frre civile tab i krig. Mennesker er for langsomme, de kan blive trtte, og de kan blive flelsesmssigt involveret, nr der skal tages hurtige beslutninger. Det kan man komme til livs med disse teknologier, og man vil muligvis ogs kunne sende frre soldater i krig. Og s vil tilhngere af teknologierne sige, at der altid er en menneskelig beslutning &quot;in the loop&quot; - alts at systemerne ikke fungerer fuldstndig autonomt.Men et problem kan vre, at nr der skal tages s hurtige og s vigtige beslutninger, risikerer man, at mennesker ikke stoler p deres egen dmmekraft, eller at de ikke kan tage beslutningen hurtigt nok. Og s vlger de mske at tro p systemerne. Dermed bliver det de facto systemerne, der tager beslutningen,siger Johannes Lang.Kunstig intelligens kan tage magten fra osDansk Institut for Internationale Studier afholdt i november mned et seminar om netop drberrobotter. Og her argumenterede flere danske eksperter for, at problematikkerne ved de nye vben, vil kunne hndteres inden for allerede eksisterende international lov som fx. krigens love og folkeretten, fortller Johannes Lang.Andre, som fx. kampagnen Campaign to Stop Killer Robots, vil have, at man helt forbyder brugen af disse teknologier, mens der ogs er nogle, som mener, man br stoppe udviklingen af teknologierne. Problemet er bare, at udviklingen af disse teknologier finder sted mange andre steder end i militre sammenhnge. Fx. i bilindustrien, hvor man at udvikle selvkrende biler, der bruger nogle af de samme teknologier,siger Johannes Lang.UN Convention on Certain Conventional Weapons har tidligere forbudt bl.a. landminer, napalm og blndende lasere.Der udvikles hele tiden flere og flere vben, som kan arbejde mere og mere autonomt. Men de rejser etiske dilemmaer, som FN nu skal tage stilling til. Her er det et Phalanx Close-in Weapons System (CIWS), som er monteret p et amerikansk krigsskib. Phalanx er et avanceret, computerstyret anti-missil-system. Foto: US Navy.Der udvikles hele tiden flere og flere vben, som kan arbejde mere og mere autonomt. Men de rejser etiske dilemmaer, som FN nu skal tage stilling til. Her er det et Phalanx Close-in Weapons System (CIWS), som er monteret p et amerikansk krigsskib. Phalanx er et avanceret, computerstyret anti-missil-system. Foto: US Navy.
        </div>
        <footer>
          <em>Jyllands-posten.dk (Abonnementsomrde)</em>
          &nbsp;&nbsp; 2016-12-17
          &nbsp;&nbsp; e6084ed9
          &nbsp;&nbsp; #42
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.994</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.628</kbd>
        </footer>
      </article>
      <article>
        <h4>Videnskabsfolk advarer mod udvikling af drberrobotter</h4>
        <div>
          Kbenhavn, fredagHvad skal vi gre, hvis robotter ikke overholder reglerne for krigsfrelse?, sprger professor.Verdenssamfundet br skride ind og stte en stopper for forskning i, hvad der populrt gr under betegnelsen drberrobotter.Det mener over 1000 videnskabsfolk og erhvervsspidser, som beskftiger sig med teknologi.I et bent brev til en konference i Buenos Aires om kunstig intelligens advarer brevskriverne om, at udviklingen af militrrobotter er net s langt, at selvstyrende drberrobotter kan blive mulige &quot;inden for r, ikke rtier&quot;, skriver Politiken.I brevet betegnes selvstyrende vben som &quot;den tredje revolution inden for krigsfrelse&quot; - efter frst opfindelsen af krudt og siden atomvben.Brevet advarer om, at hvis en stor militrmagt stter turbo p udviklingen af vben med kunstig intelligens, &quot;s er et globalt vbenkaplb uundgeligt&quot;.Underskriverne tller kendte intellektuelle som fysikeren Stephen Hawking og filosoffen Noam Chomsky.De frygter, at selvstyrende vben let kan falde i de forkerte hnder, for nr teknologien frst findes, kan de fremstilles nemmere og billigere end for eksempel atomvben.- Selvstyrende vben vil blive morgendagens Kalasjnikovs, skriver forskerne med henvisning til en type automatriffel, som er blevet srlig udbredt blandt militante og terrorister.Noel Sharkey, der er professor i robotteknologi ved University of Sheffield, er en del af en alliance, der arbejder for at f en FN-konvention, som forbyder brugen af avancerede militre robotter p verdensplan.- Man skal huske, at militre robotter er maskiner, programmeret af mennesker. Der findes ogs onde mennesker. Hvad skal vi gre, hvis maskinerne ikke overholder reglerne for krigsfrelse? Hvem er s ansvarlig?, sprger Sharkey.Det er imidlertid langtfra alle, der frygter udviklingen af drberrobotter.- Robotter er rationelle, og jeg mener ikke, at det per automatik er problematisk at overlade drabsbeslutningen til en robot, siger Klaus . Mogensen fra Instituttet for Fremtidsforskning til Politiken.- Vi har set masser af eksempler p, at den menneskelige bedmmelse af en situation i eksempelvis Iran og Irak ikke altid bliver foretaget p et rationelt grundlag. En robot trffer altid en rationel beslutning, fordi den ikke er bekymret for sit eget liv, siger han./ritzau/
        </div>
        <footer>
          <em>Ritzaus Bureau</em>
          &nbsp;&nbsp; 2015-07-31
          &nbsp;&nbsp; e52529e3
          &nbsp;&nbsp; #43
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.981</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.816</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.591</kbd>
        </footer>
      </article>
      <article>
        <h4>FN vil regulere drberrobotter, der selv finder og udsletter deres ml</h4>
        <div>
          Hightechvben, der selv identificerer deres ml og selv beslutter, om de skal udslettes, venter lige om hjrnet.De skaldte drberrobotter er ikke lngere noget, der kun hrer Arnold Schwarzeneggers lderjakke-kldte &quot;Terminator&quot;-filmfigur til. I mange lande forskes der p livet ls i den banebrydende teknologi, der dog samtidig rejser store etiske problemer.I den forlbne uge har drberrobotterne vret p dagsordenen ved et FN-mde i Genve. Hensigten er at etablere et st principper, der regulerer udviklingen af drberrobotter p fremtidens slagmark. Danmark deltog for frste gang.En drberrobot er et skaldt autonomt vben, som selv udpeger sit ml og selv afgr, om mlet skal sls ihjel eller udslettes - uden menneskelig indblanding. Sdanne vben findes, s vidt vides, ikke endnu, men det vil kun vre et sprgsml om tid, siger internationale eksperter.De har optalt 381 forskellige slags vben, som delvis tnker selv, men alts stadig i et vist omfang pvirkes af et menneske i den anden ende.En drone er et eksempel. Den finder sit ml, men det er stadig en soldat, der udlser det drbende missil mod mlet.12 lande er iflge eksperter i gang med at udvikle krigsrobotter med alle de store militrmagter i spidsen.Forelbig handler debatten meget om at definere konkret, hvad man skal forst ved drberrobotter for at kunne arbejde videre med at f dem underlagt internationale regulativer.Autonomt vbenDet er helt afgrende med en sdan afklaring af definitioner for at kunne etablere robuste og gennemsigtige reguleringer af omrdet. Alle lande har forpligtet sig til at fastholde et element af menneskelig kontrol med vbnene, men hvad vil det sige? Forskningen gr lige nu s hurtigt, at der er risiko for, at lande kan komme i konflikt med disse vben, siger seniorforsker Robin May Schott fra DIIS, Dansk Institut for Internationale Studier.Hun mener, at definitionen p en drberrobot skal indeholde to dele: Den skal selv kunne udpege sit ml og selv udlse et angreb - uden menneskelig indflydelse.Det er typisk sdan, at de lande, der har en stor militr kapacitet, med USA i spidsen, ikke er interesseret i, at aftalerne er for forpligtende.Omvendt med militrt svage lande, siger Robin May Schott.USA, der er lngst fremme med forskningen, har forpligtet sig til, at der i hvert fald frem til 2022 altid vil vre menneskelig kontrol over alle slags vben, men igen er det et definitionssprgsml, ppeger hun.I Genve fastholdt flere lande, at selve programmeringen af vbnene sikrer en menneskelig kontrol, men den tilgang er strkt omdiskuteret.21 lande har underskrevet en opfordring til at forbyde sdanne vben, og en international ngo-kampagne &quot;Stop Killer Robots&quot; har stor gennemslagskraft. Ogs Tesla-grundlggeren Elon Musk og den nu afdde fysiker Stephen Hawking har vret fremtrdende kritikere.De beskriver drberrobotterne som krigsfrelsens tredje revolution efter opfindelsen af krudtet og udviklingen af atombomben.De peger p, at autonome vben ikke kan programmeres til at overholde krigens love, og at det vil vre etisk forkasteligt at overlade sprgsmlet om liv og dd til en maskine, uden at et menneske er med inde over.Krig industrialiseresDrberrobotterne vil blive massedelggelsesvben og rene terrorvben, som terrorister og bllestater vil bruge.n programmr og en 3Dprinter vil kunne prstere det samme som en hel hr af soldater. Krig vil blive industrialiseret.Disse vben kan drbe 24/ 7, og de kan drbe hurtigere, end mennesker kan n at forsvare sig selv, siger professor i kunstig intelligens Toby Walsh til The Guardian.Han er en af de skarpeste internationale kritikere af udviklingen af krigsrobotter.Danmark deltog for frste gang i ekspertmdet i Genve og lgger sammen med EU vgt p ndvendigheden af, at den potentielle udvikling og brug af sdanne vbensystemer lever op til international humanitr folkeret og menneskerettighederne, oplyser Udenrigsministeriet.Til efterret vil FN-mdet begynde at diskutere forslag til egentlige reguleringer.joern.mikkelsen@jp.dk Fakta: AUTONOME VBEN Uberrt af menneskerFlere lande forsker intenst i autonome vben. Fuldt selvkrende vben findes, s vidt vides, ikke endnu, men 381 vbentyper, der kommer tt p, er registreret.Alle lande forsikrer officielt, at de fortsat vil lade mennesker have den endelig afgrelse, nr vbnet skal affyres.Men det lgger op til et slagsml om, hvad menneskelig ind-flydelse vil sige.En ekspertgruppe under FN forsger at f hold om omrdet.Danmark er nu med.
        </div>
        <footer>
          <em>Jyllands-Posten</em>
          &nbsp;&nbsp; 2018-04-15
          &nbsp;&nbsp; e6b44ae4
          &nbsp;&nbsp; #44
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.729</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.625</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.621</kbd>
        </footer>
      </article>
      <article>
        <h4>Er tryghed stadig vigtig?</h4>
        <div>
          Autonome robotter/droner er udstyret med kunstig intelligens (AI), der tnker langt hurtigere end mennesker. Kunstig intelligens kan selv udvikle sin intelligens. Sledes har robotter kunnet udvikle et andet sprog til kommunikation, da menneskets sprog var for langsomt.I krig er hurtige beslutninger noget, man kan vinde en krig med. Derfor er det fristende at overlade krigens beslutninger til superhurtige drberrobotter, men det vil betyde, at en atomkrig lettere vil kunne starte ved en fejl. Derfor kom og hr vort gadeteater om autonome drberrobotter p FN's fredsdag den 21. september klokken 17.00 og klokken 17.30 i Heerups Have ved Hotel Britannia i Esbjerg.
        </div>
        <footer>
          <em>Jv.dk (Abonnementsomrde)</em>
          &nbsp;&nbsp; 2018-09-18
          &nbsp;&nbsp; e6e708d6
          &nbsp;&nbsp; #45
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.978</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.596</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.566</kbd>
        </footer>
      </article>
      <article>
        <h4>INDBLIK: Inden lnge behver mennesker ikke selv at udkmpe deres krige</h4>
        <div>
          De bliver aldrig bange, trtte eller sultne. I modstning til soldater af kd og blod kan vben, som tnker selv, udlser sig selv og selv beslutter at sl ihjel - uberrt af menneskehnd - blive ved og ved. De adlyder altid, og de misser kun sjldent deres ml.Skaldt autonome vben - killer robots - rykker stadigt tttere p at blive virkelighed.Men udviklingen er forbundet med s store etiske udfordringer, at mange forsger at f den reguleret nrmere.Siden menneskene opfandt de frste vben at bruge mod hinanden, har kampen p liv og dd fjernet sig stadigt mere fra den direkte udmling af fysisk styrke. Selv en drone, der flyver tusindvis af kilometer, fr den affyrer et missil, bliver styret af et menneske i den anden ende, om end pr. joystick, og er ret beset kun en teknologisk videreudvikling af gammeldags kanoner og raketter.Med udviklingen af selvstndige drbermaskiner med kunstig intelligens gr vbenteknologien et stort skridt videre: Disse vben vil selv kunne afgre, hvor og hvornr nogen m d. Det har altid vret et stort sprgsml, hvor menneskeligheden er i krig, og hvor bizart det egentlig er at lave regler for, hvordan krigen m fres. Men nu er mennesket p nippet til at blive skrevet helt ud af krigen.Mange tnker nok straks p &quot;Terminator&quot; og Arnold Schwarzenegger, men faktisk var end ikke han fuldt autonom. Han vidste f. eks. ikke, hvordan Sarah Connor (kvinden, der skal reddes i filmen, red.) s ud. De vben, vi taler om her, ved alt og kan alt selv, siger seniorforsker Gary John Schaub Jr., Center for Militre Studier under Kbenhavns Universitet.En moralsk grnse overskridesHan publicerede tidligere p ret en rapport om emnet, som forsgte at definere, hvornr vben kan siges at tnke og agere selvstndigt, og beskrive den bagvedliggende, kunstige intelligens. Men den fokuserede ogs p de store etiske udfordringer.Den internationale ngo-kampagne Stop Killer Robots formulerer det direkte: At overlade sprgsmlet om liv og dd til maskiner overskrider en grundlggende moralsk grnse. Autonome maskiner mangler den menneskelige dmmekraft og evnen til at forst alle sammenhnge. Disse egenskaber er ndvendige for at trffe komplicerede etiske valg p slagmarken, skelne mellem soldater og civile og afveje proportionaliteten i et angreb. Af samme grund krnker drbermaskiner folkeretten, ppeger kampagnen. Den verdensbermte fysiker Stephen Hawking advarer sammen med superivrkstteren Elon Musk i et bent brev ogs om de store risici og krver et forbud: Det er oplagt, hvor denne udvikling ender: Autonome vben vil blive morgendagens Kalasjnikov-gevrer, allestedsnrvrende og billige for alle frende militrmagter at masseproducere. Det vil kun vre et sprgsml om tid, fr de havner p sortbrsen og falder i hnderne p terrorister, diktatorer og krigsherrer. Ogs FN har fet jnene op for udfordringen.I tre r har en srlig komit arbejdet med emnet ved FN i Genve. I forrige uge var den samlet igen. I frste omgang handler det om at definere, hvad en autonom drbermaskine er. Dernst flger debatten om en regulering, mske et forbud. Men der er lang vej igen. Interessemodstningerne er store mellem de frende militrmagter.Ikke alle er lige opsatte p en regulering. Og det er en vbenteknologisk udvikling, som det er svrt at stte rammer for.Mennesket har til alle tider automatiseret sine handlinger mere og mere, ogs militrt.For at forsvare sine soldater, for at ge effektiviteten, for at spare ressourcer. Ultimativt frer det til, at maskinen erstatter mennesket, siger Gary John Schaub Jr.En del vbentyper, der bruges i dag, er ganske tt p at vre autonome, men er alligevel i sidste ende afhngige af menneskelig pvirkning, hvad enten det er selve affyringen, mlsgningen eller programmeringen.Et krydsermissil finder selv vej, men er programmeret p forhnd. En drone finder sit ml, men dens missil udlses af et menneske, om end meget langt vk.Intelligente vben i DanmarkOgs det danske forsvar rder over sdanne halvautonome vben. Bde luftvbnet og svrnet har iflge rapporten fra Center for Militre Studier flere missiltyper, der falder ind under denne kategori. Aegis-missilforsvaret, der udgr rygraden i Natos forsvar mod ballistiske missiler, kan automatisk opdage fjendtlige missiler og skyde dem ned.Hvordan vil denne autonomi ndre krigens frelse? Og hvilke etiske og juridiske problemer giver det? Den diskussion m vi forberede os p. Det handler om at sikre, at menneskene fastholder kontrollen over vbnene, sagde Vincent Boulanin fra det svenske fredsforskningsinstitut Sipri forleden til det tyske ZDF.Han blev suppleret af rkebiskop Ivan Jurkovic, der er Vatikanets reprsentant i FN-komiten: Vi str foran en meget dramatisk udvikling, som vil prge det 21. rhundrede.Fuldt automatiske vben er uforenelige med kristne vrdier og anfgter selve menneskeligheden. 21 lande har forelbig opfordret til et forbud mod drbermaskiner. Danmark er ikke med. Tilhngerne af at g videre med teknologien findes isr hos de store vbenproducenter.De ppeger, at maskinerne redder menneskeliv og gr livet lettere for soldaterne ved grnsekontrol, antiterror, beskyttelse af konvojer m. m.Halvautonome vben har vret indsat i flere krige, ofte med forfrdende konsekvenser. I den frste Golf-krig skd Patriotmissiler amerikanske og britiske fly ned, og heller ikke det amerikanske drone-program lever op til egne mlstninger om altid at identificere ofrene.Teknologisk er vi ret tt p autonome vben. Allerede nu kunne man gre et Tomahawk-krydsermissil helt selvstndigt.Men politisk er der et stykke vej endnu. Problemerne er ved at g op for de fleste, siger Gary John Schaub Jr., der mener, at det er p hje tid, at ogs den danske regering systematiserer sine overvejelser.Snart bliver pizzaen bragt ud med drone i Kbenhavn. Der mangler i den grad retningslinjer for denne vigtige udvikling af vbenteknologien, tilfjer han.Lande som USA, Storbritannien, Israel og Sydkorea har alle avancerede programmer for autonome vben og har i varierende grad forpligtet sig til, at der altid vil vre en menneskelig dimension i hndteringen af de intelligente vben. Men disse lfter er iflge ngo-folkene ikke konkretiseret. Pentagon meddelte i 2012, at der altid vil vre mennesker med ind over i de flgende 10 r, alts til 2022.I sidste ende er man tilbage ved sprgsmlet om, hvorvidt det er mere delt at sl ihjel i nrkamp, soldat mod soldat, end via en drone i 10 kilometers hjde. At krigen har sine egne love, har altid vret underligt.Og er det altid rigtigt, at en dum menneskelig hjerne altid skal have forrang over selv den mest intelligente maskine? Det handler vel om, hvad formlet er med at sl ihjel, siger Gary John Schaub Jr.joern.mikkelsen@jp.dk Fakta: VBENTEKNOLOGI Kunstig intelligensMed FN i spidsen er mange aktrer ved at f jnene op for, at vbenteknologien str foran et kvantespring. Introduktionen af skaldte &quot;killer robots&quot; - autonome drbermaskiner - er lige om hjrnet. De kan selv  nde og uskadeliggre deres ml, uden at mennesker er med i processen.En international kampagne for et forbud mod disse vben spiller en afgrende rolle i debatten.Men ogs FN er get ind i den og har i de seneste tre r haft en srlig komit - Convention on Conventional Weapons (CCW) - siddende til at diskutere ikke mindst de etiske udfordringer ved, at maskiner kan agere helt selvstndigt.
        </div>
        <footer>
          <em>Jyllands-Posten</em>
          &nbsp;&nbsp; 2017-11-22
          &nbsp;&nbsp; e6834219
          &nbsp;&nbsp; #46
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.927</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.833</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.619</kbd>
        </footer>
      </article>
      <article>
        <h4>Dronen - den fattige mands krydsermissil</h4>
        <div>
          I Mellemstens virvar af krige og konflikter er dronen blevet den lille mands krydsermissil.Militser, klaner, terrororganisationer og fejlslagne stater kan med ganske f tekniske og konomiske midler nu sl igen mod hjteknologiske militrmagter, som de tidligere var helt forsvarslse mod.En drone er nem at bygge. Det rulles for tiden ogs op i Kbenhavns Byret, hvor tre mnd str tiltalt for at have indkbt avanceret droneudstyr til Islamisk Stat i Syrien.Dronen er billig og kan vre svr at opdage p en radar. Men den kan sprede dd og delggelse, og den forrykker magtbalancen mellem etablerede militre systemer og fattige oprrsbevgelser.Der er en blodig ironi i det. USA lancerede sit droneprogram for at f ram p terrorister.Men nu fr man selv dronerne tilbage i hovedet. De store magter har mistet deres monopol p at bruge droner, siger seniorforsker Lars Erslev Andersen, Dansk Institut for Internationale Studier.Det er endnu uafklaret, om det virkelig var droner, affyret af houthi-militsen i Yemen, der ramte Saudi-Arabiens to strste olieanlg i weekenden og lammede 10 pct.af kongedmmets olieproduktion. Houthierne siger selv, at de afsendte 10 droner.Men internationale eksperter tvivler trods alt p, at oprrsmilitsen rder over s avanceret droneteknologi.Men dronen som nyt vben har vret i hj kurs i Mellemsten i de senere r. Igen og igen rapporteres om droner, der har vret sat ind i strre eller mindre militre aktioner. Dronerne er hurtigt blevet en del af vbenarsenalet selv hos de mindste og fattigste militser. Tilfldige eksempler fra det seneste halve r: N I Irak kastede Islamisk Stat sprngladninger ned fra meget sm droner, som man kan bygge med materialer for f penge.N I Syrien lykkedes det oprrsstyrker at delgge dele af den russiske luftbase ved Latakia, selv om den er beskyttet af det topmoderne antimissilsystem S-400.N En israelsk kamphelikopter skd en drone ned, som menes afsendt af iranske revolutionsgardister fra Libanon.N Islamisk Stat har i flere propagandafilm pralet med, hvor farlige dens droner er.N Houthi-oprrere brugte i maj droner til et angreb p saudiske olierrledninger.Droner er svre at opdage p radarNogle af dronerne er ikke meget strre end modelfly. De flyver lavt og langsomt og har en begrnset rkkevidde, men kan vre svre at opdage p en radar. De programmeres problemfrit via gps eller fjernstyres pr. joystick og er alts ikke afhngige af satellitter, som styrer de store militrmagters droner.Iflge militre eksperter koster det mske kun op til 150.000 kr. at bygge en drone, der kan fremfre vben eller sprngladninger over lngere afstande. Da mange af de komponenter, der indgr i bygningen af en drone, er civile, er det nsten umuligt at blokere salget af dem.Dronerne er et ekstra vrktj for terrorister og fattige stater, som ellers ikke kunne svare igen i eller fra luften. De er et meget effektivt vben mod enkeltpersoner og bestemte mindre ml. Men de kan jo ikke bruges til at bekmpe en stat som sdan, siger major Karsten Marrup, Forsvarsakademiet.Han finder det logisk, at dronen har kunnet udvikles som et nyt vben for oprrsbevgelser og terrorister: Den teknologi, der udvikles af de store lande, kommer tilbage til dem igen, nr den bliver kommerciel. Det monopol p brug af droner, som USA oprindelig havde, er vk..Stormagternes drone-monopol er vkDet er ogs holdningen hos en af USA's frende Iran-kendere, Gary Sick, der har siddet i flere prsidenters nationale sikkerhedsrd.De store militrmagter er ikke lngere ene om at ramme ml via droner.USA m nu finde sig i at blive ramt med droner, hvor man tidligere under krigen mod terror var urrlige fra luften: Er tiden for nvejssmerten forbi? Den kunne sikkert ikke opretholdes i det lange lb. Nr andre begynder at kunne hndtere den ret billige dronekrigsfrelse, udfordres iden om, at USA og dets allierede har totalt luftherredmme. Teknologien til krydsermissiler er mere kompliceret, men ogs dt er kun et sprgsml om tid, skriver Gary Sick p sin blog.Selve iden om ubemandede fly opstod i USA i 1990' erne. De er billige i drift og produktion, der er ingen piloter, der bliver trtte eller kan blive drbt, og de er ukomplicerede at fre frem. I starten blev de kun brugt til rekognoscering. En amerikansk drone blev frste gang sat ind over Bosnien i 1995 i krigen p Balkan, hvor den hjalp Natos styrker p jorden.Amerikanske droner havde al-Qaeda-chefen Osama bin Laden p kornet flere gange, men p det tidspunkt var dronerne endnu ikke udstyret med missiler. Under prsident George W. Bush begyndte det egentlige bevbnede droneprogram, men det var under Barack Obama, at dronen som et nyt, hjteknologisk vben for alvor slog igennem.Nogle af de amerikanske droner er efterhnden lige s store som civile passagerfly.Den drone, som Iran i juli skd ned over Den Persiske Golf, havde et vingefang som en A320-airbus. De opererer over enorme afstande og medbringer store, hjteknologiske missiler. Andre droner, f. eks. af Predatorklassen, er knap s store, men ogs ddbringende.De kan veje 600 kg og klassificeres som en mindre drone.Utallige terrorchefer er blevet likvideretUtallige er de terrorchefer i Afghanistan og Irak, der er blevet drbt af en drone, herunder al-Qaeda-lederen Anwar al-Awlaki, som den danske PET-agent Morten Storm var med til at udpege i Yemen. Det srlige ved al-Awlaki var, at han blev den frste amerikanske statsborger, som en prsident gav ordre til at sl ihjel med en drone.I dag har over 100 lande egne militre droneprogrammer - og s alts ogs alle mulige andre grupper og bevgelser, om end af en mere begrnset strrelse og kapacitet.Sdan som dronerne er blevet udbredt i dag, smager Vesten virkelig sin egen medicin, siger seniorforsker Lars Erslev Andersen.Major Karsten Marrup peger p, at selv om det viser sig at vre houthi-militsen i Yemen, der str bag angrebene i Saudi-Arabien, er der ikke tale om droner i normal forstand.En typisk drone flyver afsted, afleverer sin vbenlast og vender hjem igen. I Saudi-Arabien er der i givet fald tale om en kamikazedrone, som flyver sig selv ind i mlet, ligesom et missil. Den gngse opfattelse af en drone er, at den fortrinsvis styres pr.fjernstyring. Her se det ud, som om vbnet var forprogrammeret p samme mde som et krydsermissil, siger han.Ikke droner, men avancerede vbenSprgsmlet er, hvorfor det saudiske luftforsvar ikke har evnet at skyde dronerne eller missilerne ned, hvor de end kom fra: Irak, Yemen eller mske ligefrem Iran.Saudi-Arabien har investeret meget i sit luftforsvar, og selv om en del er koncentreret om hovedstaden Riyadh, er olieanlggene ogs beskyttet militrt, bl. a. af amerikanske Patriot-batterier.Det vidner om, at ligegyldig hvad der ramte raffinaderierne, s var det ikke hjemmelavede droner, der blev styret frem mod mlet. Det tyder p meget avancerede vben, siger major Karsten Marrup.At dronen er et nyt militrt vben, som mange kan f fingre i og bruge efter forgodtbefindende, viser ogs forskningen i, hvordan man kan gardere sig mod droner. Laserlys, jamming af radiofrekvenser, store net foruden opsttelse af flokke af rovfugle er blandt de afvrgemetoder, der prves af, forklarer han.At en lufthavn ved London for nylig mtte lukkes ned to gange p grund af et par civile droner, der kom for tt p, siger alt om, hvor srbare hjt udviklede samfund er over for dronen. Forleden var den gal igen, da den radikale britiske miljgruppe Extinction Rebellion truede med endnu en droneaktion mod Heathrow Lufthavn. Gruppens ledere blev arresteret.Dronen er blevet et anarkistisk vben.Den kan bruges til mange ting og er svr at f under kontrol, siger Lars Erslev Andersen.Fakta: DRONER SOM VBENI mange lande forskes der i kunstig intelligens i militrt jemed. Udvikling af droner indgr, men dronerne opererer endnu ikke selvstndigt.De programmeres eller styres af et menneske.USA satte sin frste drone op i midten af 1990' erne over Balkan under krigen i Bosnien.I mange r blev de kun brugt til rekognoscering. Under prsident Obama blev droner, bevbnet med missiler, taget massivt i anvendelse.I krigene i Afghanistan og Irak blev der sat droner ind i masser af aktioner mod terrorledere.
        </div>
        <footer>
          <em>Jyllands-Posten</em>
          &nbsp;&nbsp; 2019-09-20
          &nbsp;&nbsp; e759b8c0
          &nbsp;&nbsp; #47
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.761</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.645</kbd>
        </footer>
      </article>
      <article>
        <h4>Forskere vil bruge droner til fugletllinger</h4>
        <div>
          Droner kan vre mindre forstyrrende for fugle, der ruger i kolonier, end hvis fugletllere gr rundt p jorden og skrmmer fuglene p vingerne, ppeger Thomas Eske Holm, seniorrdgiver ved Institut for Bioscience.Han har sammen med kolleger gennemfrt forsg i 2018 p adskillige jyske lokaliteter. Biologerne konstaterer, at de ynglende fugle oftest bliver p rederne, selv om der flyver en drone hen over dem.- Droner har net et stadie, hvor de er billige. De har fet bedre software, bedre kompas og gps og er meget nemme at bruge, s vi kan styre dem til at flyve automatisk i eksempelvis 20 meters hjde.- Med en lille drone til 12.000 kroner kan vi kortlgge et relativt stort omrde og f t sammenhngende foto, siger Thomas Eske Holm.Sammenligninger mellem traditionelle tllinger og dronetllinger viser ogs, at overvgning med drone ofte giver mere njagtige tal.Det glder ikke mindst, hvor alternativet er at tlle fuglene i kolonien p afstand gennem kikkert.En droneoptlling af mger p en Langli i Vadehavet gav sledes et dobbelt s hjt antal - omkring 19.000 - som en manuel opgrelse fra to erfarne fugletllere.- Og vi er helt sikre p, at dronens tal er rigtige. Ved traditionelle tllinger kan man miste overblikket over, hvad man har talt og ikke talt - eller fuglene gr pludselig i luften, siger Thomas Eske Holm.Brug af droner kan ogs i mange tilflde spare arbejdstimer og penge.Der mangler dog at blive udviklet en algoritme, der automatisk identificerer og tller fuglene p dronefotos. Herved kan der spares mange timer, som ellers bruges p manuelt at tlle de enkelte arter p billeder./Ritzau/
        </div>
        <footer>
          <em>Kristeligt-Dagblad.dk</em>
          &nbsp;&nbsp; 2019-03-24
          &nbsp;&nbsp; e720fd21
          &nbsp;&nbsp; #48
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.963</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.851</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.682</kbd>
        </footer>
      </article>
      <article>
        <h4>Brugen af selvflyvende politidroner med AI breder sig i USA</h4>
        <div>
          Borgerne br vre kritiske over for det amerikanske politis brug af droner, mener borgerrettighedsgruppen American Civil Liberties Union.Politiet i den sydcaliforniske by Chula Vista har taget selvflyvende droner med den seneste teknologi i brug for at hndhve loven, mens ogs andre politiafdelinger har lanceret droneprogrammer. Den stigende brug af droner vkker dog ogs bekymringer om get overvgning, skriver The New York TimesFlere politiafdelinger i landet har brugt droner i flere r, men det har hovedsageligt foreget p den mde, at dronen er blevet krt ud til et gerningssted, hvorefter en betjent har styret dronen manuelt.Men droner kan gre hverdagen meget nemmere for politiet, der i stedet for at bruge store summer p helikoptere og piloter kan slippe langt billigere ved at anvende droner. Den seneste teknologi bruger kunstig intelligens til at gre dronerne selvflyvende og dermed ogs mere attraktive for politiet. Teknologien minder om den, der ogs anvendes i selvkrende biler.I den sydcaliforniske by Chula Vista bruger politiet de autonome droner til at reagere p akutte situationer. Nr de modtager et ndopkald, giver en betjent dronen en lokation, som den selv flyver hen til og vender tilbage fra.For nylig modtog politiet i Chula Vista en melding om, at der l en bil p hovedet i en udtrret flod. Her sendte politiet en drone fra Silicon Valley-virksomheden Skydio af sted. Dronen flj selv hen p stedet og ned til bilen.En almindelig drone ville med garanti vre styrtet nu,  fortller politibetjenten James Horst til The New York Times, da han fremviser en video af dronen, som flyver ned mod den udtrrede flod og inspicerer bilens indre helt tt p.Op mod 15 gange om dagen sender politiet i Chula Vista en drone af sted. Det har indtil videre betydet mere end 4.100 droneflyvninger, siden politiafdelingen lancerede droneprogrammet for to r siden. Dronerne kan ogs sttes til automatisk at forflge en person eller et kretj.Flere steder i landet har politiet lanceret lignende droneprogrammer. Derudover samarbejder flere politiafdelinger med virksomheden Shield AI, der har udviklet en drone, som uden pilot kan flyve ind i en bygning og undersge den i bde lys og mrke.Flere droneproducenter, heriblandt Skydio og kinesiske DJI, arbejder p at udvikle lignende teknologier til deres droner, skriver New York Times.get overvgningIflge Jay Stanley, der er politisk analytiker i borgerrettighedsgruppen American Civil Liberties Union, s br borgere stille sig kritiske over for politiafdelingernes droneprogrammer. Han mener, at behovet for at beskytte privatlivets fred stiger i takt med, at flere politistyrker tager dronerne til sig.For jo mere politiet bruger dronerne, desto flere videooptagelser af borgernes frden i byerne optages og opbevares der, hvilket kan medfre, at borgere m opgive enhver tanke om at have et privatliv, s snart de trder ud ad dren og ud p gaden, siger han til The New York Times.Droner kan bruges til at efterforske forbrydelser. Men de er ogs sensorer, som selv kan frembringe lovovertrdelser,  siger han og tilfjer, at dronerne kan bruges p mder, som er ude trit med de sociale normer.Han ppeger, at dronerne kan bruges til at identificere personer, som eksempelvis deltager i demonstrationer. Iflge Chula Vistas politi har de dog eksempelvis ikke brugt droner til at flyve over de seneste mneders Black Lives Matter-demonstrationer, fordi deres egne politikker forbyder den brug.Politiet i Chula Vista skal ikke have tilladelse af myndighederne for at udvide brugen af droner, men har lbende underrettet borgerne om, hvad dronerne bruges til, fortller politiafdelingen til New York Times.
        </div>
        <footer>
          <em>Ing.dk (Ingeniren)</em>
          &nbsp;&nbsp; 2020-12-12
          &nbsp;&nbsp; e808695d
          &nbsp;&nbsp; #49
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.709</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.632</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.595</kbd>
        </footer>
      </article>
    </main>
  </body>
</html>
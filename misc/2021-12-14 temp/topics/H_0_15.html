<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Infomedia Articles</title>
    <style type="text/css">
/*!
 * Pico.css v1.3.3 (https://picocss.com)
 * Copyright 2019-2021 - Licensed under MIT
 */:root{--font-family:system-ui,-apple-system,"Segoe UI","Roboto","Ubuntu","Cantarell","Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";--line-height:1.5;--font-weight:400;--font-size:16px;--border-radius:.25rem;--border-width:1px;--outline-width:3px;--spacing:1rem;--typography-spacing-vertical:1.5rem;--block-spacing-vertical:calc(var(--spacing) * 2);--block-spacing-horizontal:var(--spacing);--grid-spacing-vertical:0;--grid-spacing-horizontal:var(--spacing);--form-element-spacing-vertical:.75rem;--form-element-spacing-horizontal:1rem;--transition:.2s ease-in-out}@media (min-width:576px){:root{--font-size:17px}}@media (min-width:768px){:root{--font-size:18px}}@media (min-width:992px){:root{--font-size:19px}}@media (min-width:1200px){:root{--font-size:20px}}@media (min-width:576px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 2.5)}}@media (min-width:768px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 3)}}@media (min-width:992px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 3.5)}}@media (min-width:1200px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 4)}}@media (min-width:576px){article{--block-spacing-horizontal:calc(var(--spacing) * 1.25)}}@media (min-width:768px){article{--block-spacing-horizontal:calc(var(--spacing) * 1.5)}}@media (min-width:992px){article{--block-spacing-horizontal:calc(var(--spacing) * 1.75)}}@media (min-width:1200px){article{--block-spacing-horizontal:calc(var(--spacing) * 2)}}a{--text-decoration:none}a.contrast,a.secondary{--text-decoration:underline}small{--font-size:0.875em}h1,h2,h3,h4,h5,h6{--font-weight:700}h1{--font-size:2rem;--typography-spacing-vertical:3rem}h2{--font-size:1.75rem;--typography-spacing-vertical:2.625rem}h3{--font-size:1.5rem;--typography-spacing-vertical:2.25rem}h4{--font-size:1.25rem;--typography-spacing-vertical:1.874rem}h5{--font-size:1.125rem;--typography-spacing-vertical:1.6875rem}[type=checkbox],[type=radio]{--border-width:2px}[type=checkbox][role=switch]{--border-width:3px}thead td,thead th{--border-width:3px}:not(thead)>*>td{--font-size:0.875em}code,kbd,pre,samp{--font-family:"Menlo","Consolas","Roboto Mono","Ubuntu Monospace","Noto Mono","Oxygen Mono","Liberation Mono",monospace,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji"}kbd{--font-weight:bolder}:root:not([data-theme=dark]),[data-theme=light]{color-scheme:light;--background-color:#FFF;--color:#415462;--h1-color:#1b2832;--h2-color:#23333e;--h3-color:#2c3d49;--h4-color:#374956;--h5-color:#415462;--h6-color:#4d606d;--muted-color:#73828c;--muted-border-color:#edf0f3;--primary:#1095c1;--primary-hover:#08769b;--primary-focus:rgba(16,149,193,0.125);--primary-inverse:#FFF;--secondary:#596b78;--secondary-hover:#415462;--secondary-focus:rgba(89,107,120,0.125);--secondary-inverse:#FFF;--contrast:#1b2832;--contrast-hover:#000;--contrast-focus:rgba(89,107,120,0.125);--contrast-inverse:#FFF;--mark-background-color:#fff2ca;--mark-color:#543a25;--ins-color:#388E3C;--del-color:#C62828;--blockquote-border-color:var(--muted-border-color);--blockquote-footer-color:var(--muted-color);--button-box-shadow:0 0 0 rgba(0,0,0,0);--button-hover-box-shadow:0 0 0 rgba(0,0,0,0);--form-element-background-color:transparent;--form-element-border-color:#a2afb9;--form-element-color:var(--color);--form-element-placeholder-color:var(--muted-color);--form-element-active-background-color:transparent;--form-element-active-border-color:var(--primary);--form-element-focus-color:var(--primary-focus);--form-element-disabled-background-color:#d5dce2;--form-element-disabled-border-color:#a2afb9;--form-element-disabled-opacity:.5;--form-element-invalid-border-color:#C62828;--form-element-invalid-active-border-color:#B71C1C;--form-element-valid-border-color:#388E3C;--form-element-valid-active-border-color:#2E7D32;--switch-background-color:#bbc6ce;--switch-color:var(--primary-inverse);--switch-checked-background-color:var(--primary);--range-border-color:#d5dce2;--range-active-border-color:#bbc6ce;--range-thumb-border-color:var(--background-color);--range-thumb-color:var(--secondary);--range-thumb-hover-color:var(--secondary-hover);--range-thumb-active-color:var(--primary);--table-border-color:var(--muted-border-color);--table-row-stripped-background-color:#f6f8f9;--code-background-color:#edf0f3;--code-color:var(--muted-color);--code-kbd-background-color:var(--contrast);--code-kbd-color:var(--contrast-inverse);--code-tag-color:#b34d80;--code-property-color:#3d888f;--code-value-color:#998866;--code-comment-color:#a2afb9;--accordion-border-color:var(--muted-border-color);--accordion-close-summary-color:var(--color);--accordion-open-summary-color:var(--muted-color);--card-background-color:var(--background-color);--card-border-color:var(--muted-border-color);--card-box-shadow:0 0.125rem 1rem rgba(27,40,50,0.04),0 0.125rem 2rem rgba(27,40,50,0.08),0 0 0 0.0625rem rgba(27,40,50,0.024);--card-sectionning-background-color:#fafbfc;--progress-background-color:#d5dce2;--progress-color:var(--primary);--loading-spinner-opacity:.5;--tooltip-background-color:var(--contrast);--tooltip-color:var(--contrast-inverse);--icon-chevron:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");--icon-date:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");--icon-time:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");--icon-search:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");--icon-checkbox:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-minus:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");--icon-valid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(56, 142, 60, 0.999)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-invalid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(198, 40, 40, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E")}@media only screen and (prefers-color-scheme:dark){:root:not([data-theme=light]){color-scheme:dark;--background-color:#11191f;--color:#bbc6ce;--h1-color:#edf0f3;--h2-color:#e1e6ea;--h3-color:#d5dce2;--h4-color:#c8d1d8;--h5-color:#bbc6ce;--h6-color:#aebbc3;--muted-color:#73828c;--muted-border-color:#1f2d38;--primary:#1095c1;--primary-hover:#1ab3e6;--primary-focus:rgba(16,149,193,0.25);--primary-inverse:#FFF;--secondary:#596b78;--secondary-hover:#73828c;--secondary-focus:rgba(115,130,140,0.25);--secondary-inverse:#FFF;--contrast:#edf0f3;--contrast-hover:#FFF;--contrast-focus:rgba(115,130,140,0.25);--contrast-inverse:#000;--mark-background-color:#d0c284;--mark-color:#11191f;--ins-color:#388E3C;--del-color:#C62828;--blockquote-border-color:var(--muted-border-color);--blockquote-footer-color:var(--muted-color);--button-box-shadow:0 0 0 rgba(0,0,0,0);--button-hover-box-shadow:0 0 0 rgba(0,0,0,0);--form-element-background-color:#11191f;--form-element-border-color:#374956;--form-element-color:var(--color);--form-element-placeholder-color:var(--muted-color);--form-element-active-background-color:var(--form-element-background-color);--form-element-active-border-color:var(--primary);--form-element-focus-color:var(--primary-focus);--form-element-disabled-background-color:#2c3d49;--form-element-disabled-border-color:#415462;--form-element-disabled-opacity:.5;--form-element-invalid-border-color:#B71C1C;--form-element-invalid-active-border-color:#C62828;--form-element-valid-border-color:#2E7D32;--form-element-valid-active-border-color:#388E3C;--switch-background-color:#374956;--switch-color:var(--primary-inverse);--switch-checked-background-color:var(--primary);--range-border-color:#23333e;--range-active-border-color:#2c3d49;--range-thumb-border-color:var(--background-color);--range-thumb-color:var(--secondary);--range-thumb-hover-color:var(--secondary-hover);--range-thumb-active-color:var(--primary);--table-border-color:var(--muted-border-color);--table-row-stripped-background-color:rgba(115,130,140,0.05);--code-background-color:#17232c;--code-color:var(--muted-color);--code-kbd-background-color:var(--contrast);--code-kbd-color:var(--contrast-inverse);--code-tag-color:#a65980;--code-property-color:#599fa6;--code-value-color:#8c8473;--code-comment-color:#4d606d;--accordion-border-color:var(--muted-border-color);--accordion-active-summary-color:var(--primary);--accordion-close-summary-color:var(--color);--accordion-open-summary-color:var(--muted-color);--card-background-color:#141e25;--card-border-color:#11191f;--card-box-shadow:0 0.125rem 1rem rgba(0,0,0,0.06),0 0.125rem 2rem rgba(0,0,0,0.12),0 0 0 0.0625rem rgba(0,0,0,0.036);--card-sectionning-background-color:#17232c;--progress-background-color:#23333e;--progress-color:var(--primary);--loading-spinner-opacity:.5;--tooltip-background-color:var(--contrast);--tooltip-color:var(--contrast-inverse);--icon-chevron:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");--icon-date:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");--icon-time:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");--icon-search:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");--icon-checkbox:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-minus:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");--icon-valid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(46, 125, 50, 0.999)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-invalid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(183, 28, 28, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E")}}[data-theme=dark]{color-scheme:dark;--background-color:#11191f;--color:#bbc6ce;--h1-color:#edf0f3;--h2-color:#e1e6ea;--h3-color:#d5dce2;--h4-color:#c8d1d8;--h5-color:#bbc6ce;--h6-color:#aebbc3;--muted-color:#73828c;--muted-border-color:#1f2d38;--primary:#1095c1;--primary-hover:#1ab3e6;--primary-focus:rgba(16,149,193,0.25);--primary-inverse:#FFF;--secondary:#596b78;--secondary-hover:#73828c;--secondary-focus:rgba(115,130,140,0.25);--secondary-inverse:#FFF;--contrast:#edf0f3;--contrast-hover:#FFF;--contrast-focus:rgba(115,130,140,0.25);--contrast-inverse:#000;--mark-background-color:#d0c284;--mark-color:#11191f;--ins-color:#388E3C;--del-color:#C62828;--blockquote-border-color:var(--muted-border-color);--blockquote-footer-color:var(--muted-color);--button-box-shadow:0 0 0 rgba(0,0,0,0);--button-hover-box-shadow:0 0 0 rgba(0,0,0,0);--form-element-background-color:#11191f;--form-element-border-color:#374956;--form-element-color:var(--color);--form-element-placeholder-color:var(--muted-color);--form-element-active-background-color:var(--form-element-background-color);--form-element-active-border-color:var(--primary);--form-element-focus-color:var(--primary-focus);--form-element-disabled-background-color:#2c3d49;--form-element-disabled-border-color:#415462;--form-element-disabled-opacity:.5;--form-element-invalid-border-color:#B71C1C;--form-element-invalid-active-border-color:#C62828;--form-element-valid-border-color:#2E7D32;--form-element-valid-active-border-color:#388E3C;--switch-background-color:#374956;--switch-color:var(--primary-inverse);--switch-checked-background-color:var(--primary);--range-border-color:#23333e;--range-active-border-color:#2c3d49;--range-thumb-border-color:var(--background-color);--range-thumb-color:var(--secondary);--range-thumb-hover-color:var(--secondary-hover);--range-thumb-active-color:var(--primary);--table-border-color:var(--muted-border-color);--table-row-stripped-background-color:rgba(115,130,140,0.05);--code-background-color:#17232c;--code-color:var(--muted-color);--code-kbd-background-color:var(--contrast);--code-kbd-color:var(--contrast-inverse);--code-tag-color:#a65980;--code-property-color:#599fa6;--code-value-color:#8c8473;--code-comment-color:#4d606d;--accordion-border-color:var(--muted-border-color);--accordion-active-summary-color:var(--primary);--accordion-close-summary-color:var(--color);--accordion-open-summary-color:var(--muted-color);--card-background-color:#141e25;--card-border-color:#11191f;--card-box-shadow:0 0.125rem 1rem rgba(0,0,0,0.06),0 0.125rem 2rem rgba(0,0,0,0.12),0 0 0 0.0625rem rgba(0,0,0,0.036);--card-sectionning-background-color:#17232c;--progress-background-color:#23333e;--progress-color:var(--primary);--loading-spinner-opacity:.5;--tooltip-background-color:var(--contrast);--tooltip-color:var(--contrast-inverse);--icon-chevron:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");--icon-date:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");--icon-time:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");--icon-search:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");--icon-checkbox:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-minus:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");--icon-valid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(46, 125, 50, 0.999)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-invalid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(183, 28, 28, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E")}*,:after,:before{box-sizing:border-box}:after,:before{text-decoration:inherit;vertical-align:inherit}html{-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:rgba(0,0,0,0);-moz-tab-size:4;-ms-text-size-adjust:100%;background-color:var(--background-color);color:var(--color);font-family:var(--font-family);font-size:var(--font-size);font-weight:var(--font-weight);line-height:var(--line-height);text-rendering:optimizeLegibility;cursor:default}main{display:block}body{width:100%;margin:0}body>footer,body>header,body>main{width:100%;margin-right:auto;margin-left:auto;padding:var(--block-spacing-vertical) 0}.container,.container-fluid{width:100%;margin-right:auto;margin-left:auto;padding-right:var(--spacing);padding-left:var(--spacing)}@media (min-width:576px){.container{max-width:510px;padding-right:0;padding-left:0}}@media (min-width:768px){.container{max-width:700px}}@media (min-width:992px){.container{max-width:920px}}@media (min-width:1200px){.container{max-width:1130px}}section{margin-bottom:var(--block-spacing-vertical)}.grid{grid-column-gap:var(--grid-spacing-horizontal);grid-row-gap:var(--grid-spacing-vertical);display:grid;grid-template-columns:1fr;margin:0}@media (min-width:992px){.grid{grid-template-columns:repeat(auto-fit,minmax(0%,1fr))}}.grid>*{min-width:0}figure{display:block;margin:0;padding:0;overflow-x:auto}figure figcaption{padding:calc(var(--spacing) / 2) 0;color:var(--muted-color)}b,strong{font-weight:bolder}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-0.25em}sup{top:-0.5em}dl dl,dl ol,dl ul,ol dl,ul dl{margin:0}ol ol,ol ul,ul ol,ul ul{margin:0}address,blockquote,dl,figure,form,ol,p,pre,table,ul{margin-top:0;margin-bottom:var(--typography-spacing-vertical);color:var(--color);font-size:1rem;font-style:normal}a{--color:var(--primary);--background-color:transparent;outline:none;background-color:var(--background-color);color:var(--color);text-decoration:var(--text-decoration);transition:background-color var(--transition),color var(--transition),text-decoration var(--transition),box-shadow var(--transition)}a:active,a:focus,a:hover{--color:var(--primary-hover);--text-decoration:underline}a:focus{--background-color:var(--primary-focus)}a.secondary{--color:var(--secondary)}a.secondary:active,a.secondary:focus,a.secondary:hover{--color:var(--secondary-hover)}a.secondary:focus{--background-color:var(--secondary-focus)}a.contrast{--color:var(--contrast)}a.contrast:active,a.contrast:focus,a.contrast:hover{--color:var(--contrast-hover)}a.contrast:focus{--background-color:var(--contrast-focus)}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:var(--typography-spacing-vertical);color:var(--color);font-family:var(--font-family);font-size:var(--font-size);font-weight:var(--font-weight)}h1{--color:var(--h1-color)}h2{--color:var(--h2-color)}h3{--color:var(--h3-color)}h4{--color:var(--h4-color)}h5{--color:var(--h5-color)}h6{--color:var(--h6-color)}address~h1,address~h2,address~h3,address~h4,address~h5,address~h6,blockquote~h1,blockquote~h2,blockquote~h3,blockquote~h4,blockquote~h5,blockquote~h6,dl~h1,dl~h2,dl~h3,dl~h4,dl~h5,dl~h6,figure~h1,figure~h2,figure~h3,figure~h4,figure~h5,figure~h6,form~h1,form~h2,form~h3,form~h4,form~h5,form~h6,ol~h1,ol~h2,ol~h3,ol~h4,ol~h5,ol~h6,pre~h1,pre~h2,pre~h3,pre~h4,pre~h5,pre~h6,p~h1,p~h2,p~h3,p~h4,p~h5,p~h6,table~h1,table~h2,table~h3,table~h4,table~h5,table~h6,ul~h1,ul~h2,ul~h3,ul~h4,ul~h5,ul~h6{margin-top:var(--typography-spacing-vertical)}hgroup{margin-bottom:var(--typography-spacing-vertical)}hgroup>*{margin-bottom:0}hgroup>:last-child{--color:var(--muted-color);--font-weight:unset;font-family:unset;font-size:1rem}p{margin-bottom:var(--typography-spacing-vertical)}small{font-size:var(--font-size)}ol,ul{padding-left:var(--spacing)}ol li,ul li{margin-bottom:calc(var(--typography-spacing-vertical) / 4)}ul li{list-style:square}mark{padding:.125rem .25rem;background-color:var(--mark-background-color);color:var(--mark-color);vertical-align:middle}blockquote{display:block;margin:var(--typography-spacing-vertical) 0;padding:var(--spacing);border-left:0.25rem solid var(--blockquote-border-color)}blockquote footer{margin-top:calc(var(--typography-spacing-vertical) / 2);color:var(--blockquote-footer-color)}abbr[title]{border-bottom:1px dotted;text-decoration:none;cursor:help}ins{color:var(--ins-color);text-decoration:none}del{color:var(--del-color)}::selection{background-color:var(--primary-focus)}audio,canvas,iframe,img,svg,video{vertical-align:middle}audio,video{display:inline-block}audio:not([controls]){display:none;height:0}iframe{border-style:none}img{max-width:100%;height:auto;border-style:none}svg:not([fill]){fill:currentColor}svg:not(:root){overflow:hidden}button{margin:0;overflow:visible;font-family:inherit;text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{padding:0;border-style:none}button{display:block;width:100%;margin-bottom:var(--spacing)}a[role=button]{display:inline-block;text-decoration:none}a[role=button],button,input[type=button],input[type=reset],input[type=submit]{--background-color:var(--primary);--border-color:var(--primary);--color:var(--primary-inverse);--box-shadow:var(--button-box-shadow,0 0 0 rgba(0,0,0,0));padding:var(--form-element-spacing-vertical) var(--form-element-spacing-horizontal);border:var(--border-width) solid var(--border-color);border-radius:var(--border-radius);outline:none;background-color:var(--background-color);box-shadow:var(--box-shadow);color:var(--color);font-size:1rem;font-weight:var(--font-weight);line-height:var(--line-height);text-align:center;cursor:pointer;transition:background-color var(--transition),border-color var(--transition),color var(--transition),box-shadow var(--transition)}a[role=button]:active,a[role=button]:focus,a[role=button]:hover,button:active,button:focus,button:hover,input[type=button]:active,input[type=button]:focus,input[type=button]:hover,input[type=reset]:active,input[type=reset]:focus,input[type=reset]:hover,input[type=submit]:active,input[type=submit]:focus,input[type=submit]:hover{--background-color:var(--primary-hover);--border-color:var(--primary-hover);--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0))}a[role=button]:focus,button:focus,input[type=button]:focus,input[type=reset]:focus,input[type=submit]:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--primary-focus)}input[type=reset]{--background-color:var(--secondary);--border-color:var(--secondary);--color:var(--secondary-inverse);cursor:pointer}input[type=reset]:active,input[type=reset]:focus,input[type=reset]:hover{--background-color:var(--secondary-hover);--border-color:var(--secondary-hover)}input[type=reset]:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--secondary-focus)}a[role=button].secondary,button.secondary,input[type=button].secondary,input[type=reset].secondary,input[type=submit].secondary{--background-color:var(--secondary);--border-color:var(--secondary);--color:var(--secondary-inverse);cursor:pointer}a[role=button].secondary:active,a[role=button].secondary:focus,a[role=button].secondary:hover,button.secondary:active,button.secondary:focus,button.secondary:hover,input[type=button].secondary:active,input[type=button].secondary:focus,input[type=button].secondary:hover,input[type=reset].secondary:active,input[type=reset].secondary:focus,input[type=reset].secondary:hover,input[type=submit].secondary:active,input[type=submit].secondary:focus,input[type=submit].secondary:hover{--background-color:var(--secondary-hover);--border-color:var(--secondary-hover)}a[role=button].secondary:focus,button.secondary:focus,input[type=button].secondary:focus,input[type=reset].secondary:focus,input[type=submit].secondary:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--secondary-focus)}a[role=button].contrast,button.contrast,input[type=button].contrast,input[type=reset].contrast,input[type=submit].contrast{--background-color:var(--contrast);--border-color:var(--contrast);--color:var(--contrast-inverse)}a[role=button].contrast:active,a[role=button].contrast:focus,a[role=button].contrast:hover,button.contrast:active,button.contrast:focus,button.contrast:hover,input[type=button].contrast:active,input[type=button].contrast:focus,input[type=button].contrast:hover,input[type=reset].contrast:active,input[type=reset].contrast:focus,input[type=reset].contrast:hover,input[type=submit].contrast:active,input[type=submit].contrast:focus,input[type=submit].contrast:hover{--background-color:var(--contrast-hover);--border-color:var(--contrast-hover)}a[role=button].contrast:focus,button.contrast:focus,input[type=button].contrast:focus,input[type=reset].contrast:focus,input[type=submit].contrast:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--contrast-focus)}a[role=button].outline,button.outline,input[type=button].outline,input[type=reset].outline,input[type=submit].outline{--background-color:transparent;--color:var(--primary)}a[role=button].outline:active,a[role=button].outline:focus,a[role=button].outline:hover,button.outline:active,button.outline:focus,button.outline:hover,input[type=button].outline:active,input[type=button].outline:focus,input[type=button].outline:hover,input[type=reset].outline:active,input[type=reset].outline:focus,input[type=reset].outline:hover,input[type=submit].outline:active,input[type=submit].outline:focus,input[type=submit].outline:hover{--background-color:transparent;--color:var(--primary-hover)}a[role=button].outline.secondary,button.outline.secondary,input[type=button].outline.secondary,input[type=reset].outline.secondary,input[type=submit].outline.secondary{--color:var(--secondary)}a[role=button].outline.secondary:active,a[role=button].outline.secondary:focus,a[role=button].outline.secondary:hover,button.outline.secondary:active,button.outline.secondary:focus,button.outline.secondary:hover,input[type=button].outline.secondary:active,input[type=button].outline.secondary:focus,input[type=button].outline.secondary:hover,input[type=reset].outline.secondary:active,input[type=reset].outline.secondary:focus,input[type=reset].outline.secondary:hover,input[type=submit].outline.secondary:active,input[type=submit].outline.secondary:focus,input[type=submit].outline.secondary:hover{--color:var(--secondary-hover)}a[role=button].outline.contrast,button.outline.contrast,input[type=button].outline.contrast,input[type=reset].outline.contrast,input[type=submit].outline.contrast{--color:var(--contrast)}a[role=button].outline.contrast:active,a[role=button].outline.contrast:focus,a[role=button].outline.contrast:hover,button.outline.contrast:active,button.outline.contrast:focus,button.outline.contrast:hover,input[type=button].outline.contrast:active,input[type=button].outline.contrast:focus,input[type=button].outline.contrast:hover,input[type=reset].outline.contrast:active,input[type=reset].outline.contrast:focus,input[type=reset].outline.contrast:hover,input[type=submit].outline.contrast:active,input[type=submit].outline.contrast:focus,input[type=submit].outline.contrast:hover{--color:var(--contrast-hover)}a[role=button][disabled],button[disabled],input[type=button][disabled],input[type=reset][disabled],input[type=submit][disabled]{opacity:.5;pointer-events:none}input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:1rem;letter-spacing:inherit;line-height:var(--line-height)}input{overflow:visible}select{text-transform:none}legend{max-width:100%;padding:0;color:inherit;white-space:normal}textarea{overflow:auto}[type=checkbox],[type=radio]{padding:0}::-webkit-inner-spin-button,::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}::-moz-focus-inner{padding:0;border-style:none}:-moz-focusring{outline:none}:-moz-ui-invalid{box-shadow:none}::-ms-expand{display:none}[type=file],[type=range]{padding:0;border-width:0}input:not([type=checkbox]):not([type=radio]):not([type=range]){height:calc((1rem * var(--line-height)) + (var(--form-element-spacing-vertical) * 2) + (var(--border-width) * 2))}fieldset{margin:0;margin-bottom:var(--spacing);padding:0;border:0}fieldset legend,label{display:block;margin-bottom:calc(var(--spacing) / 4);vertical-align:middle}input:not([type=checkbox]):not([type=radio]),select,textarea{display:block;width:100%}input:not([type=checkbox]):not([type=radio]):not([type=range]):not([type=file]),select,textarea{-webkit-appearance:none;-moz-appearance:none;appearance:none;padding:var(--form-element-spacing-vertical) var(--form-element-spacing-horizontal);vertical-align:middle}input,select,textarea{--background-color:var(--form-element-background-color);--border-color:var(--form-element-border-color);--color:var(--form-element-color);--box-shadow:none;border:var(--border-width) solid var(--border-color);border-radius:var(--border-radius);outline:none;background-color:var(--background-color);box-shadow:var(--box-shadow);color:var(--color);font-weight:var(--font-weight);transition:background-color var(--transition),border-color var(--transition),color var(--transition),box-shadow var(--transition)}input:not([type=submit]):not([type=button]):not([type=reset]):not([type=checkbox]):not([type=radio]):not([readonly]):active,input:not([type=submit]):not([type=button]):not([type=reset]):not([type=checkbox]):not([type=radio]):not([readonly]):focus,select:active,select:focus,textarea:active,textarea:focus{--background-color:var(--form-element-active-background-color)}input:not([type=submit]):not([type=button]):not([type=reset]):not([role=switch]):not([readonly]):active,input:not([type=submit]):not([type=button]):not([type=reset]):not([role=switch]):not([readonly]):focus,select:active,select:focus,textarea:active,textarea:focus{--border-color:var(--form-element-active-border-color)}input:not([type=submit]):not([type=button]):not([type=reset]):not([type=range]):not([type=file]):not([readonly]):focus,select:focus,textarea:focus{--box-shadow:0 0 0 var(--outline-width) var(--form-element-focus-color)}input:not([type=submit]):not([type=button]):not([type=reset])[disabled],select[disabled],textarea[disabled]{--background-color:var(--form-element-disabled-background-color);--border-color:var(--form-element-disabled-border-color);opacity:var(--form-element-disabled-opacity)}input[aria-invalid],select[aria-invalid],textarea[aria-invalid]{padding-right:2rem;background-position:center right .75rem;background-repeat:no-repeat;background-size:1rem auto}input[aria-invalid=false],select[aria-invalid=false],textarea[aria-invalid=false]{--border-color:var(--form-element-valid-border-color);background-image:var(--icon-valid)}input[aria-invalid=false]:active,input[aria-invalid=false]:focus,select[aria-invalid=false]:active,select[aria-invalid=false]:focus,textarea[aria-invalid=false]:active,textarea[aria-invalid=false]:focus{--border-color:var(--form-element-valid-active-border-color)!important}input[aria-invalid=true],select[aria-invalid=true],textarea[aria-invalid=true]{--border-color:var(--form-element-invalid-border-color);background-image:var(--icon-invalid)}input[aria-invalid=true]:active,input[aria-invalid=true]:focus,select[aria-invalid=true]:active,select[aria-invalid=true]:focus,textarea[aria-invalid=true]:active,textarea[aria-invalid=true]:focus{--border-color:var(--form-element-invalid-active-border-color)!important}input::-webkit-input-placeholder,input::placeholder,select:invalid,textarea::-webkit-input-placeholder,textarea::placeholder{color:var(--form-element-placeholder-color);opacity:1}input:not([type=checkbox]):not([type=radio]),select,textarea{margin-bottom:var(--spacing)}select::-ms-expand{border:0;background-color:transparent}select:not([multiple]):not([size]){padding-right:calc(var(--form-element-spacing-horizontal) + 1.5rem);background-image:var(--icon-chevron);background-position:center right .75rem;background-repeat:no-repeat;background-size:1rem auto}input+small,select+small,textarea+small{display:block;width:100%;margin-top:calc(var(--spacing) * -0.75);margin-bottom:var(--spacing);color:var(--muted-color)}label>input,label>select,label>textarea{margin-top:calc(var(--spacing) / 4)}[type=checkbox],[type=radio]{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:inline-block;width:1.25em;height:1.25em;margin-top:-.125em;margin-right:.375em;border-width:var(--border-width);vertical-align:middle;cursor:pointer}[type=checkbox]::-ms-check,[type=radio]::-ms-check{display:none}[type=checkbox]:checked,[type=checkbox]:checked:active,[type=checkbox]:checked:focus,[type=radio]:checked,[type=radio]:checked:active,[type=radio]:checked:focus{--background-color:var(--primary);--border-color:var(--primary);background-image:var(--icon-checkbox);background-position:center;background-repeat:no-repeat;background-size:.75em auto}[type=checkbox]~label,[type=radio]~label{display:inline-block;margin-right:.375em;margin-bottom:0;cursor:pointer}[type=checkbox]:indeterminate{--background-color:var(--primary);--border-color:var(--primary);background-image:var(--icon-minus);background-position:center;background-repeat:no-repeat;background-size:.75em auto}[type=radio]{border-radius:50%}[type=radio]:checked,[type=radio]:checked:active,[type=radio]:checked:focus{--background-color:var(--primary-inverse);border-width:.35em;background-image:none}[type=checkbox][role=switch]{--background-color:var(--switch-background-color);--border-color:var(--switch-background-color);--color:var(--switch-color);width:2.25em;height:1.25em;border:var(--border-width) solid var(--border-color);border-radius:1.25em;background-color:var(--background-color);line-height:1.25em}[type=checkbox][role=switch]:focus{--background-color:var(--switch-background-color);--border-color:var(--switch-background-color)}[type=checkbox][role=switch]:checked{--background-color:var(--switch-checked-background-color);--border-color:var(--switch-checked-background-color)}[type=checkbox][role=switch]:before{display:block;width:calc(1.25em - (var(--border-width) * 2));height:100%;border-radius:50%;background-color:var(--color);content:'';transition:margin 0.1s ease-in-out}[type=checkbox][role=switch]:checked{background-image:none}[type=checkbox][role=switch]:checked:before{margin-right:0;margin-left:calc(1.125em - var(--border-width))}[type=color]::-webkit-color-swatch-wrapper{padding:0}[type=color]::-moz-focus-inner{padding:0}[type=color]::-webkit-color-swatch{border:none;border-radius:calc(var(--border-radius) / 2)}[type=color]::-moz-color-swatch{border:none;border-radius:calc(var(--border-radius) / 2)}[type=date],[type=datetime-local],[type=month],[type=time],[type=week]{background-image:var(--icon-date);background-position:center right .75rem;background-repeat:no-repeat;background-size:1rem auto}[type=date]::-webkit-calendar-picker-indicator,[type=datetime-local]::-webkit-calendar-picker-indicator,[type=month]::-webkit-calendar-picker-indicator,[type=time]::-webkit-calendar-picker-indicator,[type=week]::-webkit-calendar-picker-indicator{opacity:0}[type=time]{background-image:var(--icon-time)}[type=file]{--color:var(--muted-color);padding:calc(var(--form-element-spacing-vertical)/2) 0;border:none;border-radius:0;background:none}[type=file]::-webkit-file-upload-button{--background-color:var(--secondary);--border-color:var(--secondary);--color:var(--secondary-inverse);margin-right:calc(var(--spacing) / 2);padding:calc(var(--form-element-spacing-vertical) / 2) calc(var(--form-element-spacing-horizontal) / 2);border:var(--border-width) solid var(--border-color);border-radius:var(--border-radius);outline:none;background-color:var(--background-color);box-shadow:var(--box-shadow);color:var(--color);font-size:1rem;font-weight:var(--font-weight);line-height:var(--line-height);text-align:center;cursor:pointer;transition:background-color var(--transition),border-color var(--transition),color var(--transition),box-shadow var(--transition)}[type=file]:active,[type=file]:focus,[type=file]:hover{--color:var(--color);border:none;background:none}[type=file]:active::-webkit-file-upload-button,[type=file]:focus::-webkit-file-upload-button,[type=file]:hover::-webkit-file-upload-button{--background-color:var(--secondary-hover);--border-color:var(--secondary-hover)}[type=range]{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:block;width:100%;height:1.25rem;background:transparent}[type=range]::-webkit-slider-runnable-track{width:100%;height:0.25rem;border-radius:var(--border-radius);background-color:var(--range-border-color);transition:background-color var(--transition),box-shadow var(--transition)}[type=range]::-moz-range-track{width:100%;height:0.25rem;border-radius:var(--border-radius);background-color:var(--range-border-color);transition:background-color var(--transition),box-shadow var(--transition)}[type=range]::-ms-track{width:100%;height:0.25rem;border-radius:var(--border-radius);background-color:var(--range-border-color);transition:background-color var(--transition),box-shadow var(--transition)}[type=range]::-ms-fill-lower{background-color:var(--border-radius)}[type=range]::-webkit-slider-thumb{-webkit-appearance:none;width:1.25rem;height:1.25rem;margin-top:-0.5rem;border:2px solid var(--range-thumb-border-color);border-radius:50%;background-color:var(--range-thumb-color);cursor:pointer;transition:background-color var(--transition),transform var(--transition)}[type=range]::-moz-range-thumb{-webkit-appearance:none;width:1.25rem;height:1.25rem;margin-top:-0.5rem;border:2px solid var(--range-thumb-border-color);border-radius:50%;background-color:var(--range-thumb-color);cursor:pointer;transition:background-color var(--transition),transform var(--transition)}[type=range]::-ms-thumb{-webkit-appearance:none;width:1.25rem;height:1.25rem;margin-top:-0.5rem;border:2px solid var(--range-thumb-border-color);border-radius:50%;background-color:var(--range-thumb-color);cursor:pointer;transition:background-color var(--transition),transform var(--transition)}[type=range]:focus,[type=range]:hover{--range-border-color:var(--range-active-border-color);--range-thumb-color:var(--range-thumb-hover-color)}[type=range]:active{--range-thumb-color:var(--range-thumb-active-color)}[type=range]:active::-webkit-slider-thumb{transform:scale(1.25)}[type=range]:active::-moz-range-thumb{transform:scale(1.25)}[type=range]:active::-ms-thumb{transform:scale(1.25)}[type=search]{border-radius:5rem;padding-left:calc(var(--form-element-spacing-horizontal) + 1.75rem)!important;background-image:var(--icon-search);background-position:center left 1.125rem;background-repeat:no-repeat;background-size:1rem auto}[type=search]::-webkit-search-cancel-button{-webkit-appearance:none;display:none}table{width:100%;border-color:inherit;border-collapse:collapse;border-spacing:0;text-indent:0}td,th{padding:calc(var(--spacing) / 2) var(--spacing);border-bottom:var(--border-width) solid var(--table-border-color);color:var(--color);font-size:var(--font-size);font-weight:var(--font-weight);text-align:left}tr{background-color:var(--background-color)}table[role=grid] tbody tr:nth-child(odd){--background-color:var(--table-row-stripped-background-color)}code,kbd,pre,samp{font-family:var(--font-family);font-size:.875rem}pre{-ms-overflow-style:scrollbar;overflow:auto}code,kbd,pre{background:var(--code-background-color);color:var(--code-color);font-weight:var(--font-weight);line-height:initial}code,kbd{display:inline-block;padding:.375rem .5rem;border-radius:var(--border-radius)}pre{display:block;margin-bottom:var(--spacing);padding:var(--spacing);overflow-x:auto;background:var(--code-background-color)}pre>code{display:block;padding:0;background:transparent;font-size:14px;line-height:var(--line-height)}code b{color:var(--code-tag-color);font-weight:var(--font-weight)}code i{color:var(--code-property-color);font-style:normal}code u{color:var(--code-value-color);text-decoration:none}code em{color:var(--code-comment-color);font-style:normal}kbd{background-color:var(--code-kbd-background-color);color:var(--code-kbd-color);vertical-align:middle}hr{box-sizing:content-box;height:0;overflow:visible;border:none;border-top:1px solid var(--muted-border-color)}[hidden],template{display:none}dialog{display:block;position:absolute;right:0;left:0;width:-moz-fit-content;width:-webkit-fit-content;width:fit-content;height:-moz-fit-content;height:-webkit-fit-content;height:fit-content;margin:auto;padding:1em;border:solid;background-color:white;color:black}dialog:not([open]){display:none}canvas{display:inline-block}details{display:block;margin-bottom:var(--spacing);padding-bottom:calc(var(--spacing) / 2);border-bottom:var(--border-width) solid var(--accordion-border-color)}details summary{color:var(--accordion-close-summary-color);line-height:1rem;list-style-type:none;list-style-type:none;cursor:pointer;transition:color var(--transition)}details summary::-webkit-details-marker{display:none}details summary::marker{display:none}details summary::-moz-list-bullet{list-style-type:none}details summary:after{display:inline-block;width:1rem;height:1rem;float:right;transform:rotate(-90deg);background-image:var(--icon-chevron);background-position:center;background-repeat:no-repeat;background-size:1rem auto;content:'';transition:transform var(--transition)}details summary:focus{outline:none;color:var(--accordion-active-summary-color)}details summary~*{margin-top:calc(var(--spacing) / 2)}details summary~*~*{margin-top:0}details[open]>summary{margin-bottom:calc(var(--spacing) / 4)}details[open]>summary:not(:focus){color:var(--accordion-open-summary-color)}details[open]>summary:after{transform:rotate(0)}article{margin:var(--block-spacing-vertical) 0;padding:var(--block-spacing-vertical) var(--block-spacing-horizontal);overflow:hidden;border-radius:var(--border-radius);background:var(--card-background-color);box-shadow:var(--card-box-shadow)}article>footer,article>header,article>pre{margin-right:calc(var(--block-spacing-horizontal) * -1);margin-left:calc(var(--block-spacing-horizontal) * -1);padding:calc(var(--block-spacing-vertical) / 1.5) var(--block-spacing-horizontal);background-color:var(--card-sectionning-background-color)}article>header{margin-top:calc(var(--block-spacing-vertical) * -1);margin-bottom:var(--block-spacing-vertical);border-bottom:var(--border-width) solid var(--card-border-color)}article>footer,article>pre{margin-top:var(--block-spacing-vertical);margin-bottom:calc(var(--block-spacing-vertical) * -1);border-top:var(--border-width) solid var(--card-border-color)}nav,nav ul{display:flex}nav{justify-content:space-between}nav ol,nav ul{align-items:center;margin-bottom:0;padding:0;list-style:none}nav ol:first-of-type,nav ul:first-of-type{margin-left:calc(var(--spacing) * -0.5)}nav ol:last-of-type,nav ul:last-of-type{margin-right:calc(var(--spacing) * -0.5)}nav li{display:inline-block;margin:0;padding:var(--spacing) calc(var(--spacing) / 2)}nav li>*,nav li>input:not([type=checkbox]):not([type=radio]){margin-bottom:0}nav a{display:block;margin:calc(var(--spacing) * -1) calc(var(--spacing) * -0.5);padding:var(--spacing) calc(var(--spacing) / 2);border-radius:var(--border-radius);text-decoration:none}nav a:active,nav a:focus,nav a:hover{text-decoration:none}aside li,aside nav,aside ol,aside ul{display:block}aside li{padding:calc(var(--spacing) / 2)}aside li a{margin:calc(var(--spacing) * -0.5);padding:calc(var(--spacing) / 2)}progress{display:inline-block;vertical-align:baseline}progress{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:inline-block;width:100%;height:.5rem;margin-bottom:calc(var(--spacing) / 2);overflow:hidden;border:0;border-radius:var(--border-radius);background-color:var(--progress-background-color);color:var(--progress-color)}progress::-webkit-progress-bar{border-radius:var(--border-radius);background:transparent}progress[value]::-webkit-progress-value{background-color:var(--progress-color)}progress::-moz-progress-bar{background-color:var(--progress-color)}@media (prefers-reduced-motion:no-preference){progress:indeterminate{background:var(--progress-background-color) linear-gradient(to right,var(--progress-color) 30%,var(--progress-background-color) 30%) top left/150% 150% no-repeat;animation:progressIndeterminate 1s linear infinite}progress:indeterminate[value]::-webkit-progress-value{background-color:transparent}progress:indeterminate::-moz-progress-bar{background-color:transparent}}@keyframes progressIndeterminate{0%{background-position:200% 0}to{background-position:-200% 0}}[aria-busy=true]{cursor:progress}[aria-busy=true]:not(input):not(select):not(textarea):before{display:inline-block;width:1em;height:1em;border:0.1875em solid currentColor;border-radius:1em;border-right-color:transparent;vertical-align:text-bottom;vertical-align:-.125em;animation:spinner 0.75s linear infinite;content:'';opacity:var(--loading-spinner-opacity)}[aria-busy=true]:not(input):not(select):not(textarea):not(:empty):before{margin-right:calc(var(--spacing) / 2)}[aria-busy=true]:not(input):not(select):not(textarea):empty{text-align:center}a[aria-busy=true],button[aria-busy=true],input[type=button][aria-busy=true],input[type=reset][aria-busy=true],input[type=submit][aria-busy=true]{pointer-events:none}@keyframes spinner{to{transform:rotate(360deg)}}[data-tooltip]{position:relative}[data-tooltip]:not(a):not(button):not(input){border-bottom:1px dotted;text-decoration:none;cursor:help}[data-tooltip]:after,[data-tooltip]:before{display:block;z-index:99;position:absolute;bottom:100%;left:50%;padding:.25rem .5rem;overflow:hidden;transform:translate(-50%,-0.25rem);border-radius:var(--border-radius);background:var(--tooltip-background-color);color:var(--tooltip-color);font-size:.875rem;font-style:normal;font-weight:var(--font-weight);text-decoration:none;text-overflow:ellipsis;white-space:nowrap;content:attr(data-tooltip);opacity:0;pointer-events:none}[data-tooltip]:after{padding:0;transform:translate(-50%,0rem);border-top:.3rem solid;border-right:.3rem solid transparent;border-left:.3rem solid transparent;border-radius:0;background-color:transparent;color:var(--tooltip-background-color);content:''}[data-tooltip]:focus:after,[data-tooltip]:focus:before,[data-tooltip]:hover:after,[data-tooltip]:hover:before{opacity:1;animation-name:slide;animation-duration:.2s}[data-tooltip]:focus:after,[data-tooltip]:hover:after{animation-name:slideCaret}@keyframes slide{0%{transform:translate(-50%,0.75rem);opacity:0}to{transform:translate(-50%,-0.25rem);opacity:1}}@keyframes slideCaret{0%{opacity:0}50%{transform:translate(-50%,-0.25rem);opacity:0}to{transform:translate(-50%,0rem);opacity:1}}[aria-controls]{cursor:pointer}[aria-disabled=true],[disabled]{cursor:not-allowed}[aria-hidden=false][hidden]{display:initial}[aria-hidden=false][hidden]:not(:focus){clip:rect(0,0,0,0);position:absolute}[tabindex],a,area,button,input,label,select,summary,textarea{-ms-touch-action:manipulation}@media (prefers-reduced-motion:reduce){:not([aria-busy=true]),:not([aria-busy=true]):after,:not([aria-busy=true]):before{background-attachment:initial!important;animation-duration:1ms!important;animation-delay:-1ms!important;animation-iteration-count:1!important;scroll-behavior:auto!important;transition-delay:0s!important;transition-duration:0s!important}}
    </style>
    <style type="text/css">
      article div {
        font-size: 1.15em;
        line-height: 1.6em;
      }
    </style>
  </head>
  <body style="background-color: #f9fafb;">
    <main class="container">
      <nav>
        <ul>
          <li><a href="../index.html"> Topic list</a></li>
        </ul>
      </nav>
      <!-- <h1>Infomedia Articles Selection: 50 articles</h1> -->
      <h1>hSBM 0_15 <kbd>H_0_15</kbd></h1>
      <h3>Words (top 25)</h3>
      <div style="margin:0px -12px">
        <span style="font-size:29.29pt; padding:0px 12px"><strong>billeder</strong>&nbsp;<span style="font-size:.5em">3347</span></span>
        <span style="font-size:22.18pt; padding:0px 12px"><strong>billedet</strong>&nbsp;<span style="font-size:.5em">1249</span></span>
        <span style="font-size:19.68pt; padding:0px 12px"><strong>kameraer</strong>&nbsp;<span style="font-size:.5em">754</span></span>
        <span style="font-size:19.29pt; padding:0px 12px"><strong>ansigt</strong>&nbsp;<span style="font-size:.5em">687</span></span>
        <span style="font-size:18.56pt; padding:0px 12px"><strong>indbygget</strong>&nbsp;<span style="font-size:.5em">571</span></span>
        <span style="font-size:17.47pt; padding:0px 12px"><strong>objekter</strong>&nbsp;<span style="font-size:.5em">419</span></span>
        <span style="font-size:17.43pt; padding:0px 12px"><strong>ansigter</strong>&nbsp;<span style="font-size:.5em">413</span></span>
        <span style="font-size:16.03pt; padding:0px 12px"><strong>optage</strong>&nbsp;<span style="font-size:.5em">253</span></span>
        <span style="font-size:15.39pt; padding:0px 12px"><strong>ansigtet</strong>&nbsp;<span style="font-size:.5em">193</span></span>
        <span style="font-size:15.23pt; padding:0px 12px"><strong>genkender</strong>&nbsp;<span style="font-size:.5em">179</span></span>
        <span style="font-size:15.18pt; padding:0px 12px"><strong>vinkler</strong>&nbsp;<span style="font-size:.5em">175</span></span>
        <span style="font-size:14.83pt; padding:0px 12px"><strong>kameraerne</strong>&nbsp;<span style="font-size:.5em">147</span></span>
        <span style="font-size:14.41pt; padding:0px 12px"><strong>optagelserne</strong>&nbsp;<span style="font-size:.5em">116</span></span>
        <span style="font-size:14.39pt; padding:0px 12px"><strong>finger</strong>&nbsp;<span style="font-size:.5em">115</span></span>
        <span style="font-size:14.03pt; padding:0px 12px"><strong>face</strong>&nbsp;<span style="font-size:.5em">92</span></span>
        <span style="font-size:13.86pt; padding:0px 12px"><strong>filme</strong>&nbsp;<span style="font-size:.5em">82</span></span>
        <span style="font-size:13.79pt; padding:0px 12px"><strong>telefonopkald</strong>&nbsp;<span style="font-size:.5em">78</span></span>
        <span style="font-size:13.70pt; padding:0px 12px"><strong>brillerne</strong>&nbsp;<span style="font-size:.5em">73</span></span>
        <span style="font-size:13.45pt; padding:0px 12px"><strong>videooptagelser</strong>&nbsp;<span style="font-size:.5em">60</span></span>
        <span style="font-size:13.35pt; padding:0px 12px"><strong>sporer</strong>&nbsp;<span style="font-size:.5em">55</span></span>
        <span style="font-size:13.26pt; padding:0px 12px"><strong>bearbejder</strong>&nbsp;<span style="font-size:.5em">51</span></span>
        <span style="font-size:13.21pt; padding:0px 12px"><strong>pc'en</strong>&nbsp;<span style="font-size:.5em">49</span></span>
        <span style="font-size:13.19pt; padding:0px 12px"><strong>hndholdt</strong>&nbsp;<span style="font-size:.5em">48</span></span>
        <span style="font-size:13.19pt; padding:0px 12px"><strong>filmer</strong>&nbsp;<span style="font-size:.5em">48</span></span>
        <span style="font-size:13.12pt; padding:0px 12px"><strong>kerner</strong>&nbsp;<span style="font-size:.5em">45</span></span>
      </div>
      <br><br>
      <h3>Articles (top 50)</h3>
      Query:
      <pre>SELECT * FROM articles WHERE articles.dupeKeep=1 AND articles.sizeKeep=1 ORDER BY H_0_15 DESC LIMIT 50</pre>
      <article>
        <h4>Ansigter kan gres mindevrdige</h4>
        <div>
          Et computerprogram, der manipulerer ansigter p billeder mere mindevrdige.Det har forskere ved MIT i USA skabt. De har udregnet en algoritme, som manipulerer billeder, s de bliver mere eller mindre mindevrdige. Da forskerne viste de manipulerede billeder til 80 forsgspersoner, viste det sig, at computerprogrammet havde formet at gre ansigterne henholdsvis lettere og vanskeligere at huske i mere end syv ud af ti tilflde.
        </div>
        <footer>
          <em>Jyllands-Posten</em>
          &nbsp;&nbsp; 2014-02-23
          &nbsp;&nbsp; e446994a
          &nbsp;&nbsp; #0
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.868</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.821</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.649</kbd>
        </footer>
      </article>
      <article>
        <h4>Kineserne bruger ansigtsgenkendelse til at betale med</h4>
        <div>
          Via en app kan kineserne betale med deres ansigt. 150 millioner kinesere er allerede i gang.Nu er teknologien til ansigtsgenkendelse s sikker, at kineserne kan overfre penge og betale med deres ansigt via Alibabas mobilbetalings-app Alipay.Det skriver Quartz.150 millioner kinesere har indtil videre benyttet sig af, at de kan bruge deres ansigt til at overfre penge.I Kina har regeringen gemt billeder af befolkningen i en database. Det gr, at ansigtsgenkendelse gennem AI kan og bliver brugt til mange ting.For eksempel kan man ogs benytte sig af at bruge sit ansigt som identifikation ved bycyklerne Didi, og den hos kinesiske Google, kaldet Baidu, kan man bruge sit ansigt som adgangskort og billet til for eksempel offentlig transport.Version2 har tidligere skrevet om, hvordan fastfood-kden Kentucky Fried Chicken benytter sig af ansigtsgenkendelse til at tilbyde kunderne det, de plejer godt at kunne lide af mad.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2017-07-07
          &nbsp;&nbsp; e653b264
          &nbsp;&nbsp; #1
          <br>
          <br>
            <kbd data-tooltip="Tech industry &amp; regulation">L02_BIGTEC&nbsp;0.714</kbd>
            <kbd data-tooltip="Facebook, fake news &amp; Trump">L05_FBTRUM&nbsp;0.543</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.624</kbd>
        </footer>
      </article>
      <article>
        <h4>Javascript genkender ansigter i browseren</h4>
        <div>
          Nu kan Javascript-udviklere bygge ansigtsgenkendelse i webapps. Face-api.js er et Javascript-api til ansigtsgenkendelse i browseren implementeret oven p Googles Tensorflow.js, som er en Javascript-implementering af firmaets populre machine learning teknologi til browsere og Node.js-miljet.Til teknologibloggen Infoq forklarer Vincent Mhler, som er skaberen af Face-api.js motivationen bag:Jeg havde et andet bibliotek, som var i stand til at detektere ansigter og udfre ansigtsgenkendelse med Node.js. P et tidspunkt opdagede jeg Tensorflow.js og blev interesseret i maskinlring i browseren. Jeg var nysgerrig p, om det var muligt at flytte eksisterende modeller til ansigtsgenkendelse og ansigtsgenkendelse til Tensorflow.js, og det fungerede ganske godt. Face-api.js kommer med tre modeller: SSD Mobilenet V1, Tiny Face Detector og MTCNN.Tiny Face Detector er trnet p et brugerdefineret datast med 14.000 billeder. Apps med begrnsede resurser br bruge denne model.Til ansigtsgenkendelse benyttes en model baseret p en ResNet-34-lignende arkitektur, til at beregne en ansigtsbeskrivelse ud fra et billede. Denne model er ikke begrnset til det st ansigter, der bruges til trning, hvilket betyder, at udviklere kan bruge det til genkendelse af alle personernes ansigter. Det er muligt at bestemme ligheden mellem to vilkrlige ansigter, ved at sammenligne deres ansigtsbeskrivelser.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2018-11-14
          &nbsp;&nbsp; e6f8ed73
          &nbsp;&nbsp; #2
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.977</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.912</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.665</kbd>
        </footer>
      </article>
      <article>
        <h4>Du behver ikke at fortrkke en mine: Dit ansigt afslrer dig alligevel</h4>
        <div>
          Nyt studie viser, at farveskift i ansigtet afslrer menneskets flelser.Sm farveskift i ansigtet, som p billede to er forstrkede, kan afslre dine flelser. Foto: Ohio State UniversityAnne FilbertSelvom du holder dit klige blik, din mund i en lige steg og din pande glat og uden en rynke, s afslrer dit ansigt dig alligevel. Et nyt studie har nemlig vist, at det ikke ndvendigvis er trkningerne i dit ansigt, der giver dig vk.Studiet undersgte evnen til at genkende andres flelser alene ud fra sm skift i farven omkring nsen, jenbrynene, kinderne eller hagen. Iflge forskningsholdet beviser studiet en sammenhng mellem centralnervesystemet og flelsesmssige udtryk i ansigtet.Farveskiftene i ansigtet kommer nemlig af en sammenhng mellem centralnervesystemet og blodtilfrslen i ansigtet, der ndrer sig i takt med vores flelser.Det har derfor ogs lykkedes forskere at konstruere et computerprogram, der kunne genkende menneskers flelser vha. ansigtfarve med en succesrate p 90 pct.Forskerholdet, der kommer fra Ohio State University, har valgt at tage patent p systemet, da de mener, at forskningen kan bruges til at udvikle kunstig intelligens og dermed lre maskiner at genkende og efterligne menneskelige flelser.For at undersge om folk rent faktisk kunne genkende flelser alene ud fra farveskift i ansigtet, retoucherede forskerholdet en rkke billeder af ansigter uden udtryk, hvor de s puttede forstrkede farver p alt efter hvilken flelse, de gerne ville have dem til at vise.Ca. 75 pct. af tilfldende gttede testpersonerne rigtigt i og kunne derfor genkende flelser alene ud fra farvekskiftene. Et andet forsg gik ud p at vende om p ansigtsudtryk og farveskift.Farverne i billedet er forstrket for at illustrere, hvordan blodet strmmer til forskellige steder i ansigtet, alt efter hvilken flelse man har. Foto: Ohio State UniversityHer tog forskerne f.eks. de farveforstrkere, der indikerer glde, og satte dem p en person, der viste et nedtrykt ansigtsudtryk. Her kommenterede strstedelen af testpersonerne, at der var noget underligt ved ansigtet.Den flelse, der var nemmest for bde computere og testpersoner at genkende, var glde. Det blev tydeligt i forsget, at glde i hjere grad fik blodet til at strmme til specifikke steder i ansigtet, hvilket gjorde flelsen lettere genkendelig.
        </div>
        <footer>
          <em>Jyllands-posten.dk</em>
          &nbsp;&nbsp; 2018-03-21
          &nbsp;&nbsp; e6ac75b1
          &nbsp;&nbsp; #3
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.927</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.606</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.647</kbd>
        </footer>
      </article>
      <article>
        <h4>ER DU KLAR OVER, HVILKEN BIAS TEKNOLOGIEN SERVERER?</h4>
        <div>
          Tech-journalist Marie Hst undersger teknologiens blinde vinkler i ingenirforeningen, IDAs podcast ' Blinde Vinkler'.Her kigger hun ind i teknologier og videnskab, som forsger at rette op p udfordringen med kns-og etnicitetsmssig bias. De forskellige podcasts tager bl. a.fat i rekruttering via machine learning og stemmestyrede digitale tjenester.Blinde vinkler Lyt her: bit. ly/ techman1.
        </div>
        <footer>
          <em>Tech Management</em>
          &nbsp;&nbsp; 2020-11-13
          &nbsp;&nbsp; e7fd2243
          &nbsp;&nbsp; #4
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.592</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.542</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.554</kbd>
        </footer>
      </article>
      <article>
        <h4>Spionkameraer mod elge</h4>
        <div>
          SVERIGE: Nr elgene bevger sig rundt i de svenske skove, skal de fremover vnne sig til, at mennesker kigger med.Der er nemlig ved at blive sat kameraer op i skovene i Gvleborg i Sverige som en del af et EU-projekt.De skal samle billeder ind af elgene, s dyrene p den mde fremover kan tlles uden hjlp fra jgere.Kameraerne bliver aktiveret af varme og bevgelse. Ved hjlp af kunstig intelligens skal det s vre muligt at genkende elgene.
        </div>
        <footer>
          <em>Ekstra Bladet</em>
          &nbsp;&nbsp; 2021-01-04
          &nbsp;&nbsp; e80ebeee
          &nbsp;&nbsp; #5
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.847</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.589</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.706</kbd>
        </footer>
      </article>
      <article>
        <h4>Facebook-algoritme genkender dig selvom dit ansigt er skjult</h4>
        <div>
          Det sociale medie fortstter sine bestrbelser inden for ansigtsgenkendelse og har nu udviklet en algoritme, som kan identificere en afbildet person med 83 procents njagtighed, selvom ansigtet ikke er synligt.Af Martin Bernth Tirsdag, 23. juni 2015 - 15:10Det seneste nye fra Facebooks laboratorium for kunstig intelligens er en -ansigtsgenkendende- algoritme, som ikke behver dit ansigt for at identificere en person p billedet.Det skriver New Scientist.I stedet for at analysere ansigter sammenholder den nye algoritme andre genkendelige trk ssom frisure, bekldning, kropsform og -holdning og skal en genkendelsesrate p 83 procent.Algoritmen er udviklet med baggrund i 40.000 billeder fra tjenesten Flickr, hvor ansigter bde var synlige og skjulte og fodret ind i et -sofistikeret neuralt netvrk-, uden at dette beskrive nrmere.Umiddelbart virker algoritmen oplagt til at lgge p som et ekstra sgefilter i Facebooks netop lancerede tjeneste, Moments, (i USA, red. ), som gennemsger en brugers telefon for billeder af venners ansigter, som systemet dernst bundler, og tilbyder at dele privat med vennerne.Den nye algoritme er dog ogs et tvegget svrd i debatten om privacy, da den p den ene side er et lovende detektionsvrktj for personer, der nsker at blive notificeret, nr et billede af dem dukker op p nettet.P den anden side, kan man argumentere for, at algoritmen vil skabe panderyner hos privacy-fortalere, der vil problematiser, at det nu er muligt at blive identificeret p billeder, man end ikke er klar over, man indgr i.Via: New Scientist
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2015-06-23
          &nbsp;&nbsp; e517e44c
          &nbsp;&nbsp; #6
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.506</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.581</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.663</kbd>
        </footer>
      </article>
      <article>
        <h4>Ny algoritme fra Adobe: Fjerner linselus fra dit feriefoto</h4>
        <div>
          Fremover er det slut med at f unskede ansigter og mennesker med p dine feriebilleder. Adobe har udviklet en ny feature, der kan fjerne bde bevgelige og stationre objekter fra dine billeder. Algoritmen blev prsenteret p Max Konferencen i denne uge.eAdobe rigtig vil ikke rigtig forklare, hvordan den nye funktion - kaldet Monument Mode - fungerer, men det ser det ud til, at algoritmen bde kan registrere stationr objekter (Eiffeltrnet, for eksempel) og bevgelige objekter (turister) i realtid, og fjerne dem fra dit fotoskud.Fr og efter. (Adobe)Her demonstrerer skuespiller Nick Offerman og Adobe community manager Kim Chambers funktionen (i fem utroligt akavede minutter).Adobe benytter ofte sine konferencer til at fremvise nye teknologier, som kan integreres i deres produkter. Idet Monument Mode fjerner objekter fra et foto, fr det er taget, er det sandsynligvis til en mobil app. Det vides endnu ikke hvornr og om det nogensinde bliver tilgngelige for forbrugere.Indtil da m vi njes med Photoshop.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2015-10-09
          &nbsp;&nbsp; e5412820
          &nbsp;&nbsp; #7
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.754</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.821</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.596</kbd>
        </footer>
      </article>
      <article>
        <h4>Ritzau Plus: Overvgning i Mannheim</h4>
        <div>
          MannheimMannheim Way 2.0:* Der opsttes 71 videokameraer. * Kameraerne opsttes p 28 offentlige steder, hvor der ofte begs kriminalitet.* Krypterede optagelser sendes til en computer p byens politistation.* Et computerprogram udviklet p Fraunhofer Institute i Karlsruhe analyserer bevgelsesmnstre fra optagelserne ved hjlp af en algoritme. * Finder computeren et atypisk mnster, tilkaldes en politibetjent. * Alle billeder slettes efter tre dage.Kilde: Borgmesterkontoret i Mannheim/ritzau/Denne nyhed m publiceres digitalt bag paywall fra d. 17/02/2018 14:00Denne nyhed publiceres ikke p NET-tjenesten
        </div>
        <footer>
          <em>Ritzaus Bureau</em>
          &nbsp;&nbsp; 2018-02-17
          &nbsp;&nbsp; e69f9590
          &nbsp;&nbsp; #8
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.681</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.575</kbd>
        </footer>
      </article>
      <article>
        <h4>Du behver ikke at fortrkke en mine: Dit ansigt afslrer dig alligevel</h4>
        <div>
          Nyt studie viser, at farveskift i ansigtet afslrer menneskets flelser.Selvom du holder dit klige blik, din mund i en lige steg og din pande glat og uden en rynke, s afslrer dit ansigt dig alligevel. Et nyt studie har nemlig vist, at det ikke ndvendigvis er trkningerne i dit ansigt, der giver dig vk.Studiet undersgte evnen til at genkende andres flelser alene ud fra sm skift i farven omkring nsen, jenbrynene, kinderne eller hagen. Iflge forskningsholdet beviser studiet en sammenhng mellem centralnervesystemet og flelsesmssige udtryk i ansigtet.Farveskiftene i ansigtet kommer nemlig af en sammenhng mellem centralnervesystemet og blodtilfrslen i ansigtet, der ndrer sig i takt med vores flelser.Det har derfor ogs lykkedes forskere at konstruere et computerprogram, der kunne genkende menneskers flelser vha. ansigtfarve med en succesrate p 90 pct.Forskerholdet, der kommer fra Ohio State University, har valgt at tage patent p systemet, da de mener, at forskningen kan bruges til at udvikle kunstig intelligens og dermed lre maskiner at genkende og efterligne menneskelige flelser.For at undersge om folk rent faktisk kunne genkende flelser alene ud fra farveskift i ansigtet, retoucherede forskerholdet en rkke billeder af ansigter uden udtryk, hvor de s puttede forstrkede farver p alt efter hvilken flelse, de gerne ville have dem til at vise.Ca. 75 pct. af tilfldende gttede testpersonerne rigtigt i og kunne derfor genkende flelser alene ud fra farvekskiftene. Et andet forsg gik ud p at vende om p ansigtsudtryk og farveskift.Her tog forskerne f.eks. de farveforstrkere, der indikerer glde, og satte dem p en person, der viste et nedtrykt ansigtsudtryk. Her kommenterede strstedelen af testpersonerne, at der var noget underligt ved ansigtet.Den flelse, der var nemmest for bde computere og testpersoner at genkende, var glde. Det blev tydeligt i forsget, at glde i hjere grad fik blodet til at strmme til specifikke steder i ansigtet, hvilket gjorde flelsen lettere genkendelig.
        </div>
        <footer>
          <em>Jyllands-posten.dk (Abonnementsomrde)</em>
          &nbsp;&nbsp; 2018-03-21
          &nbsp;&nbsp; e6ac75be
          &nbsp;&nbsp; #9
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.914</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.642</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.65</kbd>
        </footer>
      </article>
      <article>
        <h4>Nvidia-AI genererer trovrdige billeder af opdigtede mennesker</h4>
        <div>
          Ved at fodre en AI med 30.000 billeder af kendisser, er den i stand til at genere trovrdige billeder af, hvordan den mener, mennesker ser ud. Og den gr det godt.Nvidia har udviklet en algoritme, som er i stand til at skabe billeder af mennesker udelukkende baseret p en viden om, hvordan mennesker generelt ser ud.Det skriver Quartz.Nvidia GAN, som systemet hedder, er egentlig i sig selv simpelt. Man viser to AI's omkring 30.000 billeder af kendte mennesker ansigter, og fortller, at det er sdan, mennesker ser ud. Derefter bliver den ene AI sat til at skabe trovrdige billeder af mennesker, mens den anden hele tiden fortller, hvorvidt billedet faktisk er trovrdigt. Her fortstter animeringen frem til, at der er bygget et trovrdigt billede, og de to AI's gr videre til nste design.Antallet er nglenFaktisk formr AI'en at skabe billeder, som for det meste ikke falder i'the uncanny valley', eller som ser srligt unaturlige ud. Og her er nglen antallet. I 2012 viste en undersgelse, at mngden af data, som man sender gennem et neuralt netvrk er alfa-omega i forhold til succesen af den opgave, netvrket skal udfre.Og i dette tilflde fodrede Nvidia som sagt AI'en med 30.000 billeder af, hvordan kendte mennesker s ud, og det er derfra, at prcisionen kommer. Dette skal naturligvis lgges til erfaringerne, som AI'en lbende drager.Iflge Quartz er systemet allerede ved at gre sit indtog i modeverdenen, hvor den, grundet den hje grad af realisme, kan jnes at erstatte modefotograferne.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2017-11-01
          &nbsp;&nbsp; e67b8dc4
          &nbsp;&nbsp; #10
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.991</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.815</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.713</kbd>
        </footer>
      </article>
      <article>
        <h4>Googles jpg-drber: WebP viser billedet fr det er hentet</h4>
        <div>
          Se billederne: Google vil skubbe det traditionelle billedformat JPEG ud i grften med open source-billedformat WebP, som giver brugeren mulighed for at se billedet, fr det er fuldt downloadet.Af Anne Lykke ukomprimeret foto i PNG-formatGoogle forsger nu at mane det traditionelle billedformat JPEG i jorden med det nye billedformat WebP. WebP giver lossy komprimering af fotografier, men fylder 39,8 procent mindre end Jpeg-billeder af samme kvalitet.Ls ogs: Google vil slanke billed-formater: Klar med aflser for JPEGDerudover gr en helt ny feature, at WebP-billeder trinvist kan dekodes, mens computeren downloader billedet fra websiden, hvilket gr browseren i stand til at vise billedet, fr hele filen faktisk er downloaded. Denne feature virker allerede i Chrome 12. Det skriver Googles produktchef Richard Rabbat og softwareudvikler Pascal Massimino p Chromium blog.Yderligere har WebP ogs fet integreret en 'fancy upsampler', som reducerer pixeleringen af strke kanter. Som det ses p billedet af klodserne, er kanterne i billedet med 'fancy upsampling' mindre pixelerede end uden 'fancy upsampling', hvor der forekommer trappeagtige konturer.P kodnings-siden har Google fokuseret p at forbedre kvaliteten ved at indfre et filter, der kan inddele billedet i ens omrder, som komprimeres p samme mde. Mens nogle dele af billedet let kan komprimeres meget, uden at det gr ud over kvaliteten, vil andre omrder krve flere bits. Disse kaldes svre omrder, som man kan se p det sidste billede.Derved kan WebP bevare mange af detaljerne fra det oprindelige billede i modstning til Jpeg, hvor der kan forekomme skaldte omringende elementer i billedet. Disse omringende elementer kan vre forstyrrende farver eller prikker, der danner en ring om billedet ved for drlig komprimering.WebP er bklandt andet sat sammen af algoritmerne bag videoformatet VP8, som Google har gjort gratis at bruge under navnet WebM.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2011-05-23
          &nbsp;&nbsp; e2b18abf
          &nbsp;&nbsp; #11
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.809</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.796</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.685</kbd>
        </footer>
      </article>
      <article>
        <h4>IBM bruger uvidende menneskers ansigter til at udvikle ansigtsgenkendelse</h4>
        <div>
          IBM har fodret algoritmer til ansigtsgenkendelse med nsten en million Flickr-billeder uden at sprge menneskerne p billederne om lov. Det afslrer NBC i en lang udredning.IBM har indsamlet billederne fra et strre datast p 99,2 million billeder, som er delt under en Creative Commons-licens, hvilket normalt giver rettigheder til at billederne kan blive brugt frit.Men det er ikke sikkert, at rettighederne gr s vidt til, at de afbillede skal finde sig i, at deres ansigter bliver brugt til at udvikle ansigtskendelsesalgoritmer.Relateret jobannonce: Commercial Analyst to optimise wind farm business casesDen ansvarlige for AI-forskning hos IBM, John Smith, siger til NBC, at enhver har lov til at bede om at f en specifik URL fjernet fra datasttet.Men det krver, at fotografen bag det specifikke billeder sender linket til billedet, og det kan blive svrt, fordi IBM ikke har offentliggjort listen over, hvilke billeder der indgr i datasttet.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2019-03-13
          &nbsp;&nbsp; e71d546e
          &nbsp;&nbsp; #12
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.975</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.876</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.638</kbd>
        </footer>
      </article>
      <article>
        <h4>Apple udgiver frste videnskabelige artikel om AI billedgenkendelse</h4>
        <div>
          Et hold af seks forskere lfter i artiklen slret for Apples machine learning-aspirationer.For at trne computere til billedgenkendelse sender Apple neurale netvrk i krig mod hinanden. Ideen hedder Adversarial Training og er ikke helt nyt, men Apples machine learning hold har tilpasset deres GANs p en ny mde. Det skriver Engadget.Det er langt lettere at bruge computergenererede billeder til AI-udvikling i stedet for almindelige billeder, der frst skal -tagges- manuelt af ansatte. Dette stter forskere i et dilemma, da resultatet med de syntetiske billeder ikke bliver af samme kvalitet.Lsningen er iflge Apple at lade et andet system forsge at adskille syntetiske fra gte billeder for dermed at trimme de algortimer, der producerer de syntetiske billeder.Apple har lnge holdt AI kortene tt til kroppen, men kan nu ligesom resten af tech giganterne (Facebook, Google, Microsoft, m.fl.) bryste sig af at deltage i den akademiske machine learning debat.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2016-12-27
          &nbsp;&nbsp; e60b3a07
          &nbsp;&nbsp; #13
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.76</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.711</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.634</kbd>
        </footer>
      </article>
      <article>
        <h4>Tekstiler med &quot;ansigtsprint- skjuler dig for kameraerne&quot;</h4>
        <div>
          Med Hyperface vil kunstnere skabe et tekstiltryk, der kan snyde algoritmer til at se et utal af ansigter og dermed holde breren af stoffet uidentificeret. Foto: Adam HarveyVed at bre stof med et mnster af, hvad computeralgoritmer anser for ansigter i massevis, kan breren slippe udenom ansigtsgenkendelse.Af Liv Bjerg LillevangMed projektet Hyperface vil kunstneren Adam Harvey tage kampen op mod Facebook og reklamevirksomheders algoritmer til ansigtsgenkendelse og dermed sikre privatliv p internettet.Hyperface er et stoftryk, der i en computeralgoritmes optik bliver et virvar af jne, nser og munde. Med nje udvalgte sammenstninger af pixels i forskellige strrelser, skal stoffet sledes snyde algoritmen til at se ansigter overalt p billedet, hvor tekstilet er synligt.P den mde er det Adam Harveys nske, at brere af Hyperface-tekstiler kan sikre sig anonymitet p internetbilleder. Det skriver The Guardian, til hvem privacy-kunsteren fortller, at kldet skal overlsse en algoritme med det, den sger, ved at mtte et omrde med ansigter og dermed aflede computeralgoritmens blik.
        </div>
        <footer>
          <em>Ing.dk (Ingeniren)</em>
          &nbsp;&nbsp; 2017-01-04
          &nbsp;&nbsp; e60db403
          &nbsp;&nbsp; #14
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.72</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.531</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.636</kbd>
        </footer>
      </article>
      <article>
        <h4>Digitalt: Ryd op i dine fotos med kunstig intelligens</h4>
        <div>
          Du behver ikke stresse over alle de billeder, der fylder lageret op p din smartphone eller computer. Ny teknologi kan hjlpe dig med at f dem sorteret og arkiveret.Vi tager billeder som aldrig fr. Analysefirmaet InfoTrends vurderer, at der i 2017 blev taget 1.200 milliarder digitale billeder, eller cirka 160 billeder for hver af klodens 7,5 mia. Indbyggere. Tnk lige over det. Denne statistik viser, at vi mennesker, fra den fattigste tigger til den rigeste milliardr, fra det nyfdte spdbarn til den ldste beboer p plejehjemmet, i gennemsnit tager et billede cirka hver anden dag.Sdan er virkeligheden naturligvis ikke. Verdens digitale fotos er langt mere ulige fordelt. Det ved du naturligvis allerede, for nr du kigger p din smartphone eller p din harddisk, ligger der s mange billeder, at du har svrt ved at overskue, hvordan du skal f dem organiseret og sat i orden.Heldigvis findes der nu smarte vrktjer, der blandt andet via kunstig intelligens kan hjlpe dig med lige prcis den opgave - og p den platform, du foretrkker.Det er naturligvis kameraerne i vores lommer, der har sat ild i den digitale billedeksplosion, og for mange mennesker kommer billederne aldrig videre. Hvis de skal vises til andre, kommer telefonen bare op fra lommen. Hvis du helst vil bruge smartphonen - og kun smartphonen - som fotoplatform, kan du overveje disse gratis apps.Zyl. Appen bruger metadata som tidspunkt og geografisk lokation for fotografiet til at anbefale, hvordan du kan organisere billederne i mapper, der f.eks. kan deles med venner. Men du kan ogs lade vre, og det gr Zyl til et godt bud p en app til at rydde op i dine billeder, hvis du ikke har lyst til at lgge dine billeder op i skyen eller p sociale medier af privatlivshensyn.Ever. Hvis du derimod ikke er helt s bekymret for at lgge dine billeder i skyen, kan du overveje Ever. Denne app organiserer ikke bare smartphone-fotos, men ogs billeder fra sociale medier som Facebook og Instagram. Det betyder, at du ogs kan f billeder, andre har taget af dig, ind i samlingen. Ever er gratis at bruge, hvis du kan njes med komprimerede billeder, men fuld oplsning krver betalingsversionen af appen.Slidebox. Mske har du helt styr p dine fotomapper selv og har bare behov for et vrktj, der hjlpe dig med hurtigt at slette eller arkivere billederne p din telefon? S skal du have fat i Slidebox. Med denne app kan du stryge til venstre eller til hjre, afhngig af om du vil gemme eller slette billedet, og du kan lynhurtigt placere de gemte billeder i de mapper, du har lavet.Billeder p computerenDigitale billeder kommer dog ikke altid fra din smartphone. De kan komme fra et rigtigt digitalkamera eller p en e-mail fra et familiemedlem. Derfor kan en computer ofte vre et bedre sted at organisere sine billeder. Den strre skrm afslrer flere fejl, og der er ogs mere harddiskplads at gemme billederne p.Windows Photos. I efterret opdaterede Microsoft sin Billeder-app til Windows 10, s du nu kan fritekstsge efter indhold i fotos. Hvis du for eksempel skriver -l- eller -Skagen-, dukker der billeder op fra det nordjyske, eller fotos med l ombord. Den kunstige intelligens hjlper dig ogs med at lave fotoalbums eller videoer p en nem mde og kan sortere dine billeder efter de personer, der er p dem.Apple Photos. Ligesom p Windows-pc-er er der nu ogs kunstig intelligens og sgning indbygget i den medflgende Fotos-app p Mac, der hjlper dig med at sortere billeder i kategorier som -mine minder- og -personer-. Men Fotos har ogs relativt avanceret billedredigering modsat mange af konkurrenterne.Adobe Photoshop Elements. Denne let skrabede version af det professionelle Photoshop-program har ud over avancerede redigeringsfunktioner ogs objekt-genkendelse via kunstig intelligens indbygget. Det betyder, at programmet kan lave skaldte -smart tags-, der er beskrivelser af, hvad der er p billedet, som du s kan sge p og sortere efter senere.I skyenMange sky-lagertjenester ssom Dropbox understtter nu automatisk upload af billeder, nr du har taget dem p smartphonen. Oftest kan du dog bare bruge de sky-tjenester, der flger med, nr du kber noget ny teknologi, som f.eks. disse:Google Photos. Googles fototjeneste flger naturligvis med Android-telefoner, men kan ogs bruges p f.eks. iPhone. Google har en af de meste avancerede fotogenkendelsesteknologier i skyen, der helt automatisk kan forbedre dine billeder, lave albums og animationer, hvis du ikke har lyst til at bruge tid p det og ikke er nervs over, at Googles servere kigger i dine billeder.iCloud Photo Stream. Hvis du slr iCloud Photo Stream til under indstillinger p din iPhone eller iPad, bliver dine billeder automatisk lagt op p det iCloud-lager i skyen, der fulgte med dit Apple-produkt.Herfra kan du sortere p samme mde som i Fotos-appen p Mac.Microsoft OneDrive. Har du en Windows-pc eller en Surface-tablet, medflger der ogs et OneDrive-lager i skyen, som du kan uploade dine billeder til. Ogs her kan du f hjlp fra en kunstig intelligens til at sortere dine billeder, og du kan sge i dem og f adgang til dem hvor som helst. Hvis du downloader OneDrive-appen til iOS eller Android, kan du ogs uploade nye smartphone-billeder automatisk.
        </div>
        <footer>
          <em>Politiken.dk</em>
          &nbsp;&nbsp; 2018-02-18
          &nbsp;&nbsp; e69fdd5f
          &nbsp;&nbsp; #15
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.681</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.75</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.624</kbd>
        </footer>
      </article>
      <article>
        <h4>Nu kan vi alle blive Google Street View-fotografer</h4>
        <div>
          Google har annonceret flere nye funktioner i Google Street View, hvor du kan se 360-graders billeder fra gader og omrder i hele verden. Hidtil har Google selv stet for gadefotograferingen, mens fotografer efterhnden har kunnet bidrage med punktbilleder fra steder og virksomheder.Nu slipper Google ogs publikum ls p selve gadebillederne. Hvis du som fotograf har taget bedre eller nyere 360-graders billeder af et gadeomrde, vil det vre dine billeder, der vises Street View.Algoritmerne styrerVores algoritmer analyserer billedkvaliteten, og tidspunktet de er taget p, og vurderer p den mde, om de skal erstatte vores egne billeder i et bestemt omrde. Der lgges specielt vgt p, om billederne er nyere end de eksisterende, forklarer Program Manager Amit Moraya fra Google Maps til Teknisk Ukeblad.Google har forhndsgodkendt en rkke 360-graders kameraer til opgaven, idet de har de tekniske specifikationer til at klare opgaven. Blandt disse kameraer er Ricoh Theta V, Insta360 One og Insta360 Pro.Google bruger ogs avancerede algoritmer til at genkende steder og skilte p de nye billeder, som de allerede gr med Street View-billeder nu.Understtter videoNu understttes ogs 360-graders video, som bruges til at hente billedsekvenser over et bestemt omrde. Dette dukker op som en stiplet linje p kortene, som man kan navigere efter.Forelbig understttes denne funktion kun af mobiltelefoner eller andre enheder med Androids operativsystem. Der stilles ogs krav til, at fotograferne har en vis status som bidragydere i systemet.Google understreger, at fotograferne fortsat har rettigheder til billederne, som bruges til Street View og kan fjerne dem igen nr som helst. Fotografer fr ogs mulighed for at lgge deres navn eller logo i bunden af billedet, nr man ser lige ned.Jeg synes, det er en spndende mulighed for lokale myndigheder og turistorganisationer, som kan srge for opdaterede og gode billeder af deres egne omrder, siger Amit Moraya til TU.Ved hjlp af en tidslinjefunktion er det muligt at bladre tilbage til tidligere versioner af gadebillederne i et omrde, bde fra Google selv og andre bidragydere.Du kan se de danske byer, Google snart planlgger at kre igennem, her.Denne artikel er fra digi.no.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2018-05-31
          &nbsp;&nbsp; e6c5a18f
          &nbsp;&nbsp; #16
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.61</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.669</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.664</kbd>
        </footer>
      </article>
      <article>
        <h4>Sdan jagter det norske politi ID-svindlere og andre kriminelle med ansigtsgenkendelse</h4>
        <div>
          Det norske politi er begyndt at anvende ansigtsgenkendelse til brug for tjek af pas og id-kort, samt i indvandringssager og straffesager. Det sker i Kripos, som er det norske politis kompetencecenter for biometri.Det fortller Version2s norske sstermedie, Digi.no, i en artikel om politiets erfaringer med ansigtsgenkendelse i Norge. Etaten arbejder med relativt nyt it-system med automatisert ansigtsgenkendelse, ABIS (Automated Biometric Information System).Det norske politi har hjemmel til at optage fingeraftryk og billeder, fx under en anholdelse eller i en forhrssituation, hvor en borger er under mistanke. Med den nye ansigtsgenkendelsesteknologi kan ansigtsfotoet sammenlignes med politiets eksisterende billedregister ved hjlp af en algoritme.Algoritmerne svarer med en liste med cirka 25 hits, hvor sammenfaldet er strst, hvorefter det gennemgs manuelt af to sagsbehandlere.Man bliver ikke dmt i Norge, fordi ansigtsgenkendelsesystemet giver et hit, der er ugunstigt for dig. I disse tilflde skal eksperterne vurdere billederne og foretage en sammenligning af ansigtet, siger Fry Lvsdal, der er seniorrdgiver i politidirektoratet til digi.no.Med andre ord kan teknologien vre et vigtigt element, men den bliver str ikke alene.I lande med drlig retssikkerhed, kan teknologien klart vre en trussel, tilfjer Fry Lvsdal.Skal fange falske pasTeknologien anvendes ogs til 1:1 sammenligning med billeder, som tages i forbindelse med, at man sger om nyt pas. Det nye pasbillede sammenlignes med det, som blev taget sidste gang en borger sgte om pas eller ID-kort.Desuden vil man gennemfre 1:N - en til mange - sgninger. Det vil sige, at et nyt billede sammenlignes med billeder af andre pas/ID-kort indehavere, som er registreret i databasen for at sikre at et ansigt ikke registreres p en andens navn. Begge metoder skal gre det vanskeligere at f udstedt et norsk pas og ID-kort med falsk identitet.Eksperter foretager manuel kontrolEn udfordring ved ansigtsbiometri er at - i modstning til fingeraftryk - ndrer ansigtet sig i lbet af livet, og desuden er billedkvaliteten afgrende.Relateret jobannonce: ProjektlederI Norge forsger man at lse dette problem med et eksperthold, der skal evaluere tvivlssprgsml ved at sammenligne billeder manuelt, i form af skaldt morfologisk analyse. Seks fagfolk har fet uddannelse fra internationale eksperter i blandt andet anatomi, billedanalyse og kognitiv psykologi.Vi er ikke fingeraftryks-eksperter, selvom vi er fdt med ti fingre. Og selvom mange mske tror det, er vi heller ikke s gode til at sammenligne ansigter. Derfor er det vigtig at styrke vores kompetence, siger Fry Lvsdal fra politidirektoratet.Blandt de vigtige kompetencer er at man ikke m stole stole blindt p algoritmer.Algoritmerne bliver bedre, men de kan ikke erstatte mennesker, siger Berit Lima, Kripos Forensic Department Section Manager.Private overvgningsbilleder skal ogs indgPolitiets ABIS-system fr snart ny funktionalitet som kan kode billeder fra private overvgningskameraer. Disse billeder kan dermed ogs sammenkres med politiets billedregister eller op imod andre overvgningsbilleder. P denne mde vil databasen vokse og blive mere funktionel over tid, fortller politiet.Berit Lima i Kripos understreger, at overvgningsbilleder kun vil blive kodet og anvendt i forbindelse med straffesager og op imod overvgningsbilleder og politiets billedregister.Samtidig understreger man, at billederne ikke vil blive delt med tredjeparter, ejheller med andre lande eller andre aktrer.Lufthavnen i Oslo, Gardermoen, er et eksempel p en lokation, hvor der er etableret en anden form for biometrisk kontol. Lufthavnen har automatiseret grnsekontrol, hvor de rejsendes ansigter sammenlignes med billedet i passet.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2019-05-14
          &nbsp;&nbsp; e732947d
          &nbsp;&nbsp; #17
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.752</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.818</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.667</kbd>
        </footer>
      </article>
      <article>
        <h4>Twitter undskylder for race-bias i algoritme til beskring af billeder</h4>
        <div>
          Flere bruger har pvist, hvordan det sociale medie Twitter har tilbjelighed til at fokusere p hvide ansigter frem for sorte, nr billeder skal beskres. Twitter har undskyldt for at have race-bias i den algoritme, som bruges til billedbeskring p det sociale medie. Det skriver The Guardian Undskyldningen kommer i klvandet p, at flere brugere har pvist, hvordan billeder p det sociale medie har tilbjelighed til at fokusere p hvide ansigter frem for sorte, nr billeder bliver beskret automatisk. Iflge Twitter er algoritmen blevet testet for bias, inden den blev taget i brug, men nu har det sociale medie mtte erkende, at det ikke er blevet gjort tilstrkkeligt grundigt. Nr brugere uploader store eller lange billeder til Twitter, har algoritmen srget for, at billederne blev beskret, s de ikke fyldte s meget i feedet p det sociale medie. Algoritmen er udviklet til at fokusere p de vsentligste dele af billedet og sortere resten fra. Men i weekenden opdagede flere brugere, at algoritmen ofte sorterer sorte ansigter fra frem for hvide, nr det skal beskre billeder til at passe til feedet. En talsperson for Twitter har i en udtalelse erkendt, at man skal tilbage til tegnebrttet med algoritmen. Vores team har testet for bias, inden vi tog modellen i brug, og der fandt vi ikke tegn p race- eller knsbias. Men ud fra disse eksempler (fra brugerne, red.) str det klart, at vi skal lave flere analyser. Vi vil fortstte med at dele, hvad vi lrer, og hvilke beslutninger vi tager, og vi vil dele vores analyse, s andre kan gennemg og efterligne den,  ld det iflge The Guardian i udtalelsen fra Twitter. Se et af brugernes eksempler nedenfor. Flere eksempler kan findes her
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2020-09-22
          &nbsp;&nbsp; e7e711bc
          &nbsp;&nbsp; #18
          <br>
          <br>
            <kbd data-tooltip="Tech industry &amp; regulation">L02_BIGTEC&nbsp;0.675</kbd>
            <kbd data-tooltip="Facebook, fake news &amp; Trump">L05_FBTRUM&nbsp;0.614</kbd>
            <kbd data-tooltip="Social media &amp; well being">L10_SOMEWB&nbsp;0.611</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.649</kbd>
        </footer>
      </article>
      <article>
        <h4>AI kan reparere og gre slrede billeder skarpe</h4>
        <div>
          Uden at benytte andre billeder som inspiration, kan helisk neuralt netvrk gre billeder bedre.Et dybt helisk neuralt netvrk kan gre uskarpe billeder blive skarpe, ved kun at bruge information fra selve billedet. Effekten er dog mindre synlig her p grund af Version2's CMS-system. Photo: Dmitry UlyanovDet er fup og fidus, men det virker: Kunstig intelligens kan genskabe billedinformation, s resultatet til forveksling ligner originalen.Teknologien har vret fremme i et stykke tid, men nu har tre russiske forskere skabt en algoritme, der siger spar to til tidligere forsg. Det er de skaldte 'dybe heliske neurale netvrk'(deep convolutional neural networks, CNN) som er velegnede til opgaver af denne type. Det skriver Bleeping Computer.Deep Image Prior, som algoritmen er navngivet, adskiller sig fra andre tilsvarende algoritmer, ved at benytte billedets egen information til reparationsopgaverne, i stedet for at bygge p et trningsst med andre billeder til udbedring af fejl og mangler.Det kan blandt andet benyttes til at gre slrede billeder skarpe, til at fjerne stj af forskellig art og til fje manglende dele af et billede.Algoritmen EnhanceNet-PAT kan skabe et billede (nr. 3 fra venstre) ud fra en slret original (nr. 1), s det til forveksling ligner originalen (th). Photo: Mehdi S. M. SajjadiKoden bag er skrevet i Python og kan hentes hos Github.Deep Image Prior er ikke den eneste nye algoritme, der kan genskabe informationer i billeder, s det nppe er til at se. En anden ny algoritme, EnhanceNet-PAT, benytter i modstning til Deep Image Prior et testst til at gtte p den manglende information. Teknologien kan blandt andet anvendes til at skabe billeder med hjere oplsning end originalen.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2018-01-03
          &nbsp;&nbsp; e6904d2d
          &nbsp;&nbsp; #19
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.987</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.986</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.61</kbd>
        </footer>
      </article>
      <article>
        <h4>Forskere skaber endnu mere livagtige billeder af kunstige ansigter</h4>
        <div>
          Forskere fra Nvidia har i en videnskabelig artikel vist eksempler p meget realistiske ansigter fremstillet med brug af kunstig intelligens, skriver PetaPixel.Artiklen (PDF) indeholder billeder fra resultater af deres lsning, og de er meget vanskelige at skelne fra den gte vare.Forskerne kalder lsningen Generative Adversarial Network (GAN), og den indebrer kort fortalt, at man danner kunstige billeder med to neurale netvrk, hvor man forsger at &quot;narre&quot; det ene med kunstige billeder.Netvrket er fodret med store datast af gte billeder og skal forsge at skille de gte fra falske.Teknologien er langt fra ny, og allerede i november sidste r fortalte digi.no, hvordan GAN-teknologien blev brugt til at skabe ekstremt realistiske ansigter.Ogs dengang stod Nvidia-forskere bag.Nvidia-forskerne har imidlertid forbedret teknologien ved at gre det muligt for systemet automatisk at skelne mellem forskellige &quot;niveauer&quot; af attributter, for eksempel mellem positurer og skaldte stokastiske variabler, som er mere vilkrlige detaljer som fregner og hr.Derudover er datasttet nu meget strre med 70.000 hjkvalitetsbilleder med ekstra stor variation.Ved sidste rs demonstration blev der til sammenligning kun anvendt 30.000 billeder af kendte mennesker.Den nye generator har ogs den fordel, at man kan justere kombinationen af forskellige attributkategorier individuelt og dermed &quot;redigere&quot; de genererede billeder. Det giver mulighed for en strre kontrol med resultatet.Hvad teknologien prcist er beregnet til er usikkert, men som The Verge ppegede i forbindelse med sagen, kan den ikke kun anvendes til positive forml.Propaganda og reduceret tillid til billedmateriale som dokumentation kan vre blandt de negative konsekvenser, ligesom der kan skabes falske identiteter.Alle tekniske detaljer findes i forskningsdokumentet.Artiklen stammer fra digi.no.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2018-12-28
          &nbsp;&nbsp; e7066096
          &nbsp;&nbsp; #20
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.882</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.888</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.676</kbd>
        </footer>
      </article>
      <article>
        <h4>Ny AI-bot tegner overraskende detaljeret efter tekst</h4>
        <div>
          Microsoft har lftet slret for deres nye AI-bot der kan tegne billeder alene ud fra tekstbeskrivelser.En fugl med sorte vinger, en gul krop og et lille nb. Det er de eneste informationer som Microsofts research lab har fodret deres nye AI-tegnebot, fr den har tegnet en forholdsvis avanceret tegning med mange detaljer.Microsoft kalder deres nye AI-program for Drawing bot, og de har i et lftet slret for teknologien bag i et paper der er udgivet ved Cornell University i USA.Den nye teknologi, der er drevet af kunstig intelligens og er fortsat under udvikling, ser p individuelle ord, nr der skabes billeder fra tekst.Programmet kan generere billeder af alt fra klassiske scener med grssende dyr, til mere absurde situationer med en flyvende dobbeltdkkerbus. Hvert billede indeholder detaljer der ikke indgr i den tekst som tegneprogrammet har fet leveret.Hvis du gr p Bing og sger efter en fugl, s fr du et fuglebillede. Men her er billedet skabt af computeren, pixel for pixel helt fra bunden. De her fugle findes ikke i den virkelige verden. De er blot en del af computerens forestilling om fugle, siger Xiadong He, forskningsleder ved Deep Learning Technology Center hos Microsoft-s research lab i Redmond, Washington i et blogindlg hos Microsoft.To modeller kmperTegneprogrammet kommer i forlngelse af et udviklingsarbejde mellem computer vision og sprogprocessering som Microsoft har arbejdet med i en del r.Tidligere har udviklingsholdet lavet CaptionBot, der automatisk skriver billedtekster til billeder, ligesom de har udviklet AI-modeller der besvarer sprgsml om konkrete billeder, fx lokation, objekter, hvilket kan vre brugbart for eksempelvis blinde.Kernen i Microsofts tegne-bot er Generative Adversarial Network(GAN). Det er et netvrk der bestr af to machine learning modeller, en der generer billeder fra tekstbeskrivelser og en anden der kaldes diskriminatoren, der bruger tekstbeskrivelser til at vurderer autenticiteten af de genererede billeder.Den genererings-modellen forsger at f falske billeder forbi diskrimatoren, som omvendt forsger at presse genereringsmodellen til at lave s optimale billeder som muligt.Tegne-programmet er trnet med datast der indeholder billeder og tekster der er parret, s modellen kan lre at matche ord med den visuelle reprsentation af ordene.GAN-netvrket fungerer fint nr den skal generere billeder fra simple tekstbeskrivelser, fx bl fugl, eller et grnt tr, men kvaliteten dalen i takt med at kompleksiteten stiger, da det er hele stningen, der fungerer som input til GAN-netvrket.S nr man skriver en fulg med en grn krone, gule vinger og en rd mave, s bliver kvaliteten ikke s god, da de detaljerede informationer gr tabt i beskrivelsen og billedet bliver eksempelvis mere uskarpt.Skal hjlpe filmproducenterTegneprogrammet forsger at efterligne den menneskelige mde at tegne p ved at dele ordene op i forskellige afsnit af billedet.Det kaldes attentional GAN, eller AttnGAN, som matematisk reprsenterer det menneskelige koncept opmrksomhed.Opmrksomhed er en menneskelig koncept og vi bruger s matematik til at gre opmrksomhed til en beregning,  siger Xiandon He.P.t er teknologien endnu ikke funktionel, og nr man ser tttere p billederne, vil man stort set hver gang se fejl.Iflge Microsoft er AttnGAN-billeder dog alligevel tre gange bedre end de forrige GAN-netvrk.P sigt hber Microsoft at deres tegne-bot kan bruges til at assistere malere eller hjlpe filmproducenter ved at tegne animerede scener baseret p et manuskript.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2018-01-19
          &nbsp;&nbsp; e6957c40
          &nbsp;&nbsp; #21
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.933</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.953</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.663</kbd>
        </footer>
      </article>
      <article>
        <h4>Amazon giver chauffrer et ultimatum: Lad jer overvge, eller bliv fyret</h4>
        <div>
          Amazon vil i denne uge tvinge sine chauffrer til at underskrive en blanket, hvor man giver samtykke til, at virksomheden m overvge medarbejderne med AI-drevne kameraer i varevognene. Hvis ikke man siger 'ja', s bliver man fyret.Tech-giganten Amazon, har i denne uge givet sine chauffrer et ultimatum: Enten siger man 'ja' til at lade sig overvge, ellers mister man sit job.Det skriver ViceVirksomheden krver, at chauffrer i denne uge underskriver en ''biometrisk samtykke-blanket'', der giver Amazon lov til at bruge kameraer baseret p kunstig intelligens (AI) til at indsamle deres lokation, bevgelse og biometrisk data - blandt andet ansigtsgenkendelsesdata.I februar besluttede virksomheden at installere AI-drevne kameraer med fire linser i alle varevogne for at forbedre sikkerheden  og kvaliteten af leveringsoplevelsen . Kameraerne er udviklet af tech-firmaet Netradyne.Iflge produktbeskrivelsen kan Netradynes kameraer blandt andet registrere, hvis en chauffr gaber, virker distraheret eller ikke har sikkerhedssele p.Deborah Bass, talsperson for Amazon, understreger, at kameraerne kun bruges til sikkerhedsforml:Vi testede teknologien fra april til oktober 2020 p varevognsruter over to millioner mil, og resultaterne ledte til utrolige sikkerhedsforbedringer for chauffrer og fllesskabet - ulykker gik 48 procent ned, frdselsovertrdelser med stopskilte gik 20 procent ned, chauffrer uden sikkerhedssele faldt 60 procent, og distraheret krsel faldt 45 procent. Tro ikke p egoistiske kritikere, som pstr, at kameraerne har noget som helst andet forml end sikkerhed,  siger hun til Vice.I USA har Amazon omkring 75.000 chauffrer, som leverer pakker.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2021-03-25
          &nbsp;&nbsp; e82f348a
          &nbsp;&nbsp; #22
          <br>
          <br>
            <kbd data-tooltip="Tech industry &amp; regulation">L02_BIGTEC&nbsp;0.679</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.558</kbd>
        </footer>
      </article>
      <article>
        <h4>Nu er Facebook ogs for blinde</h4>
        <div>
          Facebook kan nu bruges af folk med synshandicap takket vre en ny funktion i Facebooks iOS-app.Morten BayDengang, Facebook allermest handlede om at skrive sjove opdateringer, var det sociale netvrk noget mere brugbart for blinde og andre med synshandicap.Men efterhnden som Facebook udviklede sig og teknologien tillod flere og flere billeder, blev folks nyheds-feeds i langt hjere grad en visuel oplevelse.Fortller, hvad der er i billedetFr kunne computeren blot lse op, hvad folk skrev i ens feed, og man kunne s skrive med et blindetastatur eller diktere til computeren, hvad man gerne ville svare. Men det er jo lidt svrere, nr ens Facebook-billede siger mere end 1000 ord. Og kommentarer p billedet ovenfor giver ofte ikke ret meget mening, hvis man ikke har det visuelle med.Men det vil Facebook nu gre noget ved. De har lanceret et nyt vrktj til deres Facebook-appen p iOS, der kan hjlpe svagtseende   i frste omgang p engelsk. Det sker ved, at billedet bliver analyseret for objekter og disse objekter bliver s samlet p en liste, der s lses op.Facebook bruger kunstig intelligens-teknologi og neurale netvrk til at identificere, hvad det er for objekter, der er i billedet, og er der en person til stede tydeligt i billedet, som hrer til brugerens Facebook-vennekreds, bliver denne persons navn ogs nvnt.Facebooks computere lrer om billederI et eksempel fra Facebook er der et billede, der har kommentaren Vi nede frem!. Den kunstige intelligens har s fundet ud af, at der formentlig er to mennesker, der smiler, solbriller, himmel og vand p billedet, og at det er taget udendrs.Sledes kan Facebook alts hjlpe svagtseende med at danne deres egne forestillinger af, hvad venner forsger at formidle.Som med de fleste af denne slags teknologier finder Facebooks kunstige intelligens-software ud af, hvad der er p billedet ved at genkende det fra sin egen trning.Gennem det, man kalder maskinlring fodres maskinen med informationer og billeder og dens indre logik processerer disse, sdan at softwaren kan genkende dem andre steder.Det er den samme teknologi, Google bruger til billedgenkendelse og billedsgning, og eftersom flere og flere medier er visuelt orienterede, ssom Instagram, Snapchat, Vine med mere, giver denne teknologi brugere med synshandicap en chance for ogs at vre med p sociale medier uden store begrnsninger.OPLSNING. Facebook kan nu stte talte ord p de billeder, der bliver postet p Facebook. Det kan isr hjlpe svagtseende og blinde, nr de bruger sociale medier (Foto: Facebook)..OPLSNING. Facebook kan nu stte talte ord p de billeder, der bliver postet p Facebook. Det kan isr hjlpe svagtseende og blinde, nr de bruger sociale medier (Foto: Facebook)..
        </div>
        <footer>
          <em>Politiken.dk</em>
          &nbsp;&nbsp; 2016-04-07
          &nbsp;&nbsp; e5a64ae2
          &nbsp;&nbsp; #23
          <br>
          <br>
            <kbd data-tooltip="Tech industry &amp; regulation">L02_BIGTEC&nbsp;0.539</kbd>
            <kbd data-tooltip="Social media &amp; well being">L10_SOMEWB&nbsp;0.595</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.654</kbd>
        </footer>
      </article>
      <article>
        <h4>Norsk politi har brugt kontroversiel ansigtsgenkendelses-app til efterforskning</h4>
        <div>
          Medarbejder hos norsk politi har anvendt appen med over tre milliarder billeder fra sociale medier til at efterforske i en sag om sex-overgreb mod brn. En medarbejder hos norsk politi har taget den kritiserede ansigtskendelses-app fra selskabet Clearview i brug til efterforskning. Appen, der har indsamlet mere end tre milliarder billeder fra sociale medier, kan bruges til at identificere fremmede ansigter. Det skriver NRK Medarbejderen hos det norske politi har taget appen i brug til efterforskning to uger efter, at bde norsk og ogs dansk politi dukkede op p en kundeliste hos AI-selskabet Clearview. Dengang svarede begge myndigheder, at man hverken havde brugt teknologien eller var kunde hos Clearview.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2020-03-11
          &nbsp;&nbsp; e79ddf21
          &nbsp;&nbsp; #24
          <br>
          <br>
            <kbd data-tooltip="Tech industry &amp; regulation">L02_BIGTEC&nbsp;0.858</kbd>
            <kbd data-tooltip="Facebook, fake news &amp; Trump">L05_FBTRUM&nbsp;0.625</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.535</kbd>
        </footer>
      </article>
      <article>
        <h4>Forskere rekonstruerer ansigter ved at aflse hjerneaktiviteten</h4>
        <div>
          Amerikanske forskere mener at kunne genskabe ansigter alene ud fra andre menneskers tanker ved at se personen. En norsk forsker er dog skeptisk.Forskere fra New York University, Yale og Berkeley har gjort en bde fascinerende og skrmmende opdagelse. Det skriver det norske tidsskrift Teknisk Ukeblad.Et studie, hvor seks personer blev vist billeder af ansigter, mens forskerne scannede deres hjerner med en skaldt funktionel magnetresonanstomografi (fMRI), viste, at aflsninger af hjernens aktivitet gav forskerne mulighed for at rekonstruere de ansigter, som forsgspersonerne havde kigget p.Algoritme gr tankelsning muligForsget foregr i praksis ved, at forskerne viser forsgspersonerne billeder af 300 forskellige ansigter. Ved hjlp fMRI dokumenterer de, hvordan hjernen bliver aktiveret af de forskellige ansigter.Dette datast overfres til en algoritme, der lrer, hvordan hver enkelt forsgspersons hjerne reagerer p de komponenter, som ansigter har tilflles. Derefter bliver et st nye ansigter fremvist for forsgspersonerne, mens fMRI-optagelserne bliver foretaget.Herefter vil forskerne kunne identificere, hvilke nye ansigter der blev prsenteret for enkeltpersoner, alene ved at analysere hjernens aktivitet med algoritmen.Vi genererer ansigtstrk matematisk, men ender med at f oplysninger om race, kn, ansigtsform med mere. Baseret p et billede af hjernens aktivitet kan vi forudsige nogenlunde, hvordan ansigtet ser ud, siger Alan Cowen p UC Berkeley til Teknisk Ukeblad.Hjernens algoritme er individuelfMRI registrerer mngden af ilt, der forekommer i hver af hjernens voxels, der typisk indeholder over 100.000 neuroner. De oplysninger, forskerne er ndt til at bruge, er relativt grove. Det samme glder derfor rekonstruktionerne.Iflge Hallvard Re Evensmoen, forsker ved Institut for Neurovidenskab ved Norges Teknisk-Naturvitenskapelige Universitet, er der samtidig meget stor forskel p den enkelte hjerne. Derfor skal der skabes en srlig algoritme, der er baseret p hjerneaktivitet fra hver enkelt forsgsperson, hvis rekonstruktionen skal vre korrekt, understreger han over for Teknisk Ukeblad.Alan Cowen fra Berkeley anerkender begge problemstillinger, men han tror, at det vil ndre sig i fremtiden.Jeg tvivler ikke p, at vi fr eller siden vil kunne lse hjernens aktivitet med tilstrkkelig njagtighed til at skabe genkendelige rekonstruktioner, siger han til Teknisk Ukeblad.Et tydeligere jenvidneAlan Cowen forklarer, at de neuroteknologiske metoder inden for ansigtsgenkendelse kan lre os meget om, hvordan hjernen opfatter ansigter. De kan blandt andet bruges til at forst sygdomme som prosopagnosia (svrt ved at genkende ansigter), autisme og skizofreni.Mske en dag du kan bruge teknikken til at designe en slags virtuel virkelighed, som kan hjlpe disse mennesker i deres dagligdag. Samtidig kan teknikken anvendes til at undersge erindringer, fantasier og drmme. Om 20 til 50 r har vi mske udviklet teknologien til et punkt, hvor man kan rekonstruere minder fra jenvidner, konstaterer forskeren over for Teknisk Ukeblad.Han anerkender dog, at den avancererede teknologi vil stille mennesket over for nogle etiske sprgsml, da teknologien ogs vil kunne afslre menneskets dybe begr, pinlige vaner, svagheder og frygt.Forsker Alan Cowen fra UC Berkeley tvivler ikke p, at man for fremtiden vil kunne videreudvikle teknologien, s man med njagtighed kan genskabe rekonstruktioner af ansigter og steder, som mennesker har vret vidne til..Forsker Alan Cowen fra UC Berkeley tvivler ikke p, at man for fremtiden vil kunne videreudvikle teknologien, s man med njagtighed kan genskabe rekonstruktioner af ansigter og steder, som mennesker har vret vidne til..
        </div>
        <footer>
          <em>Ing.dk (Ingeniren)</em>
          &nbsp;&nbsp; 2014-06-02
          &nbsp;&nbsp; e46db09e
          &nbsp;&nbsp; #25
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.993</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.849</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.613</kbd>
        </footer>
      </article>
      <article>
        <h4>Kunstig intelligens gransker fotos fra 2. Verdenskrig</h4>
        <div>
          Moderne teknologi giver forskerne helt nye vrktjer. Takket vre kunstig intelligens kan fotografier taget under 2. Verdenskrig blive kortlagt og kategoriseret nemmere end nogensinde fr.Det skriver Aarhus Universitet i en pressemeddelelse iflge Videnskab.dk.Ved hjlp af AI (kunstig intelligens) kan forskere ud fra indholdet p et billede nu genkende og navngive fotografier, som fotografer har taget.Ls mere p Videnskab.dk: 'Levende robotter' er skabt: Potentialet er kmpestort - og ddsensfarligtDanske forskere fra AU Engineering ved Aarhus Universitet har samarbejdet med kollegaer fra Tampere-universitetet i Finland og det finske Miljinstitut.Sammen har de gennemget omkring 160.000 fotografier taget af i alt 23 finske fotografer fra Vinterkrigen, Fortsttelseskrigen og Laplandskrigen fra rene 1939-1945.Ved hjlp af AI'en kunne forskere automatisk registrere mennesker og objekter i forskellige scenarier langt hurtigere, end et menneske kunne have gjort det.Iflge EU's tilgngelighedsdirektiv, der trdte i kraft i september 2020, skal alle offentlige billeder p internettet indeholde tekstbeskrivelser af billedindhold, og her kan AI-teknologien vre til stor hjlp.Ls mere p Videnskab.dk: Tilfldigheder adskiller de strkeste fra de svageste- Vi er ganske overraskede over den prcision, hvormed AI'en er i stand til at genkende fotografer ud fra kendetegn p billederne, ssom indhold og framing, siger Alexandros Losifidis, lektor og ekspert i kunstig intelligens ved Aarhus Universitet, i en pressemeddelelse iflge Videnskab.dk.Gennemsnitligt opnede AI'en en klassificeringsnjagtighed p 41,1 procent.Studiet viser iflge forskerne, at visse fotografer har en meget distinkt og letgenkendelig stil, mens det hos andre fotografer er svrere for AI'en at genkende.Andre artikler p Videnskab.dkNazisters buddhistiske figur stammer fra rummetSkal vi have sex med robotter?
        </div>
        <footer>
          <em>EkstraBladet.dk/Plus</em>
          &nbsp;&nbsp; 2020-11-01
          &nbsp;&nbsp; e7f7b72d
          &nbsp;&nbsp; #26
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.883</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.565</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.584</kbd>
        </footer>
      </article>
      <article>
        <h4>IBM har udviklet AI-malware, der venter med at angribe til det rette jeblik</h4>
        <div>
          IBM har udviklet proof-of-concept malware baseret p et 'convolutional neural network', som kan forblive i ro indtil helt specifikke betingelser er opfyldtKonceptet hedder DeepLocker og bliver i dag prsenteret p sikkerhedskonferencen Black Hat USA, som bliver afholdt i Las Vegas.Det skriver The Register.Ved at bruge et krypteret payload og samtidig lade et neuralt netvrk afgre, hvornr det skal aktiveres, kan konceptet gre det vsentligt svrere for sikkerhedsforskere og anti-virus-vrktjer at stoppe malwaren, skriver The Register.IBM har demonstreret konceptet ved at kryptere og gemme en kopi af Wannacry-ransomwaren i en videokommunikations-app sammen med kode, der bruger et neuralt netvrk til at afgre, hvornr en krypteringsngle skal frigives.Det neurale netvrk, var blevet trnet til at vente indtil et bestemt ansigt blev opfanget p video-appen. Da den rette person satte sig foran PC'en genkendte koden ansigtet, nglen blev frigivet, payload krt og systemets dokumenter taget til gidsel.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2018-08-09
          &nbsp;&nbsp; e6da5664
          &nbsp;&nbsp; #27
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.815</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.639</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.65</kbd>
        </footer>
      </article>
      <article>
        <h4>Barsk Pentax med unik teknologi</h4>
        <div>
          Ingen kameraer i denne prisklasse tler s barsk behandling som Pentax K-3 spejlreflekskameraet med en helt ny funktion.Du har muligvis ikke tidligere hrt om en lavpasfiltersimulator? Det havde vi heller ikke - fr nu. Men en sdan findes i Pentax K-3.De fleste kameraer har et filter foran billedsensoren, som hindrer, at der dannes moirmnstre i billederne. Noget, som ellers let kan ske, da sensorerne p overfladen af chip'en er grupperet i et mnster, som let kan give moir, nr man tager billeder af for eksempel tekstiler. Af samme grund er kameraer uden lavpasfiltre ikke populre hos modefotografer.LS OGS: Kompromisls 55 mm til fuldformatLavpasfiltret koster imidlertid detaljeskarphed. Derfor har man i Pentax K-3 droppet filtret, men har i stedet udstyret kameraet med en skaldt lavpas-simulator.Ls testen af Pentax K-5 IIs uden lavpasfilter her .Simulatoren, som fungerer ved hjlp af den den bevgelige billedsensor, kan sls til og fra, og er den slet til, reducerer den risikoen for moir-mnstre. Den rummer ogs et par andre tricks, s som at ryste stv af billedsensoren og lave automatisk niveaukontrol.Ikke nok med det, ved astrofotografering kan den flytte sig for at kompensere for jordrotationen ved lange lukketider. I s fald skal man dog investere i O-GPS-modulet som ekstraudstyr.Klar til det barske vejrDen bevgelige billedsensor kompenserer desuden for bevgelsesuskarphed p lange lukketider, hvilket betyder, at man kan skyde hndholdt p 1/15s og stadig have hb om at f skarpe billeder.Men kameraet har flere unikke egenskaber for prisklassen. Som en omfattende vejrforsegling. I K-3 er det hele 92 forseglinger som betyder, at kameraet skulle kunne fungere optimalt, selv nr det ser ned, sner tt, eller sandet pisker dig i ansigtet.Det har ogs en nyudviklet CMOS-sensor i APS-C strrelse med 24 MP, som sammen med den nye bildeprocessor Prime III, skal give minimal billedestj ved hje ISO-vrdier.K-3 har ogs et nyt autofokusmodul med 27 autofokuspunkter, hvoraf hele 25 er flsomme krydsensorer, som er placeret i centrum af sgeren, som fungerer i et omrde fra -3EV til +18EV.Det har ogs noget, som Pentax kalder &quot;Real-Time Analysis System&quot; som er en RGB lysmlingssensor med 86 000 pixels og en ny algoritme. Resultatet skulle vre mere optimal lysmling, og mere prcis autofokus, samt bedre hvidbalance.K-3 kan skyde sekvensbilleder med op til 8,3 billeder pr. sekund. Op til 22 billeder i serie i RAW-rformat, eller op til 60 billeder i serie i JPEG-format.Video i full-HDDen optiske sger er endda strre end i K-5 og med bedre forstrrelse, og kameraet kan skyde video i full-HD 1080/60i/30p med H.264-komprimering og det kan filme intervaller med 4K-oplsning (3840 x 2160).LS OGS: Nikon forbedrer sit drmmekameraEn mikrofonindgang i stereo findes ogs, samt en hovedetelefonudgang for monitoring hvor indspillingsniveauet fra den eksterne mikrofonen kan justeres direkte p kameraet.K-3 er ikke trdlst, men det kan brug en hukommelsekorttype kaldet Pentax Flu Card p 16GB lagringskapacitet, som giver adgang til at fjernstyre kameraet fra en smartphone, tage billeder, se live-billedet p telefonen, og lagre og overfre billeder.Pentax K-3 leveres i slutningen af november, og vil koste omkring 10.000 kr for kamerahuset, 10.500 kr med en 18-55mm zoom, eller ca. 13.000 kr med en vejrforseglet 18-135 mm zoom.En ny vejrforseglet zoom kan kbes samtidig: HD Pentax-DA 55-300mm f4.0 vil koste ca. 3.500 kr.
        </div>
        <footer>
          <em>Jp.dk (Jyllands-Posten)</em>
          &nbsp;&nbsp; 2013-10-15
          &nbsp;&nbsp; e409b5c7
          &nbsp;&nbsp; #28
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.701</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.779</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.715</kbd>
        </footer>
      </article>
      <article>
        <h4>Video: Sdan kan man lave billedgenkendelse hos Baidu - uden kode</h4>
        <div>
          Nu er blgen ogs net til maskinlring.Den kinesiske sgemaskinegigant Baidu har sendt sit bud p gaden under navnet EZDL (&quot;nem deep learning.&quot;) Det skriver ADTMag.EZDL anvender en fire-trins proces til projektudvikling og implementering af brugerdefinerede maskinlrings-modeller: Opret en model, upload og opmrk billeder eller andre ting, trn og test modellen og implementer resultatet med et cloud-API eller et offline udviklingsvrktj (SDK).Iflge Baidu er vrktjet mlrettet mod sm og mellemstore virksomheder.Selvom du ikke har haft nogen erfaring med programmering, kan du hurtigt bygge modeller p denne platform uden barrierer, siger Yongkang Xie, som er teknologichef for Baidu EZDL.EZDL kan hjlpe virksomheder med begrnset AI-ekspertise og it-ressourcer til hurtigt og effektivt at gennemfre trning med deep learning og implementering, selv med kun en lille mngde data. Baidu fremhver tre slags brugsscenarier:En model til automatisk klassificering af billeder med brugerdefinerede klasse til opgaver som: Klassificering af billeder af boliger, genkendelse af kinesisk urtemedicin, vilde fugle og frer, samt industriel kvalitetskontrol i forbindelse med identifikation af defekte produkter.En model til automatisk detektering af objekter i billeder og optlling af antal objekter efter klasse, til opgaver som eksempelvis optlling af celler inden for medicin.En klassifikationsmodel til at genkende forskellige typer lydtyper eller detektere klasser af begivenheder, beregnet til opgaver som sikkerhedsovervgning og videnskabelig forskning.EZDL er en del af dets kunstig intelligensprojekt, der gr under navnet Baidu Brain.P videoen herunder kan man se anvendelsen af EZDL.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2018-09-20
          &nbsp;&nbsp; e6e7d057
          &nbsp;&nbsp; #29
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.833</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.851</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.614</kbd>
        </footer>
      </article>
      <article>
        <h4>Efter et rti bliver ikonisk datast privacy-bevidst: Nu er ansigterne forsvundet fra ImageNet</h4>
        <div>
          Det gr hrdest ud over masker og mundharmonikaer. Forskere ved Stanford og Princeton har taget et signifikant skridt for at gre ImageNet bedre egnet til udvikling af ansvarlig AI. I sidste uge blev det officielle datast opdateret til en version, hvor ansigter er blevet slret.Most categories in the ImageNet challenge are not people categories, however, many incidental people appear in the images, and their privacy is a concern, skriver forskerne i en prpubliceret artikel om arbejdet.I datasttet, som hrer til den rlige ImageNet-challenge - ImageNet Large Scale Visual Recognition Challenge (ILSVRC) - er der 1.000 kategorier, og kun tre af dem handler om mennesker.Ikke desto mindre optrder mennesker p tusindvis af datasttets billeder tagget med diverse objekter - personer, der drikker l, sidder i stole, gr tur med en hund etc.Mere specifikt fandt forskerne over en halv million ansigter p omkring en kvart million billeder - svarende til ansigter i 17 procent af de 1,4 millioner billeder i sttet.P grund af den mde, som billederne i sin tid er blevet samlet p, er der ingen grund til at tro, at personerne er bevidste om, at de indgr i datasttet. Og at de alts indtil nu har vret genkendelige.Our annotations confirm that faces are ubiquitous in ILSVRC and pose a privacy issue, vurderer forskerholdet, der bestr af Kaiyu Yang, Jia Deng og Olga Russakovsky fra Princeton samt Jacqueline Yau og Li Fei-Fei ved Stanford.Wrongdoers og ngne brnImageNet har vret et signifikant datast for udvikling af deep learning-modeller til billedgenkendelse gennem ILSVRC, der i 2012 blev overbevisende vundet af AlexNet. Det var frste gang, at et neuralt netvrk vandt over de traditionelle metoder til objekt-genkendelse.Men over de seneste r er det ogs blevet benbart, at etik og privacy ikke stod ekstremt hjt p dagsordenen, da datasttet blev skabt mellem 2007 og 2009.I 2019 illustrerede kunstprojektet ImageNet Roulette benlyse bias i billedernes tags, der leder til, at afroamerikanere kategoriseres som 'wrongdoer'og'offender'. Samme r kunne machine learning scientist Vinay Prabhu demonstrere, at datasttet rummede ngne brn og materiale taget fra pornografiske hjemmesider.For nylig viste forskning, at systemer til billedegenerering - som iGPT og SimCLR - trnet p ImageNet var mere tilbjelige til at generere mnd i jakkest og kvinder i bikinier.Ansigtsgenkendelse ikke nokAf samme grund af ImageNet vret igennem en lngere overhaling, der blandt andet skulle have sorteret ud i problematiske tags og billeder. Og nu er turen alts kommet til ansigter.Forskerholdet startede med at bruge Amazon Recognition til at detektere ansigter, hvilket viste sig at vre et effektivt frste skridt, selvom fejlraten i visse kategorier var for hj. For at komme af med falske positive (srligt i billeder af dyr) og falske negative (srligt i billeder af sport) blev resultatet sendt til menneskelig behandling gennem Amazon Mechanical Turk.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2021-03-18
          &nbsp;&nbsp; e82c40ea
          &nbsp;&nbsp; #30
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.866</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.504</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.571</kbd>
        </footer>
      </article>
      <article>
        <h4>Professionel kamerakvalitet i kompakt design</h4>
        <div>
          De nye kameraer i RX-serien byder p lynhurtig billedbehandling samt 40x Super Slow Motion, 4K-videooptagelser og meget mere.Sony lancerer nu de kompakte RX100 IV og RX10 II. De to nye modeller har begge verdens frste &quot;1.0 type Stacked Exmor RS CMOS--sensor i med avanceret signalbehandling og indbygget DRAM-hukommelseschip.Den hurtige signalbehandling og DRAM-hukommelseschippen giver tilsammen fem gange hurtigere behandling af billeddata samt en rkke spndende funktioner, der tidligere kun fandtes i udvalgte, professionelle videokameraer.Du fr for eksempel 40x super slow motion-optagelser i op til 1000 fps, en ultrahurtig &quot;Anti-Distortion Shutter- med en hastighed p op til 1/32000 af et sekund, 4K-videooptagelser og meget mere.Sony RX10 IIAlsidigt design og hurtig autofokusDet nye RX100 IV beholder det kompakte design, som kendetegner RX100-serien, s det passer stadig lige ned i lommen. RX100 IV er udstyret med et ZEISS Vario-Sonnar T 24-70mm F1.8-F2.8-objektiv svarende til 35mm. RX10 II beholder ligeledes samme design som det originale RX10, og det er udstyret med et ZEISS Vario-Sonnar T 24-200mm F2.8-objektiv svarende til 35 mm.PartnerAOD-logo_BOXstreg.pngDenne artikel er blevet til i samarbejde med Alt om DATA.Ls flere nyheder, artikler, guides og test paltomdata.dkBegge kameraer har en ny indbygget XGA OLED Tru-Finder med hj kontrast. Du fr her en oplsning p omkring 2,35 millioner punkter, hvilket sikrer visning og afspilning af indhold som det ser ud i virkeligheden. RX100 IV beholder den praktiske elektroniske sger med ZEISS T-coating fra RX100 III-modellen, som blev lanceret forrige r.Begge modeller byder desuden p en opgraderet &quot;Fast Intelligent--autofokus, der giver hurtig og prcis kontrast-detektions-autofokus af objekter i bevgelse p helt ned til 0,09 sekunder. Med den nye autofokus-algoritme udviklet af Sony kan kameraerne genkende og lse sig fast p objekter langt mere effektivt end tidligere modeller. Det eneste du skal gre er at trykke udlserknappen halvt ned. De nye kameraer er Wi-Fi- og NFCT-kompatible, og de har begge adgang til det voksende udvalg af PlayMemories Camera-apps fra Sony.De to nye kameraer har begge en rkke brugerdefinerbare knapper og funktioner, og de kan justeres, s de passer til enhver fotografs nsker.RX100 IV og RX10 II vil vre tilgngelige fra midten af juli til priser p henholdsvis 9.200 og 12.500 kr.Sony RX100 IV. Foto: Sony.Sony RX100 IV. Foto: Sony.
        </div>
        <footer>
          <em>Jp.dk (Jyllands-Posten) (Abonnementsomrde)</em>
          &nbsp;&nbsp; 2015-06-27
          &nbsp;&nbsp; e519baff
          &nbsp;&nbsp; #31
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.783</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.719</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.622</kbd>
        </footer>
      </article>
      <article>
        <h4>Sociale medier: AI-baseret ansigtsbytte p pornomodeller skal stoppes</h4>
        <div>
          Twitter, Pornhub og Gfycat accepterer ikke deepfakes, hvor kendte menneskers ansigter bliver klippet ind i pornografiske videoer ved hjlp af et nyt software-vrktj baseret p machine learningHarry Potter-skuespilleren Emma Watson og popstjernen Taylor Swift har i den seneste tid kunne se deres ansigter blive klippet ind i pornografiske videoer p internettet.Fnonometet er kendt som deepfake, og har for alvor taget fart siden december 2017, hvor en bruger p Reddit viste hvordan han bruger machine learning og neurale netvrk til at bytte ansigter p kendte mennesker og pornoskuespillere.I januar publicerede en anden Reddit-bruger s vrktjet Fakeapp, som p en brugervenlig mde gr det muligt at bytte ansigter p mennesker i videoer og gifs.App'en er i skrivende stund blevet downloadet over 100.000 gange.Ansigtsbyttet bliver muligt fordi Reddit-brugerne har brugt en kombination af open source software der anvender machine learning, eksempelvis Google-s TensorFlowNu har Twitter, Pornhub, Gfycat og Discord alle meldt ud, at de fjerner alle former for deepfake-videoer.Det gr de med henvisning til, at de betragter det som hvnporno, nr internetbrugere bruger vrktjet Fakeapp, til at klippe billeder af kendte menneskers ansigter ind i pornografiske videoer. Vores brugerbetingelser tillader os at fjerne indhold som vi finder anstdeligt. Vi fjerner aktivt det type indhold, skriver en talsperson fra Gfycat til The Verge.Ogs det store porno-site Pornhub er nu begyndt at fjerne de skaldte deepfakes.Vi accepterer ikke nogen former for indhold, hvor der ikke er givet samtykke p vores side, og vi fjerner denne type indhold s snart vi bliver opmrksomme p det, skriver Pornhub tilMotherboard.P Reddit, som fnomenet er vokset ud af, og hvor FakeApp er publiceret, har man ikke forbudt deepfakes, med mindre der er tale om brnepornografi.Reddit-trden med deepfakes har over 91.000 flgere og strstedelen af indlggende handler om netop pornografi, hvor kendte menneskers ansigter er klippet ind.At bytte ansigter ud p billeder er ikke nyt. Det sociale medie Snapchat har haft funktionen i flere r, ligesom Faceapp gr dig i stand til at se en yngre eller ldre version af dig selv.Men med de nye machine learning-vrktjer er kvaliteten forbedret markant.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2018-02-07
          &nbsp;&nbsp; e69bfa80
          &nbsp;&nbsp; #32
          <br>
          <br>
            <kbd data-tooltip="Tech industry &amp; regulation">L02_BIGTEC&nbsp;0.523</kbd>
            <kbd data-tooltip="Facebook, fake news &amp; Trump">L05_FBTRUM&nbsp;0.517</kbd>
            <kbd data-tooltip="Social media &amp; well being">L10_SOMEWB&nbsp;0.558</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.639</kbd>
        </footer>
      </article>
      <article>
        <h4>Verdensfirma p en mark i Stige</h4>
        <div>
          STIGE: STIGE: Ude bag et drivhus, ned ad en grusvej og p en mark med juletrer ligger et stort, hvidt hus.Her holder en masse biler og cykler, og hvis man ikke vidste det, var det ikke til at gtte, at her ligger en international virksomhed.For enden af grusvejen ligger nemlig det firma, som Shinta Darling Aarup og Esben Darling Meng etablerede tilbage i 2006: Colourbox.Colourbox er en kmpe billeddatabase, hvor du kan finde billeder af stort set alt.Parret har en fortid i reklamebranchen, og deres erfaring var, at det var meget besvrligt at kbe billeder til netop dette.-S lavede vi en streamingtjeneste.Her var der 65.000 billeder, forklarer Esben Darling Meng.I dag har Colourbox ti millioner billeder, og der kommer 10.000 nye til hver dag.-I begyndelsen lavede vi selv billederne og agerede selv modeller, s der findes mange billeder af os selv, hunden, katten, brnene og bedsteforldrene, siger Esben Darling Meng og smiler.Lokale ansigterHvis du kender Colourbox og bruger det, kan det vre, du har set et ansigt derinde, som du ogs har set et sted i byen.Der findes nemlig en del folk fra Odense, der har ageret modeller til colourboxbilleder.-Vi tog p et tidspunkt nogle billeder i Billund Lufthavn, der skulle handle om flyforsinkelser.Der var jeg model, og der sad jeg p en bnk og kiggede p mit ur. Nste gang jeg s det billede, var det i en artikel om mnd og depression. Lidt efter var det i en artikel om, at kloge mnd har god sdkvalitet, siger Esben Darling Meng og griner.Nr billeder fra Colourbox kan bruges frit til hvad som helst, s kan der ske mrkelige ting og sager.-For halvandet rs tid siden blev vi ringet op af en kvinde.Hun havde lst Ugeavisen Odense, og deri var et billede af en mand og en kvinde i en intim situation. Kvinden spurgte, hvem den anden kvinde p billedet var, for manden var hendes kreste, og han havde bestemt ikke fet lov til at lave den slags billeder. Det viste sig s, at manden sammen med sin ekskreste havde lavet de billeder uden den nuvrende krestes viden, fortller Esben Darling Meng.Fra Skibhus til Stige Da Shinta og Esben Darling etablerede firmaet, var det i en lejlighed p Dckerslundsvej i Skibhuskvarteret.Ret hurtigt fik de brug for mere plads, og s fandt de en gammel grd fra 1877 i Stige.-Vi skulle finde noget, der bde kunne bruges til privatbolig og havde muligheder for ar udvide til erhverv. Det skulle ikke vre noget, der havde nogle kedelige kontorer, og s skulle der vre en god skole i nrheden, forklarer Esben Darling Meng.Sdan endte de i Stige.I dag er den gamle grd ikke at se. Bygningerne er topmoderne og vrimler med medarbejdere.Store tal p skrmen Hos Colourbox er der medarbejdere fra mange forskellige lande, blandt andet Pakistan og Rumnien, derfor er sproget engelsk, nr alle taler sammen.P en skrm i mdelokalet popper der tal op hele tiden.Handlen af billeder p forskellige kontinenter overvges tt, og det er store tal -i euro vel at mrke.Alt i Colourbox mles hele tiden.-Det er algoritmer, der styrer, hvilket billede, der kommer frem, siger Esben Darling.Ogs faktorer som hvor brugeren kommer fra, hvilke hjtider der er i landet og hvad der sidst er blevet sgt p, er med til at bestemme, hvilket foto, der kommer frem.Alt i alt gr det meget godt hos Colourbox, og det er nok ogsget meget hurtigere, end parret havde turde hbe p.-Vores succes er, at vi gode har layouts og gode priser. Bde en erfaren IT-bruger og en uerfaren kan finde det, de sger p vores side. Og s var vi med fra start af, siger Esben Darling Meng.Vi tog p et tidspunkt nogle billeder i Billund Lufthavn, der skulle handle om flyforsinkelser. Der var jeg model, og der sad jeg p en bnk og kiggede p mit ur. Nste gang jeg s det billede, var det i en artikel om mnd og depression. Lidt efter var det i en artikel om, at kloge mnd har god sdkvalitet.ESBEN DARLING MENG, MEDEJER OG -STIFTER AF COLOURBOX.Om ColourboxColourbox har billeder af stort set alt. Her kan reklamebureauer finde billeder, som de kan anvende i reklamer, og aviser kan finde et billede, der passer til en artikel, hvis der ikke findes et billede i forvejen. Det kunne foreksempel vre, at der blev afholdt andespil i forsamlingshuset, og at der dertil skulle vre et billede af en andesteg. Sdan et billede kan man finde p Colourbox.Colourbox har 50.000 fotografer tilknyttet. Nye fotografer skal sende 14 billeder ind, som bliver kigget igennem af en medarbejder p kontoret i Stige, og bliver de godkendt, kan fotografen levere s mange billeder, det skal vre.For sit foto fr fotografen 20 % af salgsprisen, dog minimum 20 cent.Alle billeder, der kommer ind fra fotografer, bliver set igennem. Colourbox sikrer sig, at der ikke er racistisk eller pornografisk materiale iblandt.En fotograf skal selv srge for at stte s mange sgeord p sine billeder som muligt. Dem, der fr sat de bedst rammende sgeord p billedet, vil ogs f solgt flest billeder, da billederne s vil dukke op p flere sgninger.Nr en kunde kber en billede p Colourbox, er billedet frit til brug af hvad som helst. Derfor kan det samme billede blive brugt til to meget forskellige ting.Colourbox har kunder i hele Verden. Iflge Esben Darling Meng vil der p en mned kun vre 25 lande i hele Verden, der ikke har kbt et billede hos Colourbox.Colourbox har 200.000 aktive brugere, der kber billeder, og der er 75.000 besgende hver dag.Colourbox har ogs en afdeling i Berlin, og alt i alt er der 30 ansatte.
        </div>
        <footer>
          <em>Erhvervsavisen Fyn</em>
          &nbsp;&nbsp; 2014-11-18
          &nbsp;&nbsp; e4aa7da5
          &nbsp;&nbsp; #33
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.874</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.689</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.69</kbd>
        </footer>
      </article>
      <article>
        <h4>Algoritme gr dig mere genkendelig p Facebook</h4>
        <div>
          Profilbilledet p de sociale medier eller p en datingprofil kan vre afgrende for, om folk husker dig. Forskere fra MIT har skabt et stykke software, der klarer rterne.Vi bliver bombarderet med ansigter p de sociale medier og i reklamer, men hvad er det egentlig, der afgr, om vi kan huske ansigtet bagefter?Det har en gruppe amerikanske forskere fra MIT luret p for at gre det muligt selv at manipulere med sin genkendelighed, skriver gizmag.com .Forskerne er get efter at kreere en algoritme, hvor man i et program kan uploade sit foto, hvorefter man fr et nyt billede af sit ansigt, der str skarpere i folks hukommelse.Og der er tale om meget diskrete ndringer, s de frreste burde ane, at man er blevet 'photoshoppet' en smule.Det blev iflge forskningsrapporten grebet an p den mde, at en rkke frivillige fra et crowdsourcing-netvrk p Amazon til at begynde med fik lov at sidde og se p tusindvis af billeder af ansigter fra en database. Derefter blev 2.000 af dem udvalgt som vrende 'genkendelige' ansigter - uden at de frivillige behvede at stte ord p hvorfor.Det foregik p den langstrakte mde, at der blev taget tusindvis af kopier af hvert foto, hvor der blev ndret en lille smule. Herefter blev de bedste udvalgt, hvorefter mllen krte en gang til, indtil forskerne kunne deklarere, at softwaren nu var tilstrkkeligt mttet med oplysninger.Til sidst endte holdet op med 500 ansigter, som blev krt igennem programmet, som nu var udstyret med lighedstrkkene for bde de let genkendelige og de mindst genkendelige.Disse 500 ansigter blev sat over for de to forskellige former for lighed, s der i alt forel tre fotos af hvert ansigt: Det oprindelige, det 'forbedrede' og det 'forvrrede'.Nogle af ansigterne kan ses til hjre, hvor det umiddelbart kan se ud som om, ansigterne er gjort lidt smallere, hvis de skal vre mere genkendelige, og mske er kben ogs lige blevet spidset lidt. Og er der ikke ogs kommet lidt mere 'trut' p lberne?Iflge forskerne har det dog vre vigtigt, at ndringerne skulle vre meget diskrete og ikke mtte ndre grundlggende ved ansigtet. Det mtte helst heller ikke gre dem mindre attraktive.Ud over lige at gre billedet p Facebook eller jobansgningen lige dn snas lkrere, mener forskerne ogs, at softwaren omvendt kan bruges i f.eks. film-makeup, hvor man mske nske, at statister skal trde lidt mere i baggrunden og ikke blive for genkendelige.Prv selv forskernes lille hukommelsesspil her eller hent en del af forskernes kode, som kan forudsige genkendelighed her.Eksempler p fotos, der har vret en tur igennem MIT-forskernes program. Billedet i midten er det oprindelige, mens varianten til hjre er blevet gjort mere genkendelig og det til venstre mindre genkendelig. Foto: MIT.Eksempler p fotos, der har vret en tur igennem MIT-forskernes program. Billedet i midten er det oprindelige, mens varianten til hjre er blevet gjort mere genkendelig og det til venstre mindre genkendelig. Foto: MIT.
        </div>
        <footer>
          <em>Ing.dk (Ingeniren)</em>
          &nbsp;&nbsp; 2013-12-25
          &nbsp;&nbsp; e42e47a7
          &nbsp;&nbsp; #34
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.744</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.664</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.706</kbd>
        </footer>
      </article>
      <article>
        <h4>Kun til arbejdsbrug: Microsoft lancerer nye Hololens-briller til 23.000 kr.</h4>
        <div>
          Synsvinklen var for lille. Hologrammerne var fine nok, men optrdte kun midt i synsfeltet - og forsvandt alts, nr du drejede hovedet lidt.Sdan kan man kort opsummere modtagelsen af Microsofts frste bud p briller med indbygget skrm, Hololens, der kom p gaden i forret 2016. Men nu er Microsoft klar med en version 2 - og synsfeltet med hologrammer er blevet klart forbedret, lyder dommen hos tech-mediet The Verge.Hololens-brillerne er lavet til skaldt augmented reality og mixed reality, alts hvor man bde ser den virkelige verden og et digitalt lag. Et klassisk eksempel p, hvad man kan bruge teknologien til, er at st i et tomt hus, men se det fyldt med mbler igennem brillerne.Med en startpris p 23.000 kr. for et par Hololens 2-briller har Microsoft dog besluttet ikke at prve at slge til almindelige forbrugere. Mlgruppen er nu kun virksomheder og andre professionelle brugere, for eksempel fabriksarbejdere eller tekniske konsulenter, som rejser rundt og reparerer udstyr.For at f gjort synsfeltet strre og Hololens-brillen nemmere at bruge, har Microsoft ndret markant p teknologien i brillerne. Kort fortalt opstr det gennemsigtige digitale billede ved at 'tegne' med laser i et srligt glaslag. Og de problemer, der normalt er med den type teknologi, er blevet fikset, bl.a. ved at have to kameraer, som holder je med brugerens jne.Dermed kan brillerne selv justere laserbilledet prcist efter, hvor jenbningerne er, i stedet for at man selv skal skrue og tilpasse, indtil billedet str klart. Og som ekstra bonus har Hololens 2-brillerne ogs styr p, hvor brugeren kigger hen. Det bliver for eksempel brugt til automatisk at scrolle en tekst opad, nr brugeren har lst sig igennem et skrmbillede. Kameraerne bliver ogs brugt som ekstra sikkerhed, s man kan lse computeren i Hololens-brillen op med sine jne, ligesom man bruger et fingeraftryk eller sit ansigt til at lse sin telefon op.En anden nyskabelse er, at brillerne som standard skal kommunikere med Microsofts cloud-tjeneste Azure og derfra f hjlp til at forst, hvad den ser. Kameraer og sensorer registrerer hele tiden omgivelserne, s de digitale billeder for eksempel kan hvile p et bord eller hnge fra loftet. Men i version 1 af Hololens var det en simpel 3D-forstelse af omgivelserne. I den nye udgave skal brillerne kunne forst, om den ser en sofa eller en stueplante ved hjlp af kunstig intelligens i skyen.Det gr det ogs muligt bedre at forst brugerens hndbevgelser. I stedet for at skulle lre nogle f, srlige hndtegn, nr man skal styre indholdet, er det i den nye version langt mere naturligt. Man kan for eksempel uden problemer trykke p knapper i den digitale verden med sin finger, rapporterer The Verges anmelder.Microsoft har siden lancering af Hololens i 2016 stet ret alene p markedet, men fik i efterret 2018 en udfordrer, nemlig Magic Leap. Men de nye briller er forelbigt kun blevet prsenteret. De kommer frst til salg 'i lbet af 2019', fortller Microsoft.
        </div>
        <footer>
          <em>Jyllands-posten.dk</em>
          &nbsp;&nbsp; 2019-02-27
          &nbsp;&nbsp; e718a9bd
          &nbsp;&nbsp; #35
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.753</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.571</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.685</kbd>
        </footer>
      </article>
      <article>
        <h4>VICTIM BLAMING FOR TV-LICENSEN</h4>
        <div>
          DR oplyser i et stort opsat journalistisk projekt om en ny form for digitale krnkelser. En rkke kvinder, der har delt billeder af sig selv p Instagram, er af ukendte gerningsmand blevet ' afkldt' p billederne med et srligt program, som via kunstig intelligens kan imitere, hvordan de ser ud uden tj p. P nul komma fem genererer programmet en falsk krop, som passer til ansigtet p billedet.Og voila - fabrikeret hvnporno.Det er godt, grundigt og forstemmende journalistisk arbejde. Men man indigneres desvrre yderligere af det her 100 procent victim blamende sprgsml, som journalisterne stiller den 20-rige influencer Anna Briand, der har vret udsat for forbrydelsen: Du har over 200.000 flgere p Instagram og bruger dig selv meget via mange opslag, og du har selv optrdt i bikini og bh p din profil. Er det med til at lgge op til, at de falske billeder bliver lavet? Buh, DR.
        </div>
        <footer>
          <em>Information</em>
          &nbsp;&nbsp; 2021-04-16
          &nbsp;&nbsp; e838b5a2
          &nbsp;&nbsp; #36
          <br>
          <br>
            <kbd data-tooltip="Tech industry &amp; regulation">L02_BIGTEC&nbsp;0.51</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.601</kbd>
        </footer>
      </article>
      <article>
        <h4>FBI kber ansigtsgenkendelse for 5,8 milliarder</h4>
        <div>
          Et nyt projekt skal gre det nemmere for det amerikanske forbundspoliti FBI at lokalisere og identificere forbrydere.Det amerikanske forbundspoliti, FBI, er i fuld gang med at sstte et nyt ambitist ansigtsgenkendelsessystem, som i 2014 skal finde forbrydere over hele USA. Projektet gr under navnet Next Generation Idenfication (NGI) programme og koster ikke mindre end n milliard dollar eller 5,8 milliarder kroner.Med billeder af kriminelle i politiets database er det meningen, at det nye system skal kunne registrere en mistnkt, nr han eller hun bevger sig ind i synsfeltet af et sikkerhedskamera. Omvendt kan det ogs bruges til at finde en forbryder i databasen, hvis forbrydelsen er fanget p kamera.FBI har endnu ikke frigivet nogen detaljer om den algoritme, NGI bruger, men tidligere tests viser, at moderne algoritmer til ansigtsgenkendelse kan identificere en person med 92 procent sikkerhed i en database med 1,6 millioner billeder. Selv hvis personen er optaget p en skv vinkel kan algoritmer generere en 3D-version af ansigtet og dreje det op til 70 grader, s det matcher billeder i databasen.Ud over ansigtsgenkendelse vil NGI ogs indeholde DNA-analyser, stemmegenkendelse og iris-scanner.Pilotprojektet kan kun sge efter tidligere kriminelle, men det er ukendt om FBI ogs vil tilfje billeder af andre, som ellers ikke har vret i politiets sgelys.Moderne algoritmer til ansigtsgenkendelse kan identificere en person med 92 procent sikkerhed i en database med 1,6 millioner billeder..
        </div>
        <footer>
          <em>Ing.dk (Ingeniren)</em>
          &nbsp;&nbsp; 2012-09-14
          &nbsp;&nbsp; e367038c
          &nbsp;&nbsp; #37
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.614</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.647</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.601</kbd>
        </footer>
      </article>
      <article>
        <h4>MIT fjerner datast, der har trnet AI-systemer til at vre racistisk og sexistisk</h4>
        <div>
          Universitetet undskylder for datast, der er annoteret med nedsttende ord om kvinder og sorte. MIT, et af verdens ledende universiteter inden for AI-forskning, har permanent fjernet et billeddatast p grund af racisitisk og sexistiske labels. Det skriver The Register Datasttet blev skabt i 2006, og er siden blevet flittigt brugt til at udvikle modeller, der kan identificerer personer og objekter p billeder. Men da MIT sammensatte datasttet - 80 Million Tiny Images - blev det gjort uden nogen nrmere kuratering af de label, der er tilknyttet hvert billede, og som f.eks. skal lre et neuralt netvrk, at billedet forestiller en cykel eller en bil. Tusindvis af billeder er nemlig annoteret med ord som 'luder', 'bitch' og 'pdofil'. Tilsvarende er mange billeder noteret med nedsttende ord rettet mod bestemte etniske grupper. Det viser en strre kulegravning , som Vinay Prabhu, chief scientist hos UnifyID, og Abeba Birhane, ph.d.-studerende ved University College Dublin, har lavet. Forskere: Undskyld De problematiske labels er opstet fordi MIT i sin tid hentede navneord fra ord-databasen Wordnet, og brugte dem til automatisk at hente korresponderende billeder p sgemaskiner. I en meddelelse fra Antonio Torralba, Rob Fergus og Bill Freeman, der oprindeligt prsenterede datasttet , fortller MIT-forskerne, at de ikke var klar over de problematisk labels. Vi er meget berrte over det, og vi undskylder over for alle, der er blevet pvirket,  skriver de. At manuelt rydde op i de 80 millioner billeder er ikke muligt, skriver forskerne. Og derfor fjerner de nu datasttet og opfordrer udviklere til at slette lokale kopier. Oprydning i ImageNet 80 Million Tiny Images er ligesom det ikoniske ImageNet-datast blevet brugt til at benchmarke AI-modeller. Men i modstning til ImageNet har ingen alts tidligere lavet et grundig og kritisk gennemgang af indholdet. ImageNet - der er skabt af forskere ved Stanford og Princeton - har vret signifikant for udvikling af deep learning-modeller til billedgenkendelse gennem den skaldte ImageNet Challenge. Men heller ikke her stod etikken ekstremt hjt p dagsordenen, da datasttet blev skabt mellem 2007 og 2009. Vinay Prabhu har tidligere demonstreret, at der er flere tvivlsomme billeder at finde i arkivet med over 14.000.000 billeder - foruden problematiske labels fandt Prabhu flere billeder af ngne brn samt pornografisk materiale. Forskerne bag ImageNet satte i september sidste r gang i en strre indsats, der blandt andet skal fjerne knsmssige og etniske bias i datasttet.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2020-07-03
          &nbsp;&nbsp; e7c796cc
          &nbsp;&nbsp; #38
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.99</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.719</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.61</kbd>
        </footer>
      </article>
      <article>
        <h4>Machine learning sorterer agurker i Japan</h4>
        <div>
          Raspberry Pi, et kamera, et neuralt netvrk og en lille kreds p et kort er de centrale dele i et selvlrende agurkesorteringsanlg.Vi skriver p Version2 om mange mere eller mindre spektakulre lsninger inden for sundhed, kundeservice og politiarbejde der anvender machine learning.Systemdiagram over agurkesorteringsanlggetMen teknologien kan smnd ogs bruges til noget s banalt som at sortere agurker - agurketid eller ej.Japaneren Makoto Koike, der er tidligere udvikler af indlejrede systemer, har bygget et agurke-sorteringsanlg, der gr brug af Googles TensorFlow machine learning teknologi for at spare hans forldre, der ejer grntsagsproduktionen, for en masse arbejde. Det fortller Engadget.Systemet bruger Raspberry Pi 3 med et kamera til at tage billeder af grntsagerne og sende optagelserne til et lille TensorFlow neuralt netvrk, hvori identificeres som agurker.Herefter sendes billeder til en Linux-server, der klassificerer agurkerne efter farve, form og strrelse. Et kort med en lille kreds, Arduino Micro, styrer herefter selve sorteringen, mens en Windows-pc sikrer at det neurale netvrk lbende optrnes ved hjlp af billeder.Det er ikke et perfekt system, i hvert fald lige nu. Til trods for at 7000 billeder er hvlet igennem systemet.Makoto Koike anslr, at det tager omkring 2-3 dage at trne den intelligente software op i sortering, hvilket dog sker billeder meget meget lav oplsning (80 x 80 pixels).Uanset at resultatet ikke er perfekt, antyder eksemplet en fremtid, hvor robotbaseret landbrugsudstyr kan hndterer mange opgaver, der tidligere krvede menneskehnd og -jne.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2016-09-05
          &nbsp;&nbsp; e5de815a
          &nbsp;&nbsp; #39
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.988</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.942</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.642</kbd>
        </footer>
      </article>
      <article>
        <h4>Svenske elge bliver nye linselus</h4>
        <div>
          GVLEBORG: Nr elgene bevger sig rundt i de svenske skove, skal de fremover vnne sig til, at mennesker kigger med.Der er nemlig ved at blive sat kameraer op i skovene i Gvleborg i Sverige som en del af et EU-projekt.De skal samle billeder ind af elgene, s dyrene p den mde fremover kan tlles uden hjlp fra jgere.Kameraerne bliver aktiveret af varme og bevgelse. Ved hjlp af kunstig intelligens skal det s vre muligt at genkende elgene og p den mde f oplysninger om elgbestanden i skovene. Elgen skal ogs kunne genkendes p andre biometriske data som strrelse eller afstand mellem krop og hoved. I fremtiden skal teknologien ogs bruges til at kortlgge andre typer dyr. / ritzau/TT.
        </div>
        <footer>
          <em>Dagbladet Kge</em>
          &nbsp;&nbsp; 2021-01-04
          &nbsp;&nbsp; e80ef119
          &nbsp;&nbsp; #40
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.82</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.746</kbd>
            <kbd data-tooltip="New technologies">L80_NEWTEC&nbsp;0.523</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.664</kbd>
        </footer>
      </article>
      <article>
        <h4>'Drmmende'computer rekonstruerer George Clooney fra ny vinkel</h4>
        <div>
          Computere efterligner menneskets forestillingsevne i ny metode udviklet i samarbejde mellem danske og amerikanske forskere.Mlet med forskningen er, at billedgenkendelse bliver strkere, nr kun f billeder er til rdighedMennesket overgr den dyreste og mest komplicerede computer, nr det kommer til at improvisere lring og finde kreative lsninger. Derfor forsger forskningen med den skaldte Deep Learning at efterligne funktioner i vores hjerner.Deep Learning vinder frem i arbejdet med kunstig intelligens. Forskere ved Danmarks Tekniske Universitet samarbejder med det amerikanske MIT (Massachusetts Institute of Technology) med at forbedre kunstig intelligens ved at f computere til at forestille sig nye billeder p baggrund af oplysninger fra billeder, den er blevet fodret med.Vi kalder det, at computeren drmmer, fordi billeddannelsen i computeren minder om, nr mennesker i drmme er i stand til at forestille sig noget, vi ikke har set i virkeligheden, siger Lars Kai Hansen, der er professor ved Danmarks Tekniske Universitet, og som sammen med postdoc Sren Hauberg str bag den danske del af det nye resultat, der netop er blevet prsenteret p konferencen -Artificial Intelligence and Statistics- i Cadiz i Spanien.Drmmer om George ClooneyForskerne har eksempelvis fodret computere med billeder af George Clooneys ansigt set forfra. De har udviklet algoritmer og statistiske modeller, der resulterer i, at computere kunne konstruere et billede af skuespillerens ansigt fra en lidt anden synsvinkel, end synsvinklen p de billeder, den blev fodret med.Selvom det kan lyde kurist, sigter projektet p konkrete anvendelsesmuligheder.Mlet med forskningen er, at billedgenkendelse bliver strkere, nr kun f billeder er til rdighed. Dette vil specielt f stor indflydelse p analyse af medicinske scanningsbilleder, som vi oftest kun har i meget begrnset antal, siger Lars Kai Hansen.Et velkendte eksempel p Deep Learning var, da Google Deep Mind for nylig vandt over den erfarne topspiller Lee Sedol i computerspillet GO. Her var resultaterne, som ofte med Deep Learning, opnet p baggrund af, at computeren var blevet fodret med meget store mngder af data. I resultaterne fra det dansk-amerikanske samarbejde, som netop er blevet prsenteret, kan computerne arbejde ud fra frre billeder.Forskernes efterligninger af menneskets forestillingsevne er i sin spde begyndelse. For eksempel kan computeren endnu kun dreje George Clooneys ansigt en lille smule   og der er endnu lang vej, fr computeren eksempelvis vil kunne vise skuespilleren i profil p baggrund af det billedmateriale, forskerne her har brugt, vurderer Lars Kai Hansen.forsgsperson. Fotomontage af George Clooney, som er et af flere ansigter i billeddatasttet -Labelled Faces in The Wild-, der bliver brugt til forskning i ansigtsgenkendelse af danske og amerikanske forskere i ny metode til at forbedre kunstig intelligens. Fotomontage. Foto: AP.forsgsperson. Fotomontage af George Clooney, som er et af flere ansigter i billeddatasttet -Labelled Faces in The Wild-, der bliver brugt til forskning i ansigtsgenkendelse af danske og amerikanske forskere i ny metode til at forbedre kunstig intelligens. Fotomontage. Foto: AP.
        </div>
        <footer>
          <em>Politiken.dk</em>
          &nbsp;&nbsp; 2016-05-10
          &nbsp;&nbsp; e5b3ea03
          &nbsp;&nbsp; #41
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.98</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.668</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.596</kbd>
        </footer>
      </article>
      <article>
        <h4>t kamera skyld i bder p 29 mio kr</h4>
        <div>
            I Australien har politiet intelligente trafik-kameraer, der kan fange ulovlig mobiltelefon-brug. Rigspolitiet i Danmark synes det lyder spndende. - Storartet. - Vi har brug for 10 kameraer yderligere rundt omkring i Sydney. - S kan politiet bruge tiden p noget andet - som f.ex. kan de fange forbrydere. Ingen hndholdt, intet problem Sdan skriver Leigh G i en af de 51 kommentarer, der er skrevet p Sydney Morning Heralds Facebook-profil om det intelligente trafik-kamera p byens M4-ringvej har fanget mere end 20.000 bilister, der har brugt mobilen. Det er nemlig sket p bare fire mneder ved hjlp af srlige algoritmer og Leigh er ikke den eneste, der er positiv: - Ingen hndholdt mobil i bilen = intet problem, skriver Triskele R og Shrileen B synes ogs, der er en let mde at indg bder p. - Gr nu bare det rigtige, og lad vr med at udst mit og dit eget liv for fare, skriver Shrileen. Bder for 64 mio I Sydney begyndte man at stte kameraer op i trafikken i slutningen af 2019, og i alt har de seks kameraer indbragt cirka 64 millioner kr i bder. Mobil-synder kameraet str for nsten halvdelen af det belb og i Danmark flger Rigspolitiet spndt med: Vi flger det med interesse - Med hensyn til de intelligente kameraer, s flger vi udviklingen p omrdet med interesse, da det er et spndende omrde. .- Uopmrksomhed i trafikken er et af tre store fokus omrder for frdselspolitiet, da uheldsraten umiddelbart er meget hj p det omrde, skriver Christian Berthelsen, politiassistent i Rigspolitiet til nationen! Sidste r blev der udstedt 24.000 bder for brug af hndholdt mobiltelefon og andre former for telekommunikationsudstyr. I 2013 var det tal oppe p 48.000.
        </div>
        <footer>
          <em>EkstraBladet.dk/Plus</em>
          &nbsp;&nbsp; 2020-08-19
          &nbsp;&nbsp; e7d80b46
          &nbsp;&nbsp; #42
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.627</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.509</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.611</kbd>
        </footer>
      </article>
      <article>
        <h4>Googles Captcha-aflser hjlper computeren med at lre at fortolke billeder</h4>
        <div>
          Mennesker er stadig bedre end computere til at genkende billeder. Men flere forskerhold arbejder p at gre kl p menneskets forspring.Af Jesper Stein SandalGoogle har sagt farvel til den klassiske CAPTCHA, som skulle skille mennesker fra automatiske scripts ved at bede dem tyde en slret tekststreng. Aflseren bruger billeder, og det skal hjlpe Googles billedgenkendelsessoftware, skriver New Scientist .I den nye udgave af Googles CAPTCHA-udfordring vil et menneske som regel kunne genkendes alene ud fra visse kendetegn som eksempelvis musens bevgelser, som kan aflses af hjemmesiden. Men hvis Googles algoritme kommer i tvivl, kan brugeren blive bedt om eksempelvis at identificere et billede, som skiller sig ud i en gruppe af billeder.CAPTCHA-udfordringer bruges blandt andet til at forhindre automatiske scripts, som kan registrere sig p hjemmesider og spamme debattrde med reklamer.De gamle udgaver er ikke lngere s plidelige, fordi computerne er blevet bedre til at afkode de slrede tekster. Men computere er stadig meget mere uplidelige til eksempelvis at se, om et lille pelset dyr er en kat eller en kanin. Det er mennesker til gengld ekstremt gode til.Det er det, Google nu udnytter, men ud over at beskytte hjemmesider mod spam, s giver teknologien ogs Google vrdifulde datast. Hver gang et menneske har hjulpet med at identificere et billede ud af en mngde, s kan Google bruge det samme datast til oplring af billedanalysealgoritmer.Det vil blandt andet kunne hjlpe Google med at forbedre billedsgning, hvor Google i dag er afhngig af enten tekst i sammenhng med et billede eller mnstergenkendelse, som har en vis fejlrate.Google arbejder ogs iflge MIT Technology Review p et billedanalysevrktj, som bruger vektormatematik til at stte ord p billeder. Det er en videreudvikling af en teknik, som Google i forvejen bruger til tekstoversttelse mellem sprog, men den kan ogs bruges til billeder.Et forskerhold ved Stanford University arbejder ligeledes p et st af maskinlringsalgoritmer, der kan sttes ord p billeder . Ved hjlp af en database bestende af 14 millioner objekter udtrykt ved hjlp af vektorer, kan algoritmerne genkende objekterne i billeder og sammenstte en beskrivelse. Det gr det eksempelvis muligt at beskrive indholdet af et billede som eksempelvis 'en kat sidder p et tastatur'.Denne type avanceret analyse af indholdet i billeder er isr interessant i forhold til at kunne sge i og kategorisere de millioner af billeder og videoer, som distribueres p internettet, som ofte ikke er forsynet med mange oplysninger om, hvad de forestiller.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2014-12-11
          &nbsp;&nbsp; e4b7abfc
          &nbsp;&nbsp; #43
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.707</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.654</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.688</kbd>
        </footer>
      </article>
      <article>
        <h4>Amazon planlgger intens kameraovervgning af medarbejdere</h4>
        <div>
          Amazon vil overvge medarbejdere med kameraer i virksomhedens leveringsbiler. Iflge tech-giganten skal data skal bruges til evaluere frernes arbejde og forbedre deres sikkerhed.Amazon planlgger at installere kameraer i sine leveringsbiler, s man bedre kan holde je med medarbejderne, nr de leverer pakker.Det skriver The VergeSystemet leveres af virksomheden Netradyne, som str bag Driveri - en platform, der bruger kameraer og kunstig intelligens til at analysere frerne. Systemet indsamler data, der bruges til at evaluere de enkelte frere, samtidig med, det under krslen giver freren beskeder som distraheret krsel  og st venligst farten ned .Vi leder altid efter innovative mder at styrke vores freres sikkerhed p. Det er derfor, vi har indget et samarbejde med Netradyne for at forbedre frerens oplevelse,  siger Karolina Haraldsdottir, Chef for Amazons 'last-mile safety', i en marketingsvideo.Kameraerne optager hele tiden, og data sendes direkte til Amazon. Dog kan freren deaktivere kameraet - men kun nr bilen er slukket.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2021-02-04
          &nbsp;&nbsp; e81c9937
          &nbsp;&nbsp; #44
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.53</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.585</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.584</kbd>
        </footer>
      </article>
      <article>
        <h4>Twitter indrmmer: Billedbeskring med AI var diskriminerende</h4>
        <div>
          Det var korrekt, da en Twitter-bruger ppegede, at tjenestens algoritme til billedbeskring foretrak hvide ansigter frem for sorte.Twitter fik sidste r kritik, da en algoritme til at bestemme, hvordan billeder skal beskres, viste sig at vre mere tilbjelig til at skre sorte personer fra, og lade hvide personer blive i billedet.Twitter-brugeren @bascule testede den gang beskring med et billede, der verst har et portrt af den amerikanske senator Mitch McConnell, som er hvid, og nederst tidligere prsident Barack Obama.Her valgte Twitters beskring fotoet af den hvide senator. I et senere tweet skrev @bascule:Flere, der svarede p min tweet, har prvet alle mulige grundige slags 'tweaks' for at f andre resultater. Det forbigr min originale pointe med mit eksperiment: Jeg prvede bare at finde to nogenlunde ens udseende billeder og (hnden p hjertet) ville se hvad resultatet var. Et bestemt 'tweak' - nemlig at ge kontrasten p det ene billede - afslrer problemet, mente Twitter-brugeren, som testede med to billeder af Barack Obama, hvor det ene har hjere kontrast, og er mere sort:Algoritmen synes at foretrkke en lysere Obama frem for en mrkere. Nu har selskabets egne interne undersgelser sat tal p problemet, skriver vores sstermedie DataTech , der citerer Zdnet.En rapport fra Twitter viser en forskel p 4 procent mellem hvide mennesker og sorte mennesker. Vrre ser det ud mellem kn, hvor kvinder foretrkkes over mnd med en forskel p 7 procent. Til gengld fandt undersgelsen ikke tegn p, at modellen foretrkker bestemte kropsdele, nr billeder skal beskres.Det sociale medie valgte allerede sidste at justere den automatiske beskring af billeder og i hjere grad give brugere mulighed for at vlge.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2021-05-25
          &nbsp;&nbsp; e847da81
          &nbsp;&nbsp; #45
          <br>
          <br>
            <kbd data-tooltip="Tech industry &amp; regulation">L02_BIGTEC&nbsp;0.529</kbd>
            <kbd data-tooltip="Facebook, fake news &amp; Trump">L05_FBTRUM&nbsp;0.527</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.605</kbd>
        </footer>
      </article>
      <article>
        <h4>Lyde genskabes ud fra vibrationer i chipspose</h4>
        <div>
          Amerikanske forskere har fundet ud af, at man kan rekonstruere lyd ud fra vibrationer fra objekter. Den nye opfindelse skal blandt andet bruges til at opklare af forbrydelserForskere fra Massachusetts Institute of Technology, MIT, har i samarbejde med Microsoft Research og Adobe udviklet en algoritme, de kalder 'Den visuelle mikrofon'. Den gr det muligt at lytte til andres samtaler, udelukkende ved at analysere videomontager af vibrerende objekter, skriver Videnskab.dk.Projektet, som forskerne kalder 'The Visual Microphone: Passive Recovery of Sound from Video' er blevet publiceret i tidsskriftet ACM Transactions on Graphics.I forsget benyttede forskerne sig blandt andet af vibrationerne fra en chipspose, planteblade og hretelefoner, der l p et bord, til at afkode lyden fra en person, som sang sangen 'Mary had a little lamb'.Se video af det spektakulre forsg p Videnskab.dkForskerne optog blandt andet chipsposens vibrationer i en afstand p 15 meter bag et lydisoleret glas, og det med stor succes.Det kan mske vre svrt at forst, hvordan man kan rekonstruere lyd ud fra videooptagelser. Forskningsleder og kandidatstuderende Abe Davis fra MIT forklarer:- Nr en lyd rammer et objekt, begynder objektet at vibrere. Denne vibrerende bevgelse skaber et lille subtilt visuelt signal, som normalt er usynligt for det blotte je. Disse informationer har vi ikke fr vidst eksisterede, udtaler Abe Davis i en pressemeddelelse fra MIT.Ls ogs p Videnskab.dk: Forskere: Fingre afslrer lngden p penisForskerne benyttede sig i de fleste tilflde af et hjshastighedskameraer til at optage vibrationerne fra objekterne. I sdanne kameraer br antallet af billeder pr. sekund, Frames Per Second (FPS), vre hjere end frekvensen p lydsignalet.Kameraene, som forskerne anvendte i forsget, kunne optage 2.000-6.000 FPS. Til sammenligning optager de fleste smartphones omkring 60 FPS.Den nye teknologi skal blandt andet bruges inden for efterforskningsverdenen, hvor optagelsesudstyr og aflytninger allerede benyttes.Andre artikler fra Videnskab.dk:Forskere aflurer Bruce Lees bermte trick: Sdan imponerer du tserneSe en Coca Cola-dse blive fuldstndig oplstFascinerende billeder: Jorden set fra rummetFoto: Linda Johansen.Foto: Linda Johansen.
        </div>
        <footer>
          <em>EkstraBladet.dk</em>
          &nbsp;&nbsp; 2014-08-08
          &nbsp;&nbsp; e485b9c3
          &nbsp;&nbsp; #46
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.983</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.706</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.557</kbd>
        </footer>
      </article>
      <article>
        <h4>EUC Syd jager meteorer fra hustag i Snderborg</h4>
        <div>
          DEL Af Bent Christensen, express5@jfmedier.dk 16. oktober 2019 kl. 08:39Snderborg: Som en del af et stort verdensomspndende netvrk har EUC Syd dette efterr opsat et webcam p et af tagene i Snderborg. Der foregr nu en uafbrudt monitorering af himlen for at spore meteoritters oprindelse og fald, og det foregr i et samarbejdet mellem EUC Syd, Den Tyske Skole i Snderborg og organisationen fripon.org.EUC Syd er som de frste fra Skandinavien med i projekt Vigie Ciel (Sky Watch) og er indtil videre det nordligste observationspunkt.Meningen er, at alle data og billeder fra samtlige deltageres digitale kameraer lbende bliver analyseret via nogle algoritmer. Nr der optrder asymmetri i meteoritters bevgelse hen over himlen, kan man meget prcist dkke nedfaldene, da man har observationer og data fra adskillige kameraer med optagelser fra mange forskellige vinkler. Sledes forventes det, at man kan spore og finde meteoritter efter nedfald.Bde Den Tyske Skole og EUC Syd har planer om at kunne bruge de forskellige observationer, data og tekniske udregninger i undervisningen.
        </div>
        <footer>
          <em>Ugeavisen-soenderborg.dk</em>
          &nbsp;&nbsp; 2019-10-16
          &nbsp;&nbsp; e76654ee
          &nbsp;&nbsp; #47
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.918</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.643</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.651</kbd>
        </footer>
      </article>
      <article>
        <h4>Her er resultatet, nr neurale netvrk fr frit spil p fotos</h4>
        <div>
          Et billede af en ridder, udsat for 'dyregenkendelse' i et neuralt netvrk. Netvrket er blevet bedt om at finde dyr i billedet, hvorefter de elementer, netvrket har fundet, er blevet forstrket. Derefter er processen krt igen og igen. (Foto: Google)Neurale netvrk, der er trnet til at se p billeder, kan faktisk ogs skabe billeder. Det viser et interessant   nogle vil mske sige foruroligende   eksperiment fra Googles forskningsafdeling.Af 11. jul 2015 kl. 14:00Internetgiganten Google bruger neurale netvrk til billedgenkendelse, bl.a. i sin nye fototjeneste Google Photos. Men hvor imponerende det end kan vre, at disse netvrk kan 'se' p en mngde billeder og finde dem med en 'hund' eller en 'banan', s str det faktisk ikke helt klart for forskerne, hvordan det foregr.Derfor har softwareingenirer hos Google prvet at vende processen p hovedet: I stedet for f.eks. at vise netvrket millioner af billeder af bananer, indtil det er i stand til at genkende n, s har de taget et grmeleret billede bestende af tilfldig stj og bedt netvrket om at se efter bananer.Nr netvrket mente at have set noget, der lignede en banan, forstrkede forskerne det fundne en lille smule og sendte s det nye billede ind i netvrket igen   og s videre, og s videre, indtil der opstod billeder, der begyndte at ligne noget:Eksempler p, hvad Googles neurale netvrk kan f ud af et billede med gr stj, hvis det bliver bedt om at se efter forskellige genstande som f.eks. sstjerner, skruer eller koantiloper (hartebeest). (Foto: Google)Som forskerne skriver i deres blogindlg om forsget , er det lrerigt at vende processen p hovedet, fordi det kan afslre, om netvrket nu ogs fokuserer p de rigtige karakteristika, nr det kigger efter en banan, en sstjerne eller en skrue.Frie fortolkningerNeurale netvrk bestr af flere 'lag', der i forbindelse med billedgenkendelse ser efter stadigt mere komplicerede elementer. Hvis man beder et af de lavere lag om at 'g i selvsving' p billeder, der rent faktisk forestiller noget, vil de producere fortolkninger, der typisk indeholder forstrkede linjer eller ornamenteringer af forlgget.Til venstre et originalfoto af Zachi Evenor, til hjre behandlet i Googles neurale netvrk af softwareingenir Gnther Noack. (Foto: Google)Er det i stedet et af de hjere lag i netvrket, der bearbejder et billede, kan der opst mere komplekse elementer eller objekter. Som Google-ingenirerne forklarer i blogindlgget beder de igen bare netvrket om 'mere af det samme': 'Hvis en sky har en smule lighed med en fugl, vil netvrket f den til at ligne en fugl endnu mere. Det vil f netvrket til at genkende fuglen endnu nemmere nste gang, indtil et meget detaljeret billede af en fugl kommer frem   tilsyneladende ud af ingenting.' Som i eksemplet herunder:Fugle opstet ud af 'ingenting' i et foto af en bl himmel med skyer. (Foto: Google)Forskerne mener, at teknikken kan give en kvalitativ forstelse af det abstraktionsniveau, et givet lag i et neuralt netvrk har udviklet i sin forstelse af billeder. De kalder teknikken 'inceptionism' og har samlet et helt galleri over eksempler p, hvilke billeder, der kan hentes ud af et neuralt netvrk. Som f.eks. denne gruppe af billeder, der alle er skabt ved at lade et neuralt netvrk oplrt af MIT Computer Science and AI Laboratory til at genkende steder tygge p gr billeder af tilfldig stj, rigtig mange gange:Fantasier over bygninger   skabt ud fra gr stj af et neuralt netvrk. (Foto: Google)Efter det frste blogindlg om deres eksperimenter har forskerne nu valgt at lgge deres kode ud open source, s andre kan forsge at eftergre dem kunsten   og de opfordrer folk, der gr det, til at tagge deres billeder #deepdream.
        </div>
        <footer>
          <em>Ing.dk (Ingeniren)</em>
          &nbsp;&nbsp; 2015-07-11
          &nbsp;&nbsp; e51ee60c
          &nbsp;&nbsp; #48
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.907</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.727</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.648</kbd>
        </footer>
      </article>
      <article>
        <h4>Her er Huaweis frste mobil i Danmark i r</h4>
        <div>
          Men Huawei spytter nye modeller i stor hast. Derfor er det heller ikke overraskende, at rets frste mobil allerede er blevet lanceret.Solidt batteriNyheden hedder og er bygget til de yngre mobilbrugere. Telefonen har et 6,21 tommers display i strrelsesforholdet 19.5:9, 64 gigabyte lagerplads og et pnt batteri p 3400 mAh.Displayet er p 415ppi og FHD+ med en oplsning p 2340 x 1080 pixels. Og selvom modellen koster 1899 kroner i vejledende pris, er der blevet plads til ganske habile kameraer.Sdan er kameraerneDer er to kameraer p bagsiden p henholdsvis 13 og 2 megapixels. Det sidstnvnte bruges iflge Huawei til at 'ge detaljegraden, s du kan skyde de helt store vidder og landskaber og mere detaljerede portrtbilleder.'Selfiekameraet er p 8 megapixels. Og der er som i P20- og Mate-serien indbygget kunstige intelligens, som kan gre det nemmere at skyde bedre billeder.Du kan dog alene optage video i op til 1080p og ikke 4K.Ekstra hukommelseModsat flere dyrere udgaver af Huaweis telefoner kan du bruge et ekstern hukommelseskort p op til 512 gigabyte i P Smart 2019.Opladningen sker via et microUSB-kabel, der er normalt hovedtelefonstik i modellen, og der flger en hovedtelefon med i salgskassen.Modellen er allerede til salg hos Elgiganten og Power i farverne Midnight Black og Aurora Blue. Den kommer i nste kvartal til salg hos andre forhandlere.
        </div>
        <footer>
          <em>Ekstrabladet.dk</em>
          &nbsp;&nbsp; 2019-01-12
          &nbsp;&nbsp; e70a5e50
          &nbsp;&nbsp; #49
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.644</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.567</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.602</kbd>
        </footer>
      </article>
    </main>
  </body>
</html>
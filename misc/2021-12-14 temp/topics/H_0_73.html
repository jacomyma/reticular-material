<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Infomedia Articles</title>
    <style type="text/css">
/*!
 * Pico.css v1.3.3 (https://picocss.com)
 * Copyright 2019-2021 - Licensed under MIT
 */:root{--font-family:system-ui,-apple-system,"Segoe UI","Roboto","Ubuntu","Cantarell","Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";--line-height:1.5;--font-weight:400;--font-size:16px;--border-radius:.25rem;--border-width:1px;--outline-width:3px;--spacing:1rem;--typography-spacing-vertical:1.5rem;--block-spacing-vertical:calc(var(--spacing) * 2);--block-spacing-horizontal:var(--spacing);--grid-spacing-vertical:0;--grid-spacing-horizontal:var(--spacing);--form-element-spacing-vertical:.75rem;--form-element-spacing-horizontal:1rem;--transition:.2s ease-in-out}@media (min-width:576px){:root{--font-size:17px}}@media (min-width:768px){:root{--font-size:18px}}@media (min-width:992px){:root{--font-size:19px}}@media (min-width:1200px){:root{--font-size:20px}}@media (min-width:576px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 2.5)}}@media (min-width:768px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 3)}}@media (min-width:992px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 3.5)}}@media (min-width:1200px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 4)}}@media (min-width:576px){article{--block-spacing-horizontal:calc(var(--spacing) * 1.25)}}@media (min-width:768px){article{--block-spacing-horizontal:calc(var(--spacing) * 1.5)}}@media (min-width:992px){article{--block-spacing-horizontal:calc(var(--spacing) * 1.75)}}@media (min-width:1200px){article{--block-spacing-horizontal:calc(var(--spacing) * 2)}}a{--text-decoration:none}a.contrast,a.secondary{--text-decoration:underline}small{--font-size:0.875em}h1,h2,h3,h4,h5,h6{--font-weight:700}h1{--font-size:2rem;--typography-spacing-vertical:3rem}h2{--font-size:1.75rem;--typography-spacing-vertical:2.625rem}h3{--font-size:1.5rem;--typography-spacing-vertical:2.25rem}h4{--font-size:1.25rem;--typography-spacing-vertical:1.874rem}h5{--font-size:1.125rem;--typography-spacing-vertical:1.6875rem}[type=checkbox],[type=radio]{--border-width:2px}[type=checkbox][role=switch]{--border-width:3px}thead td,thead th{--border-width:3px}:not(thead)>*>td{--font-size:0.875em}code,kbd,pre,samp{--font-family:"Menlo","Consolas","Roboto Mono","Ubuntu Monospace","Noto Mono","Oxygen Mono","Liberation Mono",monospace,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji"}kbd{--font-weight:bolder}:root:not([data-theme=dark]),[data-theme=light]{color-scheme:light;--background-color:#FFF;--color:#415462;--h1-color:#1b2832;--h2-color:#23333e;--h3-color:#2c3d49;--h4-color:#374956;--h5-color:#415462;--h6-color:#4d606d;--muted-color:#73828c;--muted-border-color:#edf0f3;--primary:#1095c1;--primary-hover:#08769b;--primary-focus:rgba(16,149,193,0.125);--primary-inverse:#FFF;--secondary:#596b78;--secondary-hover:#415462;--secondary-focus:rgba(89,107,120,0.125);--secondary-inverse:#FFF;--contrast:#1b2832;--contrast-hover:#000;--contrast-focus:rgba(89,107,120,0.125);--contrast-inverse:#FFF;--mark-background-color:#fff2ca;--mark-color:#543a25;--ins-color:#388E3C;--del-color:#C62828;--blockquote-border-color:var(--muted-border-color);--blockquote-footer-color:var(--muted-color);--button-box-shadow:0 0 0 rgba(0,0,0,0);--button-hover-box-shadow:0 0 0 rgba(0,0,0,0);--form-element-background-color:transparent;--form-element-border-color:#a2afb9;--form-element-color:var(--color);--form-element-placeholder-color:var(--muted-color);--form-element-active-background-color:transparent;--form-element-active-border-color:var(--primary);--form-element-focus-color:var(--primary-focus);--form-element-disabled-background-color:#d5dce2;--form-element-disabled-border-color:#a2afb9;--form-element-disabled-opacity:.5;--form-element-invalid-border-color:#C62828;--form-element-invalid-active-border-color:#B71C1C;--form-element-valid-border-color:#388E3C;--form-element-valid-active-border-color:#2E7D32;--switch-background-color:#bbc6ce;--switch-color:var(--primary-inverse);--switch-checked-background-color:var(--primary);--range-border-color:#d5dce2;--range-active-border-color:#bbc6ce;--range-thumb-border-color:var(--background-color);--range-thumb-color:var(--secondary);--range-thumb-hover-color:var(--secondary-hover);--range-thumb-active-color:var(--primary);--table-border-color:var(--muted-border-color);--table-row-stripped-background-color:#f6f8f9;--code-background-color:#edf0f3;--code-color:var(--muted-color);--code-kbd-background-color:var(--contrast);--code-kbd-color:var(--contrast-inverse);--code-tag-color:#b34d80;--code-property-color:#3d888f;--code-value-color:#998866;--code-comment-color:#a2afb9;--accordion-border-color:var(--muted-border-color);--accordion-close-summary-color:var(--color);--accordion-open-summary-color:var(--muted-color);--card-background-color:var(--background-color);--card-border-color:var(--muted-border-color);--card-box-shadow:0 0.125rem 1rem rgba(27,40,50,0.04),0 0.125rem 2rem rgba(27,40,50,0.08),0 0 0 0.0625rem rgba(27,40,50,0.024);--card-sectionning-background-color:#fafbfc;--progress-background-color:#d5dce2;--progress-color:var(--primary);--loading-spinner-opacity:.5;--tooltip-background-color:var(--contrast);--tooltip-color:var(--contrast-inverse);--icon-chevron:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");--icon-date:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");--icon-time:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");--icon-search:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");--icon-checkbox:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-minus:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");--icon-valid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(56, 142, 60, 0.999)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-invalid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(198, 40, 40, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E")}@media only screen and (prefers-color-scheme:dark){:root:not([data-theme=light]){color-scheme:dark;--background-color:#11191f;--color:#bbc6ce;--h1-color:#edf0f3;--h2-color:#e1e6ea;--h3-color:#d5dce2;--h4-color:#c8d1d8;--h5-color:#bbc6ce;--h6-color:#aebbc3;--muted-color:#73828c;--muted-border-color:#1f2d38;--primary:#1095c1;--primary-hover:#1ab3e6;--primary-focus:rgba(16,149,193,0.25);--primary-inverse:#FFF;--secondary:#596b78;--secondary-hover:#73828c;--secondary-focus:rgba(115,130,140,0.25);--secondary-inverse:#FFF;--contrast:#edf0f3;--contrast-hover:#FFF;--contrast-focus:rgba(115,130,140,0.25);--contrast-inverse:#000;--mark-background-color:#d0c284;--mark-color:#11191f;--ins-color:#388E3C;--del-color:#C62828;--blockquote-border-color:var(--muted-border-color);--blockquote-footer-color:var(--muted-color);--button-box-shadow:0 0 0 rgba(0,0,0,0);--button-hover-box-shadow:0 0 0 rgba(0,0,0,0);--form-element-background-color:#11191f;--form-element-border-color:#374956;--form-element-color:var(--color);--form-element-placeholder-color:var(--muted-color);--form-element-active-background-color:var(--form-element-background-color);--form-element-active-border-color:var(--primary);--form-element-focus-color:var(--primary-focus);--form-element-disabled-background-color:#2c3d49;--form-element-disabled-border-color:#415462;--form-element-disabled-opacity:.5;--form-element-invalid-border-color:#B71C1C;--form-element-invalid-active-border-color:#C62828;--form-element-valid-border-color:#2E7D32;--form-element-valid-active-border-color:#388E3C;--switch-background-color:#374956;--switch-color:var(--primary-inverse);--switch-checked-background-color:var(--primary);--range-border-color:#23333e;--range-active-border-color:#2c3d49;--range-thumb-border-color:var(--background-color);--range-thumb-color:var(--secondary);--range-thumb-hover-color:var(--secondary-hover);--range-thumb-active-color:var(--primary);--table-border-color:var(--muted-border-color);--table-row-stripped-background-color:rgba(115,130,140,0.05);--code-background-color:#17232c;--code-color:var(--muted-color);--code-kbd-background-color:var(--contrast);--code-kbd-color:var(--contrast-inverse);--code-tag-color:#a65980;--code-property-color:#599fa6;--code-value-color:#8c8473;--code-comment-color:#4d606d;--accordion-border-color:var(--muted-border-color);--accordion-active-summary-color:var(--primary);--accordion-close-summary-color:var(--color);--accordion-open-summary-color:var(--muted-color);--card-background-color:#141e25;--card-border-color:#11191f;--card-box-shadow:0 0.125rem 1rem rgba(0,0,0,0.06),0 0.125rem 2rem rgba(0,0,0,0.12),0 0 0 0.0625rem rgba(0,0,0,0.036);--card-sectionning-background-color:#17232c;--progress-background-color:#23333e;--progress-color:var(--primary);--loading-spinner-opacity:.5;--tooltip-background-color:var(--contrast);--tooltip-color:var(--contrast-inverse);--icon-chevron:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");--icon-date:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");--icon-time:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");--icon-search:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");--icon-checkbox:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-minus:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");--icon-valid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(46, 125, 50, 0.999)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-invalid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(183, 28, 28, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E")}}[data-theme=dark]{color-scheme:dark;--background-color:#11191f;--color:#bbc6ce;--h1-color:#edf0f3;--h2-color:#e1e6ea;--h3-color:#d5dce2;--h4-color:#c8d1d8;--h5-color:#bbc6ce;--h6-color:#aebbc3;--muted-color:#73828c;--muted-border-color:#1f2d38;--primary:#1095c1;--primary-hover:#1ab3e6;--primary-focus:rgba(16,149,193,0.25);--primary-inverse:#FFF;--secondary:#596b78;--secondary-hover:#73828c;--secondary-focus:rgba(115,130,140,0.25);--secondary-inverse:#FFF;--contrast:#edf0f3;--contrast-hover:#FFF;--contrast-focus:rgba(115,130,140,0.25);--contrast-inverse:#000;--mark-background-color:#d0c284;--mark-color:#11191f;--ins-color:#388E3C;--del-color:#C62828;--blockquote-border-color:var(--muted-border-color);--blockquote-footer-color:var(--muted-color);--button-box-shadow:0 0 0 rgba(0,0,0,0);--button-hover-box-shadow:0 0 0 rgba(0,0,0,0);--form-element-background-color:#11191f;--form-element-border-color:#374956;--form-element-color:var(--color);--form-element-placeholder-color:var(--muted-color);--form-element-active-background-color:var(--form-element-background-color);--form-element-active-border-color:var(--primary);--form-element-focus-color:var(--primary-focus);--form-element-disabled-background-color:#2c3d49;--form-element-disabled-border-color:#415462;--form-element-disabled-opacity:.5;--form-element-invalid-border-color:#B71C1C;--form-element-invalid-active-border-color:#C62828;--form-element-valid-border-color:#2E7D32;--form-element-valid-active-border-color:#388E3C;--switch-background-color:#374956;--switch-color:var(--primary-inverse);--switch-checked-background-color:var(--primary);--range-border-color:#23333e;--range-active-border-color:#2c3d49;--range-thumb-border-color:var(--background-color);--range-thumb-color:var(--secondary);--range-thumb-hover-color:var(--secondary-hover);--range-thumb-active-color:var(--primary);--table-border-color:var(--muted-border-color);--table-row-stripped-background-color:rgba(115,130,140,0.05);--code-background-color:#17232c;--code-color:var(--muted-color);--code-kbd-background-color:var(--contrast);--code-kbd-color:var(--contrast-inverse);--code-tag-color:#a65980;--code-property-color:#599fa6;--code-value-color:#8c8473;--code-comment-color:#4d606d;--accordion-border-color:var(--muted-border-color);--accordion-active-summary-color:var(--primary);--accordion-close-summary-color:var(--color);--accordion-open-summary-color:var(--muted-color);--card-background-color:#141e25;--card-border-color:#11191f;--card-box-shadow:0 0.125rem 1rem rgba(0,0,0,0.06),0 0.125rem 2rem rgba(0,0,0,0.12),0 0 0 0.0625rem rgba(0,0,0,0.036);--card-sectionning-background-color:#17232c;--progress-background-color:#23333e;--progress-color:var(--primary);--loading-spinner-opacity:.5;--tooltip-background-color:var(--contrast);--tooltip-color:var(--contrast-inverse);--icon-chevron:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");--icon-date:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");--icon-time:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");--icon-search:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");--icon-checkbox:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-minus:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");--icon-valid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(46, 125, 50, 0.999)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-invalid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(183, 28, 28, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E")}*,:after,:before{box-sizing:border-box}:after,:before{text-decoration:inherit;vertical-align:inherit}html{-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:rgba(0,0,0,0);-moz-tab-size:4;-ms-text-size-adjust:100%;background-color:var(--background-color);color:var(--color);font-family:var(--font-family);font-size:var(--font-size);font-weight:var(--font-weight);line-height:var(--line-height);text-rendering:optimizeLegibility;cursor:default}main{display:block}body{width:100%;margin:0}body>footer,body>header,body>main{width:100%;margin-right:auto;margin-left:auto;padding:var(--block-spacing-vertical) 0}.container,.container-fluid{width:100%;margin-right:auto;margin-left:auto;padding-right:var(--spacing);padding-left:var(--spacing)}@media (min-width:576px){.container{max-width:510px;padding-right:0;padding-left:0}}@media (min-width:768px){.container{max-width:700px}}@media (min-width:992px){.container{max-width:920px}}@media (min-width:1200px){.container{max-width:1130px}}section{margin-bottom:var(--block-spacing-vertical)}.grid{grid-column-gap:var(--grid-spacing-horizontal);grid-row-gap:var(--grid-spacing-vertical);display:grid;grid-template-columns:1fr;margin:0}@media (min-width:992px){.grid{grid-template-columns:repeat(auto-fit,minmax(0%,1fr))}}.grid>*{min-width:0}figure{display:block;margin:0;padding:0;overflow-x:auto}figure figcaption{padding:calc(var(--spacing) / 2) 0;color:var(--muted-color)}b,strong{font-weight:bolder}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-0.25em}sup{top:-0.5em}dl dl,dl ol,dl ul,ol dl,ul dl{margin:0}ol ol,ol ul,ul ol,ul ul{margin:0}address,blockquote,dl,figure,form,ol,p,pre,table,ul{margin-top:0;margin-bottom:var(--typography-spacing-vertical);color:var(--color);font-size:1rem;font-style:normal}a{--color:var(--primary);--background-color:transparent;outline:none;background-color:var(--background-color);color:var(--color);text-decoration:var(--text-decoration);transition:background-color var(--transition),color var(--transition),text-decoration var(--transition),box-shadow var(--transition)}a:active,a:focus,a:hover{--color:var(--primary-hover);--text-decoration:underline}a:focus{--background-color:var(--primary-focus)}a.secondary{--color:var(--secondary)}a.secondary:active,a.secondary:focus,a.secondary:hover{--color:var(--secondary-hover)}a.secondary:focus{--background-color:var(--secondary-focus)}a.contrast{--color:var(--contrast)}a.contrast:active,a.contrast:focus,a.contrast:hover{--color:var(--contrast-hover)}a.contrast:focus{--background-color:var(--contrast-focus)}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:var(--typography-spacing-vertical);color:var(--color);font-family:var(--font-family);font-size:var(--font-size);font-weight:var(--font-weight)}h1{--color:var(--h1-color)}h2{--color:var(--h2-color)}h3{--color:var(--h3-color)}h4{--color:var(--h4-color)}h5{--color:var(--h5-color)}h6{--color:var(--h6-color)}address~h1,address~h2,address~h3,address~h4,address~h5,address~h6,blockquote~h1,blockquote~h2,blockquote~h3,blockquote~h4,blockquote~h5,blockquote~h6,dl~h1,dl~h2,dl~h3,dl~h4,dl~h5,dl~h6,figure~h1,figure~h2,figure~h3,figure~h4,figure~h5,figure~h6,form~h1,form~h2,form~h3,form~h4,form~h5,form~h6,ol~h1,ol~h2,ol~h3,ol~h4,ol~h5,ol~h6,pre~h1,pre~h2,pre~h3,pre~h4,pre~h5,pre~h6,p~h1,p~h2,p~h3,p~h4,p~h5,p~h6,table~h1,table~h2,table~h3,table~h4,table~h5,table~h6,ul~h1,ul~h2,ul~h3,ul~h4,ul~h5,ul~h6{margin-top:var(--typography-spacing-vertical)}hgroup{margin-bottom:var(--typography-spacing-vertical)}hgroup>*{margin-bottom:0}hgroup>:last-child{--color:var(--muted-color);--font-weight:unset;font-family:unset;font-size:1rem}p{margin-bottom:var(--typography-spacing-vertical)}small{font-size:var(--font-size)}ol,ul{padding-left:var(--spacing)}ol li,ul li{margin-bottom:calc(var(--typography-spacing-vertical) / 4)}ul li{list-style:square}mark{padding:.125rem .25rem;background-color:var(--mark-background-color);color:var(--mark-color);vertical-align:middle}blockquote{display:block;margin:var(--typography-spacing-vertical) 0;padding:var(--spacing);border-left:0.25rem solid var(--blockquote-border-color)}blockquote footer{margin-top:calc(var(--typography-spacing-vertical) / 2);color:var(--blockquote-footer-color)}abbr[title]{border-bottom:1px dotted;text-decoration:none;cursor:help}ins{color:var(--ins-color);text-decoration:none}del{color:var(--del-color)}::selection{background-color:var(--primary-focus)}audio,canvas,iframe,img,svg,video{vertical-align:middle}audio,video{display:inline-block}audio:not([controls]){display:none;height:0}iframe{border-style:none}img{max-width:100%;height:auto;border-style:none}svg:not([fill]){fill:currentColor}svg:not(:root){overflow:hidden}button{margin:0;overflow:visible;font-family:inherit;text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{padding:0;border-style:none}button{display:block;width:100%;margin-bottom:var(--spacing)}a[role=button]{display:inline-block;text-decoration:none}a[role=button],button,input[type=button],input[type=reset],input[type=submit]{--background-color:var(--primary);--border-color:var(--primary);--color:var(--primary-inverse);--box-shadow:var(--button-box-shadow,0 0 0 rgba(0,0,0,0));padding:var(--form-element-spacing-vertical) var(--form-element-spacing-horizontal);border:var(--border-width) solid var(--border-color);border-radius:var(--border-radius);outline:none;background-color:var(--background-color);box-shadow:var(--box-shadow);color:var(--color);font-size:1rem;font-weight:var(--font-weight);line-height:var(--line-height);text-align:center;cursor:pointer;transition:background-color var(--transition),border-color var(--transition),color var(--transition),box-shadow var(--transition)}a[role=button]:active,a[role=button]:focus,a[role=button]:hover,button:active,button:focus,button:hover,input[type=button]:active,input[type=button]:focus,input[type=button]:hover,input[type=reset]:active,input[type=reset]:focus,input[type=reset]:hover,input[type=submit]:active,input[type=submit]:focus,input[type=submit]:hover{--background-color:var(--primary-hover);--border-color:var(--primary-hover);--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0))}a[role=button]:focus,button:focus,input[type=button]:focus,input[type=reset]:focus,input[type=submit]:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--primary-focus)}input[type=reset]{--background-color:var(--secondary);--border-color:var(--secondary);--color:var(--secondary-inverse);cursor:pointer}input[type=reset]:active,input[type=reset]:focus,input[type=reset]:hover{--background-color:var(--secondary-hover);--border-color:var(--secondary-hover)}input[type=reset]:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--secondary-focus)}a[role=button].secondary,button.secondary,input[type=button].secondary,input[type=reset].secondary,input[type=submit].secondary{--background-color:var(--secondary);--border-color:var(--secondary);--color:var(--secondary-inverse);cursor:pointer}a[role=button].secondary:active,a[role=button].secondary:focus,a[role=button].secondary:hover,button.secondary:active,button.secondary:focus,button.secondary:hover,input[type=button].secondary:active,input[type=button].secondary:focus,input[type=button].secondary:hover,input[type=reset].secondary:active,input[type=reset].secondary:focus,input[type=reset].secondary:hover,input[type=submit].secondary:active,input[type=submit].secondary:focus,input[type=submit].secondary:hover{--background-color:var(--secondary-hover);--border-color:var(--secondary-hover)}a[role=button].secondary:focus,button.secondary:focus,input[type=button].secondary:focus,input[type=reset].secondary:focus,input[type=submit].secondary:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--secondary-focus)}a[role=button].contrast,button.contrast,input[type=button].contrast,input[type=reset].contrast,input[type=submit].contrast{--background-color:var(--contrast);--border-color:var(--contrast);--color:var(--contrast-inverse)}a[role=button].contrast:active,a[role=button].contrast:focus,a[role=button].contrast:hover,button.contrast:active,button.contrast:focus,button.contrast:hover,input[type=button].contrast:active,input[type=button].contrast:focus,input[type=button].contrast:hover,input[type=reset].contrast:active,input[type=reset].contrast:focus,input[type=reset].contrast:hover,input[type=submit].contrast:active,input[type=submit].contrast:focus,input[type=submit].contrast:hover{--background-color:var(--contrast-hover);--border-color:var(--contrast-hover)}a[role=button].contrast:focus,button.contrast:focus,input[type=button].contrast:focus,input[type=reset].contrast:focus,input[type=submit].contrast:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--contrast-focus)}a[role=button].outline,button.outline,input[type=button].outline,input[type=reset].outline,input[type=submit].outline{--background-color:transparent;--color:var(--primary)}a[role=button].outline:active,a[role=button].outline:focus,a[role=button].outline:hover,button.outline:active,button.outline:focus,button.outline:hover,input[type=button].outline:active,input[type=button].outline:focus,input[type=button].outline:hover,input[type=reset].outline:active,input[type=reset].outline:focus,input[type=reset].outline:hover,input[type=submit].outline:active,input[type=submit].outline:focus,input[type=submit].outline:hover{--background-color:transparent;--color:var(--primary-hover)}a[role=button].outline.secondary,button.outline.secondary,input[type=button].outline.secondary,input[type=reset].outline.secondary,input[type=submit].outline.secondary{--color:var(--secondary)}a[role=button].outline.secondary:active,a[role=button].outline.secondary:focus,a[role=button].outline.secondary:hover,button.outline.secondary:active,button.outline.secondary:focus,button.outline.secondary:hover,input[type=button].outline.secondary:active,input[type=button].outline.secondary:focus,input[type=button].outline.secondary:hover,input[type=reset].outline.secondary:active,input[type=reset].outline.secondary:focus,input[type=reset].outline.secondary:hover,input[type=submit].outline.secondary:active,input[type=submit].outline.secondary:focus,input[type=submit].outline.secondary:hover{--color:var(--secondary-hover)}a[role=button].outline.contrast,button.outline.contrast,input[type=button].outline.contrast,input[type=reset].outline.contrast,input[type=submit].outline.contrast{--color:var(--contrast)}a[role=button].outline.contrast:active,a[role=button].outline.contrast:focus,a[role=button].outline.contrast:hover,button.outline.contrast:active,button.outline.contrast:focus,button.outline.contrast:hover,input[type=button].outline.contrast:active,input[type=button].outline.contrast:focus,input[type=button].outline.contrast:hover,input[type=reset].outline.contrast:active,input[type=reset].outline.contrast:focus,input[type=reset].outline.contrast:hover,input[type=submit].outline.contrast:active,input[type=submit].outline.contrast:focus,input[type=submit].outline.contrast:hover{--color:var(--contrast-hover)}a[role=button][disabled],button[disabled],input[type=button][disabled],input[type=reset][disabled],input[type=submit][disabled]{opacity:.5;pointer-events:none}input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:1rem;letter-spacing:inherit;line-height:var(--line-height)}input{overflow:visible}select{text-transform:none}legend{max-width:100%;padding:0;color:inherit;white-space:normal}textarea{overflow:auto}[type=checkbox],[type=radio]{padding:0}::-webkit-inner-spin-button,::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}::-moz-focus-inner{padding:0;border-style:none}:-moz-focusring{outline:none}:-moz-ui-invalid{box-shadow:none}::-ms-expand{display:none}[type=file],[type=range]{padding:0;border-width:0}input:not([type=checkbox]):not([type=radio]):not([type=range]){height:calc((1rem * var(--line-height)) + (var(--form-element-spacing-vertical) * 2) + (var(--border-width) * 2))}fieldset{margin:0;margin-bottom:var(--spacing);padding:0;border:0}fieldset legend,label{display:block;margin-bottom:calc(var(--spacing) / 4);vertical-align:middle}input:not([type=checkbox]):not([type=radio]),select,textarea{display:block;width:100%}input:not([type=checkbox]):not([type=radio]):not([type=range]):not([type=file]),select,textarea{-webkit-appearance:none;-moz-appearance:none;appearance:none;padding:var(--form-element-spacing-vertical) var(--form-element-spacing-horizontal);vertical-align:middle}input,select,textarea{--background-color:var(--form-element-background-color);--border-color:var(--form-element-border-color);--color:var(--form-element-color);--box-shadow:none;border:var(--border-width) solid var(--border-color);border-radius:var(--border-radius);outline:none;background-color:var(--background-color);box-shadow:var(--box-shadow);color:var(--color);font-weight:var(--font-weight);transition:background-color var(--transition),border-color var(--transition),color var(--transition),box-shadow var(--transition)}input:not([type=submit]):not([type=button]):not([type=reset]):not([type=checkbox]):not([type=radio]):not([readonly]):active,input:not([type=submit]):not([type=button]):not([type=reset]):not([type=checkbox]):not([type=radio]):not([readonly]):focus,select:active,select:focus,textarea:active,textarea:focus{--background-color:var(--form-element-active-background-color)}input:not([type=submit]):not([type=button]):not([type=reset]):not([role=switch]):not([readonly]):active,input:not([type=submit]):not([type=button]):not([type=reset]):not([role=switch]):not([readonly]):focus,select:active,select:focus,textarea:active,textarea:focus{--border-color:var(--form-element-active-border-color)}input:not([type=submit]):not([type=button]):not([type=reset]):not([type=range]):not([type=file]):not([readonly]):focus,select:focus,textarea:focus{--box-shadow:0 0 0 var(--outline-width) var(--form-element-focus-color)}input:not([type=submit]):not([type=button]):not([type=reset])[disabled],select[disabled],textarea[disabled]{--background-color:var(--form-element-disabled-background-color);--border-color:var(--form-element-disabled-border-color);opacity:var(--form-element-disabled-opacity)}input[aria-invalid],select[aria-invalid],textarea[aria-invalid]{padding-right:2rem;background-position:center right .75rem;background-repeat:no-repeat;background-size:1rem auto}input[aria-invalid=false],select[aria-invalid=false],textarea[aria-invalid=false]{--border-color:var(--form-element-valid-border-color);background-image:var(--icon-valid)}input[aria-invalid=false]:active,input[aria-invalid=false]:focus,select[aria-invalid=false]:active,select[aria-invalid=false]:focus,textarea[aria-invalid=false]:active,textarea[aria-invalid=false]:focus{--border-color:var(--form-element-valid-active-border-color)!important}input[aria-invalid=true],select[aria-invalid=true],textarea[aria-invalid=true]{--border-color:var(--form-element-invalid-border-color);background-image:var(--icon-invalid)}input[aria-invalid=true]:active,input[aria-invalid=true]:focus,select[aria-invalid=true]:active,select[aria-invalid=true]:focus,textarea[aria-invalid=true]:active,textarea[aria-invalid=true]:focus{--border-color:var(--form-element-invalid-active-border-color)!important}input::-webkit-input-placeholder,input::placeholder,select:invalid,textarea::-webkit-input-placeholder,textarea::placeholder{color:var(--form-element-placeholder-color);opacity:1}input:not([type=checkbox]):not([type=radio]),select,textarea{margin-bottom:var(--spacing)}select::-ms-expand{border:0;background-color:transparent}select:not([multiple]):not([size]){padding-right:calc(var(--form-element-spacing-horizontal) + 1.5rem);background-image:var(--icon-chevron);background-position:center right .75rem;background-repeat:no-repeat;background-size:1rem auto}input+small,select+small,textarea+small{display:block;width:100%;margin-top:calc(var(--spacing) * -0.75);margin-bottom:var(--spacing);color:var(--muted-color)}label>input,label>select,label>textarea{margin-top:calc(var(--spacing) / 4)}[type=checkbox],[type=radio]{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:inline-block;width:1.25em;height:1.25em;margin-top:-.125em;margin-right:.375em;border-width:var(--border-width);vertical-align:middle;cursor:pointer}[type=checkbox]::-ms-check,[type=radio]::-ms-check{display:none}[type=checkbox]:checked,[type=checkbox]:checked:active,[type=checkbox]:checked:focus,[type=radio]:checked,[type=radio]:checked:active,[type=radio]:checked:focus{--background-color:var(--primary);--border-color:var(--primary);background-image:var(--icon-checkbox);background-position:center;background-repeat:no-repeat;background-size:.75em auto}[type=checkbox]~label,[type=radio]~label{display:inline-block;margin-right:.375em;margin-bottom:0;cursor:pointer}[type=checkbox]:indeterminate{--background-color:var(--primary);--border-color:var(--primary);background-image:var(--icon-minus);background-position:center;background-repeat:no-repeat;background-size:.75em auto}[type=radio]{border-radius:50%}[type=radio]:checked,[type=radio]:checked:active,[type=radio]:checked:focus{--background-color:var(--primary-inverse);border-width:.35em;background-image:none}[type=checkbox][role=switch]{--background-color:var(--switch-background-color);--border-color:var(--switch-background-color);--color:var(--switch-color);width:2.25em;height:1.25em;border:var(--border-width) solid var(--border-color);border-radius:1.25em;background-color:var(--background-color);line-height:1.25em}[type=checkbox][role=switch]:focus{--background-color:var(--switch-background-color);--border-color:var(--switch-background-color)}[type=checkbox][role=switch]:checked{--background-color:var(--switch-checked-background-color);--border-color:var(--switch-checked-background-color)}[type=checkbox][role=switch]:before{display:block;width:calc(1.25em - (var(--border-width) * 2));height:100%;border-radius:50%;background-color:var(--color);content:'';transition:margin 0.1s ease-in-out}[type=checkbox][role=switch]:checked{background-image:none}[type=checkbox][role=switch]:checked:before{margin-right:0;margin-left:calc(1.125em - var(--border-width))}[type=color]::-webkit-color-swatch-wrapper{padding:0}[type=color]::-moz-focus-inner{padding:0}[type=color]::-webkit-color-swatch{border:none;border-radius:calc(var(--border-radius) / 2)}[type=color]::-moz-color-swatch{border:none;border-radius:calc(var(--border-radius) / 2)}[type=date],[type=datetime-local],[type=month],[type=time],[type=week]{background-image:var(--icon-date);background-position:center right .75rem;background-repeat:no-repeat;background-size:1rem auto}[type=date]::-webkit-calendar-picker-indicator,[type=datetime-local]::-webkit-calendar-picker-indicator,[type=month]::-webkit-calendar-picker-indicator,[type=time]::-webkit-calendar-picker-indicator,[type=week]::-webkit-calendar-picker-indicator{opacity:0}[type=time]{background-image:var(--icon-time)}[type=file]{--color:var(--muted-color);padding:calc(var(--form-element-spacing-vertical)/2) 0;border:none;border-radius:0;background:none}[type=file]::-webkit-file-upload-button{--background-color:var(--secondary);--border-color:var(--secondary);--color:var(--secondary-inverse);margin-right:calc(var(--spacing) / 2);padding:calc(var(--form-element-spacing-vertical) / 2) calc(var(--form-element-spacing-horizontal) / 2);border:var(--border-width) solid var(--border-color);border-radius:var(--border-radius);outline:none;background-color:var(--background-color);box-shadow:var(--box-shadow);color:var(--color);font-size:1rem;font-weight:var(--font-weight);line-height:var(--line-height);text-align:center;cursor:pointer;transition:background-color var(--transition),border-color var(--transition),color var(--transition),box-shadow var(--transition)}[type=file]:active,[type=file]:focus,[type=file]:hover{--color:var(--color);border:none;background:none}[type=file]:active::-webkit-file-upload-button,[type=file]:focus::-webkit-file-upload-button,[type=file]:hover::-webkit-file-upload-button{--background-color:var(--secondary-hover);--border-color:var(--secondary-hover)}[type=range]{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:block;width:100%;height:1.25rem;background:transparent}[type=range]::-webkit-slider-runnable-track{width:100%;height:0.25rem;border-radius:var(--border-radius);background-color:var(--range-border-color);transition:background-color var(--transition),box-shadow var(--transition)}[type=range]::-moz-range-track{width:100%;height:0.25rem;border-radius:var(--border-radius);background-color:var(--range-border-color);transition:background-color var(--transition),box-shadow var(--transition)}[type=range]::-ms-track{width:100%;height:0.25rem;border-radius:var(--border-radius);background-color:var(--range-border-color);transition:background-color var(--transition),box-shadow var(--transition)}[type=range]::-ms-fill-lower{background-color:var(--border-radius)}[type=range]::-webkit-slider-thumb{-webkit-appearance:none;width:1.25rem;height:1.25rem;margin-top:-0.5rem;border:2px solid var(--range-thumb-border-color);border-radius:50%;background-color:var(--range-thumb-color);cursor:pointer;transition:background-color var(--transition),transform var(--transition)}[type=range]::-moz-range-thumb{-webkit-appearance:none;width:1.25rem;height:1.25rem;margin-top:-0.5rem;border:2px solid var(--range-thumb-border-color);border-radius:50%;background-color:var(--range-thumb-color);cursor:pointer;transition:background-color var(--transition),transform var(--transition)}[type=range]::-ms-thumb{-webkit-appearance:none;width:1.25rem;height:1.25rem;margin-top:-0.5rem;border:2px solid var(--range-thumb-border-color);border-radius:50%;background-color:var(--range-thumb-color);cursor:pointer;transition:background-color var(--transition),transform var(--transition)}[type=range]:focus,[type=range]:hover{--range-border-color:var(--range-active-border-color);--range-thumb-color:var(--range-thumb-hover-color)}[type=range]:active{--range-thumb-color:var(--range-thumb-active-color)}[type=range]:active::-webkit-slider-thumb{transform:scale(1.25)}[type=range]:active::-moz-range-thumb{transform:scale(1.25)}[type=range]:active::-ms-thumb{transform:scale(1.25)}[type=search]{border-radius:5rem;padding-left:calc(var(--form-element-spacing-horizontal) + 1.75rem)!important;background-image:var(--icon-search);background-position:center left 1.125rem;background-repeat:no-repeat;background-size:1rem auto}[type=search]::-webkit-search-cancel-button{-webkit-appearance:none;display:none}table{width:100%;border-color:inherit;border-collapse:collapse;border-spacing:0;text-indent:0}td,th{padding:calc(var(--spacing) / 2) var(--spacing);border-bottom:var(--border-width) solid var(--table-border-color);color:var(--color);font-size:var(--font-size);font-weight:var(--font-weight);text-align:left}tr{background-color:var(--background-color)}table[role=grid] tbody tr:nth-child(odd){--background-color:var(--table-row-stripped-background-color)}code,kbd,pre,samp{font-family:var(--font-family);font-size:.875rem}pre{-ms-overflow-style:scrollbar;overflow:auto}code,kbd,pre{background:var(--code-background-color);color:var(--code-color);font-weight:var(--font-weight);line-height:initial}code,kbd{display:inline-block;padding:.375rem .5rem;border-radius:var(--border-radius)}pre{display:block;margin-bottom:var(--spacing);padding:var(--spacing);overflow-x:auto;background:var(--code-background-color)}pre>code{display:block;padding:0;background:transparent;font-size:14px;line-height:var(--line-height)}code b{color:var(--code-tag-color);font-weight:var(--font-weight)}code i{color:var(--code-property-color);font-style:normal}code u{color:var(--code-value-color);text-decoration:none}code em{color:var(--code-comment-color);font-style:normal}kbd{background-color:var(--code-kbd-background-color);color:var(--code-kbd-color);vertical-align:middle}hr{box-sizing:content-box;height:0;overflow:visible;border:none;border-top:1px solid var(--muted-border-color)}[hidden],template{display:none}dialog{display:block;position:absolute;right:0;left:0;width:-moz-fit-content;width:-webkit-fit-content;width:fit-content;height:-moz-fit-content;height:-webkit-fit-content;height:fit-content;margin:auto;padding:1em;border:solid;background-color:white;color:black}dialog:not([open]){display:none}canvas{display:inline-block}details{display:block;margin-bottom:var(--spacing);padding-bottom:calc(var(--spacing) / 2);border-bottom:var(--border-width) solid var(--accordion-border-color)}details summary{color:var(--accordion-close-summary-color);line-height:1rem;list-style-type:none;list-style-type:none;cursor:pointer;transition:color var(--transition)}details summary::-webkit-details-marker{display:none}details summary::marker{display:none}details summary::-moz-list-bullet{list-style-type:none}details summary:after{display:inline-block;width:1rem;height:1rem;float:right;transform:rotate(-90deg);background-image:var(--icon-chevron);background-position:center;background-repeat:no-repeat;background-size:1rem auto;content:'';transition:transform var(--transition)}details summary:focus{outline:none;color:var(--accordion-active-summary-color)}details summary~*{margin-top:calc(var(--spacing) / 2)}details summary~*~*{margin-top:0}details[open]>summary{margin-bottom:calc(var(--spacing) / 4)}details[open]>summary:not(:focus){color:var(--accordion-open-summary-color)}details[open]>summary:after{transform:rotate(0)}article{margin:var(--block-spacing-vertical) 0;padding:var(--block-spacing-vertical) var(--block-spacing-horizontal);overflow:hidden;border-radius:var(--border-radius);background:var(--card-background-color);box-shadow:var(--card-box-shadow)}article>footer,article>header,article>pre{margin-right:calc(var(--block-spacing-horizontal) * -1);margin-left:calc(var(--block-spacing-horizontal) * -1);padding:calc(var(--block-spacing-vertical) / 1.5) var(--block-spacing-horizontal);background-color:var(--card-sectionning-background-color)}article>header{margin-top:calc(var(--block-spacing-vertical) * -1);margin-bottom:var(--block-spacing-vertical);border-bottom:var(--border-width) solid var(--card-border-color)}article>footer,article>pre{margin-top:var(--block-spacing-vertical);margin-bottom:calc(var(--block-spacing-vertical) * -1);border-top:var(--border-width) solid var(--card-border-color)}nav,nav ul{display:flex}nav{justify-content:space-between}nav ol,nav ul{align-items:center;margin-bottom:0;padding:0;list-style:none}nav ol:first-of-type,nav ul:first-of-type{margin-left:calc(var(--spacing) * -0.5)}nav ol:last-of-type,nav ul:last-of-type{margin-right:calc(var(--spacing) * -0.5)}nav li{display:inline-block;margin:0;padding:var(--spacing) calc(var(--spacing) / 2)}nav li>*,nav li>input:not([type=checkbox]):not([type=radio]){margin-bottom:0}nav a{display:block;margin:calc(var(--spacing) * -1) calc(var(--spacing) * -0.5);padding:var(--spacing) calc(var(--spacing) / 2);border-radius:var(--border-radius);text-decoration:none}nav a:active,nav a:focus,nav a:hover{text-decoration:none}aside li,aside nav,aside ol,aside ul{display:block}aside li{padding:calc(var(--spacing) / 2)}aside li a{margin:calc(var(--spacing) * -0.5);padding:calc(var(--spacing) / 2)}progress{display:inline-block;vertical-align:baseline}progress{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:inline-block;width:100%;height:.5rem;margin-bottom:calc(var(--spacing) / 2);overflow:hidden;border:0;border-radius:var(--border-radius);background-color:var(--progress-background-color);color:var(--progress-color)}progress::-webkit-progress-bar{border-radius:var(--border-radius);background:transparent}progress[value]::-webkit-progress-value{background-color:var(--progress-color)}progress::-moz-progress-bar{background-color:var(--progress-color)}@media (prefers-reduced-motion:no-preference){progress:indeterminate{background:var(--progress-background-color) linear-gradient(to right,var(--progress-color) 30%,var(--progress-background-color) 30%) top left/150% 150% no-repeat;animation:progressIndeterminate 1s linear infinite}progress:indeterminate[value]::-webkit-progress-value{background-color:transparent}progress:indeterminate::-moz-progress-bar{background-color:transparent}}@keyframes progressIndeterminate{0%{background-position:200% 0}to{background-position:-200% 0}}[aria-busy=true]{cursor:progress}[aria-busy=true]:not(input):not(select):not(textarea):before{display:inline-block;width:1em;height:1em;border:0.1875em solid currentColor;border-radius:1em;border-right-color:transparent;vertical-align:text-bottom;vertical-align:-.125em;animation:spinner 0.75s linear infinite;content:'';opacity:var(--loading-spinner-opacity)}[aria-busy=true]:not(input):not(select):not(textarea):not(:empty):before{margin-right:calc(var(--spacing) / 2)}[aria-busy=true]:not(input):not(select):not(textarea):empty{text-align:center}a[aria-busy=true],button[aria-busy=true],input[type=button][aria-busy=true],input[type=reset][aria-busy=true],input[type=submit][aria-busy=true]{pointer-events:none}@keyframes spinner{to{transform:rotate(360deg)}}[data-tooltip]{position:relative}[data-tooltip]:not(a):not(button):not(input){border-bottom:1px dotted;text-decoration:none;cursor:help}[data-tooltip]:after,[data-tooltip]:before{display:block;z-index:99;position:absolute;bottom:100%;left:50%;padding:.25rem .5rem;overflow:hidden;transform:translate(-50%,-0.25rem);border-radius:var(--border-radius);background:var(--tooltip-background-color);color:var(--tooltip-color);font-size:.875rem;font-style:normal;font-weight:var(--font-weight);text-decoration:none;text-overflow:ellipsis;white-space:nowrap;content:attr(data-tooltip);opacity:0;pointer-events:none}[data-tooltip]:after{padding:0;transform:translate(-50%,0rem);border-top:.3rem solid;border-right:.3rem solid transparent;border-left:.3rem solid transparent;border-radius:0;background-color:transparent;color:var(--tooltip-background-color);content:''}[data-tooltip]:focus:after,[data-tooltip]:focus:before,[data-tooltip]:hover:after,[data-tooltip]:hover:before{opacity:1;animation-name:slide;animation-duration:.2s}[data-tooltip]:focus:after,[data-tooltip]:hover:after{animation-name:slideCaret}@keyframes slide{0%{transform:translate(-50%,0.75rem);opacity:0}to{transform:translate(-50%,-0.25rem);opacity:1}}@keyframes slideCaret{0%{opacity:0}50%{transform:translate(-50%,-0.25rem);opacity:0}to{transform:translate(-50%,0rem);opacity:1}}[aria-controls]{cursor:pointer}[aria-disabled=true],[disabled]{cursor:not-allowed}[aria-hidden=false][hidden]{display:initial}[aria-hidden=false][hidden]:not(:focus){clip:rect(0,0,0,0);position:absolute}[tabindex],a,area,button,input,label,select,summary,textarea{-ms-touch-action:manipulation}@media (prefers-reduced-motion:reduce){:not([aria-busy=true]),:not([aria-busy=true]):after,:not([aria-busy=true]):before{background-attachment:initial!important;animation-duration:1ms!important;animation-delay:-1ms!important;animation-iteration-count:1!important;scroll-behavior:auto!important;transition-delay:0s!important;transition-duration:0s!important}}
    </style>
    <style type="text/css">
      article div {
        font-size: 1.15em;
        line-height: 1.6em;
      }
    </style>
  </head>
  <body style="background-color: #f9fafb;">
    <main class="container">
      <nav>
        <ul>
          <li><a href="../index.html">← Topic list</a></li>
        </ul>
      </nav>
      <!-- <h1>Infomedia Articles Selection: 50 articles</h1> -->
      <h1>H_0_73 <kbd>H_0_73</kbd></h1>
      <h3>Words (top 25)</h3>
      <div style="margin:0px -12px">
        <span style="font-size:11.32pt; padding:0px 12px"><strong>model</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>features</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>modellen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>parametrene</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>performance</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>metoder</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>udviklere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kompleksiteten</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>open</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>genkende</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>træne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>edge</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>softwaresystemer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>maskinlæring</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>latency</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>teknikker</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>network</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>regnekraften</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sandsynligheder</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>beslutningstræ</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>rafal</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ai-systemer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>scientist</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>feature</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>datasættet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sætningen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fejlrate</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>case</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>input</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>networks</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>trænet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>slutbrugeren</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>billedanalyse</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ghosh</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>cpu</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>protein</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>computerkraft</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>differentialligninger</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ml</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>iteration</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>udfra</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>learning-modellen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>datasæt</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>neuralt</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>neurale</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>bias</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>oplæring</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>skalerer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>variabel</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>inputs</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>læsbar</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>reproduceres</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>detektion</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>object</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>memory</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>processeres</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sebastian</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>hukommelsen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>detekterer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>visionsystemer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>udlede</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>metoderne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>genkendelse</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>output</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>validering</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>cleve</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>trænes</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>embedded</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>visualisere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>slutbrugerne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>lego-klodser</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>maskinlæringsalgoritmer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ai-software</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>klassificering</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fintune</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>estimere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>practice</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>funktionelle</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>statiske</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>oplære</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>datalogiprofessor</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>benchmarks</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>generalisere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>netværkene</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>goals</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>annotere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>moores</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sekvensen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>grammatisk</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>opstilling</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>tensor</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>tilgængeligheden</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>stikprøver</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ieee</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ai-teknologien</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>programmøren</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>generator</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>angry</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>billeddata</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>optimeringer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>numerisk</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>cornell</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>explainable</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>marin</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kompilere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kolonner</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>iterationer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>convolutional</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>vector</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>skævhed</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>outputtet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>goodwin</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>license</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>teknikkerne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>tunet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>cay</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>binær</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>modellere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>gruppere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>billedgenkendelse</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>bi</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>bachelorer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>udtrække</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>lommeregneren</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>niko</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ræsonnement</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>modellernes</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>rescue</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>træningssæt</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>vektor</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>processere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>supervised</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>inputtet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ng</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>gpu-er</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>tagge</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>additive</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>klassificere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>udviklernes</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kai</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>singh</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>spark</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ai-applikationer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>medtage</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>label</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>synonymer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>molekyle</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>implementeringer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>klodser</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>erhvervs-ph.d</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>succesraten</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>indkomne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kodebase</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fejlslutninger</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ansigtsmimik</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>informationssystemer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>statistiker</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>brandes</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>lex</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>elements</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>jean-philippe</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>datakvaliteten</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>lstm</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ai-modellen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fpga</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>goldberg</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>mainframe</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>grafikprocessor</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sensitiv</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ai-systemerne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>array</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fejlagtig</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>write</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>klassificeres</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>geer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>osten</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>konfigurere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>gans</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>delmængde</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>morfologi</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>proof-of-concept</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>scalable</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>easyjet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>visualiseres</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>tidsserier</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>overrepræsentation</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>hao</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>aasa</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fuzzy</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>crow</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>switch</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>securitas</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>mierswa</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>hrushikesh</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>gioia</strong>&nbsp;<span style="font-size:.5em">1</span></span>
      </div>
      <br><br>
      <h3>Articles (top 50)</h3>
      Query:
      <pre>SELECT * FROM articles WHERE articles.dupeKeep=1 AND articles.sizeKeep=1 ORDER BY H_0_73 DESC LIMIT 50</pre>
      <article>
        <h4>OpenAI lancerer Safety Gym til reinforcement learning</h4>
        <div>
          Safety Gym er en ny række væktøjer fra OpenAI, der skal hjælpe udviklere med bygge AI-systemer, der respekterer sikkerhedsbegrænsninger, når de trænes. Det skriver Venture Beat Safety Gym er spicifikt designet til brug for reinforcemnet learning for at styre, at agenten ikke foretager desideret farlige handlinger i førsøg på at optimere belønningen. Redaktionen
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2019-11-25
          &nbsp;·&nbsp; e775d044
          &nbsp;·&nbsp; #0
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.936</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.919</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.647</kbd>
        </footer>
      </article>
      <article>
        <h4>Google gør AI-modelsøger til open source</h4>
        <div>
          Tensorflow-værktøj sammensætter på egen hånd deep learning-modeller. Et hold fra Google Research har udsendt værktøjet Model Search som open source. Det er en automatiseret machine learning-platform beregnet på at udvikle deep learning-modeller, skriver InfoqEksperimentelle resultater viser, at systemet kan producere modeller, der overgår de bedste designs fra menneskelig hånd, med færre trænings-iterationer og modelparametre.Forskerne Hanna Mazzawi og Xavi Gonzalvo har beskrevet systemet i et blogindlæg . Model Search er implementeret med Googles Tensorflow-teknologi og sammensætter et dybt neuralt netværk, som er neurale netværk med mange skjulte lag, ud fra komponenter, der eksempelvis kan være transformere eller LSTM-lag (Long Short-Term Memory).Systemet træner og evaluerer et sæt kandidatmodeller, der hver består af flere blokke. En søgealgoritme vælger derefter den mest effektive model og 'muterer' den. Denne proces gentages iterativt, indtil den bedste model er fundet.Google-teamet har angiveligt brugt Model Search til at oprette deep learning-systemer til talebehandling, der med kun 60 procent af parametrene overgår dagens bedst ydende modeller.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2021-03-11
          &nbsp;·&nbsp; e829b984
          &nbsp;·&nbsp; #1
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.978</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.891</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.558</kbd>
        </footer>
      </article>
      <article>
        <h4>Hybrid mellem neuralt net og beslutningstræ giver forklarlig deep learning</h4>
        <div>
          Neurale net arrangeret som beslutningstræ giver både forklarlighed og præcision, mener AI-forskere. Beslutningstræer er den gyldne standard, hvis en model skal være både forklarlig og intuitiv. Men på komplekse opgaver som at klassificere billeder fejler træerne med en præcision, der er væsentligt ringere end et neuralt netværk. Men med et nyt koncept, udviklet af forskere fra Berkleys center for AI-forskning, kan man få det bedste af begge verdener. Neural-Backed Decision Trees (NBDT) tager den overordnede, intuitive gennesigtighed fra beslutningstræer, men bruger neurale netværk til at tage beslutninger. Resultatet er ifølge Berkeley-forskerne en model, der kan matche almindelige neurale netværk i præcision, men hvor en almindelig bruger kan aflæse, hvordan modellen kom frem til sin beslutning. NBDT-modellen består af et beslutningstræ, hvor hver node er et neuralt netværk. På billede-datasæts CIFAR10, CIFAR100, og TinyImageNet200 slår den kombination andre forklarlige, træbaserede metoder med en betydelig margin. Og forbliver indenfor omkring 1 procent i nærheden af performance af neurale netværk. Forklaringen giver særligt menig, når modellen skal klassificere billeder med indhold, den ikk har set før. CIFAR10-modellen har f.eks. aldrig set et Zebra, men gennem NBDT-modellen kan vi se, at modellen korrekt identificere at der er tale om et hovdyr, før den gætter på hest. Bedre performance betyder mere forstålig Ideen er simpel, men det er ikke helt simpelt, at omdanne et neuralt netværk til et beslutningstræ. Processen kræver blandt andet, hvad forskerne kalder induced hierarchy, der afgør, hvilke sæt af klasser - f.eks. hund eller kat - noderne modellen skal tage stilling til. Hierarkiet bliver bygget ud fra vægtene i et prætrænet neuralt netværk, og med en clustering-teknik finder man frem til hvilke klassifikationer bør have en fælles 'forældre'-node. De noder kan efterfølgende testes kvantitativt. Hvis man f.eks. antager, at en node afgør om billedet forestiller dyr eller fartøj, kan man teste det ved at løbe en masse billeder af dyr og fartøjer gennem modellen. Og på den måde kan man give hver node - som effektivt er en underdel af et lag i det samlede neurale netværk - en semantisk betydning. I forskernes præpublicerede artikel bemærker de en positiv sammenhæng mellem det neurale netværks præcision og hvor semantisk fornuftig hierakiet i stidste ende virker. »We believe that higher-accuracy models exhibit more semantically-sound weight spaces. Thus, unlike previous work, NBDTs feature better interpretability with higher accuracy, instead of sacrificing one for the other.«  Fugl eller fly Eksisterende metoder til at forklare belsutningerne fra et neuralt netværk, har sin mangler, påpeger Alvin Wan, der er en af forskerne bag projektet og pt. skriver sin ph.d. i AI ved Berkeley, i en blog Saliency maps, som kan bruges til at forstå klassifikationer af billeder, kan f.eks. ikke bruges, når et netværk kommer frem til forkerte beslutninger, men fokuserer på det rigtige - som f.eks. når en fugl klassificeres som et fly. Endnu er NBDT-modellen kun brugt på de klassiske billede-klassifikationsdatabaser. Det er derfor uvist, hvor meget klarhed NBDT-modellen kan bringe til situationer, hvor den logiske vej til en beslutning ikke er så simpel som at skelne dyr fra køretøjer - f.eks. når et neuralt netværk skal spotte brystkræft. Ikke desto mindre er der givet situationer, hvor kombinationer af et effektivt neuralt netværk og et visuelt, intuitivt beslutningstræ er attraktivt. Man kan afprøve prætrænede NBDT-modeller her , hvor man også kan hente koden.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2020-05-28
          &nbsp;·&nbsp; e7b9f4fe
          &nbsp;·&nbsp; #2
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.969</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.973</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.665</kbd>
        </footer>
      </article>
      <article>
        <h4>Ph.d.-forsvar: På jagt i kræft-data</h4>
        <div>
           Tobias Madsen holder ph.d.-forsvar torsdag 30. november om &quot;Robuste statistiske metoder til signifikans evaluering med anvendelser indenfor detektion af cancer-drivende mutationer og biomarkører&quot;.Det sker kl. 12 i bygning 1110, lokale 223, BiRC, Aarhus Universitet, C.F. Møllers Alle 8, Aarhus C. Der er offentlig adgang.I forbindelse med sin forskning har Tobias Madsen udviklet nye statistiske metoder til at analysere store genomiske datasæt. Han og hans forskningskollegaer har taget del i et stort internationalt cancerkonsortium med adgang til mere end 2500 cancergenomer. Adgangen til denne hidtil største database af sin art giver mulighed for nye fund indenfor kræftforskningen. På den anden side giver de store datasæt også store udfordringer: For det første kan de metoder, man bruger til mindre datasæt, være for grove til at anvende på større datasæt. For det andet er det vanskeligt at udvikle algoritmer, der skalerer til disse data sådan, at analyserne kan blive gennemført på overskuelig tid. Den proteinkodende del af genomet er velstuderet, og metoderne, som Tobias Madsen har udviklet, er blevet brugt til at finde elementer udenfor det proteinkodende genom impliceret i udviklingen af cancer.
        </div>
        <footer>
          <em>Stiften.dk (Århus Stiftstidende)</em>
          &nbsp;·&nbsp; 2017-11-29
          &nbsp;·&nbsp; e685ff91
          &nbsp;·&nbsp; #3
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.928</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.625</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.606</kbd>
        </footer>
      </article>
      <article>
        <h4>Lego-sortering med kunstig intelligens</h4>
        <div>
          Australier har bygget en sorteringsmaskine til Lego-klodser. Ved hjælp af neurale netværk og open source-databaser kan den trænes til at genkende alle eksisterende Lego-klodser.De fleste kender problemet fra børneværelset: Jo mere Lego, der kommer ind i huset, desto mere uoverskueligt bliver det at finde de rigtige klodser. Da jeg var barn, lå al mit Lego i kasser, og jeg husker den evindelige kamp med at finde de rette klodser - især de små havde det med at gemme sig nede på bunden af kassen.Derfor virker det oplagt med en sorteringsmaskine. Sådan en har australieren Daniel West bygget - af Lego, eller nærmere bestemt cirka 10.000 klodser.Umiddelbart tænker man, at der er brug for et avanceret vision-system for at kunne genkende de mange forskellige klodser. Men problemet er, at der eksisterer omkring 10.000 forskellige klodser, og det ville være umuligt at få traditionel billedegenkendelses-software til at genkende klodser, som passerer forbi i dårlig belysning. Derfor har Daniel West taget et neuralt netværk i brug.Men inden da skal der bygges et automationssystem, der kan håndtere en spandfuld Lego-klodser. Til det har han opdelt maskinen i tre dele: en føder, som klodserne kan hældes ned i, og et bæltesystem, som fører dem videre til et vibrationssystem. Her bruger han Legos hurtigste motor til at vibrere klodserne, så de ikke ligger oven på hinanden, men bliver ført videre én ad gangen.Næste skridt er selve scanneren. Der har tidligere været byggeprojekter til at sortere Lego-klodser, men Daniel West mener, at hans er det første, som kan håndtere alle klodser, der nogensinde er blevet produceret af Lego. For at det kan lade sig gøre, bruger han AI og en database med CAD-modeller af klodserne. Det er ikke noget, som Lego selv har offentliggjort, men brugere har over en årrække opbygget databaser som LDraw.org og Rebrickable.AI kan trænes på databasenI systemet bliver klodsen scannet, en Raspberry Pi-computer registrerer scanningen og sender billedet videre til en pc, som kører en variant af neurale netværk kaldet convolutional neural network. Softwaren sammenligner hver enkelt Lego-klods med databasen og får derefter et nummer ud.Daniel West siger, at han kan sortere 3.000 forskellige klodser, men potentielt kan maskinen klare alle klodser, også dem, den ikke har set endnu. Den kan nemlig trænes blot ved at bruge databaserne med klodser.Det nummer, som hver enkel klods får tildelt, sendes tilbage til sorteringsmaskinen, som så kan fordele klodserne i 18 forskellige bokse. Antallet af bokse kan udvides uendeligt, det kræver bare en større maskine. Maskinen er i stand til at håndtere en klods på to sekunder.Det tog seks måneder at bygge sorteringsmaskinen, og den består af seks Lego-motorer, en række servoer, en Raspberry Pi, lyssætning, et kamera og en pc til at køre AI-softwaren - og så altså cirka 10.000 Lego-klodser.
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2019-12-15
          &nbsp;·&nbsp; e77f3dc8
          &nbsp;·&nbsp; #4
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.964</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.991</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.719</kbd>
        </footer>
      </article>
      <article>
        <h4>Android får bedre machine learning-muligheder</h4>
        <div>
            ML Kit er ikke længere syet sammen med Firebase. Android-udviklingsholdet tilføjer nye funktioner til sit machine learning-bibliotek 'ML Kit,' der i bruges i over 25.000 iOS- og Android-apps. Det skriver mediet SD Times ML Kit er virksomhedens løsning til at integrere maskinlæring i mobile applikationer. Det blev lanceret i 2018. Det opdaterede bibliotek er ikke længere afhængig af Googles Firebase-miljø, som den originale version af ML Kit gjorde. Feedback fra brugerne pegede på, at der var et ønske om større fleksibilitet. Udviklere har dog stadig muligheden for at bruge ML Kit sammen med Firebase. Fordelene ved at benytte machine learning på selve enheden i forhold til at bruge en servertjeneste er hastighed, muligheden for at arbejde offline og mere privatliv, skriver SD Times.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2020-06-26
          &nbsp;·&nbsp; e7c4f360
          &nbsp;·&nbsp; #5
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.713</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.814</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.591</kbd>
        </footer>
      </article>
      <article>
        <h4>Lego-sortering med TensorFlow og syntetisk træningsdata</h4>
        <div>
          Australier har bygget en sorteringsmaskine til Lego-klodser. Ved hjælp af neurale netværk og open source-databaser kan den trænes til at genkende alle eksisterende Lego-klodser. ING.DK : De fleste kender problemet fra børneværelset: Jo mere Lego, der kommer ind i huset, desto mere uoverskueligt bliver det at finde de rigtige klodser. Da jeg var barn, lå al mit Lego i kasser, og jeg husker den evindelige kamp med at finde de rette klodser - især de små havde det med at gemme sig nede på bunden af kassen. Derfor virker det oplagt med en sorteringsmaskine. Sådan en har australieren Daniel West bygget - af Lego, eller nærmere bestemt cirka 10.000 klodser. Det skriver Gizmodo Umiddelbart tænker man, at der er brug for et avanceret vision-system for at kunne genkende de mange forskellige klodser. Men problemet er, at der eksisterer omkring 10.000 forskellige klodser, og det ville være umuligt at få traditionel billedegenkendelses-software til at genkende klodser, som passerer forbi i dårlig belysning. Derfor har Daniel West taget et neuralt netværk i brug. Men inden da skal der bygges et automationssystem, der kan håndtere en spandfuld Lego-klodser. Til det har han opdelt maskinen i tre dele: en føder, som klodserne kan hældes ned i, og et bæltesystem, som fører dem videre til et vibrationssystem. Her bruger han Legos hurtigste motor til at vibrere klodserne, så de ikke ligger oven på hinanden, men bliver ført videre én ad gangen. Næste skridt er selve scanneren. Der har tidligere været byggeprojekter til at sortere Lego-klodser, men Daniel West mener, at hans er det første, som kan håndtere alle klodser, der nogensinde er blevet produceret af Lego. Syntetisk træningsdata I systemet bliver klodsen scannet, en Raspberry Pi-computer registrerer scanningen og sender billedet videre til en pc, som kører et convolutional neural network bygget i TensorFlow. Softwaren sammenligner hver enkelt Lego-klods med databasen og får derefter et nummer ud. For at det kan lade sig gøre, bruger han AI og en database med CAD-modeller af klodserne. Det er ikke noget, som Lego selv har offentliggjort, men brugere har over en årrække opbygget databaser som LDraw.org og Rebrickable Udfra CAD-modellerne, der er 3D-repræsentationer af hver enkelt klods, kunne Daniel West skabe syntetisk træningsdata til sit netværk. Med den data har Daniel West brugt en teknik kaldet Domain Randomization , som indbygger tilfældigheder i genereringen af den kunstige træningsdata, som skaber variation i træningsdata og gør modellen mere robust. Endelig er modellen fintunet med et mindre sample af manuelt annoterede billeder. Daniel West siger, at han kan sortere 3.000 forskellige klodser, men potentielt kan maskinen klare alle klodser, også dem, den ikke har set endnu. Den kan nemlig trænes blot ved at bruge databaserne med klodser. Det nummer, som hver enkel klods får tildelt, sendes tilbage til sorteringsmaskinen, som så kan fordele klodserne i 18 forskellige bokse. Antallet af bokse kan udvides uendeligt, det kræver bare en større maskine. Maskinen er i stand til at håndtere en klods på to sekunder. Det tog seks måneder at bygge sorteringsmaskinen, og den består af seks Lego-motorer, en række servoer, en Raspberry Pi, lyssætning, et kamera og en pc til at køre AI-softwaren - og så altså cirka 10.000 Lego-klodser.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2019-12-18
          &nbsp;·&nbsp; e780e55d
          &nbsp;·&nbsp; #6
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.969</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.992</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.709</kbd>
        </footer>
      </article>
      <article>
        <h4>Microsoft går ekstra dybt med neuralt netværk med 152 lag</h4>
        <div>
          Microsofts neurale netværk indeholder 20 gange flere lag end almindelige dybe neurale netværk og har netop vundet en konkurrence for computersyn.Den bedste algoritme til at genkende en banjo eller en blåskimmelost på et vilkårligt foto er lige nu Microsofts 'deep residual network', som har vundet konkurrencen for computerdrevet billedgenkendelse, ImageNet. Men faktisk er der tale om et uhørt komplekst neuralt netværk, skriver Wired .Microsoft benytter maskinlæringsmetoden deep learning, hvor flere lag af algoritmer bruges til eksempelvis at genkende bestemte objekter på billeder. Normalt anvender denne type neurale netværk seks eller syv lag - i visse tilfælde op til 30 lag - men Microsofts netværk benytter hele 152 lag.Normalt vil det ikke være en fordel at anvende så mange lag, fordi signalet så at sige bliver mudret til undervejs gennem lagene. Microsoft har løst dette problem ved at implementere metoder til at springe visse lag over, som ikke er nødvendige for den aktuelle kørsel.»Når du springer over lag på denne måde, så bevarer du signalstyrken meget længere, og det viser sig at have en enorm positiv indvirkning på præcisionen,« siger forskningschef Peter Lee fra Microsoft Research til Wired.En anden udfordring ved så stort et antal lag er arbejdet ved at udvælge de specifikke algoritmer i hvert lag. Her har Microsoft brugt en teknik, som er blevet mere almindelig for dybe neurale netværk, nemlig at give netværket et bedste bud på et sæt algoritmer og derefter lade det afprøve forskellige varianter for at finde frem til en konfiguration, der giver de bedste resultater.Teknikkerne har været kendt længe inden for feltet, men de er gjort mulige i praksis takket være muligheden for at afvikle algoritmerne på grafikprocessorer, som gør det muligt at oplære det neurale netværk på enorme datasæt.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2016-01-14
          &nbsp;·&nbsp; e574ba97
          &nbsp;·&nbsp; #7
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.938</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.876</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.692</kbd>
        </footer>
      </article>
      <article>
        <h4>IBM har udviklet AI-malware, der venter med at angribe til det rette øjeblik</h4>
        <div>
          IBM har udviklet proof-of-concept malware baseret på et 'convolutional neural network', som kan forblive i ro indtil helt specifikke betingelser er opfyldtKonceptet hedder DeepLocker og bliver i dag præsenteret på sikkerhedskonferencen Black Hat USA, som bliver afholdt i Las Vegas.Det skriver The Register.Ved at bruge et krypteret payload og samtidig lade et neuralt netværk afgøre, hvornår det skal aktiveres, kan konceptet gøre det væsentligt sværere for sikkerhedsforskere og anti-virus-værktøjer at stoppe malwaren, skriver The Register.IBM har demonstreret konceptet ved at kryptere og gemme en kopi af Wannacry-ransomwaren i en videokommunikations-app sammen med kode, der bruger et neuralt netværk til at afgøre, hvornår en krypteringsnøgle skal frigives.Det neurale netværk, var blevet trænet til at vente indtil et bestemt ansigt blev opfanget på video-appen. Da den rette person satte sig foran PC'en genkendte koden ansigtet, nøglen blev frigivet, payload kørt og systemets dokumenter taget til gidsel.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2018-08-09
          &nbsp;·&nbsp; e6da5664
          &nbsp;·&nbsp; #8
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.815</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.639</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.65</kbd>
        </footer>
      </article>
      <article>
        <h4>Danske forskere bruger deep learning til at finde stemmer i en høstak af støj</h4>
        <div>
          Brødtekst Den menneskelige evne til at lytte efter en enkelt stemme, når du har en samtale i et rum fuld af konkurrerende samtaler, er enorm svær at efterligne med en algoritme.I arbejdet med avanceret lydanalyse er det såkaldte cocktailparty-problem stadig uløst. Nu har danske forskere taget skridtet nærmere en løsning med deep learning.»Udfordringen er, hvordan man fjerner uønskede støjkilder, når du optager i et støjfuldt rum med en enkelt mikrofon,« forklarer Morten Kolbæk, der netop har skrevet sin ph.d. om emnet ved Aalborg Universitet.Når man kender et lydbillede på forhånd, som i et klinisk test-setup, kan algoritmer identificere en enkelt taler lige så godt som et menneske. Men hvis teknikken skal anvendes i fx. høreapparater, er det ikke nok. Modellen må kunne identificere en ukendt taler blandt en ukendt mængde af talere i en situation med en ukendt mængde baggrundsstøj.»Uden forudgående kendskab er den menneskelige hjerne stadig den bedste maskine,« siger Morten Kolbæk.Label permutationUdfordringen ved at få en algoritme til at separere lyden fra to talere - der ikke er kendt på forhånd - er, hvad litteraturen kalder 'label permutation'-problemet.Basalt set går problemet ud på, at man gerne vil have et output fra modellen med en kanal for hver taler. Men du ved ikke på forhånd, hvilken stemme, der kommer ud af hvilken kanal.Det er en udfordring, når man træner modellen, forklarer Morten Kolbæk, fordi du med supervised learning skal sammenligne modellens output med det rigtige resultat - her i form af lyden fra de to separate talere.Med andre ord: Hvis taler A bliver separeret ud af modellen som output B, men træningsmodellen forventede, at taleren kom i output A, vil det fremstå som et forkert resultat.»På den måde kan man ikke træne modellen, fordi du ikke kan guide det neurale netværk,« siger Morten Kolbæk.Problemet løste de danske forskere ved at ændre lidt i træningsalgoritmen, og essentielt gøre rækkefølgen af talere ligegyldig under træning.»Ved at gøre det, så løser vi label permutation-problemet. Det betyder, at man relativt simpelt kan træne et neuralt netværk til at separere talere fra hinanden. Det er noget, som man ikke kunne gøre før,« siger forskeren.Algoritmen er demonstreret i følgende video:
        </div>
        <footer>
          <em>Pro.ing.dk/industrytech</em>
          &nbsp;·&nbsp; 2019-01-10
          &nbsp;·&nbsp; e709c0a4
          &nbsp;·&nbsp; #9
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.991</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.803</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.665</kbd>
        </footer>
      </article>
      <article>
        <h4>Microsoft finder software-fejl med kunstig intelligens</h4>
        <div>
            Model kan genkende sikkerhedsfejl i 99 procent af tilfældende. Microsoft har indsamlet 13 millioner arbejdsopgaver og fejl siden 2001 og har brugt disse data til at oprette en maskinlæringsmodel til at få has på softwarebugs.Ifølge virksomheden kan modellen udpege fejl, som har at gøre med sikkerhed i 99 procent af tilfældene. Tillige identificeres de vigtigste fejl 97 procent af tiden. Det skriver SD Times »Hos Microsoft skaber 47.000 udviklere næsten 30.000 fejl om måneden. De gemmes på over 100 AzureDevOps- og Github-lagre. For bedre at opmærke og prioritere programfejl i den skala kunne vi ikke bare anvende flere mennesker til problemet. Store mængder af semi-kuraterede data er perfekte til maskinlæring,«  skriver Microsoft i et blogindlæg
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2020-04-21
          &nbsp;·&nbsp; e7ac5530
          &nbsp;·&nbsp; #10
          <br>
          <br>
            <kbd data-tooltip="Tech industry &amp; regulation">L02_BIGTEC&nbsp;0.538</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.612</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.563</kbd>
        </footer>
      </article>
      <article>
        <h4>Facebooks glemsomme AI skal gøre Transformers mere effektive</h4>
        <div>
          Facebooks nye deep learning-metode giver alle input en udløbsdato alt efter, hvor relevant informationen er. BrødtekstFacebook har udviklet en ny deep learning-metode, der lader modeller huske den vigtigste information - og glemme resten.Expire Span - som løsningen hedder - fungere grundlæggende ved at give al indkommende data en udløbsdato baseret på en prædiktion af, hvor relevant den bliver for at løse en given opgave. Når tindtræffer bliver data'en smidt ud som den sure mælk i køleskabet.Målet er at gøre den notorisk beregningstunge Transformer-model bedre til at udnytte regnekraften på den mest relevante måde.Evnen til at glemmeDet kritiske ved den menneskelige hukommelse er ikke bare evnen til at huske, skriver AI-forskerne fra Facebook Research i en artikel, der er optaget på dette års ICML. Tricket er samtidig at glemme støjen for at kunne bruge båndbredde på de væsentlig detaljer.Det er en evne, som machine learning-modeller mangler generelt.Transformer-arkitekturen store styrke ligger i Attention-mekanismen, der lader modellen fokusere på en mindre del af inputtet ved at give systemet adgang til de såkaldte hidden states. Men når inputtet vokser sig rigtig stort - som f.eks. en hel bog - eksplodere den nødvendige mængde computerkraft på grund af antallet af hidden states modellen holder styr på.Ved at lade en Transformer-model glemme input, der ikke længere er relevante, kan man skalere modellen op til at kunne håndtere meget lange input som f.eks. video, pointerer Facebook-forskerne i en blog.Hvis man f.eks. beder en standard Transformers model om at finde en gul dør i en video af en korridor med mange døre, vil den gemme informationen i hver frame. Hvis hver frame bliver vurderet og forkastet, hvis de ikke er relevante for opgaven med at finde den gule dør, kan modellen processorer en langt længere video inden hukommelsen bliver fyldt op.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2021-05-20
          &nbsp;·&nbsp; e84620cf
          &nbsp;·&nbsp; #11
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.891</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.857</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.684</kbd>
        </footer>
      </article>
      <article>
        <h4>Forskere advarer: AI-forklaringsteknikker som Shap og Lime kan snydes</h4>
        <div>
          Et hold amerikanske forskere har demonstreret, at udbredte metoder til at åbne black box-modeller rent faktisk kan snydes, så indbygget bias kan skjules. I arbejdet med at gøre black box-machine learning til at forstå bliver frameworks som Shap og Lime brugt mere og mere. Men teknikkerne er faktisk ikke pålidelige, når det handler om at afsløre ellers skjult bias i ML-modellerne. Det mener et hold amerikanske forskere fra Harvard University og University of California. I en forskningsartikel , som blev offentliggjort i november, demonstrerer forskerne, at det er muligt at opbygge en klassifikationsmodel til at have en bias mod f.eks. race, men hvor forklaringer fra Lime og Shap ser uskyldige ud: »In particular, our results show that the explanations of these classifiers generated using off-the-shelf implementations of Lime and Shap do not flag any of the relevant sensitive attributes (e.g., race) as important features of the classifier, thus demonstrating that the adversarial classifiers successfully fooled these explanation methods.«  Forklaringsteknikker er ikke undersøgt Shap og Lime er begge teknikker til at forklare et specifikt resultat fra en model, som ellers ikke er umiddelbart aflæselig, som f.eks. en random forest. Modellen estimerer det bidrag, som den enkelte variabel giver til det endelige resultat. Det sker med en teknik, der kaldes 'input perturbations', hvilket grundlæggende går ud på at lave syntetisk data, som varierer inputtet for at se, hvad det betyder for resultatet, og på den måde afgør, hvilken del af inputtet er vigtigt for resultatet. Teknikkerne er blevet udbredt i takt med, at black box-modeller tages i brug til beslutningsstøtte. Med Shap kan en radiolog således få at vide, præcis hvilke dele af et billede der har fået deep learning-modellen til at mene, at patienten har en tumor. Eller en rekrutteringsalgoritme kan vise, hvilke dele af ansøgerens CV der gør kandidaten interessant. Og i forlængelse deraf kan teknikken således også vise, om modellen fokuserer på noget, der ikke hensigtsmæssigt. »However, there has been little analysis of the reliability and robustness of these explanation techniques, especially in the adversarial setting, making their utility for critical applications unclear,«  skriver forskerne. Med andre ord er spørgsmålet, hvor meget teknikkerne er værd, hvis skaberne af modellen prøver at snyde. Og her er svaret ifølge de amerikanske forskere altså ikke opløftende. Klassifikation med stillads Forskerne forestiller sig at have et incitament til at bruge en model, der har en indbygget bias, men omvendt er underlagt regulatoriske krav om at lade modellen blive analyseret med teknikker som Shap og Lime. I artiklen præsenterer forskerne et framework, der som input har den diskriminerende klassifikationsmodel samt et sample af den data, som modellen skal bruges på. Med det input bygger frameworket, hvad forskerne kalder et stillads (scaffold) rundt om en klassifikationsmodel. Modellen med stilladset udnytter det faktum, at Lime og Shap bruger syntetisk data for at teste variablernes betydning. Distributionen i den syntetiske data er nemlig tilpas anderledes end den ægte data, til at den ondsindede model kan skelne mellem, hvornår den bliver brugt, og hvornår den bliver testet. »By being able to differentiate between data points coming from the input distribution and instances generated via perturbation, an adversary can create an adversarial classifier (scaffolding) that behaves like the original classifier (perhaps be extremely discriminatory) on the input data points, but behaves arbitrarily differently (looks unbiased and fair) on the perturbed instances, thus effectively fooling Lime or Shap into generating innocuous explanations,«  skriver forskerne. Lime godkender kreditvurdering ud fra køn alene Artiklen giver to eksempler, hvor godt det virker i praksis. Forskerne bygger tre modeller: to, der på forskellige datasæt skal forudsige, om kriminelle vil begå ny kriminalitet alene baseret på race, og én model, der godkender lån alene baseret på køn. I alle tre tilfælde kunne modellen snyde Lime til at lave forklaringer, der ikke afslører modellernes bias. I Shap er forklaringen mere blandet. En af modellerne formåede at snyde Shap i 100 procent af tilældene, mens Shap afslører de andre to modellers bias i omkring 15 procent af tilfældene. »Our findings suggest that existing post hoc explanation techniques are not sufficiently robust for ascertaining discriminatory behavior of classifiers in sensitive applications,«  skriver forskerne, der foreslår, at man udvikler nye teknikker til at åbne black box-modeller, som ikke kan narres. Professor: Drop black box-modeller De amerikanske forskere er ikke de eneste, der er skeptiske over for praksissen med at tilføje et forklaringslag til en black box-model. I en kommentar , der er udgivet i maj og senest opdateret i september, advokerer Cynthia Rudin, der er datalogiprofessor ved Duke University, for at bruge modeller, der i sig selv kan forstås og fortolkes, som f.eks. beslutningstræer. »Rather than trying to create models that are inherently interpretable, there has been a recent explosion of work on 'Explainable ML', where a second (posthoc) model is created to explain the first black box model. This is problematic. Explanations are often not reliable, and can be misleading,«  skriver hun. Selv hvis både black box-modellen og den efterfølgende model til forklaring gør deres arbejde efter hensigten, så er det alt for lidt information, der komme ud af det, argumenterer Rudin. Hun nævner som eksempel saliency maps, der kan bruges til at forstå, hvad en computer vision-model egentlig ser på i et billede. Her demonstrerer Rudin, at et saliency map, der kategoriserer en hund som en fløjte, essentielt ser ligedan ud, når hunden kategorises korrekt. Fra Cynthia Rudins synsvinkel skal brugen af black box-modeller i kritiske miljøer helt undgås. »Trying to explain black box models, rather than creating models that are interpretable in the first place, is likely to perpetuate bad practices and can potentially cause catastrophic harm to society.« 
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2019-12-10
          &nbsp;·&nbsp; e77bda69
          &nbsp;·&nbsp; #12
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.996</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.659</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.544</kbd>
        </footer>
      </article>
      <article>
        <h4>Javascript genkender ansigter i browseren</h4>
        <div>
          Nu kan Javascript-udviklere bygge ansigtsgenkendelse i webapps. Face-api.js er et Javascript-api til ansigtsgenkendelse i browseren implementeret oven på Googles Tensorflow.js, som er en Javascript-implementering af firmaets populære machine learning teknologi til browsere og Node.js-miljøet.Til teknologibloggen Infoq forklarer Vincent Mühler, som er skaberen af Face-api.js motivationen bag:»Jeg havde et andet bibliotek, som var i stand til at detektere ansigter og udføre ansigtsgenkendelse med Node.js. På et tidspunkt opdagede jeg Tensorflow.js og blev interesseret i maskinlæring i browseren. Jeg var nysgerrig på, om det var muligt at flytte eksisterende modeller til ansigtsgenkendelse og ansigtsgenkendelse til Tensorflow.js, og det fungerede ganske godt.« Face-api.js kommer med tre modeller: SSD Mobilenet V1, Tiny Face Detector og MTCNN.Tiny Face Detector er trænet på et brugerdefineret datasæt med 14.000 billeder. Apps med begrænsede resurser bør bruge denne model.Til ansigtsgenkendelse benyttes en model baseret på en ResNet-34-lignende arkitektur, til at beregne en ansigtsbeskrivelse ud fra et billede. Denne model er ikke begrænset til det sæt ansigter, der bruges til træning, hvilket betyder, at udviklere kan bruge det til genkendelse af alle personernes ansigter. Det er muligt at bestemme ligheden mellem to vilkårlige ansigter, ved at sammenligne deres ansigtsbeskrivelser.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2018-11-14
          &nbsp;·&nbsp; e6f8ed73
          &nbsp;·&nbsp; #13
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.977</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.912</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.665</kbd>
        </footer>
      </article>
      <article>
        <h4>Sebastian Siem Bach-Nielsen ny som machine learning-specialist i IIH Nordic</h4>
        <div>
          Sebastian Siem Bach-Nielsen er ansat som machine learning specialist i Analytics teamet hos datakonsulenthuset IIH Nordic. Sebastian er uddannet Cand. Scient. i Medialogi fra Aalborg Universitet og har tidligere arbejdet for KMD og Falck Healthcare som studentermedhjælper. star Log ind eller prøv 3 ugers gratis prøveabonnement for at læse videre
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2018-08-13
          &nbsp;·&nbsp; e6db7357
          &nbsp;·&nbsp; #14
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.941</kbd>
            <kbd data-tooltip="AI &amp; innovation">L05_INNOAI&nbsp;0.694</kbd>
        </footer>
      </article>
      <article>
        <h4>PRM / Huawei lancerer verdens kraftigste AI-processor</h4>
        <div>
          KøbenhavnPressemeddelelse fra HuaweiAscend 910, der har mere computerkraft end nogen anden AI-processor i verden, er en del af Huaweis serie af Ascend-Max-chipsæt. Huawei offentliggjorde de planlagte specifikationer for processoren ved Huawei Connect, en af virksomhedens største events sidste år. Efter et år med løbende udvikling viser testresultater nu, at Ascend 910-processoren leverer sine resultater med et langt lavere strømforbrug end først antaget.Modeltræning af kunsting intelligens bliver dobbelt så hurtig Ascend 910 bruges til modeltræning til kunstig intelligens. Under en typisk træning er kombinationen af Ascend 910 og MindSpore cirka dobbelt så hurtig til at træne AI-modeller end konventionelle træningskort, der bruger TensorFlow.- Ascend 910 præsterer langt bedre, end vi forventede, og har uden tvivl mere computerkraft end nogen anden AI-processor i verden. Vi lovede en full-stack AI-portefølje til alle scenarier. Det har vi nu leveret med lanceringen af Ascend 910 og MindSpore, siger Eric Xu, Rotating Chairmand hos Huawei.MindSpore er navnet på det AI-framework, som Huawei lancerede sammen med Ascend 910. Det nye AI-framework understøtter udvikling af AI-applikationer i alle scenarier - på tværs af enheder, edge og cloudmiljøer - og tilbyder on-demand samspil mellem dem.Øger udvikleres effektivitetMindSpore vil være open source fra januar til og med marts i 2020, og dets designkoncept, AI Algorithm As Code, giver udviklere mulighed for nemt at udvikle avancerede AI-applikationer og træne modeller hurtigere. I et typisk, neuralt netværk til behandling af naturlige sprog (NLP) har MindSpore 20 procent færre linjer med kernekode end førende frameworks på markedet. Det kan øge effektiviteten hos udviklere med mere end 50 procent.AI-frameworks er afgørende for lettere udvikling af AI-applikationer, for at gøre AI-applikationer mere udbredte og tilgængelige samt for at sikre beskyttelse af personlige oplysninger. Gennem framework-innovation samt optimering af MindSpore- og Ascend-processorer kan Huaweis løsning hjælpe udviklere med mere effektivt at tackle udfordringer på komplekse AI-projekter og imødekomme behovet for alsidig computerkraft til forskellige applikationer.Ud over Ascend-processorer understøtter MindSpore også GPU'er, CPU'er og andre processortyper.Ifølge Huawei er deres første full-stack AI-portefølje til alle scenarier et bevis på virksomhedens engagement i at opbygge et mere robust og dynamisk økosystem for kunstig intelligens.Om Huaweis AI-porteføljeHuaweis AI-portefølje dækker alle installationsscenarier, herunder offentlig cloud, privat cloud, edge computing, IoT-enheder og forbrugerenheder. Porteføljen er også full-stack: Den omfatter Ascend IP og chip-serien, CANN (Compute Architecture for Neural Networks), trænings- og inferensplatformen MindSpore samt en applikationsplatform, der kaldes ModelArts.Kontakt:For yderligere information: Huawei Denmark Public Affairs and Communications Department: liuyinhanxiao@huawei.comLæs hele pressemeddelelsen på Via Ritzau her: https://via.ritzau.dk/pressemeddelelse/huawei-lancerer-verdens-kraftigste-ai-processor?releaseId=13578451
        </div>
        <footer>
          <em>Ritzaus Bureau</em>
          &nbsp;·&nbsp; 2019-08-30
          &nbsp;·&nbsp; e75294b1
          &nbsp;·&nbsp; #15
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.626</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.588</kbd>
        </footer>
      </article>
      <article>
        <h4>Transparens og præcision: SHAP-analyse forklarer, hvad der foregår i black-box-modeller</h4>
        <div>
          Et nyt værktøj til arbejdet med komplekse machine learning-modeller gør det muligt at åbne den sorte kasse og forklare, hvordan modellen kom frem til en bestemt forudsigelse. SHAP-værktøjet - SHapley Additive exPlanation - åbner for, at virksomheder ikke behøver at ofre præcision for at kunne forsvare algoritmens forudsigelse.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2018-10-02
          &nbsp;·&nbsp; e6eb61b6
          &nbsp;·&nbsp; #16
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.899</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.837</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.608</kbd>
        </footer>
      </article>
      <article>
        <h4>Tester du?</h4>
        <div>
          Test i data science gør lidt ondt i starten, men man ender op med en solid, produktionsklar kodebase man kan stole på, skriver Anders Bogsnes. Det var en gang hvor datascientists mødtes, og snakken gik på algoritmer - hvad var nyt og hot? I disse dage går snakken mere på software-udfordringer. Hvordan får vi denne model i produktion? Hvordan sikrer vi datakvalitet? Hvordan overvåger vi modellerne? Algoritmerne er stadig en vigtig del af hverdagen, men vi begynder nu at indse, at den bedste model er den, der kan komme i produktion. Datascience er nu en teamsport Datascience er blevet mere modent - mere produktionssætning og mindre POC. Der er flere datascience-teams frem for ensomme ulve og krav til, at man kan arbejde sammen i en kodebase. Det kan man ikke, hvis kodebasen ikke er læsbar, testet og produktionsklar! Uden automatiserede tests, er det svært at ændre i en delt kodebase - det er som at spille Klodsmajor men uden, at man må se tårnet, når man trækker brikkerne ud. Til trods for at alle er enige om, at det er vigtigt, så sker det alt for tit, at datascience kode ender med ikke at have tests. For at komme i gang vil jeg foreslå fire forskellige teststrategier: Pipeline testing Runtime testing Property-based testing Example-based testing Pipeline testing Som jeg har skrevet om tidligere , så handler machine learning om meget mere end bare modellen. Hver eneste del af din pipeline op til modellen bør have unit-tests. Din transformationsfunktion der konverter fødselsdato til alder skal have en test. Din funktion der finder ud af hvornår en kunde sidst har købt baseret på solgte produkter skal have en test! Disse er typisk nemme at teste. Giv din funktion et input, hvor du kender svaret, og tjek at resultatet af din funktion matcher det kendte svar. Jeg vil anbefale pytest som test framework. Det er ved at være standard for testing i Python efterhånden, og er nemt at komme i gang med. Runtime testing En machine learning-pipeline handler typisk om at behandle meget data over tid. Har I tests der tjekker, om den nye data har ændret sig? Ville I opdage, hvis der mangler en kolonne, en kolonne har skiftet datatype eller der mangler en dato? Hvad med dataens karakteristika? Har gennemsnittet ændret sig markant siden sidste load? Max- og min værdier? Har nye kategorier sneget sig ind? Det er meget bedre at fange disse typer ændringer og fejl, før man begynder at træne modellen! Jeg vil anbefale bulwark great expectations eller pandera afhængig af størrelsen af projektet. De er alle biblioteker lavet til validering af datapipelines, hvor bulwark og pandera er mere lightweight end great expectations, men har til gengæld ikke lige så mange features. Kig på dem alle og vurder, hvad der giver mening for jeres projekt! Property-based testing Når man arbejder med kode, hvor det ikke er nemt at vide nøjagtig, hvad det forventede output burde være, så kan vi bruge property-based testing i stedet for &quot;traditionel&quot; testing (eller sammen med). Property-based-testing betyder, at man definerer, hvordan input data kan se ud. F.eks. definerer vi input til modellen som et array med 6 kolonner, 5 tal og en string. Vi erklærer så, hvilke &quot;properties&quot; dit output skal have efter den har været gennem din funktion. F.eks. kunne din pipeline indeholde en skaleringsfunktion, der skalerer alle numeriske værdier til mellem 0 og 1 og en One-Hot Encoding til strings. Så dit output vil have følgende &quot;properties&quot;: output skal ikke indeholde strings output skal have flere værdier end input (pga One Hot encodingen) output skal ikke indeholde tal større end 1 og mindre en 0 output skal kun indeholde floats Et bibliotek som hypothesis definerer mange strategier for at erklære disse &quot;properties&quot;, og prøver at finde kombinationer af input værdier, der gør at output ikke længere overholder vores definerede &quot;properties&quot;. Den vil prøve sig frem med alle mulige mærkelige værdier, meget store tal, negative tal, unicode symboler osv, og når den finder en fejl, så vil hypothesis finde den simpleste version af inputs, der skaber fejlen. Det er som at skrive 100 tests i et hug! Derved får man både en sikkerhed i, at man har tænkt på hjørnetilfælde, men man slipper også for at &quot;opfinde&quot; testinput data, der ligner reel data. Man skal bare beskrive hvordan det ser ud, og hypothesis går bare i gang. Example-based testing Vi har nu fået en god testdækningsgrad på vores data pipeline, men hvad med modellen? Det er sværere at bruge traditionelle unit-testing metoder, da modeller ofte ikke er deterministiske - der er randomiserede hændelser i træningen af en model. For at teste en given model, kan man sammenligne resultater med kendte eksempler - når man forstår sin model, så har man også en ide om hvilke features der er udslagsgivende. Givet at vores model skal forudsige huspriser, så kunne en god test være, at hvis input er et hus på 200 kvm på Frederiksberg, så skal output være over 5 millioner. Fra vores domæneviden ved vi, at det altid er tilfældet, så hvis vores model ikke kan fange den &quot;nemme&quot;, så er der nok noget galt! Man kunne også have en test på, at et hus i Frederiksberg er dyrere end hvis vi tager det samme hus, men ændrer kommune-kolonnen til Lolland. Jeres domæneeksperter kan meget hurtigt finde nogle eksempler der er sund fornuft, som I kan inkorporere i jeres test-suite. Man kan også inkludere tests på om modellens metrikker er bedre end en fast baseline. Det kan være at et af acceptkravene er, at modellen skal være bedre end 50/50 eller, at den skal performe bedre end et menneske, eller måske bare bedre end den forrige model? Den første gør mest ondt Vi har nu gennemgået 4 forskellige måder at teste datascience kode på. Det svære er at bygge det ind som en fast rutine i hverdagen og tvinge sig selv til at få skrevet de første par tests. Som med så meget andet godt i livet, så gør det lidt ondt i starten, men når man ender op med en solid, produktionsklar kodebase man kan stole på, er det det hele værd!
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2019-12-11
          &nbsp;·&nbsp; e77d563a
          &nbsp;·&nbsp; #17
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.996</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.898</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.653</kbd>
        </footer>
      </article>
      <article>
        <h4>Danske forskere bruger deep learning til at finde stemmer i en høstak af støj</h4>
        <div>
          Artiklen er originalt bragt på DataTechDen menneskelige evne til at lytte efter en enkelt stemme, når du har en samtale i et rum fuld af konkurrerende samtaler, er enorm svær at efterligne med en algoritme.I arbejdet med avanceret lydanalyse er det såkaldte cocktailparty-problem stadig uløst. Nu har danske forskere taget skridtet nærmere en løsning med deep learning.»Udfordringen er, hvordan man fjerner uønskede støjkilder, når du optager i et støjfuldt rum med en enkelt mikrofon,« forklarer Morten Kolbæk, der netop har skrevet sin ph.d. om emnet ved Aalborg Universitet.Når man kender et lydbillede på forhånd, som i et klinisk test-setup, kan algoritmer identificere en enkelt taler lige så godt som et menneske. Men hvis teknikken skal anvendes i fx. høreapparater, er det ikke nok. Modellen må kunne identificere en ukendt taler blandt en ukendt mængde af talere i en situation med en ukendt mængde baggrundsstøj.DataTechArtiklen her er fra DataTech, et nyt PRO-medie fra Ingeniøren om data og analytics. Vi giver dig inspirerende cases, nyheder og debat om alt fra machine learning-modeller til dataetik.Følg med på pro.ing.dk/datatech»Uden forudgående kendskab er den menneskelige hjerne stadig den bedste maskine,« siger Morten Kolbæk.Label permutationUdfordringen ved at få en algoritme til at separere lyden fra to talere - der ikke er kendt på forhånd - er, hvad litteraturen kalder 'label permutation'-problemet.Basalt set går problemet ud på, at man gerne vil have et output fra modellen med en kanal for hver taler. Men du ved ikke på forhånd, hvilken stemme, der kommer ud af hvilken kanal.Det er en udfordring, når man træner modellen, forklarer Morten Kolbæk, fordi du med supervised learning skal sammenligne modellens output med det rigtige resultat - her i form af lyden fra de to separate talere.Med andre ord: Hvis taler A bliver separeret ud af modellen som output B, men træningsmodellen forventede, at taleren kom i output A, vil det fremstå som et forkert resultat.»På den måde kan man ikke træne modellen, fordi du ikke kan guide det neurale netværk,« siger Morten Kolbæk.Problemet løste de danske forskere ved at ændre lidt i træningsalgoritmen, og essentielt gøre rækkefølgen af talere ligegyldig under træning.»Ved at gøre det, så løser vi label permutation-problemet. Det betyder, at man relativt simpelt kan træne et neuralt netværk til at separere talere fra hinanden. Det er noget, som man ikke kunne gøre før,« siger forskeren.Algoritmen er demonstreret i følgende video:
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2019-01-08
          &nbsp;·&nbsp; e708eac2
          &nbsp;·&nbsp; #18
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.918</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.812</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.648</kbd>
        </footer>
      </article>
      <article>
        <h4>RapidMiner-boss: Pas på den skjulte sorte boks i AutoML</h4>
        <div>
          Brødtekst Automatiseret machine learning er et glimrende værktøj til at gøre data scientists mere produktive. Men hvis du ikke kigger AutoML-systemerne efter i kortene, vil du ikke kunne stole på, at systemet ikke producere modeller med kritiske fejl.Sådan lyder budskabet fra RapidMiner-grundlægger Ingo Mierswa, der opfordrer til en open source-tilgang til AutoML, som kan øge tilliden til værktøjerne.»Det er den samme open source-idé, vi ser inden for it-sikkerhed. Hvis nok mennesker har kigget på koden og ikke fundet huller, så kan vi nok stole på det,« forklarer han, da DataTech møder ham i London.»Men det kræver stadig en form for open source-tilgang eller -attitude over for det her. At du rent faktisk åbner op.« Det er ikke alle leverandører af systemer til automatiseret machine learning-systemer, der vælger den tilgang. Og den strategi er Ingo Mierswa skeptisk over for.Stort set alt inden for data science er i forvejen drevet af open source, pointerer han.»De fleste rigtig gode machine learning-modeller er open source, der er Python og R, der er TensorFlow. Vi har som softwareselskab stadig delelementer, der er closed source - vi vil stadig gerne tjene penge, det skal der ikke være tvivl om. Men på samme tid er data scientists så vant til åbenhed, at det ikke er en god strategi at være lukket omkring det her. Så jeg forstår ikke hemmelighedskræmmeriet,« siger Ingo Mierswa.Uden åbenhed ingen tillidPå samme måde som open source skaber tillid til softwareprodukter, fordi tilstrækkeligt mange kigger koden igennem, skal åbenhed i AutoML-værktøjer sikre tillid til de computerskabte modeller.»Jo flere, der rent faktisk kigger efter, desto højere vil tillidsniveauet blive. Og før eller siden vil tillidsniveauet være så højt, at behovet for at kigge ind i det her vil blive mindre og mindre,« siger Ingo Mierswa.»Men det vil kun være sandt for leverandører, der har den her åbne tilgang. Hvis man ikke deler, hvordan modellen bliver bygget, hvordan kan man så stole på det? For de leverandører vil det tillidsproblem, nok altid hænge ved,« vurderer han.I RapidMiner har man - ikke overraskende - valgt at gå efter mest mulig transparens i platformens Automodeller-funktion, der kan bygge ML-modeller for brugeren.Brugeren kan blandt andet få indsigt i, hvordan modellen fungerer gennem simulering. Her kan brugeren gå ind i modellen og justere på parametre og på den måde validere, at modellen opererer som forventet. RapidMiner har desuden implementeret en version af Lime-frameworket, der kan vise, hvilke parametre der understøtter et givent resultat, og hvilke der modsiger det.Skjult sort boksUden åbenhed skabes, hvad Ingo Mierswa kalder skjulte sorte bokse - det vil sige modeller, hvor modelbyggeren ikke selv ved, hvordan modellen blev til.De skjulte sort bokse skal aldrig accepteres, siger Ingo Mierswa fra scenen på Gartners Data &amp; Analytics Summit, der fandt sted i London tidligere på måneden.»Du har ingen idé om, hvordan modellen er blevet skabt. Du har bare klikket på fem knapper. Men hvad gjorde du med data, hvordan optimerede du modellen, hvordan validerede du modellen. Ud fra hvad du ved, kan modellen være resultatet af en tilfældig proces - eller en proces, der lækkede valideringsdata ind i træningsdata, hvilket er en absolut no-go i data science,« siger han og fortsætter:»Du skal i det mindste være i stand til at se alle detaljerne omkring, hvordan data er blevet præpareret, hvordan modellen blev optimeret, og hvordan den blev valideret. Det gør de fleste AutoML-værktøjer ikke, og de fleste citizen data scientist har ikke nok erfaring med at sætte spørgsmålstegn ved det.« Løsningen er foruden den nødvendige åbenhed i AutoML-værktøjerne, at en citizen data scientist får sine modeller tjekket igennem af en data scientist, hvis han eller hun ikke selv har kompetencerne.»Så du kan være sikker på, at du ikke laver dumme fejl,« siger Ingo Mierswa.TillidskriseÅbenheden har til formål at gøre det muligt, at gå systemet efter i sømmene og dermed skabe bund for tillid til modellerne, det skaber. Manglende tillid er nemlig det største problem for data science i dag, mener Ingo Mierswa og henviser til tal fra Gartner:»60 procent af alle modeller, der er tænkt til at blive sat i produktion, bliver faktisk aldrig operationaliseret. En model, der ikke sættes i produktion, giver ingen værdi, så hvorfor bygge den i første omgang?« spørger han retorisk.»Jeg tror, at problemet er, at data scientist ofte arbejder i et vakuum. Og når de kommer med komplekse matematiske formler, har forretningen ikke været en del af processen. De forstår det ikke, og dermed stoler de ikke på det.« Ingo Mierswa sammenligner det med at hyre en person, du ikke deler et sprog med, til at udføre en vigtig opgave.Data scientists skal generelt fokusere mindre på præcision og fejlrate og mere på, om en model kan forklares og forstås, siger RapidMiner-bossen.»Du skal bruge lige så meget tid på at forklare modeller, som på at skabe dem,« understreger han.»Som regel er det sådan i machine learning, at jo bedre en model er, des mere kompleks bliver den. Selv en lineær model kan være svær at forstå, og lad os slet ikke tale om neurale netværk. Det er den situation, vi står i.« Men hvis man ofrer læsbarhed for præcision, risikerer man, at forretningen ikke har tillid til modellen - og dermed at modellen aldrig sættes i produktion. Og når modellen bliver skrottet, er det lige meget, hvor god den er, fastslår Ingo Mierswa.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2019-03-26
          &nbsp;·&nbsp; e721847a
          &nbsp;·&nbsp; #19
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.98</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.996</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.663</kbd>
        </footer>
      </article>
      <article>
        <h4>Google gør sprog-AI til open source</h4>
        <div>
          Med udgivelsen, som hedder BERT (Bidirectional Encoder Representations from Transformers), kan man træne modeller til &quot;spørgsmål-og-svar-systemer&quot;, tillige med andre modeller. Det tager cirka 30 minutter på Googles specielle processorer til maskinlæring eller et par timer på en grafik-processor.Udgivelsen indeholder kildekode som er bygget oven på Googles populære AI-bibliotek Tensorflow og kommer med en række fortrænede sprogmodeller.I en videnskabelig artikel viser Googles forskere, hvordan de med modellerne kan få resultater, som er sammenlignelige med det bedste i forskningsverdenen, på blandt andet Stanford Question Answering Dataset (SQuAD v1.1), som benyttes til at vurdere forskellige AI-algoritmers færdigheder i forhold til hinanden.En af de udfordringerne inden for sprogbehandling, også kaldet NLP (Natural Language Processing), er manglen på træningsdata.Da NLP er et bredt felt med mange forskellige opgaver, indeholder de fleste opgave-specifikke datasæt kun et par tusind eller et par hundrede tusind træningseksempler, som er opmærket af mennesker.Såkaldte deep learning-modeller, der benytter neurale netværk med mange 'hidden layers', benytter fordelene ved større mængder data, der forbedres, når de trænes på millioner eller milliarder af træningseksempler.For at lukke dette hul i datamængden, har forskerne udviklet en række teknikker til at træne sprogmodeller rettet mod generelle anvendelser ved hjælp af den enorme mængde ikke-opmærket tekst på internettet.Den fortrænede model kan derefter finjusteres til NLP-opgaver på mindre datasæt, til formål som at svare på spørgsmål samt 'sentiment'-analyse, hvor eksempelvis filmanmeldelser opdeles i positive og negative. Teknikken skulle resultere i betydelige nøjagtige forbedringer, i forhold til træning på disse datasæt fra bunden.I modsætning til tidligere modeller kan BERT gennemskue den sammenhæng, som et ord indgår i, og er trænet på tekst fra Wikipedia.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2018-11-26
          &nbsp;·&nbsp; e6fcd4cd
          &nbsp;·&nbsp; #20
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.976</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.86</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.64</kbd>
        </footer>
      </article>
      <article>
        <h4>Amazon lukker op for meget mere machine learning</h4>
        <div>
          Bunkevis af nye ML-værktøjer fra cloudgiganten på produktkonference. Den ombruste ehandel- og cloudleverandør Amazon holdt i sidste uge konferencen Reinvent for at slå på tromme for egne produkter.Det var første gang, at der blev givet en selvstændig hovedtale om machine learning (kræver login) på konferencen, der naturligt nok var af den virtuelle slags, og som ufrivilligt humoristisk var garneret med kunstige klapsalver, der næppe krævede machine learning.Tøjlerne blev holdt af Swami Sivasubramanian, som er vicechef i Amazon Machine Learning. Han indledte med at fortælle, hvordan ML ikke længere er et niche-produkt. Eksempelvis behandler bilfabrikanten BMW 7 petabyte data med Sagemaker, som er Amazons ML-platform. Firmaet mener selv, at det dominerer på cloud-markedet for Tensorflow- og Pytorch-baseret ML med markedsandele på lige over 90 procent, lød det.Blandt de mange nyheder for Sagemaker-platformen, som blev lagt for dagen, var Managed Data Parallelism, som skal gøre det nemmere at træne på store datasæt, i størrelsen hundrede- til tusindvis af gigabyte, og 40 procent hurtigere end før, lød det glade budskab.Teknikken består i at opdele træningssæt i mini-batches, som fordeles over alle GPU'er. Med jævne mellemrum udveksler GPU'erne gradient-data mellem hinanden eller til en central server, der opdaterer GPU'erne.Automat-vaskDen næste produktnyhed i talen var Data Wrangler, der skal prøve at løse de tidskrævende problemer med datafangst, transformering samt datavask og -rens.Produktet gør det muligt at indhente data fra Amazons egne storage- og database-produkter tillige med CSV-filer og database-tabeller. Mere end 300 indbyggede transformationer kan benyttes, for eksempelvis at konvertere en kolonnes type fra tekst til tal eller interpolere manglende data med gennemsnit eller median. Man kan også skrive sine egne transformationer med eksempelvis SQL.Dernæst kan data visualiseres, også uden at skulle skrive kode. Til sidst kan det tjekkes, om data vil producere en korrekt model. Hele forløbet kan konverteres til en notebook eller et script og anvendes i produktion.Feature Store er et andet nyt produkt, der som navnet antyder er en store for features - ingen overraskelser der. Mere præcist kan features gemmes og tilgås på en måde, så det er nemmere at navngive og organisere dem og anvende samme features i træning og til inferens, uden at skulle skrive kode eller benytte manuelle processer.Tjek af biasBias er altid et varmt emne i AI og ML, og her skal gigant-leverandørerne naturligvis også være med. Amazons nye produkt på denne front hedder Clarify, og det skal finde bias under forberedelse af data, efter træning af model, og i den udrullede model baseret på attributter. Man kan eksempelvis tjekke for aldersrelateret bias i indledende datasæt eller i en trænet model, hvor slutresultatet er en rapport, der sætter tal på forskellige slags mulig bias.Produktet, som er integreret med det tidligere nævnte Data Wrangler-værktøj, kan også visualisere vigtigheden af forskellige features i grafer, som kan forklare modellens forudsigelser og identificere problemer. Det kan også anvendes med færdige modeller, hvor man eksempelvis kan se, hvorfor en model giver negative svar oftere for en gruppe end en anden.DebuggerEn anden ny produktnyhed i Sagemaker-familien er Debugger, som skal give ML-udviklere de samme slags værktøjer, som forretningsprogrammører benytter til fejlretning. Hvis man træner modeller med kode udviklet til Tensorflow, Keras, Pytorch og andre miljøer, kan man benytte et debugger-udviklerkit til på bestemte punkter at gemme modellens tilstand i Amazons S3-storagetjeneste.Tilstanden består af de parametre, som modellen lærer, såsom vægte for neurale netværk, gradienter, optimeringsparametre, skalarværdier som accuracy og loss samt output fra hvert layer.Ved hjælp af regler skrevet i Python kan man kigge efter uønskede problemer. Et sæt af færdiglavede regler kan eksempelvis holde øje med parametre, der giver NaN- eller nul-værdier, samt loss, der ikke ændrer værdi og mere til. Der er også mulighed for at skrive egne regler.Macine learning fra SQL og graf-databaserEn række nyheder bygger ML oven på eksisterende Amazon-produkter. Amazon Redshift ML gør det muligt at træne og udrulle modeller fra SQL-databaser i Redshift, som er Amazons datawarehouse-tjeneste. Det kan anvendes til eksempelvis churn prediction og svindel-detektering, lyder det.I samme genre findes Neptune ML, der også bygger oven på et eksisterende produkt, nemlig graf-databasen Neptune. Det skulle give bedre accuracy end ved andre fremgangsmåder såsom XGBoost.Pipelines er også et nyt produkt, som er en continuous integration-tjeneste (CI/CD) til ML, der kan orkestrere hele pipelinen og holde styr på udviklings- og udrulningsscyklussen, som det kendes fra CI/CD til forretningsprogrammering.I BI-genren var nyheden Quicksight Q, som i GPT-3-stil oversætter forespørgsler i naturligt sprog til søgninger. Det kan være spørgsmål som »What is my year-to-date year-over-year sales growth?« eller»Which products grew the most year-over-year?« der genererer et svar uden SQL-kode eller andre mellemliggende krumspring.Edge og industriel machine learningOgså for edge-behandling kunne Amazon vise en lang række nyheder. Edge Manager er en slags flådestyring for edge-enheder, hvor fordelen skulle være, at man kan anvende de samme værktøjer på cloud som på edge-enhederne. Samtidig bliver det muligt at overvåge og forbedre modeller på enheder.Derudover er der fem nye tjenester til industriel ML med navne som Amazon Monitron, Amazon Lookout for Equipment, AWS Panorama Appliance, AWS Panorama SDK og Amazon Lookout for Vision. De fem tjenester skal hjælpe industri og produktion med at forbedre driftseffektivitet, kvalitetskontrol og sikkerhed på arbejdspladsen. Om det også handler om sikkerheden for Amazons egne medarbejdere, vides ikke.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2020-12-17
          &nbsp;·&nbsp; e80a1b20
          &nbsp;·&nbsp; #21
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.706</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.831</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.664</kbd>
        </footer>
      </article>
      <article>
        <h4>Video: Sådan kan man lave billedgenkendelse hos Baidu - uden kode</h4>
        <div>
          Nu er bølgen også nået til maskinlæring.Den kinesiske søgemaskinegigant Baidu har sendt sit bud på gaden under navnet EZDL (&quot;nem deep learning.&quot;) Det skriver ADTMag.EZDL anvender en fire-trins proces til projektudvikling og implementering af brugerdefinerede maskinlærings-modeller: Opret en model, upload og opmærk billeder eller andre ting, træn og test modellen og implementer resultatet med et cloud-API eller et offline udviklingsværktøj (SDK).Ifølge Baidu er værktøjet målrettet mod små og mellemstore virksomheder.»Selvom du ikke har haft nogen erfaring med programmering, kan du hurtigt bygge modeller på denne platform uden barrierer,« siger Yongkang Xie, som er teknologichef for Baidu EZDL.»EZDL kan hjælpe virksomheder med begrænset AI-ekspertise og it-ressourcer til hurtigt og effektivt at gennemføre træning med deep learning og implementering, selv med kun en lille mængde data.« Baidu fremhæver tre slags brugsscenarier:En model til automatisk klassificering af billeder med brugerdefinerede klasse til opgaver som: Klassificering af billeder af boliger, genkendelse af kinesisk urtemedicin, vilde fugle og frøer, samt industriel kvalitetskontrol i forbindelse med identifikation af defekte produkter.En model til automatisk detektering af objekter i billeder og optælling af antal objekter efter klasse, til opgaver som eksempelvis optælling af celler inden for medicin.En klassifikationsmodel til at genkende forskellige typer lydtyper eller detektere klasser af begivenheder, beregnet til opgaver som sikkerhedsovervågning og videnskabelig forskning.EZDL er en del af dets kunstig intelligensprojekt, der går under navnet Baidu Brain.På videoen herunder kan man se anvendelsen af EZDL.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2018-09-20
          &nbsp;·&nbsp; e6e7d057
          &nbsp;·&nbsp; #22
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.833</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.851</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.614</kbd>
        </footer>
      </article>
      <article>
        <h4>IBM hopper med på vognen og open sourcer system til kunstig intelligens</h4>
        <div>
          IBM har lanceret sit machine learning system SystemML som open source i kølvandet på lignende træk fra både Facebook og Google.Det er åbenbart blevet populært blandt it-giganterne at frigive deres machine learning-software, som kan bruges til at udvikle selvlærende systemer.Først frigav Facebook machine learning-systemet Torch, og siden hen fulgte Google trop med systemet TensorFlow, som blandt andet står bag de avancerede algoritmer som søgemaskinen bruger til at forudsige, hvad du vil søge på, mens du skriver.Nu har IBM så lanceret SystemML som open source, hvilket gør valgmulighederne endnu større for virksomheder, der vil forsøge sig med machine learning.Platformen er tilgængelig på Github .Silicon Angle skriver :The SystemML technology emerged from IBM-s development of Watson, and integrates closely with another Apache project, Spark. SystemML helps Watson to keep up to date by providing a language that directly exposes the capabilities of the artificial intelligence so data scientists can harvest it. Queries are written in syntax modeled after the popular R statistical programming framework, before being executed according to the most efficient mode of operation for the specific workload and operational characteristics of a Spark cluster.&quot;SystemML provides declarative large-scale machine learning (ML) that aims at flexible specification of ML algorithms and automatic generation of hybrid runtime plans ranging from single node, in-memory computations, to distributed computations on Apache Hadoop and Apache Spark. ML algorithms are expressed in a R or Python syntax, that includes linear algebra primitives, statistical functions, and ML-specific constructs. This high-level language significantly increases the productivity of data scientists as it provides (1) full flexibility in expressing custom analytics, and (2) data independence from the underlying input formats and physical data representations. Automatic optimization according to data characteristics such as distribution on the disk file system, and sparsity as well as processing characteristics in the distributed environment like number of nodes, CPU, memory per node, ensures both efficiency and scalability.-IBM said it would be donating SystemML to The Apache Foundation back in June this year, and the project has already hit a significant number of milestones since then, including more than 320 patches including APIs, Data Ingestion, Optimizations and Additional Algorithms. There have also been more than 90 contributions to the Apache Spark project from IBM-s engineers, aimed at making Machine Learning compatible with Spark.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2015-11-25
          &nbsp;·&nbsp; e5550c02
          &nbsp;·&nbsp; #23
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.925</kbd>
            <kbd data-tooltip="AI &amp; innovation">L05_INNOAI&nbsp;0.659</kbd>
        </footer>
      </article>
      <article>
        <h4>VIDEO: Forstå hvorfor man bruger grafikkort til kunstig intelligens</h4>
        <div>
          Grafikkort er den foretrukne computerkraft bag kunstig intelligens, men hvorfor?Grafikkort er eftertragtede af kryptovaluta 'minere', der flyver dem rundt i hele verden, for at kunne skrabe endnu flere digitale mønter til sig. Kortene er dog ikke kun brugt til computerspil og kryptovaluta. De er også den foretrukne form for computerkraft bag kunstig intelligens, machine learning og neurale netværk. Men hvorfor?Læs også den mere tekniske forklaring her på Version2.
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2018-02-06
          &nbsp;·&nbsp; e69b610f
          &nbsp;·&nbsp; #24
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.959</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.642</kbd>
        </footer>
      </article>
      <article>
        <h4>DeepMind-forskere tackler black box-problem i algoritme, der spotter øjensygdomme</h4>
        <div>
          Googles DeepMind-afdeling for sundhed har skabt en model, der kan aflæse øjen-skanninger og spotte akutte sager med samme præcision som en trænet specialist. Systemet vil i fremtiden gøre det muligt at redde synet for flere patienter, mener man på det specialiserede Moorfields Eye Hospital i England, der har samarbejdet med DeepMind-forskerne om projektet.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2018-09-18
          &nbsp;·&nbsp; e6e6e235
          &nbsp;·&nbsp; #25
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.918</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.833</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.648</kbd>
        </footer>
      </article>
      <article>
        <h4>Hvad er maskinlæring</h4>
        <div>
          KØGE: Hvad er maskinlæring og kunstig intelligens? På to timer kan du få et indblik i, hvad maskinlæring er, hvordan kunstig intelligens virker og hvilke konsekvenser maskinlæring allerede har for fremtidens samfund. Det skriver Køge Bibliotek: -Maskinlæring findes overalt i vores samfund. Du oplever det anvendt i blandt andet anbefalingssystemer som Netflix, i ansigts-, stemme-og billedgenkendelse, i computerspil og meget mere, fortæller bibliotekar Stine Kjær Schmidt, der står for workshoppen på Køge Bibliotek tirsdag 14. januar kl. 16. Her vil hun blandt andet fortælle om teknologiens muligheder og begrænsninger.Hvad er maskinlæring og hvorfor skulle det være interessant for mig, tænker du måske? Ja, netop derfor bør du komme denne eftermiddag, hvor du også får lejlighed til selv at prøve -helt konkret og praktisk -at træne en algoritme, så du kan opleve, hvordan maskinlæring virker i praksis. Alle er velkomne.Der kræves ingen digitale forudsætninger for at deltage i arrangementet, som er gratis.Biblioteket stiller computere til rådighed. Tilmelding anbefales og kan ske via koegebib.dk eller på det lokale bibliotek.
        </div>
        <footer>
          <em>Køge Onsdag</em>
          &nbsp;·&nbsp; 2020-01-07
          &nbsp;·&nbsp; e787b16d
          &nbsp;·&nbsp; #26
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.844</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.67</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.568</kbd>
        </footer>
      </article>
      <article>
        <h4>Sådan kan kvantecomputere løse ikke-lineære differentialligninger</h4>
        <div>
          Mange problemer inden for naturvidenskab og teknisk videnskab drejer sig om at løse differentialligninger. Kvantecomputere har potentialet til også at kunne udføre sådanne beregninger. Der er udviklet algoritmer, der håndterer lineære differentialligninger, men kvantecomputere har vanskeligt ved at klare ikke-lineære differentialligninger, som optræder måske steder inden for f.eks. strømningsmekanik. Det skyldes, at kvantemekanik er et lineært system. To forskergrupper har nu fundet en udvej til, hvordan kvantecomputere alligevel i visse tilfælde kan håndtere ikke-lineære differentialligninger. En artikel i Quanta Magazine beskriver, hvorfor kvantecomputere generelt har svært ved at løse ikke-lineære problemer, og den måde man forsøger at omgå dette problem.
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2021-01-06
          &nbsp;·&nbsp; e80f98dc
          &nbsp;·&nbsp; #27
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.971</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.965</kbd>
            <kbd data-tooltip="Problem solving AI">L80_SOLVAI&nbsp;0.556</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.615</kbd>
        </footer>
      </article>
      <article>
        <h4>Transfer learning hos Amazon: Alexa lærer japansk af engelsk sprogdata</h4>
        <div>
          Brødtekst For Amazons digitale assistent Alexa er evnen til at erobre nye markeder mere eller mindre lig evnen til at lære nye sprog.Men god sprogdata til at træne de neurale netværk er notorisk svære eller dyre at få fat på, hvorfor Alexa-udviklerne har kastet deres kræfter på transfer learning. Med andre ord at lade systemet overføre viden om ét sprog til et andet sprog for at lære det hurtigere og bedre.Strategien er effektiv, fortæller Research &amp; Development Program Manager ved Amazon Alexa AI Lucie Flekova på konferencen Women in Data Science, der fandt sted i sidste uge.»Cross lingual transfer learning er brugbart i både lille og stor skala, kan forbedre præstationen både på sætnings- og ordniveau, og det kan i vores tilfælde spare os mere end halvdelen af træningsdata,« siger Lucie Flekova om erfaringerne indtil videre.Fra stort til lille datasætTransfer learning er typisk brugbar i situationer, hvor du har et stort datasæt og et datasæt, der i sig selv er for lille til at træne en model.»Det store datasæt hjælper dig med at lære noget, og overføre det til det mindre datasæt uden at lære det igen,« forklarer Lucie Flekova.I Alexas tilfælde er det store datasæt - kaldet source - typisk engelsk sprogdata, hvor mængderne af træningsdata er massive, mens det mindre datasæt - kaldet target - f.eks. kunne være tysk eller japansk.I praksis betyder det, at man først træner modellen på source-datasættet (engelsk) og herefter bruger target-datasættet til at finetune netværket. Dermed får man en model, der forstår target-sproget bedre, end hvis den kun var trænet på target-datasættet.»Tidligere forskning har peget på, at værdien af transfer learning falder, når sprogene er lingvistisk forskellige. Men vores erfaring er, at transfer learning mellem japansk og engelsk virker lige så godt som mellem tysk og engelsk,« sagde Lucie Flekova på konferencen.Halvering af træningsdataSelv hvis du har adgang til et relativt stort datasæt fra dit target-sprog, er der gevinst at hente ved at starte med at træne på det sprog, hvor der er træningsdata i overflod.»Vi har set på, hvad grænserne er for, hvor meget data der skal være i dit target datasæt. Om der er en grænse, hvor det giver bedre mening at træne modellen alene på target-sproget. Det, vi fandt, var, at det var der faktisk ikke,« siger Lucie Flekova.»Modellen lærer stadig mere, hvis du starter med informationen fra source-sproget.« Alexa-udviklerne udgav tidligere på måneden en forskningsartikel om arbejdet med transfer learning fra ét sprog til et andet. Her skelner udviklerne først og fremmest mellem intention classification - formålet med en sætning - og såkaldt slot tagging - de dataemner, som sætningen handler om.Hvis en Alexa-bruger siger &quot;Alexa, play 'High Hopes' by Panic! at the Disco,&quot; er intentionen PlayMusic, og &quot;High Hopes&quot; og &quot;Panic! at the Disco&quot; udfylder de to slots SongName og ArtistName, forklarer udviklerne i en blog.Af udviklernes arbejde fremgår det, at et træningssæt med en million engelske udsagn og 10.000 tyske udsagn skabte en model, der var bedre i stand til at forstå intentionen med en tysk sætning, end en model trænet alene på 20.000 tyske udsagn.Når det handlede om at forstå, hvad der blev talt om - slots tagging - klarede modellen sig fire procent bedre, hvis den først blev trænet på source-datasættet, uanset om udviklerne efterfølgende brugte de 10.000 eller 20.000 tyske udsagn som target-datasæt.Flere klasser kræver mere dataAlt i alt baner teknikken vejen for at overføre Alexa til nye sprog med mindre tæningsdata, noterer udviklerne.Hvor meget træningsdata, man egentlig har brug for fra target-sproget, afhænger af opgaven, understreger Lucie Flekova.»Det afhænger af, hvor mange klasser du i sidste ende vil kunne klassificere. Hvis du har tusindvis af klassifikationer, skal du gerne have flere sætninger, end du har kategorier. Det varierer også meget fra sprog til sprog,« understreger hun.Alexa er i skrivende stund tilgængelig på engelsk, tysk, japansk, fransk, spansk, italiensk og yderligere seks varianter af de sprog. Flekova ville på konferencen ikke afsløre, hvilke sprog Amazon har i pipelinen for Alexa.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2019-04-25
          &nbsp;·&nbsp; e72c50ca
          &nbsp;·&nbsp; #28
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.971</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.856</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.645</kbd>
        </footer>
      </article>
      <article>
        <h4>Gratis værktøjer skal spotte algoritmernes fordomme</h4>
        <div>
          Bias, fordomme og diskrimination er ikke bare noget der foregår i den fysiske verden. Det finder i den grad også sted i de algoritmer, der blandt andet bruges til ansigtsgenkendelse og en lang række beslutningsprocesser.Nu har IBM lanceret en værktøjskasse med navnet 'Fairness 360', som scanner for tegn på bias i algoritmer.I den første udgivelse af Fairness 360, også navngivet AIF360 Python Package, finder man ni forskellige algoritmer, hvis mål er at afbøde bias. Det er et sæt af fairness- målinger på datasæt og machine learning-modeller.Åbner den sorte boksBehovet for nye former for indsigt i algoritmerne skyldes blandt andet, at udviklere ofte ikke ved, hvilke beslutninger der tages med deres kunstige intelligens og hvorfor.Kunstig intelligens er kendt som en black box, en sort boks. IBM's værktøj vil gøre AI-beslutninger mere gennemsigtige, så udviklere kan se, hvilke faktorer der bruges i den kunstige intelligens.Softwaren er cloud-baseret og open source, og den virker til de mest kendte AI-frameworks, inklusiv Watson, Tensorflow, SparkML, AWS SageMaker og AzureMLDu kan finde Fairness 360 på Github
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2018-09-27
          &nbsp;·&nbsp; e6ea1676
          &nbsp;·&nbsp; #29
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.985</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.862</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.642</kbd>
        </footer>
      </article>
      <article>
        <h4>Metoder inden for Explainable AI (XAI)</h4>
        <div>
          Explainable AI (XAI), altså forklarlig kunstig intelligens, har meget fokus i øjeblikket, fordi maskinlæringsmodeller bliver mere ugennemskuelige og komplekse, og fordi datadrevne modeller bliver brugt mere til kritiske beslutninger og af ikke-ekspertbrugere. Der findes dog mange forskellige måder at lave forklarlig kunstig intelligens på og dermed også et hav af forskellige metoder. Ved at definere egenskaber og typer af metoder og forklaringer og ved at give et overblik over de mest kendte metoder, vil vi hjælpe med at finde rundt i junglen af XAI-metoder.Bekymringer om forklarlighed vedrørende systemer baseret på kunstig intelligens er ikke noget nyt, se f.eks. 'ekspertsystemer' [1], 'case-based reasoning' [2, 3] eller, for et historisk overblik, se reviewet der blev lavet som del af DARPAs XAI projekt [4]. Men i de sidste 2-3 år er der kommet et hav af nye metoder til at lave forklarlig kunstig intelligens.Hvad er forskellen mellem de forskellige metoder? Hvilke typer af forklaringer generer de? Og hvilke metoder passer i hvilken situation, til hvilke type data eller modeller? I dette blogindlæg giver vi et overblik over forskellige metoder og grupperer dem ved at definere en taksonomi af XAI-metoder. Taksonomien og inddelingen i forskellige grupper er inspireret af diagrammet fra IBM's AIX360 open-source bibliotek, Christoph Molnars e-bog og forskellige artikler om XAI-metoder [5, 6, 7, 8, 9, 10, 11, 12].Helt generelt kan man adskille metoder på måden, man interagerer med dem. De kan være statiske eller interaktive (får man bare en eller flere forklaringer, eller kan man også ''spørge'' ind til en anden eller dybere forklaring). Der findes dog os bekendt ingen interaktive metoder, så vi fokuserer her udelukkende på statiske metoder.Desuden kan man gruppere XAI-metoder efter hvilken type af data, de er egnet til, og efter hvilke typer af forklaring de genererer. Der findes både metoder, der kan forklare data, og metoder, der forklarer modellerne. Sidstnævnte kan videre separeres på 1) hvilket område forklaringerne virker på, altså forklarer de dele af modellen (global ) eller modellens resultater (lokal ), 2) om det er modeller, der kan forklare sig selv (iboende ) eller metoder, der forklarer en ugennemsigtig model (post-hoc ), og 3) om de er lavet til en specifik type af model.I det følgende vil vi beskrive, lidt mere i dybden, hvilke typer af data der kan forekomme, hvilke typer af forklaringer der eksisterer, og hvad iboende, post-hoc, lokal og global egentlig betyder, samt nævne nogle eksempler på XAI-metoder i hver kategori. Til sidst giver vi et overblik over et udvalg af metoder i form af et taksonomitræ.Typer af dataForklaringer og XAI-metoder er afhængige af den datatype, som modellen er udviklet til. De fleste anvendelser af datadrevne modeller er lavet til tabel-, billede-, tekstdata eller tidsserier.TabeldataTabeldata data er data, der kan beskrives i form af en tabel, hvor hver kolonne repræsenterer en variabel eller feature, og hver række repræsenterer et eksempel eller datapunkt. Denne type data er brugt i de mest klassiske anvendelser af maskinlæring, såsom fraud detection eller churn prediction. Desuden kan mange andre datakilder tit udtrykkes som en tabel gennem såkaldt feature extraction.BilleddataBilleddata er den type data, der forekommer i computer vision-opgaver, såsom object detection, optical character recognition eller image segmentation. Hvert billede i datasættet repræsenterer et eksempel eller datapunkt. Man kan bruge dybe neurale netværk (convolutional neural networks) til billeddata, eller ekstrahere nogle features fra et billede så datasættet kan udtrykkes som en tabel.TekstdataTekstdata er den type data, der forekommer i NLP-opgaver (natural language processing), som f.eks. named entity recognition, speech to text, eller at analysere toner i debatten. Hver tekst, såsom sætninger, afsnit eller dokumenter, i datasættet repræsenterer et eksempel eller datapunkt. Man kan bruge dybe neurale netværk (recurrent neural networks) til tekstdata, eller ekstrahere nogle features fra tekster så datasættet kan udtrykkes som tabel.TidsserierTidsserier bliver tit udtrykt som tabeldata, så det kan bruges til maskinlæring. Derfor kan alle XAI-metoder, der arbejder på tabeldata, normalt også bruges på tidsserier.Typer af forklaringerForklarlighed skal altid defineres i en given kontekst. Denne kontekst indeholder mål og andre dimensioner, der er afhængige af tidsbegrænsninger og slutbrugerens ekspertise i forhold til maskinlæring [5] (se også vores andet blogindlæg om forklarlighed ).Tiden, en bruger har til at forstå eller kigge på en forklaring, kan være begrænset i en given applikation, som sætter begrænsninger på forklarligheden. Yderligere begrænsninger og krav er givet fra den type bruger, der interagerer med modellen. Brugerens ekspertise kan være alt imellem en beslutningstager uden teknisk baggrund og høje domæneviden, som læger, dommere, eller planlæggere, over forskere eller ingeniører med en basis, teknisk viden, hen til data scientists og maskinlæringseksperter med en dyb viden om selve modellen. Forskellige typer af brugere har brug for forskellige typer af forklaringer. I den her del af blogindlægget vil vi gerne komme det nærmere, hvilke typer af forklaringer, der findes, og hvordan de udmønter sig. Det er dog ikke en udtømmende liste, og det er vigtigt at bemærke, at nogle gange kan en brugers behov løses gennem UX-design eller forklaringer, der ikke er automatisk genererede.EksemplerEn måde at generere forklaringer på er ved at bruge eksempler. Fordelen ved forklaringer gennem eksempler er, at det er let forståeligt for slutbrugeren eller domæneeksperten, da eksempler, og dermed forklaringer, kommer fra selve datadomænet. Desuden bruger mennesker tit eksempler til at træffe en beslutning, såkaldt cased-based reasoning [2, 3]. For eksempel når en læge stiller en diagnose, er det baseret på symptomer, og de erfaringer han har med patienter, der har udvist lignende symptomer. Eller når en data-scientist skal løse en opgave, så husker han en opgave, han har løst tidligere, og hvilke metoder og modeller der virkede bedst til at løse opgaven.Dog giver det kun mening at bruge eksempler som forklaring, hvis selve data let kan repræsenteres og er forståeligt. Det gælder for eksempel for billeder eller tekst, som mennesker kan give en mening til. Det kan også virke for tabeldata, men det kræver, at kolonner (variabler) har en mening, som pris, antal værelser eller hustype for et hus-datasæt, og at der kun er en håndfuld kolonner, ellers er enkelte datapunkter ikke gennemskuelige.PrototyperEksemplerne kan både bruges som forklaring af selve data eller for at forklare en models resultat. For at forklare data søger man efter de eksempler i et datasæt, der bedst repræsenterer datasættet, såkaldte prototyper. Når man har et datasæt med forskellige grupper (klassifikationsproblem), vil man som regel finde prototyper for hver klasse.Udover prototyper er det også vigtig at kunne afgrænse datasættet, altså finde de datapunkter der ligger på grænsen af datasættet eller længst væk fra prototyperne, såkaldt criticisms. Det blev først præsenteret fra Kim et al. sammen med deres MMD-critic metode[13]. ProtoDash er en anden metode til at finde prototyper og criticisms og er en videreførelse af 'MMD-critic' lavet af en IBM-forsker [14].Udover at finde repræsentative datapunkter i et datasæt findes der også modeller, der sammen med deres output giver en prototype-forklaring [15, 16].Eksempler fra træningsdataEksempler kan ikke kun bruges til at forklare data, men også til at forklare et bestemt resultat af modellen [17]. En måde at gøre det på er at finde de eksempler fra træningsdata, der havde mest indflydelse på modellens beslutning [18]. Det kræver, at man definerer en såkaldt influencer-funktion, der kan beregne indflydelsen.En klassisk maskinlæringsmodel, der træffer beslutninger baseret direkte på eksempler fra træningsdata, er k-nearest neighbour (k-NN ). Her får man forklaringer som eksempler ''gratis'' sammen med modellens resultat. Der findes også forskning til at bruge k-NN sammen med et dybt neural netværk til at både lære komplekse sammenhæng i data og få en forklaring [19].CounterfactualsEn anden måde at bruge eksempler som en beslutningsforklaring på er at finde counterfactuals [20]. Counterfactuals undersøger, hvad der ville være sket, hvis udgangspunktet havde været anderledes, altså hvilke fakta-ændringer der ville have sørget for et modsat resultat. Hvis man for eksempel får afvist et lån, så kan det være, at man ville have fået det, hvis man havde en højere indkomst. Den form for kontrastiv forklaring er også tit brugt af mennesker [21].Der findes forskellige metoder til at generere counterfactuals på, både til tabeldata [22], billeddata [23] og forskellige datatyper [24, 25].ReglerRegel-baserede modeller, såkaldte ekspertsystemer, har været måden at lave forklarlige modeller på og var meget populære i 80'erne. I disse systemer bliver regler defineret af domæneeksperter, og så kan de bruges til en automatisk beslutning. Disse regler har en hvis-så form, f.eks. hvis der er skyer, og gulvet er vådt, så har det regnet. Reglerne kan have flere betingelser (''der er skyer'', ''gulvet er vådt''), men kun maksimalt to resultater (''det regnede'', ''det regnede ikke''). Reglerne kan kombineres med hinanden og udføres efter hinanden, dvs. en regel bestemmer hvilken regel, der skal bruges i næste trin.Udover ekspertsystemer findes der også maskinlæringsmodeller, der automatisk genererer regler baseret på sammenhænge i data [26, 27, 28]. En bestemt form af disse modeller er beslutningstræer, hvor regler er binære (en betingelse og to veje) og kombineret i et træ. Beslutninger bliver så lavet ved at starte i roden af træet og følge regler igennem, indtil man lander i et blad, som udgør resultatet.Regler kan både bruges til at forklare hele modellen gennem alle reglerne, modellen består af, og som lokal forklaring ved at give de regler der var afgørende for en bestemt beslutning [29].Feature attributionsFeature attributions er den type forklaring, der er mest udbredt i de metoder, der er blevet udviklet for nyligt, og som der er mest hype omkring. Feature attributions beskriver for hver variabel, hvor vigtig den er for modellens resultat. Det kan både være globalt, altså hvilke variabler er grundsatslig vigtige, eller lokalt, altså hvilke variabler var mest afgørende for en bestemt beslutning.Når man kigger i junglen af maskinlæringsmodeller så findes der en gruppe af såkaldt lineære modeller: lineær regression, logistisk regression, Generalized Linear Models (GLMs) og Generalized Additive Models (GAMs). På grund af deres struktur er det muligt at få både en global eller lokal forklaring i form af feature attributions (læs mere ved at klikke på links). Der har været en del udvikling i den seneste tid af algoritmer til at lave lineære modeller, der har lige så god eller bedre performance end mere komplekse black-box-modeller, f.eks. GA2M [30] eller SLIM [31].Der findes også metoder, der kan generere feature attributions for en ikke-lineær black-box-model, f.eks. SHAP [32], som er baseret på såkaldte shapley values [33], LIME [34], DeepLIFT[35], Grad-CAM [36] eller LRP [37]. De sidstnævnte (DeepLIFT, Grad-CAM og LRP) er specielt lavet til dybe neurale netværk, og her er idéen blandt andet, at outputtet af netværket bliver ført tilbage til inputtet igennem netværket for at vise, hvilke dele af inputtet der var mest betydningsfulde. De fleste af disse metoder virker på alle typer af data, og vi vil gerne beskrive i lidt flere detaljer, hvordan feature attributions kan se ud på billede- eller tekstdata.BillederFeatures i billeder er de enkelte pixels i billedet eller dele af billedet. Så når vi bruger feature attributions på billeddata, handler det om at markere de pixels eller områder i billedet, som var mest betydningsfulde for modellens resultat.TekstFeatures i tekst er de enkelte ord eller sætninger i teksten. Så når vi bruger feature attributions på tekstdata, handler det om at markere de ord, som var mest betydningsfulde for modellens resultat.VisualiseringerVisualiseringer er en god måde at repræsentere komplekse sammenhænge på, og er den foretrukne måde for data scientists, statistikere og analytikere til at forstå data og modeller. Desuden er smarte visualiseringer hjertet af business intelligence-løsninger. Visualiseringer er derfor også en god måde at forklare data eller modeller på.Her vil vi kort beskrive forskellige måder at bruge visualiseringer som forklaring på. Vær opmærksom på at nogle af de tidligere præsenterede typer af forklaringer (regler og feature attributions) også skal visualiseres, men der findes mange forskellige måder at gøre det på, hvorimod de visualiseringer, vi beskriver her, hænger tæt sammen med metoden.DatavisualiseringerLigesom med andre typer forklaringer, så kan man både forklare data og modeller. Visualiseringer bliver som regel brugt til at forstå data, inden man begynder at designe og træne en model. Det er forholdsvis nemt at visualisere enkelte eksempler på tekst- og billeddata, da deres form allerede er en visualisering i sig selv. Der er dog udfordringer med at visualisere et helt datasæt. Her bruger man tit en form af 'manifold visualisering', f.eks. t-SNE.For tabeldata kræves det først, at man reducerer dimensionen af de enkelte datapunkter til 2 eller 3 variabler, da data så kan visualiseres i et 2D eller 3D plot. Principal component analysis (PCA ) er en kendt metode til reducering af dimensioner. Yellowbrick er et godt Python-bibliotek, der samler forskellige visualiserings- og dimensionsreducerings-metoder.Partial dependence plot (PDP)Partial Dependence Plots (PDPs ) er en måde til at forklare en model. Selve plotsene viser, hvordan værdien af en enkelt variabel, eller værdierne af et par af variablerne, ændrer modellens resultat. Det er Jerome H. Friedman, der først præsenterede PDP i 2001 [38].Goldstein et al. videreudviklede metoden til Individual Conditional Expectation (ICE) plots, hvor man også kan se effekten for et eller flere udvalgte datapunkter, udover at kun se den samlede effekt [39]. ICE plots kan dog kun laves for en enkelt variabel ad gangen.Neuron-visualiseringerDybe neurale netværk består af hundrede eller tusindvis af neuroner, der er forbundet til hinanden og organiseret i en grafstruktur med forskellige lag. Hvert lag eller gruppe af lag transformerer data fra selve inputtet til outputtet af modellen igennem mere og mere abstrakte repræsentationer, jo dybere (tættere på output) man kommer ned i netværket.Der findes forskellige metoder til at visualisere disse abstrakte repræsentationer, som modellen har lært [40]. Metoderne er begrænset på billed- eller tekstdata, da visualiseringer som billed eller tekst intuitivt kan forstås. Med tabeldata er det svært at forstå abstrakte repræsentationer, da de ikke direkte relaterer tilbage til input-domænet eller specifikke attributter.Det er for eksempel brugbart til at visualisere, hvordan netværket ''ser'' et bestemt input i de forskellige lag [40, 41, 42], eller til at visualisere hvad forskellige neuroner eller lag i netværket detekterer eller ekstraherer generelt fra dataene [43, 44, 45, 46].KoncepterKoncepter er det, der kommer tættest på, hvordan vi som mennesker forstår verden. Når vi ser et objekt med hjul, så tænker vi nok, at man kan køre med det, selvom vi måske ikke kender selve objektet. Når vi ser et dyr med vinger, så vil vi nok genkende det som en fugl, også hvis vi ikke har set den type fugl før. Ved at interagere med vores omverden og ved at læse bøger, se film, gå i skole osv. lærer vi koncepter, der kan hjælpe også med at forstå nye ting.Nuværende modeller brugt i maskinlæring, der bliver trænet med data, lærer ikke koncepter eller kausale sammenhænge, men en korrelation mellem input- og output-variabler. Der er derfor en aktiv forskning, der handler om, hvordan vi kan skabe modeller, der faktisk har lært koncepter, f.eks. causal inference [47] (se også DoWhy eller CausalNex Python-biblioteker) eller kognitive modeller [48]. Men forskningen er bare påbegyndt og er ikke moden nok til at blive brugt i industrien, selvom der er nogle lovende resultater inden for både NLP [49] og computer vision (Neuro-Symbolic Concept Learner ).Når vi så snakker om koncepter her, så handler det stadig om modeller, der lærer en korrelation, men som ved hjælp af værktøjer kan generere en forklaring, der kommer tæt på koncept-tanken og adskiller sig fra de øvrige typer af forklaringer, vi har beskrevet i dette indlæg.En måde at få konceptforklaringer på er at annotere datasættet, så hvert datapunkt også har en konceptlignende forklaring givet af en domæneekspert, og så træne en model der både genererer et output og en forklaring [50].En anden måde er ved at definere koncepter gennem eksempel-datapunkter og undersøge sensitiviteten overfor disse datapunkter for hver af modellens output i et klassificerings-problem [51]. For eksempel kan man undersøge om en model til at klassificere billeder er sensitiv overfor konceptet ''striber'', når den klassificerer en zebra. Ghorbani et al. automatiserer denne tilgang, så koncepterne bliver genereret automatisk for et givent billede [52].Det er også muligt at træne en model, så den kan svare på spørgsmål i forhold til et billede, såkaldt visual question answering [53, 54, 55]. Her handler det om, at modellen forstår de koncepter, der er til stede i spørgsmålene og billedet.Global eller lokal - Post-hoc eller iboendeI ovenstående afsnit har vi set, at forklaringsmetoder kan grupperes afhængigt af, hvilken type forklaring de genererer. En anden måde at adskille metoderne, der forklarer modeller på, er baseret på deres virkningsområde. Typisk adskiller man mellem global og lokal [5, 56, 57].Global forklarlighed gør det muligt at forstå hele logikken bag, hvordan en model virker og at følge dens ræsonnement for alle mulige prædiktioner [5]. Global forklarlighed kan videre separeres i transparens [10], som man også kalder iboende, global forklarlighed, og post-hoc global forklarlighed [56]. Hvor transparens er en direkte egenskab, der er bygget ind i modellen, er post-hoc global forklarlighed som regel udført ved at bruge en metode, der forklarer hvilke mønstre, en model har lært [56].Lokal forklarlighed giver yderligere informationer og forklaringer om en enkelt models prædiktion. Ligesom ved global forklarlighed kan man igen adskille imellem iboende lokal forklarlighed og post-hoc lokal forklarlighed [10, 56].Global forklarlighedDatadrevne modeller, især dem baseret på maskinlæring og deep learning, er tit beskrevet som ugennemskuelige ''black boxes'', hvor det selv for eksperter er svært at forstå modellens indre logikker. Global forklarlighed kan forstås som en modsætning til en black box. Global forklarlighed er evnet til at forklare hele modellens logik og at følge dens beslutning hele vejen igennem fra input-data til modellens prædiktion [5]. Det kan opnås ved at bygge en model, der har iboende global forklarlighed (transparent) eller ved at bruge en post-hoc model til at forklare en black box-models logik.TransparensTransparens er defineret som evnen til direkte at forstå hele modellen. Algoritmer eller metoder til at generere en transparent model, kan man gruppere under ''transparent design'' [5].Men hvad er transparens egentlig? Z. C. Lipton beskriver forskellige typer af transparens: simulatibility (simulerbarhed), decomposability (nedbrydelighed) og algoritmisk transparens [10]:Følger man Liptons definition af transparens, er lineære regressionsmodeller, beslutningstræer og regel-baserede modeller alle sammen transparente, da man ''nemt'' kan forstå og beregne de underliggende mekanismer. Men disse modeller kan hurtigt blive store (antal af parametre, dybden og bredden af træet, antal af regler). Så hvornår er de små nok til stadig at gælde som global forklarlige? En mulighed for at undgå problemet er at tilføje begrænsninger i træningsprocessen, der minimerer størrelsen og kompleksiteten af modellen. Den strategi kan bruges både til ''enkle'' modeller, som lineære regressioner og beslutningstræer, men også til black box-modeller som neurale netværk [58].Transparens kan også defineres som en grad af transparens fra black box til fuld transparens, hvor nogle dele af modellen er transparente og nogen andre er uigennemskuelige.Post-hoc global forklarlighedPost-hoc global forklarlighed opnås ved at anvende metoder på black box-modeller for at gøre dem global forklarlige. For eksempel kan man vise, hvor meget forskellige input-variabler og deres værdier har indflydelse på modellens prædiktion (PDP [38], ICE [39], permutation test ).For dybe neurale netværk (DNN) ligesom convolutional neural networks (CNN) eller recurrent neural networks (RNN) (tit brugt sammen med billed- eller tekstdata), findes der særlige post-hoc metoder. Disse metoder prøver at ekstrahere, hvilke repræsentationer et dyb neuralt netværk har lært af data [40, 43, 44, 45, 46]. Repræsentationer er en implicit abstraktion fra den ''rå'' data (billede eller tekst), lært af de første lag af et netværk, for eksempel lag der genkender kanter i et billede [46]. Desuden findes der metoder til at undersøge, om modellen har lært bestemte koncepter [51].Disse typer af post-hoc globale forklaringsmetoder, der kan bruges til at få indsigt i black box-modellen ved at belyse dele af dens logik, kalder Guidotti et al. ''black box-inspektions''-metoder [5]. Det er dog ikke den eneste type af metoder til post-hoc global forklarlighed. Der findes også de såkaldte ''surrogat-model''-metoder.Surrogat-modellerSurrogat-model-metoder, eller model-forklaringsmetoder (model explanation) [5], bygger en model til at erstatte black box-modellen, hvor black box-modellen er brugt til prædiktioner og surrogat-modellen til at generere forklaringer. Sidstnævnte model skal virke på samme måde som den originale black box-model, altså generere prædiktioner så tæt som muligt på black box-modellens prædiktioner. Hvis det ikke er tilfældet, så forklarer denne model ikke black box-modellen, men kun sig selv. Selvfølgelig vil surrogat-modellen altid være forskellig, dvs. have en ringere performance en black box-modellen, da man ellers kunne erstatte black box-modellen fuldstændig med surrogat-modellen.Surrogat-modeller tager som regel form af de klassiske transparente modeller, ligesom lineære modeller [59], beslutningstræer [60, 61], eller regel-baserede modeller [62], men kan også være et simpel neuralt netværk [63].Lokal forklarlighedI de fleste tilfælde vil det være svært at bruge en transparent model til at opnå global forklarlighed, men det er tit nok til at forklare en bestemt prædiktion. Man kan faktisk argumentere for, at der skabes en mental repræsentation af modellen, når man interagerer med en model længe nok og samtidig får lokale forklaringer. Jo mere den mentale repræsentation afspejler den faktiske model, jo mere global forklarlig er modellen for brugeren.Forklaringer, der er genereret af lokal forklarlige metoder, kan være tekst, visualiseringer, eksempler i træningsdata eller feature attributions [10]. Ligesom med global forklarlighed kan man adskille mellem iboende lokal forklarlighed og post-hoc lokal forklarlighed [56].Iboende lokal forklarlighedModeller, der har iboende global forklarlighed, er som regel også lokal forklarlige, ligesom lineære modeller, beslutningstræer eller regel-basered modeller. Der findes dog også modeller, der opnår lokal forklarlighed ved at tilføje dele til en model, der genererer en forklaring [15, 52, 64], hvor forklaringer er en del af træningsdata [50], eller hvor selve konceptet er, at prædikationer er baseret på eksempler (k-NN ). I alle tilfælde er modellen bygget, så den genererer en forklaring sammen med en prædiktion.Når vi kigger på dybe neurale netværk, så kan man for eksempel tilføje særlige lag, der genererer (og lærer) forklaringer [15, 16, 52, 64, 65, 66]. Det kan være i form af eksempler eller prototyper [15, 16], koncepter [52], tekst [65] eller feature attribution [64, 66]. Og så findes der også en metode, der kombinerer neurale netværk, der hver især genkender dele af et billede til et beslutningstræ og dermed opnår forklarlighed (Neural-Backed Decision Tree ) [67].Post-hoc lokal forklarlighedMetoder til post-hoc lokal forklarlighed gør modeller forklarlige gennem en separat proces efter prædiktionen. Det ligner måden, den menneskelige hjerne virker på, hvor der er forskellige processer til at træffe en beslutning og at forklare den.Metoder til post-hoc lokal forklarlighed, også kaldt ''resultat-forklaring'' (outcome explanation) [5], kan fungere på forskellige måder. Det kan for eksempel være metoder, der arbejder primært med et eksempel-datasæt og modellens output til at finde lignende eller betydningsfulde eksempler [14, 18], eller metoder der finder counterfactuals [22, 23, 24, 25]. Andre metoder udnytter modellens struktur, f.eks. at det er et neuralt netværk [35, 36, 37], bruger idéen om shapley values [32, 68, 69], eller bygger en transparent model for et lokalt område [29, 34].Fordelen ved post-hoc lokal forklarlighed er, at man ikke behøver at pille ved selve modellen, og at mange metoder fungerer med forskellige typer af black box-modeller. Tit har de dog brug for adgang til modelstrukturen for at udnytte den til at generere forklaringer hurtigere og mere nøjagtigt.ModeltypeModeller, der er transparente eller har en iboende lokal forklarlighed, har en bestemt type. Det kan være lineære modeller, regel-baserede modeller, beslutningstræer, versioner af k-NN eller neurale netværk [15, 16, 52, 58, 64, 65, 66] eller kombinationer af det [67].Post-hoc metoder derimod virker i forbindelse med en black box-model til at gøre den forklarlig. Typen af model kan have en betydning for, hvilken post-hoc metode man kan bruge. De typer af black box-modeller, man typisk ser, er dybe neural netværk, enten med convolutional layers eller recurrent layers, ensemble-modeller bestående af beslutningstræer (Random Forest, Gradient Boosting [70, 71], eller ensemblemodeller sat sammen af forskellige andre typer af modeller.Der findes post-hoc metoder, der er model-agnostiske, dvs. de virker med alle typer black box-modeller, da de bare skal have mulighed for at få modellens resultater for et givent input [14, 24, 25, 29, 32, 39, 59]. Andre metoder er lavet specifikt til dybe neurale netværk [72, 73] og kræver, at man har adgang til selve netværket, da de udnytter netværksstrukturen [23, 36, 51, 63], bruger en lignende proces til at generere forklaringer, som man bruger til at træne af netværket [35, 37], eller viser hvad netværket har lært [40, 43, 44, 45, 46].Nogle metoder eksisterer kun til træ-baserede modeller eller er en variant af en model-agnostisk metode optimeret til træer [74], og andre kræver, at man har adgang til en gradient, man også bruger i træningsprocessen [18].TaksonomitræEfter vi nu har været inde over datatyper, typer af forklaringer og typer af XAI-metoder, samt hvordan nogle modeller er lavet til en bestemt type black box-modeller, vil vi nu give et overblik over forskellige XAI-metoder i form af et taksonomitræ.Træet viser ikke alle metoder, der findes, men metoderne er valgt, så de, så vidt muligt, afdækker alle typer af forklaringer, data og black box-modeller. Hvis der er flere metoder i en kategori, så har vi udvalgt den mest udbredte, bedst dokumenterede eller den metode, hvor der findes en god open source-implementering. For hver metode indikerer farverige kasser, hvilken type data de er egnet til, og farven af metoden viser, om de er til en bestemt type black box-model.Her kan du læse Christoph Molnars e-bog for hver metode.Tak for fordi du læste med!Dette synspunkt blev oprindeligt bragt i Medium.Bibliografi[1] Peter Jackson, Introduction to Expert Systems, Harlow: Addison-Wesley Longman, 1990.[2] A. Kofod-Petersen, J. Cassens og A. Aamodt, Explanatory Capabilities in the CREEK Knowledge-Intensive Case-Based Reasoner, Proceedings of SCAI 2008, pp. 28-35, 2008.[3] A. Aamodt og E. Plaza, Case-Based Reasoning: Foundational Issues, Methodological Variations, and System Approaches, AI Communications 7(1), pp. 39-59, 1994.[4] S. T. Mueller, R. R. Hoffman, W. Clancey et al., Explanation in Artificial Intelligence Systems: An Historical Perspective, Explanation in Human-AI Systems: A Literature Meta-Review, Synopsis of Key Ideas and Publications, and Bibliography for Explainable AI, DARPA XAI Program, pp. 43-70, 2019.[5] R. Guidotti, A. Monreale, S Ruggieri et al., A Survey Of Methods For Explaining Black Box Models, arXiv:1802.01933v3 [cs.CY], 2018.[6] B. Mittelstadt, C. Russell og S. Wachter, Explaining Explanations in AI, arXiv:1811.01439v1[cs.AI], 2018.[7] G. Ras, M. van Gerven og P. Haselager, Explanation Methods in Deep Learning: Users, Values, Concerns and Challenges, arXiv:1803.07517v2 [cs.AI], 2018.[8] A. Adadi og M. Berrada, Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI), IEEE Access 6, pp. 52138-52160, 2018.[9] M. Du, N. Liu og X. Hu, Techniques for Interpretable Machine Learning, arXiv:1808.00033v3[cs.LG], 2019.[10] Z. C. Lipton, The Mythos of Model Interpretability, arXiv:1606.03490v3 [cs.LG], 2017.[11] S. Chakraborty, R. Tomsett, R. Raghavendra et al., Interpretability of deep learning models: A survey of results, IEEE 2017 SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI, pp. 1-6, 2017.[12] G. Vilone og L. Longo, Explainable Artificial Intelligence: a Systematic Review, arXiv:2006.00093 [cs.AI], 2020.[13] B. Kim, R. Khanna og O. O. Koyejo, Examples are not enough, learn to criticize! Criticism for Interpretability, NIPS 2016, pp. 2280-2288, 2016.[14] K. S. Gurumoorthy, A. Dhurandhar, G. Cecchi et al., Efficient Data Representation by Selecting Prototypes with Importance Weights, arXiv:1707.01212 [stat.ML], 2019.[15] C. Chen, O. Li, C. Tao et al., This Looks Like That: Deep Learning for Interpretable Image Recognition, arXiv:1806.10574v5 [cs.LG], 28 december 2019.[16] S. O. Arik og T. Pfister, ProtoAttend: Attention-Based Prototypical Learning, arXiv:1902.06292 [cs.LG], 2019.[17] C. J. Cai, J. Jongejan og J. Holbrook, The Effects of Example-Based Explanations in a Machine Learning Interface, IUI '19, pp. 258-262, 2019.[18] P. W. Koh og P. Liang, Understanding Black-box Predictions via Influence Functions, arXiv:1703.04730 [stat.ML], 2017.[19] N. Papernot og P. McDaniel, Deep k-Nearest Neighbors: Towards Confident, Interpretable and Robust Deep Learning, arXiv:1803.04765 [cs.LG], 2018.[20] S. Wachter, B. Mittelstadt og C. Russell, Counterfactual Explanations without Opening the Black Box: Automated Decisions and the GDPR, arXiv:1711.00399 [cs.AI], 2017.[21] Tim Miller, Explanation in Artificial Intelligence: Insights from the Social Sciences, arXiv:1706.07269 [cs.AI], 2017.[22] R. K. Mothilal, A. Sharma og C. Tan, Explaining machine learning classifiers through diverse counterfactual explanations, FAT* 2020, pp. 607-617, 2020.[23] Y. Goyal, Z. Wu, J. Ernst et al., Counterfactual Visual Explanations, Proceedings of the 36th ICML, pp. 2376-2384, 2019.[24] S. Sharma, J. Henderson og J. Ghosh, CERTIFAI: Counterfactual Explanations for Robustness, Transparency, Interpretability, and Fairness of Artificial Intelligence models, arXiv:1905.07857 [cs.LG], 2019.[25] A. Dhurandhar, P.-Y. Chen, R. Luss et al., Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives, NIPS 2018, pp. 592-603, 2018.[26] C. Chen og C. Rudin, An Optimization Approach to Learning Falling Rule Lists, arXiv:1710.02572 [cs.LG], 2017.[27] H. Lakkaraju, S. H. Bach og J. Leskovec, Interpretable Decision Sets: A Joint Framework for Description and Prediction, KDD'16, pp. 1675-1684, 2016.[28] J. H. Friedman og B. E. Popescu, Predictive learning via rule ensembles, Ann. Appl. Stat. 2 (3), pp. 916-954, 2008.[29] M. T. Ribeiro, S. Singh og C. Guestrin, Anchors: High-Precision Model-Agnostic Explanations, AAAI 2018, 2018.[30] 
. Lou, R. Caruana, J. Gehrke at al., Accurate intelligible models with pairwise interactions, KDD'13, pp. 623-631, 2013.[31] B. Ustun og C. Rudin, Supersparse Linear Integer Models for Optimized Medical Scoring Systems, arXiv:1502.04269 [stat.ML], 2015.[32] S. M. Lundberg og S.-I. Lee, A Unified Approach to Interpreting Model Predictions, NIPS 2018, pp. 4765-4774, 2017.[33] M. Sundararajan og A. Najmi, The Many Shapley Values for Model Explanation, ICML 2020, 2020.[34] M. T. Ribeiro, S. Singh og C. Guestrin, ''Why should i trust you?'': Explaining the predictions of any classifier, KDD'16, pp. 1135-1144, 2016.[35] A. Shrikumar, P. Greenside og A. Kundaje, Learning Important Features Through Propagating Activation Differences, arXiv:1704.02685 [cs.CV], 2017.[36] R. R. Selvaraju, M. Cogswell, A. Das et al., Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization, ICCV'17, pp. 618-626, 2017.[37] S. Bach, A. Binder, G. Montavon et al., On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation, PLOS ONE 10(7): e0130140, 2015.[38] Jerome H. Friedman, Greedy Function Approximation: A Gradient Boosting Machine, The Annals of Statistics 29(5), pp. 1189-1232, 2001.[39] A. Goldstein, A. Kapelner, J. Bleich et al., Peeking Inside the Black Box: Visualizing Statistical Learning With Plots of Individual Conditional Expectation, Journal of Computational and Graphical Statistics, pp. 44-65, 2015.[40] C. Olah, A. Satyanarayan, I. Johnson et al., The Building Blocks of Interpretability, Distill, 2018.[41] H. Strobelt, S. Gehrmann, H. Pfister et al., LSTMVis: A Tool for Visual Analysis of Hidden State Dynamics in Recurrent Neural Networks, arXiv:1606.07461 [cs.CL], 2016.[42] L. Arras, F. Horn, G. Montavon et al., ''What is Relevant in a Text Document?'': An Interpretable Machine Learning Approach, arXiv:1612.07843 [cs.CL], 2016.[43] C. Olah, A. Mordvintsev og L. Schubert, Feature Visualization, Distill, 2017.[44] A. Nguyen, A. Dosovitskiy, J. Yosinski et al., Synthesizing the preferred inputs for neurons in neural networks via deep generator networks, NIPS 2016, pp. 3387-3395, 2016.[45] A. Karpathy, J. Johnson og L. Fei-Fei, Visualizing and Understanding Recurrent Networks, arXiv:1506.02078 [cs.LG], 2015.[46] M. D. Zeiler og R. Fergus, Visualizing and Understanding Convolutional Networks, arXiv:1311.2901v3 [cs.CV], 2013.[47] Bernhard Schölkopf, »Causality for Machine Learning, arXiv:1911.10500 [cs.LG], 2019.[48] Gary Marcus, The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence, arXiv:2002.06177 [cs.AI], 2020.[49] P. Clark, O. Etzioni, D. Khashabi et al., From 'F' to 'A' on the N.Y. Regents Science Exams: An Overview of the Aristo Project, arXiv:1909.01958 [cs.CL], 2019.[50] M. Hind, D. Wei, M. Campbell et al., TED: Teaching AI to Explain its Decisions, AIES'19, pp. 123-129, 2019.[51] B. Kim, M. Wattenberg, J. Gilmer et al., Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV), arXiv:1711.11279[stat.ML], 2017.[52] A. Ghorbani, J. Wexler, J. Y. Zou et al., Towards Automatic Concept-based Explanations,« NIPS 2019, pp. 9277-9286, 2019.[53] Y. Goyal, T. Khot, A. Agrawal et al., Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering, International Journal of Computer Vision 127, pp. 398-414, 2019.[54] R. Hu, J. Andreas, M. Rohrbach et al., Learning to Reason: End-To-End Module Networks for Visual Question Answering, ICCV 2017, pp. 804-813, 2017.[55] J. Mao, C. Gan, P. Kohli et al., The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences from Natural Supervision, arXiv:1904.12584 [cs.CV], 2019.[56] M. Nu, N. Liu og X. Hu, Techniques for Interpretable Machine Learning, arXiv:1808.00033v2 [cs.LG], 2018.[57] Adrian Weller, Challenges for Transparency, arXiv:1708.01870v1 [cs.CY], 2017.[58] Q. Zhang, Y. N. Wu, S.-C. Zhu, Interpretable CNNs, arXiv:1901.02413v1 [cs.LG], 2019.[59] S. Tan, R. Caruana, G. Hooker et al., Distill-and-Compare: Auditing Black-Box Models Using Transparent Model Distillation, AIES'18, pp. 303-310, 2018.[60] C. Yang, A. Rangarajan og S. Ranka, Global Model Interpretation via Recursive Partitioning, arXiv:1802.04253 [cs.LG], 2018.[61] O. Bastani, C. Kim og H. Bastani, Interpretability via Model Extraction, arXiv:1706.09773[cs.LG], 2017.[62] W. J. Murdoch og A. Szlam, Automatic Rule Extraction from Long Short Term Memory Networks, arXiv:1702.02540 [cs.CL], 2017.[63] A. Dhurandhar, K. Shanmugam, R. Luss et al., Improving Simple Models with Confidence Profiles, NIPS 2018, pp. 10296-10306, 2018.[64] E. Choi, M. T. Bahadori, J. A. Kulas et al., RETAIN: An Interpretable Predictive Model for Healthcare using Reverse Time Attention Mechanism, arXiv:1608.05745v4 [cs.LG], 2017.[65] K. Xu, J. Ba, R. Kiros et al., Show, Attend and Tell: Neural Image Caption Genereation with Visual Attention, arXiv:1502.03044v3 [cs.LG], 2016.[66] Amirhossein Tavanaei, Embedded Encoder-Decoder in Convolutional Networks Towards Explainable AI, arXiv:2007.06712 [cs.CV], 2020.[67] A. Wan, L. Dunlap, D. Ho et al., NBDT: Neural-Backed Decision Tree, arXiv:2004.00221[cs.CV], 2020.[68] K. Aas, M. Jullum og A. Løland, Explaining individual predictions when features are dependent: More accurate approximations to Shapley values, arXiv:1903.10464[stat.ML], 2019.[69] M. Sundararajan og A. Najmi, The many Shapley values for model explanation, arXiv:1908.08474 [cs.AI], 2019.[70] T. Chen og C. Guestrin, XGBoost: A Scalable Tree Boosting System, KDD'16, pp. 785-794, 2016.[71] G. Ke, Q. Meng, T. Finley et al., LightGBM: A Highly Efficient Gradient Boosting Decision Tree, NIPS 2017, pp. 3146-3154, 2017.[72] G. Montavon, W. Samek og K.-R. Müller, Methods for interpreting and understanding deep neural networks, Digital Signal Processing 73, pp. 1-15, 2018.[73] W. Samek, G. Montavon, A. Vedaldi, L. K. Hansen og K.-R. Müller (Eds.), Explainable AI: Interpreting, Explaining and Visualizing Deep Learning, Springer, 2019.[74] S. M. Lundberg, G. Erion, H. Chen et al., From local explanations to global understanding with explainable AI for trees, Nature Machine Intelligence 2, pp. 56-67, 2020.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2020-11-26
          &nbsp;·&nbsp; e80203c1
          &nbsp;·&nbsp; #30
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.981</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.725</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.54</kbd>
        </footer>
      </article>
      <article>
        <h4>Facebook åbner kildekoden til kunstig intelligens-værktøjer</h4>
        <div>
          Programmører kan nu selv lege med en række værktøjer til maskinlæring, som har gjort den sociale medie-virksomhed i stand til at udvikle store neurale netværk på kort tid.Af Elías Christian Lundström Tirsdag, 20. januar 2015 - 15:30Facebooks egen forskningsgruppe Facebook AI Research har frigivet kildekoden til en række udviklingsværktøjer, som selskabet selv har udviklet og bruger til maskinlæring. Det skriver det norske teknologiemedie Digi.no .Værktøjerne er moduler til Torch, som er et åbent kildekodebaseret rammenetværk for videnskabelig databehandling og maskinlæring.Facebooks værktøjer går samlet under navnet fbcunn og skulle efter sigende være hurtigere end standardmodulerne til Torch, hvilket har gjort det muligt for det sociale medie at træne større neurale netværk på kortere tid ifølge det norske medie.»Fremskridt inden for videnskab og teknologi accelereres, når forskere ikke bare deler deres resultater, men også deres værktøj og metoder,« skriver Facebook-forskeren Soumith Chintala i et blogindlæg .Værktøjerne er blandt andet optimeret til at bruge grafikprocessorerne til at bygge visse typer netværksmodeller, som man for eksempel bruger, når man skal behandle naturlige sprog.Torch bruges ifølge Facebook af både Google, AMD, Intel, Twitter og flere store akademiske institutioner.Via: Digi.noLæs ogsåFacebook lancerer beta-udgave af Facebook til arbejdet
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2015-01-20
          &nbsp;·&nbsp; e4c852c7
          &nbsp;·&nbsp; #31
          <br>
          <br>
            <kbd data-tooltip="Tech industry &amp; regulation">L02_BIGTEC&nbsp;0.698</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.614</kbd>
        </footer>
      </article>
      <article>
        <h4>Google forskere: Hårdt brug for bedre dokumentation af ML-modeller</h4>
        <div>
          Der eksisterer i dag ingen standarder for, hvordan udviklere dokumenterer de machine learning-modeller de træner og skabe. Hvad var modellens oprindelige formål? Hvad er dens begrænsninger? Disse spørgsmål bliver typisk ikke besvaret, når modellerne bliver frigivet til brug.Og det er et problem, mener et hold forskere fra Google. Særligt når modellerne bruges på områder, hvor de kan have alvorlig indvirkning på personers liv - som i sundhedssektoren samt inden for beskæftigelse, uddannelse og retsvæsen.Eksempler på systematisk bias i algoritmer er efterhånden talrige, skriver de ni forskere i en artikel, der i slutningen af denne måned bliver præsenteret på konferencen Fairness, Accountability and Transparency (ACM FAT* ) i Atlanta, USA.»However, these systematic errors were only exposed after models were put into use, and negatively affected users reported their experiences.« MIT-studerende Joy Buolamwini fandt f.eks. ud af, at kommercielle løsninger til ansigtsgenkendelse klarede sig signifikant dårligere på mørke kvinder end på hvide mænd.Men i dokumentationen for modellerne om deres performance og use cases er der meget lidt information om den type svagheder, bemærker forskerne.»This highlights the need to have detailed documentation accompanying trained machine learning models, including metrics that capture bias, fairness and inclusion considerations,« lyder konklusionen.Brug ikke denne model...Løsningen, som Google-forskerne foreslår, er en dokumentationsstandard, de har døbt Model Cards - én til to siders information om kritiske aspekter af ML-modellen. Informationen skal kunne bruges af brugere og udviklere såvel som lovgivere og personer, der måtte være påvirket af en ML-model og gerne vil forstå den bedre.»The proposal of &quot;Model Cards&quot; specifically aims to standardize ethical practice and reporting - allowing stakeholders to compare candidate models for deployment across not only traditional evaluation metrics but also along the axes of ethical, inclusive, and fair considerations,« skriver forskerne.Om forskningen:Artiklen 'Model Cards for Model Reporting'er skrevet af en række forskere ved Google.Forfatterne er Margaret Mitchell, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer, Inioluwa Deborah Raji og Timnit Gebru.Artiklen bliver præsenteret i slutningen af januar på Fairness, Accountability and Transparency (ACM FAT) i Atlanta, USA.»This goes further than current solutions to aid stakeholders in different contexts. For example, to aid policy makers and regulators on questions to ask of a model, and known benchmarks around the suitability of a model in a given setting.« Model-kortet, som forskerne foreslår, skal først og fremmest rumme basal information om modellen såsom dato og udviklere. Dette punkt bør også rumme information om træningsalgoritmer og parametre.Under punktet Intended Use anføres, hvilke brugere og use cases udviklerne forestillede sig under udvikling, samt hvilke uses case, man ikke anbefaler. Sidstnævnte element sammenligner forskerne med advarsler på legetøj og madvarer. En sådan varsel på en ML-model kunne f.eks. være &quot;Brug kun modellen på billeder i sort-hvid.&quot;Performance på tværs af køn og aldersgrupperUnder punktet Factors skal udviklere notere, hvordan modellen klarer sig på tværs af f.eks. befolkningsgrupper og miljøer. En analyse af et billede kan f.eks. være påvirket af kameraets hardware, lysforhold og - ikke mindst - personen på billedets køn, alder og race.DataTechArtiklen her er fra DataTech, et nyt PRO-medie fra Ingeniøren om data og analytics. Vi giver dig inspirerende cases, nyheder og debat om alt fra machine learning-modeller til dataetik.Følg med på pro.ing.dk/datatechModel-kortet skal desuden indeholde punktet Metrics, som skal rumme de parametre, som modellen er blevet bedømt efter og hvorfor. Dette vil variere mellem forskellige model-typer, bemærker forskerne - ligesom vurderingen af, hvilke paramtre, der er vigtige, vil afhænge af formålet og konteksten:»For example, in a surveillance scenario, surveillors may value a low false negative rate (or the rate at which the surveillance system fails to detect a person or an object when it should have). On the other hand, those being surveilled may value a low false positive rate (or the rate at which the surveillance system detects a person or an object when it should not have). We recommend listing all values and providing context about which were prioritized during development and why.« I forlængelse af de to punkter vil forskerholdet have, at hver model udstyres med en kvantitativ analyse, der viser, hvordan modellen så performer på de forskellige parametre for hver gruppe.Hvis algoritmen således skal gætte på om en person smiler - se eksempel længere nede - skal modelkortet vise, hvor godt den klarer sig på tværs af køn og aldersgrupper.Kan ikke stå aleneFor at gøre det muligt at verificere modellen, foreslår forskerholdet, at man deler datasættet som modellen er evalueret med. Tilsvarende vil modelkortet ideelt set indeholde så meget information om træningsdata, som der kan lade sig gøre.Endelig skal udviklere skrive, hvilke etiske overvejelser der følger med modellen, og hvilke forbehold de vil tage sig. Dette kan f.eks. handle om, hvorvidt modellen bruger følsom persondata, samt risici ved at bruge modellen.Selvom modelkortet kan øge transparens inden for machine learning-systemer, ser forskerne det ikke som sandsynligt, at værktøjet bliver gjort til en standard inden for den nærmeste fremtid.»It is therefore important to consider model cards as one transparency tool among many, which could include, for example, algorithmic auditing by third-parties (both quantitative and qualitative), &quot;adversarial testing&quot; by technical and non-technical analysts, and more inclusive user feedback mechanisms,« skriver forskerne.Denne artikel stammer fra PRO-mediet DataTech. Læs den fulde version her. (kræver abonnement)
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2019-01-24
          &nbsp;·&nbsp; e70def43
          &nbsp;·&nbsp; #32
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.939</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.64</kbd>
        </footer>
      </article>
      <article>
        <h4>Måske tænker computere bare bedre uden vores hjælp</h4>
        <div>
          Tag mennesket ud af modellen: Ny forskning indikerer, at det væsentligste succesparameter for kunstig intelligens ikke er selve computermodellen, men kolde træningsdata og rå computerkraft.BrødtekstGPT-3 kan skrive tekster, AlphaGo Zero kan spille Go, og AlphaFold 2 kan folde proteiner. Tre eksempler fra den nyeste forskning i kunstig intelligens (AI) på simple, minimalt forudindtagede modeller trænet på enorme mængder data og med enorme mængder computerkraft.Den markante succes for blandt andre disse modeller har rettet opmærksomheden mod et essay, som en af pionererne inden for såkaldt reinforcement learning tilbage i 2019 udgav på sin blog 'Incomplete Ideas':'The Bitter Lesson' hed essayet, og i det uddrog Richard Sutton, AI-forsker og manden bag den førende tekstbog i reinforcement learning, hvad han kaldte »den største læresætning fra 70 års AI-research,« nemlig at»generelle, skalerbare metoder i sidste ende er de mest effektive, og med en stor margin« i forhold til specialiserede modeller med en høj grad af menneskeligt input.En stor del af forklaringen er ifølge Richard Sutton Moores lov, der som bekendt siger, at antallet af transistorer, det er muligt at rumme i et integreret kredsløb, fordobles hvert andet år. En lignende eksponentiel lov kan siges at gælde for tilgængeligheden af data.Richard Suttons pointe er, at hvis vi antager, at både transistor- og datatilgængelighed vedbliver med at følge en eksponentielt opadgående kurve, vil det også i fremtiden være fornuftigt at basere vores modeller på metoder, der skalerer med computerkraft - og undlade at blande mennesker ind i oplæringen.En formel med stor succesIkke alle på området er enige med Richard Sutton - det vender vi tilbage til - men først kigger vi nærmere på en af de aktører, der har anvendt hans formel med stor succes.Google-ejede DeepMinds computerprogram AlphaGo slog i 2016 verdensmesteren Lee Sedol i det kinesiske spil Go. AlphaGo blev indledningsvist trænet mod menneskelige amatører og eksperter, men det var overgangen til self-play - en strategi, hvor computeren spiller mod sig selv - som sendte computerens præstationsevne på himmelflugt.Den logiske konklusion på udviklingen var programmet AlphaGo Zero. Med denne model fjernede forskerne alt menneskeligt input fra modellen. Med kun Go-reglerne som input, ugevis af læring via self-play og 5.000 såkaldte TPU'er - specialiserede kredsløb til neurale netværk - outperformede AlphaGo Zero alle tidligere modeller inklusive AlphaGo.Samme formel blev fulgt, da DeepMind i 2020 proklamerede at have løst det 50 år gamle proteinfoldningsproblem ved at opnå en score på over 92,4 i CASP-konkurrencen (Critical Assessment of protein Structure Prediction). Den nye model, AlphaFold 2, erstattede fysikkomponenten i AlphaFold 1 med ren mønstergenkendelse og firedoblede det proteinkorpus, der blev trænet på, relativt til forgængeren. AlphaFold 2 kunne derudover med sine 128 TPU'er trække på to størrelsesordenener mere computerkraft end Baker-gruppen, som blev 2'er i konkurrencen.Den måske mest demonstrative succes i nyere tid opnået ved rendyrket opskalering af simple modeller skal dog findes i firmaet OpenAI's GPT-chatbotter. Den oprindelige chatbot, GPT-1, krævede kostelig menneskelig håndkraft til annotering af data. Den væsentligt bedre præsterende GPT-2 var derimod funktionsdygtig udelukkende via ren usuperviseret læring, hvilket tillod en opskalering til 1,5 milliarder parametre.Den seneste model fra 2020, GPT-3, hvis output kun svært adskilles fra menneskeskrevet tekst, kan bryste sig af en model med hele 175 milliarder parametre. Konklusionen, vi kan drage af OpenAI's resultater, er, at skala i sidste ende opvejer for støj i datasættet.Ifølge Richard Sutton er vi dog endnu ikke gået vidt nok. Vi har endnu ikke »lært den bitre lektie, at det i det lange løb ikke hjælper at bygge vores ideer om, hvordan mennesker tænker, ind i vores modeller.« For selvom OpenAI og DeepMind har præsenteret succes på succes, mener Richard Sutton, at folkene bag kun modvilligt har trukket mennesket ud af modellerne. Hans tese er, at AlphaFold 2 givetvis kunne være skabt før AlphaFold 1, og AlphaGo Zero før AlphaGo. Data, computerkraft og den historiske viden om fortidens bitre resultater var synligt tilgængelige for forskerne.En twist på en vedvarende debatLangt fra alle forskere på området mener dog, at sagen er så simpel, som Richard Sutton fremlægger den.David Silver, Lead Researcher på AlphaGo-projektet, har i et interview med AI-forskeren Lex Fridman sagt, at det »lige fra starten var vores mål at bygge et system baseret udelukkende på self-play, og for os var menneskelige data et skridt, der kunne hjælpe os med at nå vores mål hurtigere.« Læs også: Dansk startup vil bygge ML med sund fornuft: Der er et fundamentalt problem i de metodologier, vi normalt brugerOgså datalogen Max Welling ser med skeptiske øjne på Richard Suttons tese. I et offentligt modsvar, 'Do we still need models or just more data and compute?', vedstår han, at det historisk set har været tilfældet, at vores modeller er blevet simplere, i takt med at øget computerkraft er blevet tilgængelig. Men så længe relevante data mangler, er specialiserede, fintunede modeller en nødvendighed, uanset computerkraft.»Måske kan en computer uden supervision lære en model med meget lidt indkodet menneskelig viden og med stor computerkraft. På den måde er jeg enig med Sutton,« skriver Welling.»Men vi kan ikke tale om nyttigheden af menneskeligt designede modeller uden også at tale om tilgængeligheden af data.« Richard Sutton på sin side ser kritikken fra Welling Max og David Silver som en misforståelse og uddyber over for Ingeniøren i en e-mail:»Den bitre erkendelse er ikke, at computerkraft er alt, der betyder noget, og at vi skal glemme alt om at forsøge at modellere verden. Den bitre erkendelse er, at metoder, som skalerer med computerkraft, er alt, der betyder noget.« Modellering af verden er altså stadig vigtig, mener han:»Det er bare maskinerne, der skal gøre det, og ikke os.« Læs også: Bayesian ML vs. aktiemarkedet: Det giver os meget information, når modellen ikke ved, hvad den skal gøreI sidste ende er det et spørgsmål om omkostninger. Vil det vise sig, at der er problemer, hvor det på sigt er mere omkostningstungt at lade en computer træne sig frem til en løsning på et problem, end det er at bruge menneskelig håndkraft til at indkode løsningen på problemet i modellen?Eller er der simpelthen modeller, som uanset datatilgængelighed og computerkraft er mere effektive at skrive i computersproget C end i et neuralt netværk?Én ting, man vel kan tage med i sine overvejelser, når man diskuterer dette spørgsmål, er diskonteringssatsen for læringsalgoritmer. Den menneskelige hjerne er det klareste eksempel. For selvom hjernen kører på blot 20 watt, er mængden af energi, evolutionen har brugt på træning af synapsforbindelser, enorm.Hvis samme gunstige omregning gør sig gældende for kunstige, neurale netværk, åbnes døren således for, at generelle læringsmodeller på sigt er de mest effektive over hele spektret af løselige problemer. Og ifølge et nyt studie fra OpenAI er effektiviteten af neurale netværk netop eksponentielt stigende.Richard Suttons logik hviler dog i sidste ende på en antagelse om, at Moores lov fortsætter. Selv er han sikker på, at vi endnu ikke har indhentet Moores lov. Vi har ganske simpelt ikke nået den fysiske grænse for, hvor små transistorer kan blive.»Pessimisterne har ikke fået ret endnu,« skriver Sutton i sit svar til Ingeniøren:»I sidste ende vil de få ret, men de vil tage fejl mange årtier endnu.« Mange er dog uenige med Richard Sutton i den vurdering, og det vil vise sig, om den bitre erkendelse er, at Sutton i sidste ende tager fejl. Det vil i så fald betyde, at vi ikke kan klare os uden omkostningstung menneskelig håndkraft foreløbig.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2021-03-15
          &nbsp;·&nbsp; e82af284
          &nbsp;·&nbsp; #33
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.965</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.736</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.617</kbd>
        </footer>
      </article>
      <article>
        <h4>Google bringer maskinlæring til mobilen</h4>
        <div>
          Googles kodebibliotek TensorFlow til maskinlæring flyttes til Android i Lite-udgaveNu kommer maskinlæring til Android-udviklerne. På den nyligt afholdte Google I/O-konference meddelte David Burke, som er én af Android-projektets udviklingschefer, at firmaets kodebibliotekTensorflow til maskinlæring og kunstig intelligens vil blive flyttet til mobilsystemet i en letvægtsudgave.Maskinlæring kan kræve store mængder af hukommelse og CPU-forbrug, noget som ikke spiller godt sammen med mobile enheders begrænsninger i kapacitet og batteri, med mindre den tunge databehandling foregår i skyen.Med Tensorflow Lite, som er optimeret til mobile enheder, bliver det muligt at skabe anvendelser som ellers ville være problematiske på små enheder.Mobil-hardware med indbygget AIIfølge Google vil Tensorflow Lite spille sammen med specifikke hardware-komponenter.»På sigt forventer vi at se DSP-chips som er specielt designet til behandling og træning af neurale netværk. Vi mener at disse nye funktioner vil hjælpe med til, på selve enheden, at drive den næste generation af talegenkendelse, visuel søgning, 'augmented reality,'«i modsætning til i skyen, siger David Burke.Tidligere på året meddelte chip-designeren Qualcomm at firmaet vil tilføje understøttelse af Tensorflow til deres kommende Snapdragon 835 mobilchip. Det skulle resultere væsentlige forbedringer i både afvikling samt strømforbrug af programmer med maskinlæring.Tensorflow blev udviklet som en del af Googles med henblik på maskinlæring og forskning i såkaldt dybe neurale netværk, men systemet er generelt nok til at kunne benyttes i en lang række sammenhænge.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2017-05-29
          &nbsp;·&nbsp; e6463684
          &nbsp;·&nbsp; #34
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.869</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.707</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.651</kbd>
        </footer>
      </article>
      <article>
        <h4>Maskinlæring kommer til mobilen: Googles Tensorflow klar til iOS</h4>
        <div>
          Machine learning kræver normalt en del regnekraft, men alligevel er Google nu klar med en udgave af Tensorflow til både Android og iOS.Googles software til machine learning, TensorFlow, er nu frigivet i den første næsten-færdige udgave til Apples mobilstyresystem iOS. Det skriver CNet.Google har i forvejen en udgave af Tensorflow til Android, og nu findes maskinlæringssoftwaren altså til de to største smartphone-platforme. Det er interessant, fordi machine learning normalt er en disciplin, der kræver betydelig regnekraft.Derfor har machine learning på smartphones normalt været afhængig af, at applikationerne har kunnet trække på maskinlæring i skyen. Sådan kommer det også primært til at foregå et stykke tid endnu til de mere krævende opgaver, men der findes visse typer oplæring af de neurale netværk, der kan foregå på en smartphone.Det kan eksempelvis være begrænset ansigtsgenkendelse eller andre opgaver med computer vision baseret på neurale netværk.TensorFlow er ét af en række populære open source-værktøjer til maskinlæring, som bliver brugt ikke bare af Google men af mange andre it-virksomheder og forskere. Ved at lave mobile udgaver af softwaren bliver det muligt for app-udviklere at inkludere neurale netværk i deres applikationer.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2016-06-09
          &nbsp;·&nbsp; e5bfc5e7
          &nbsp;·&nbsp; #35
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.841</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.807</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.688</kbd>
        </footer>
      </article>
      <article>
        <h4>Blogindlæg: Dybe neurale net</h4>
        <div>
          Som nævnt sidste gang er dybe net tidens hotte område inden for kunstig intelligens. Anvendelsen af dette sæt af maskinlæringsteknikker har løst mange problemer som fagfeltet har kæmpet med i mange år. Men hvad er de der dybe net egentlig, hvordan fungerer de, og hvad kan de bruges til? Jeg skal forsøge at give en kort introduktion. Specielt interesserede henvises til e.g. Schmidhubers eller Bengios oversigtsartikler.Dybe net er et sæt af metoder som alle deler den underliggende idé om at man kan lære et højt abstraktionsniveau af data ved at benytte mange lag af forbundne knuder som kan beregne ikke-lineære funktioner. Et klassisk, og efterhånden lidt banalt eksempel er at man kan træne et netværk til at genkende katte (højt abstraktionsniveau) fra pixler i et billede (lavt abstraktionsniveau). På vej fra pixler til kat vil lagene lære højere og højere abstraktionsniveauer.Dybe net er, som de fleste (hvis ikke alle) AI metoder, ikke en ny opfindelse som er opstået ud af det blå. Hvis vi vælger at ignorere alle de tidligere arbejder fra mange fagfelter som har været inspirationer, er det første eksempel på dybe net nok fra 1979 udført af Fukushima.Grunde til at dybe net har fået et renæssance er delvist at vi i dag har adgang til meget store datasæt og kraftige maskiner (typisk stakke af GPU-er). Men der er også sket en hel del metodeudvikling.Som nævnt sidste gang er kernen i flade net at man tager noget data som man så bruger til at træne sin model. Derefter bruger man denne model på ny og ukendt data. En af de store udfordringer er det at vælge hvilke inputparametre (features) man skal bruge. Dette refereres ofte til som -feature engineering-, er delvist en videnskab og delvist sort magi.I tillæg bruger flade net typisk overvåget læring (supervised learning), altså at man har et træningssæt bestående af kendte forbindelser mellem input og output (labelled dataset).Altså vil man have behov for et kendt træningssæt samt kunne udføre kunsten af feature engineering. Dette er ikke altid trivielt.De dybe net kan bruges til ikke-overvåget læring (og overvåget læring) som kan bruge store datasæt uden kendt klassificering (unlabelled) for at finde strukturer og mønstre i disse data. Eller mindske udfordringen med at vælge inputparametre (features). Generelt kan man sige at de er gode til mønstergenkendelse og feature- og repræsentationslæring.Hvordan fungere dybe net så?Lad os starte med knuderne i et netværk. De er af samme type som i flade net. Altså en ikke-lineær aktiveringsfunktion som oversætter inputværdier til outputværdier. Man starter med et inputlag og afslutter med et output lag. Hvor flade net typisk ikke har mange skjulte lag, vil et dybt net have rigtig mange.Man kan så træne dybe net, enten på fundamentalt samme måde som med flade net, altså som overvåget læring via f.eks. backpropagation. Man kan også vælge at gå for ikke-overvåget læring (unsupervised).Overvåget læring forsøger at forudsige en vektor, som er kendt i forvejen, ved a ud fra en matrix af input. Ikke-overvåget læring forsøger at finde mønstre som ikke er kendte i forvejen. F.eks. autoencoderen, som forsøger at lære at reproducere den samme matrix som bruges som input. Derfor har et sådan net samme antal inputknuder og outputknuder som størrelse på inputmatricen. De skjulte lag vil i sagens natur have færre knuder. Dette bliver et net med en klassisk timeglasform (se figur). Figuren viser et net som lærer at genkende håndskrift.Det virker fordi man træner vægtene i hvert lag. Hvert lag er en ikke-lineær kombination af laget over, og også en ikke-lineær projektion ind i færre dimensioner. En projektion ind i færre dimensioner kan man også betragte som en højere abstraktion (som med eksemplet med katte ovenfor).Dybe net er som nævnt et sæt af metoder, og de kommer derfor i mange afskygninger. Eksemplet ovenfor er, som nævnt, en bestemt version som kaldes en -autoencoder-. Der findes en helt række andre afskygninger, så som -convolutional net-, -deep belief network-, og -recurrent networks-.Teoretisk kan et feed-forward netværk med et skjult lag approksimere enhver funktion. Så man kan jo spørge sig hvorfor man skulle bruge et dybt net. Der er to argumenter for dette: det første er at et dybt net kan approksimere funktioner ved brug af færre knuder, det andet og måske bedre er at det er en langt mere praktisk løsning.
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2016-06-07
          &nbsp;·&nbsp; e5bee433
          &nbsp;·&nbsp; #36
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.993</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.993</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.71</kbd>
        </footer>
      </article>
      <article>
        <h4>Google tager specialudviklet 180 teraflops processor i brug til machine learning i skyen</h4>
        <div>
          Googles TensorFlow får nu specialbygget hardware til rådighed på Googles sky, som skal gøre det hurtigere at oplære machine learning-modeller på store datasæt.Oplæring af machine learning-modeller kan være ekstremt beregningstungt på modeller for store datasæt, og til tider er det endda ikke tilstrækkeligt at benytte grafikprocessorer for ekstra regnekraft. Det mener i hvert fald Google, som nu har tilføjet en specialbygget processor til selskabets cloud, der er optimeret til Googles Tensorflow-framework.Google Tensor Processing Unit. Foto: GoogleGoogle har selv tidligere brugt den specialbyggede processor, men nu bliver den næste videreudvikling altså tilgængelig som en del af Google Compute Engine, hvor man vil kunne købe kapacitet på Tensor Processing Units (TPU), ligesom det er muligt at blande dem med almindelige processorer og grafikprocessorer, oplyser Google i et blogindlæg.Ifølge Google har hver af disse TPU'er en regnekraft svarende til 180 teraflops, og de er samlet i'pods', der til sammen har en regnekraft på 11,5 petaflops. Det er i princippet nok til at være i top 10 for supercomputere, men tallene for en TPU eller GPU er ikke direkte sammenlignelig med den generelle kapacitet for en ægte supercomputer.TPU-erne optimeret Tensorflow-frameworkTPU'erne er optimeret til oplæring af machine learning-algoritmer og specifikt Googles eget Tensorflow-framework.At der er forskel på regnekraften ved denne type specialiserede processorer og en supercomputer afspejler sig blandt andet i, at Googles næste skridt er at opdatere infrastrukturen i selskabets cloud-datacentre for at storage og netværk kan følge med.De kraftige, specialiserede processorer skal fodres med store datasæt, og Googles plan med TPU'erne er, at de skal gøre det muligt at oplære machine learning-modeller hurtigt på meget store sæt af produktionsdata.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2017-05-18
          &nbsp;·&nbsp; e6429bd7
          &nbsp;·&nbsp; #37
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.683</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.578</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.672</kbd>
        </footer>
      </article>
      <article>
        <h4>Transfer learning hos Amazon: Alexa lærer japansk af engelsk sprogdata</h4>
        <div>
          For Amazons digitale assistent Alexa er evnen til at erobre nye markeder mere eller mindre lig evnen til at lære nye sprog.Men god sprogdata til at træne de neurale netværk er notorisk svære eller dyre at få fat på, hvorfor Alexa-udviklerne har kastet deres kræfter på transfer learning. Med andre ord at lade systemet overføre viden om ét sprog til et andet sprog for at lære det hurtigere og bedre.Strategien er effektiv, fortæller Research &amp; Development Program Manager ved Amazon Alexa AI Lucie Flekova på konferencen Women in Data Science, der fandt sted i sidste uge.»Cross lingual transfer learning er brugbart i både lille og stor skala, kan forbedre præstationen både på sætnings- og ordniveau, og det kan i vores tilfælde spare os mere end halvdelen af træningsdata,« siger Lucie Flekova om erfaringerne indtil videre.Relateret jobannonce: Data business analystFra stort til lille datasætTransfer learning er typisk brugbar i situationer, hvor du har et stort datasæt og et datasæt, der i sig selv er for lille til at træne en model.»Det store datasæt hjælper dig med at lære noget, og overføre det til det mindre datasæt uden at lære det igen,« forklarer Lucie Flekova.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2019-05-02
          &nbsp;·&nbsp; e72ea4ec
          &nbsp;·&nbsp; #38
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.959</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.908</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.616</kbd>
        </footer>
      </article>
      <article>
        <h4>Booz Allen lancerer 'app store' til AI</h4>
        <div>
            Booz Allen Hammilton er i færd med at lancere en markedsplads for AI-software i stil med en app-butik. Konsulentfirmaet kalder platformen for Modzy, skriver Fortune Modzy vil rumme prætrænede AI-modeller til specifikke opgaver så som at genkende bygninger i luftfotos, og de vil være tilgængelige under en simpel licens, hvor man betaler efter brug, skriver mediet. Redaktionen
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2019-11-06
          &nbsp;·&nbsp; e76d7c37
          &nbsp;·&nbsp; #39
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.67</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.799</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.672</kbd>
        </footer>
      </article>
      <article>
        <h4>Forskere skaber syntetiske træningsdata med deep learning</h4>
        <div>
          En af de store udfordringer ved at bruge deep learning i sundhedssektoren er mangel på pålidelige data til at træne de neurale netværk. Det forsøger forskere nu at løse ved at bruge Generative Adversarial Networks (GAN) til at generere syntetiske hjernescanninger til træningsdata.Udfordringen med træningsdata er ikke kun et spørgsmål om datasættets størrelse, lyder budskabet fra forskerholdet, der er sammensat af eksperter fra NVIDIA, Center for Clinical Data Science i Boston og Mayo-klinikken i Rochester, Minnesota.»Data-diversitet er kritisk for succesen, når det handler om at træne deep learning-modeller,« fremgår det af forskningsartiklen, der udkom i sidste uge.Datasæt med medicinske billeder er ofte ubalancerede, fordi antallet af billeder, der reelt indikerer sygdom, generelt er sjældne. Når modellen skal trænes, er der således ganske få datapunkter, der viser, hvad den reelt skal lede efter.Løsningen er ofte at sætte læger til at optegne billeder for at lave et datasæt, der kan lære en algoritme at segmentere et billede - f.eks. for at skelne mellem tumor og rask væv.Men det er en krævende metode, påpegede Nicola Rieka, der arbejder med deep learning i sundhedssektoren hos NVIDIA, da hun gæstede konferencen Nordic.AI Health i sidste uge.»I computer vision kan du få enhver til at udpege et objekt - her er en hund, her er en kat. I sundhedssektoren er det ikke så nemt. Hvis du skal markere en tumor, skal du bruge en ekspert, hvilket gør det dyrere,« sagde hun.Automatiseret og billigI GAN bruger man to deep learning-netværk: en generator og en diskriminator.Generatoren trænes til at producere den syntetiske data - i dette tilfælde en falsk hjernescanning komplet med såkaldt grey matter. Diskriminatoren har efterfølgende til opgave at gætte, om scanningen er ægte eller syntetisk.På den måde kan de to modeller træne hinanden. Resultatet er en metode til at fabrikere 'anormale' hjernescanninger, som ellers skulle optegnes manuelt.»Dette giver en automatiseret, billig kilde til forskelligartede data, der kan bruges til at supplere træningssættet,« skriver forskerne, der har anvendt PyTorch-frameworket sammen med to offentligt tilgængelige datasæt med hjernescanninger - ADNI og BRATS15 Challenge.»For eksempel kan vi ændre en tumors størrelse, ændre dens placering eller placere en tumor i en ellers sund hjerne for systematisk at have billedet og den korresponderende annotation.« Ingen privacy-problemer med falsk dataDen falske data kan ikke stå alene, understreger forskerne, der har fået de bedste resultater ved først at træne modellen på 100 procent syntetisk data og efterfølgende fintune med omkring 10 procent af den ægte data tilfældigt udvalgt. Her kan modellen måle sig med en model udelukkende trænet på ægte hjernescanninger.»I dette tilfælde leverer den syntestiske data en slags for-træning, hvilket efterfølgende kræver langt mindre 'ægte' data for at opnå en sammenlignelig performance,«  står der i artiklen.Det kan igen betyde, at man, selv hvis man som klinik kun har begrænsede data til rådighed, stadig kan have succes med at træne en deep learning-model. Under normale omstændigheder ville det være vanskeligt at hente data andre steder fra pga. de naturlige krav til databeskyttelse og privacy.Men da de syntetiske data ikke er knyttet til en bestemt person, er der i sagens natur ingen personer bag hjernescanningen, og data kan derfor uden problemer deles med andre forskere og hospitaler.Du kan se koden til forskernes GAN på GitHub.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2018-09-20
          &nbsp;·&nbsp; e6e79ea6
          &nbsp;·&nbsp; #40
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.99</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.993</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.624</kbd>
        </footer>
      </article>
      <article>
        <h4>Lingvistisk går forud for machine learning hos tekstanalyse-specialist</h4>
        <div>
          For tiden kan man få indtryk af, at maskinlæring er svaret på det meste. Det kan utvivlsomt bruges til meget, men samtidig er maskinlæring ofte afhængig af store datamængder. Det har man ikke altid, for eksempel når målet er at hente viden ud af ustrukturerede data, for eksempel dokumentsamlinger i relativt små virksomheder.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2018-11-20
          &nbsp;·&nbsp; e6faf228
          &nbsp;·&nbsp; #41
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.819</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.792</kbd>
            <kbd data-tooltip="New technologies">L80_NEWTEC&nbsp;0.593</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.746</kbd>
        </footer>
      </article>
      <article>
        <h4>Det sværeste problem i Machine Learning</h4>
        <div>
          En af de helt store udfordringer inden for Machine Learning er, hvordan man laver et produkt af noget, der lever på en laptop, mener Anders Bogsnes, der er Tech Lead for Analytics og Machine Learning ved Alm. Brand. Han gennemgår her, hvordan Alm. Brand arbejder med udfordringen.En af de sværeste problemer indenfor machine learning er ikke, hvordan man træner den nyeste ''state of the art'' Deep Learning model, eller hvordan man tuner sin gamle churn model - det er, hvordan man tager noget, der lever på en laptop og laver et produkt ud af det.Jeg kommer til at gennemgå den ''typiske'' deployment og sammenligne med den løsning, vi arbejder med i Alm Brand.''Over muren'' deployment modellenDen ''typiske'' workflow starter med, at dine datascientists finder et problem, de synes er spændende. De har fundet noget nyt data, bruger en måned på at tune, træne og teste og ender op med en model, de er tilfreds med. Så bliver den smidt ''over muren'' til IT, der får opgaven med at produktionssætte modellen. Denne fremgangsmåde har et par problemer:Problem 1: SprogbarrierenIT arbejder typisk ikke i samme sprog som dine datascientists - det er typisk Java, C++ eller lignenede ''enterprise'' sprog, mens machine learning typisk sker i Python eller R. Så for at kunne produktionssætte modellen, så skal modellen kodes om til noget der passer ind i ITs deployment processer, vel og mærke uden at ændre i hvordan modellen fungerer.Problem 2: Produktionsklar kodeMange datascientists kommer fra en akademikerbaggrund - statistikere, forskere, geologer osv. De har ikke nødvendigvis en software engineering baggrund, og fokus er mere på optimere modellen end at gøre koden produktionsklar.Best practice ifht funktioner, DRY, SOLID, unittesting, CI og andre flotte forkortelser, som software engineers tager som en selvfølge, er ikke nødvendigvis fulgt. Før modellen kan sættes i produktion, så er man nødt til at implementere disse best practice, ellers risikerer man at ende op med en kodebase, ingen kan navigere rundt i.Problem 3: UdviklingshastighedDatascience er en iterativ proces, og man kan hele tiden finde små forbedringer til modellerne. IT investerer en masse ressourcer i at omkode modellen i Java, implementeret unittests og ellers gjort koden produktionsklar.Måneden efter kommer datascience teamet tilbage og siger, at de nu har forbedret modellen med 0.5 ROCAUC, og kan vi ikke implementere denne nye model? Det bør være en positiv ting at man forbedrer sine modeller løbende, men det bliver hurtig en negativ oplevelse, hvor man hele tiden skal afveje, om forbedringen er værd omkostningen.Alm Brands deployment modelVi har valgt at angribe denne problemstilling fra nogle forskellige vinkler:Løsning 1: Hele stacken i PythonEn af fordelene ved at vi koder modeller i Python, er, at vi har tilgang til mange ''produktionsressourcer''. Det betyder, at vi kan kode hele stacken i Python, fra model til API. Ved at bruge Docker er det nemt at levere en færdigindpakket model til produktion, hvor datascience-teamet kan styre hele processsen fra start til slut - IT skal bare starte en ny container, de behøver ikke at bekymre sig om, hvad der er indeni. Datascience teamet tager nu ejerskab for modellen og dens udvikling, mens IT tager ejerskab for drifting af server og lignende.Løsning 2: Byg vores eget ML frameworkFor at drive best practice så har vi bygget vores eget framework, der standardiserer best practice for teamet.Vores framework er bygget ovenpå scikit-learn, så det er nemt og kendt materiale for datascientists og indeholder mange af de læringer, vi har gjort indenfor machine learning.Når vi tester f.eks en ny metode for feature selection, så testes det på ''Data science måden'' - eksperimenter for at afgøre om det skaber en reel forbedring i modelperformance. Når vi er enige i, at det er den korrekte måde at lave feature selection på, så opdaterer vi frameworket til at indeholde denne nye funktionalitet. Nu er vi i ''produktionskodemodus'', hvor vi sørger for at skrive en omfattende testsuite, vi skriver dokumentation, vi kigger på optimeringer som parallelisering, og det arbejdes ind i et sammehængende API, så det er genkendeligt og kompatibelt med resten af vores kodebase.Den sidste viktige komponent er, at det er datascience teamet selv, der skriver og vedligeholder vores framework. Det er slutbrugeren, der bestemmer, hvordan skal APIet se ud, hvilke features der skal prioriteres, og hvilke bugs der bør løses først. Det giver også en forståelse for software engineering verden, så datascientist teamet får et bedre fundament indenfor kodning, og hvordan det kan gøres bedre.På denne måde får vi det bedste af begger verdener - den hurtige eksperimentering, men også den bundsolide implementering.Løsning 3: StandardiseringVed at bruge vores eget framework får vi også den kæmpe fordel, at vi standardiserer API til modellerne. Det gør, at når vi skal produktionssætte vores modeller, så starter vi ikke forfra i at definere, hvordan modellen skal tilgå data, eller hvordan REST apiet skal spørge om en prædiktion - det er det samme hver gang. Det gør, at vi kan standardisere resten af vores pipeline og give kontrollen end-to-end til datascience teamet. Så når teamet næste måned laver en bedre model, så behøver vi ikke balancere gevinsten af den bedre model mod kosten af implementation - vi pusher bare den nye model til master, og CI serveren bygger en ny model og sætter den i produktion!KonklusionFor at undgå ''Over Muren'' deployment modellen anbefaler vi følgende:Ved at inddrage datascience teamet i at bygge sine egne værktøjer og bruge ITs ekspertise til at standardisere og drifte bliver modelprocessen bliver smidigere, og vi kan agere hurtigere. Best practice for modellering bliver standardiseret og testet ved at samles i frameworket, så man ikke genimplementerer den dybe tallerken på fem forskellige måder.Datascience teamet skal ikke være software engineers, men en forståelse for best practice og end-to-end processen vil gøre produktionssætning meget smidigere og modellerne mere robuste.Standardiser løsningerJo mere der kan standardiseres i deployment processen, jo hurtigere kan man iterere og prøve ting af - det bedste eksperiment gøres live!Dette synspunkt blev oprindeligt bragt på Anders Bogsnes egen blog.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2020-12-01
          &nbsp;·&nbsp; e803b3b3
          &nbsp;·&nbsp; #42
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.997</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.91</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.611</kbd>
        </footer>
      </article>
      <article>
        <h4>Deep learning erstatter dyre objektiver hos Novo Nordisk</h4>
        <div>
          Tungt, kompleks og dyrt. Det er tre ord, som oftest går igen, når talen falder på visionsystemer til kvalitetskontrol i industrien. Det er uanset, om man skal finde fejl på små metalkomponenter til bilindustrien eller insulinpenne til diabetespatienter. Alle tænkelige fejl skal findes og sorteres fra, før produktet ender hos slutbrugerne.Den teknologi-beskrivelse bliver i disse tider kraftigt udfordret af nye visionsystemer, der er baseret på deep learning i stedet for mere klassiske regelbaserede computervision-algoritmer.Et af de systemer er udviklet af danske software-virksomhed Criterion AI, som arbejder inden for den farmaceutiske industri og blandt andet hjælper Novo Nordisk med at effektivisere kvalitetskontrollen med billedgenkendelse.»I dag føder man emnerne ind i store vision-maskiner, hvor der sidder 5-6 kameraer, der tager billeder, der så køres ind i klassiske computervision-algoritmer. De er ikke altid stærke nok til at finde alle fejl, og det forsøger man at kompensere for med meget dyre objektiver og ved at bruge mange ressourcer på at skabe det bedst mulige lys. Målet er at kontrollere billedprocessen, så billederne bliver så knivskarpe og dermed nemmere at genkende for algoritmerne,« fortalte Sebastian Brandes, medstifter af Criterion AI, på konferencen Big Data, AI &amp; Analytics - Hvad skal vi med al den data, som Dansk Automationsselskab afholdt tidligere i maj.Det gør industrielle visionsystemer komplekse og dyre. Men hvis man kan forbedre algoritmerne, der genkender billeder, så behøver man måske ikke dyre objektiver til kameraer og perfekt lyssætning på fabriksgulvet.»Vi arbejder med en mere datapræget tilgang, hvor algoritmerne er stærkere, og så har vi ikke samme høje krav til billederne. Det betyder, at man kan bruge billigere og mindre kameraer, der kan sættes op i selve produktionsmiljøet,« sagde Sebastian Brandes.Criterion AI bruger deep learning, en serie algoritmer der er bedre i stand til at lære mønstre ud af rå data end mere konventionelle machine learning-algoritmer, hvor algoritmerne skal trænes manuelt på forhånd.Men det lyder næsten som en lidt for god salgstale, når man vil øge kvaliteten for færre ressourcer.Kraftige grafikkort genopliver gamle algoritmerDet er ikke, fordi Criterion AI eller andre virksomheder, der udvikler nye løsninger baseret på kunstig intelligens, har udviklet vidunder-algoritmer fra den ene dag til den anden. Faktisk er det snarere en række af teknologiske fremskridt inden for hardware, der har revitaliseret deep learning-metoderne.De matematiske modeller, der ligger bag deep learning-algoritmerne, blev nemlig udviklet for over 30 år siden. Men mangel på processorkraft og datasæt satte en stopper for udbredelsen af algoritmerne.»I slutningen af 80'erne havde man ikke den nødvendige computerkraft og digitale data til at køre algoritmerne, og gejsten omkring deep learning døde delvist i 90'erne. Det var først, da chip-producenten Nvidia lancerede et nyt grafikkort og udviklerværktøjet Cuda i 2007, at deep learning fik et nyt gennembrud,« fortalte Sebastian Brandes.Det var altså ny hardware, i form af chips, der har boostet brugen af deep learning.»Grafikkort er blevet så stærke, at selvom vi banker 3.000 billeder ind i minuttet på en server, så kommer grafikkortet ikke over 52 grader. For selvom de kraftige grafikkort ikke kan så meget som et traditionelt CPU, så er de er vanvittigt gode til at lave matrix-operationer parallelt, så man kan træne neurale netværk på meget kort tid. Og det er vigtigt til billedanalyse i industrien,« fortalte Sebastian Brandes.Den store forskel på klassisk machine learning og deep learning er, at man med machine learning skal bruge mere tid på at forberede sine produktionsdata, før de kan smides ind i en algoritme, der kan afgøre, om produktet er godkendt eller skal kasseres.»Med deep learning skal man lave langt mindre præ-processering, og vi kan føde rådata ind, uden at vise algoritmen hvad sammenhængen er,« sagde Sebastian Brandes.
        </div>
        <footer>
          <em>Pro.ing.dk/industrytech</em>
          &nbsp;·&nbsp; 2019-05-14
          &nbsp;·&nbsp; e7327cb4
          &nbsp;·&nbsp; #43
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.994</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.864</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.651</kbd>
        </footer>
      </article>
      <article>
        <h4>Dataminimering og privacy-bevarende teknikker i AI-systemer</h4>
        <div>
           Generelt kræver AI-systemer store mængder data. Men organisationer skal også overholde 'minimeringsprincippet' under databeskyttelseslovgivningen, hvis de bruger personlige data. Det betyder, at de skal sikre, at alle personlige data er tilstrækkelige, relevante og begrænset til det, der er nødvendigt til det formål, de processeres til. Hvad der er tilstrækkeligt, relevant og nødvendigt i relation til AI-systemer vil afhænge af use-casen. Der er dog flere teknikker, som organisationer kan benytte sig af i udviklingen af AI-systemer, der processerer så få personlige data som muligt, men stadig er funktionelle. I dette blogindlæg ser vi på nogle af de mest relevante teknikker til superviserede machine learning (ML)-systemer, som i øjeblikket er den mest brugte type AI. Internt i en organisation bliver de personer, der er ansvarlige for risikohåndtering og compliance, når det gælder AI-systemer, nødt til at være opmærksomme på, at sådanne teknikker eksisterer, og de skal kunne diskutere forskellige tilgange med deres tekniske medarbejdere. Default-tilgangen, som data scientists har, når de designer og bygger AI-systemer, betyder, at de ikke nødvendigvis vil tage dataminimeringsbegrænsninger i betragtning. Organisationer skal derfor have praksisser relateret til risikohåndtering på plads for at sikre, at dataminimeringskrav og alle relevante minimeringsteknikker er indtænkt fra designfasen eller - hvis AI-systemerne købes eller opereres af tredjeparter - som en del af den rettidige omhu i indkøbsprocessen. Men dataminimeringsteknikker vil ikke helt udrydde risici. Og mens nogle teknikker ikke vil kræve kompromiser for at levere dataminimeringsfordele, så vil andre kræve, at organisationer balancerer dataminimering med anden compliance eller brugsmål, f.eks. at lave mere nøjagtige og ikke-diskriminerende ML-modeller. Det første skridt, organisationer bør tage mod overholdelse af dataminimering, er at forstå og kortlægge alle de ML-processer, i hvilke personlige data kan blive brugt. Sådan bruges personlige data i ML-modeller Superviserede ML-algoritmer kan trænes til at identificere mønstre og skabe modeller ud fra datasæt ('træningsdata'), hvilket inkluderer tidligere eksempler på den type tilfælde, modellen vil blive bedt om at klassificere eller forudsige. Specifikt indeholder træningsdataene både 'mål-variablen', altså det, som modellen stiler mod at forudsige eller klassificere, og forskellige 'forudsigelses'-variabler, f.eks. det input, der bruges til at lave forudsigelsen. For eksempel kan forudsigelsesvariablen i træningsdataene for en banks ML-model om kreditrisiko inkludere alderen, indkomsten, stillingen og lokationen for forskellige kunder, mens målvariablen er, om kunderne tilbagebetalte deres lån eller ej. Når ML-systemerne først er trænet, kan de klassificere og lave forudsigelser baseret på nye data, der indeholder eksempler, som systemet aldrig har set før. En forespørgsel (query) bliver sendt til ML-modellen, og den indeholder forudsigelsevariablerne for et nyt tilfælde (f.eks. en ny kundes alders, indkomst, stilling mv.) Modellen svarer med sit bedste gæt mht. målvariablen for dette nye tilfælde (f.eks. om kunden vil tilbagebetale sit lån). Superviserede ML-tilgange bruger derfor data i to hovedfaser: Træningsfasen, hvor data bruges til at udvikle modeller baseret på tidligere eksempler, og Følgeslutningsfasen, hvor modellen bruges til at lave en forudsigelse eller klassificering af nye tilfælde Hvis modellen bruges til at lave forudsigelser eller klassificeringer af individer , så er det meget sandsynligt, at personlige data vil blive brugt i både trænings- og følgeslutningsfasen. Teknikker til at minimere personlige data Når data scientists designer og bygger ML-applikationer, vil de generelt formode, at al data, der bruges i træningen, testen og operationen af systemet, vil være indsamlet centralt og beholdt i sin fulde og originale form af en enkelt enhed gennem hele AI'ens livscyklus. Men der er faktisk forskellige tilgange og flere teknikker, som kan bruges i stedet, og som minimerer den mængde data, en organisation har brug for for at indsamle og processere, eller minimerer, i hvor høj grad dataene er identificerbare i forhold til bestemte individer. Dataminimering i træningsfasen Udvalg af oplysninger Som vi har forklaret, involverer træningsfasen en læringsalgoritme til et datasæt, der indeholder et sæt oplysninger ('features') for hvert individ, som bruges til at generere forudsigelsen eller klassificeringen. Men ikke alle oplysninger inkluderet i et datasæt vil nødvendigvis være relevante for opgaven. For eksempel vil ikke alle finansielle og økonomiske oplysninger være brugbare i forhold til at forudsige en kreditrisiko. Der er flere forskellige standardmetoder til at udvælge oplysninger , som data scientists bruger til at vælge oplysninger, som vil være brugbare at inkludere i en model. Disse metoder er 'good practice' i data science, men er også i nogen grad et skridt på vejen til at overholde dataminimeringsprincippet. Som man kan læse i en tidligere rapport (PDF) fra ICO (Information Commissioner's Office, den britiske databeskyttelsesvagthund, red. ) om AI og big data, er det faktum, at nogle data senere i processen kan vise sig brugbare til at lave forudsigelser, ikke nok til at fastslå nødvendigheden af det aktuelle formål, og det retfærdiggør heller ikke med bagudvirkende kraft indsamling, brug eller lagring af data. Privacy-bevarende metoder Der er også flere teknikker, som bevarer privacy, og som kan bruges til at minimere dataprocessering i træningsfasen. Nogle af disse teknikker involverer modificering af træningsdataene for at reducere, i hvor høj grad de kan spores tilbage til specifikke individer, mens de stadig er brugbare i forhold til at træne velpræsterende modeller. Dette kunne f.eks. involvere tilfældig ændring af datapunkters værdi - det kendes også som 'forstyrrelse' af data eller at føje 'støj' til data - på en måde, der bevarer nogle af disse oplysningers statistiske egenskaber (se f.eks. Rappor-algoritmen) Disse typer privacy-bevarende teknikker kan anvendes på træningsdataene, efter de allerede er blevet indsamlet. Men når det er muligt, bør de anvendes før indsamlingen af personlige data for at undgå, at der overhovedet skabes store personlige datasæt. For eksempel er automatiske tekstforudsigelser i smartphones baseret på de ord, brugeren tidligere har skrevet. Frem for altid at indsamle en brugers faktiske tastaturtryk kunne systemet designes til at skabe 'støjende', altså falske ord, tilfældigt. Dette ville betyde, at en organisation ikke ville kunne være sikker på, hvilke ord der var 'støj', og hvilke der faktisk blev skrevet af en specifik bruger. Selv om data ville være mindre nøjagtige på individniveau, kunne mønstre stadig opfanges og brugt til at træne ML'er på indsamlingsniveau. Hvor effektive disse privacy-bevarende teknikker er, når det gælder balancen mellem individers privatliv og brugbarheden af et ML-system, kan måles matematisk ved at bruge en metode som 'differential privacy'. Det er en måde, hvorpå man kan måle, om en model skabt af en ML-algoritme er afhængig af dataene for ethvert individ, der bruges til at træne det. En relateret privacy-bevarende teknik er 'federated learning' (forbundet læring). Dette gør det muligt, at flere forskellige parter træner deres modeller på deres egne data ('lokale' modeller) og så kombinerer nogle af de mønstre, som disse modeller har identificeret (kendt som 'gradienter'), til en enkelt, mere nøjagtig 'global' model uden at skulle dele træningsdata med hinanden. Federated learning er ret nyt og har flere storskala-egenskaber. Disse inkluderer automatisk rettelse og tekstforudsigelser i smartphones, men også i forhold til medicinsk forskning, der involverer analyser på tværs af flere patientdatabaser. Mens det at dele gradienten, der er opnået med en lokalt trænet model, betyder en lavere privacy-risiko end at dele selve træningsdataene, kan en gradient stadig afsløre personlig information relateret til dataobjekterne, den kom fra, især hvis modellen er kompleks med en masse finkornede variabler. Data controllere vil derfor stadig skulle vurdere risikoen for re-identificering. Ved federated learning vil deltagende organisationer højst sandsynligt bliver anset som værende fælles data controllers, selv om de ikke har adgang til hinandens data. Minimering af personlige data på følgeslutningsstadiet For at lave en forudsigelse om eller klassificering af et individ behøver ML- modeller sædvanligvis et fuldt sæt forudsigelsesvariabler for personen, der skal være med i forespørgslen. Ligesom i træningsfasen er der flere forskellige teknikker, som kan bruges til at minimere data på følgeslutningsstadiet. Her dækker vi et par af de mest lovende tilgange. Konvertering af data til mindre let forståelige ('human readable') formater I mange tilfælde kan processen med at konvertere data til et format, hvor de kan klassificeres af en model, bringe dem flere skridt på vejen mod at minimere dem. Rå personlige data vil som oftest først skulle konverteres til et mere abstrakt format, hvis der skal forudsiges på dem. For eksempel ville letforståelige ord normalt blive oversat til en serie tal (kaldet en 'feature vector'). Dette betyder, at organisationen, der benytter sig af en AI-model, måske ikke behøver at processere den for mennesker forståelige version af de personlige data indeholdt i forespørgslen, for eksempel hvis konverteringen sker på brugerens enhed. Men det faktum, at det ikke længere er let forståeligt af mennesker, betyder ikke, at de konverterede data ikke længere er personlige. Tænk bare på ansigtsgenkendelsesteknologi, Facial Recognition Technology (FRT). For at en ansigtsgenkendelsesteknologimodel skal fungere, skal digitale billeder af ansigterne, der klassificeres, konverteres til 'ansigtsaftryk'. Dette er de matematiske repræsentationer af de geometriske egenskaber, som de underliggende ansigter har - f.eks. afstanden mellem en persons næse og overlæbe. Frem for at sende selve ansigtsbillederne til en organisations server kunne fotos blive konverteret til ansigtsaftryk direkte på enheden, som tager billederne, før de sendes til modellen med henblik på en forespørgsel. Disse ansigtsaftryk kunne være mindre henførbare til en bestemt person end ansigtsfotos. Men ansigtsaftrykkene er stadig personlige (faktisk biometriske) data og derfor i høj grad identificerbare inden for konteksten af de ansigtsgenkendelsesmodeller, der bruger dem. Lokalt skabte følgeslutninger En anden metode til at undgå risiciene involveret i deling af forudsigelsesvariabler er at hoste modellen på den enhed, forespørgslen er genereret på, og som allerede indsamler og lagrer dataobjektets personlige data. For eksempel kunne en ML-model installeres på brugerens egen enhed og lave følgeslutninger 'lokalt' frem for at blive hosted på en cloud-server. Eksempelvis kunne modellerne, der skal forudsige, hvilke annoncer en bruger kunne være interesseret i, køres lokalt på brugerens smartphone (se PrivAd og MobiAd for proof of concept-eksempler). Når en annonceringsmulighed opstod, kunne flere forskellige annoncer blive afsendt fra et annoncenetværk, og den lokale model kunne udvælge den mest relevante at vise brugeren uden at afsløre brugerens faktiske personlige vaner eller profilinformation for annoncørerne. Begrænsningen er, at ML-modeller bliver nødt til at være tilstrækkeligt små og computermæssigt effektive nok til at køre på brugerens egen hardware. Den nylige udvikling inden for specialbygget hardware til smartphones og indlejrede enheder betyder, at dette er en mere og mere gennemførlig mulighed. Det er vigtigt at gøre opmærksom på, at lokal processering ikke nødvendigvis er uden for databeskyttelseslovgivningens område. Selv hvis den personlige data involveret i træningen processeres på brugerens egen enhed, så vil organisationen, som skaber og distribuerer modellen, stadig være data controller, idet de bestemmer, hvordan processeringen skal foregå og med hvilket formål. Privacy-bevarende forespørgselstilgange Hvis det ikke er muligt at anvende modellen lokalt, eksisterer der andre privacy-bevarende teknikker [1], der kan minimere de data, der afsløres i en forespørgsel sendt til en ML-model (se f.eks. TAPAS). Disse tillader, at en af parterne henter en forudsigelse eller klassificering uden at afsløre al denne information til parten, der kører modellen. Kort og godt: De tillader, at du får et svar uden helt at behøve at afsløre dit spørgsmål. Anonymisering Der er konceptuelle og tekniske ligheder mellem dataminimering og anonymisering. I visse tilfælde betyder brugen af privacy-bevarende teknikker, at nogle data brugt i ML-systemer bliver pseudonyme eller anonyme. ICO's Anonymisation Code of Practice kan give organisationer information om disse koncepter. ICO er også i øjeblikket i gang med at udvikle nye opdaterede guides om anonymisering, der skal medtage nylige udviklinger og teknikker på dette område. [1] Du kan finde et overblik over disse i kapitel 11 af 'The Algorithmic Foundations of Differential Privacy' (PDF). Blogindlægget blev oprindeligt publiceret på ico.org.uk.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2019-09-10
          &nbsp;·&nbsp; e7562277
          &nbsp;·&nbsp; #44
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.966</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.972</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.646</kbd>
        </footer>
      </article>
      <article>
        <h4>28. jun 04:18</h4>
        <div>
          Alexandra Instituttet og NVIDIA Deep Learning Institue (DLI) afholder dette endagskursus for udviklere og dataanalytikere. På kurser vil der være undervisning i det grundlæggende ved deep learning gennem træning og implementering af neurale netværk. Kurset er målrettet applikationer indenfor automatisk billedgenkendelse.Den årlige KDD-konference er en stor tværfaglig konference, der samler forskere og praktikere fra datalogi, dataudvinding, analytics på stor skala og big data. I løbet ad de fem dage konferencen varer vil der være skiftende fokus på forskellige brancher, for eksempel sundhedssektoren og deep learning.
        </div>
        <footer>
          <em>Pro.ing.dk/Gridtech</em>
          &nbsp;·&nbsp; 2018-06-28
          &nbsp;·&nbsp; e6ce6de6
          &nbsp;·&nbsp; #45
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.954</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.829</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.522</kbd>
        </footer>
      </article>
      <article>
        <h4>NLP-specialisterne hos Hugging Face barsler med Automatisk NLP</h4>
        <div>
          AutoNLP gør det muligt at lave et hurtigt proof-of-concept, men egner sig ikke til en enterprise-løsning, vurderer data scientist.BrødtekstDet ledende NLP-startup Hugging Face har på få år formået at skabe et stort open source-miljø omkring udvikling af NLP-teknologi - ikke mindst Transformer-biblioteket, som bruges af virksomheder som Google, Microsoft og Facebook.Nu tilføjer selskabet automatisk NLP til porteføljen med systemet AutoNLP - en automatiseret metode til at træne og udrulle state-of-the-art NLP-modeller.Løsningen, der stadig er i beta, kan automatisk udvælge model, træne, fintune og gøre modellen tilgængelig via et API.Og det vil være et effektivt værktøj i nogle sammenhænge, men ikke hvis man som virksomhed skal bygge et NLP-produkt til produktion, vurderer Malte Højmark-Bertelsen, der er data scientist hos KMD og selv har udviklet den danske sprogmodel Ælæctra.Læs også: Udvikler bag ny dansk sprogmodel: Hårdt brug for dansk evaluerings-standard» Der er sikkert nogle firmaer, hvor det er favorabelt, at man slet ikke skal tænke på at hoste eller deploye sin model, og man bare skal kalde en API og få en prædiktion,« siger han.»Men lige så snart, man kommer dertil, hvor man arbejder med følsom data, som skal håndteres fornuftigt, så er det ikke fedt, at man har trænet sin model, og den ligger i en cloud-tjeneste, man ikke rigtig har adgang til.« Kræver mere explainabilityIndtil videre understøtter AutoNLP binær og multi-klasse klassifikationer samt entity recognition. Og flere muligheder bliver tilføjet på ugentlig basis, lover Hugging Face.Hugging Face-udvikler Abhishek Thakur forklarer her, hvordan systemet kan bruges:Derudover er det fortsat småt med information om, hvad AutoNLP-systemet egentlig er, mener Malte Højmark-Bertelsen.»Fordi du uploader dine data, skal der typisk laves databehandleraftaler med Hugging Face. Det kræver mere gennemsigtighed omkring, hvordan de data, man træner på, bliver behandlet.« »Og yderligere kommer der et etisk ansvar, når vi udvikler AI, om at gøre det ordentligt. Til det har vi brug for forklarbarhed, og det virker ikke på nogen måde til at være integreret her.« Malte Højmark-Bertelsen pointerer, at brugen af AutoML skaber endnu et lag, som har brug for en forklaring:»Hvis du f.eks laver en løsning, der kategoriserer e-mails som spam eller ej, vil du gerne kunne se, hvorfor en specifik mail bliver klassificeret, som den gør. På samme måde vil en data scientist, der bruger en AutoNLP-løsning også gerne se, hvilke beslutninger der er blevet truffet i det her framework, hvordan hyperparametre ser ud og så videre.« Hurtig MVP og APIDer hvor AutoNLP til gengæld kan få lov til at brillere, er i de tilfælde, hvor du vil teste noget hurtigt af på ikke-sensitive data, fortæller Malte Højmark-Bertelsen.»Hvis du har et åbent datasæt, og du har brug for at få et Minimum Viable Product op at stå og kalde en model gennem et hurtigt API, så vil AutoNLP kunne fjerne en masse af de problemer, man ellers ville støde ind i, ved at sætte sådan en løsning op.« En anden oplagt opgave at overlade til et AutoNLP-system er ifølge Malte Højmark-Bertelsen arbejdet med at få de forskellige frameworks og miljøer til at spille sammen, og få forbinde med de forskellige GPU'er eller TPU'er, der måtte være brug for.»Det kunne løfte nogle af de trælse opgaver fra data scientist. Men jeg tror ikke, at AutoNLP er god til at vælge modellen, der skal trænes. Det er muligt, at den kan træne en model til sentiment-detection. Men jeg vil mene, at det kræver en data scientists forretningsviden og domæneviden at vide, hvilken slags sentiment detection der er brug for. Skal det f.eks. være binært, eller skal det være på en gradient? Det kræver mere specifik domæneviden og indsigt i kundens ønsker.« Open source er et must for dansk NLPMalte Højmark-Bertelsen understreger, at han er generelt begejstret for Hugging Faces arbejde med at facilitere et open-source NLP-miljø med værktøjer, der gør det nemt for den gængse data scientist eller hobby-koder at få lavet en pipeline, hvor man kan bygge meget komplicerede modeller rigtigt nemt.»Hugging Faces open source-tilgang er også den, som vi i KMD er interesseret i. Det er noget af det, der kræves for at løfte mulighederne inden for NLP, især inden for dansk NLP.« 
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2021-03-04
          &nbsp;·&nbsp; e826d204
          &nbsp;·&nbsp; #46
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.86</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.814</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.697</kbd>
        </footer>
      </article>
      <article>
        <h4>Ny professor på DTU: Styrker forskning for maskinlæring til bæredygtige formål</h4>
        <div>
          DTU styrker forskningen indenfor maskinlæring med udnævnelsen af Darko Zibar, gruppeleder ved DTU Fotonik, til professor, skriver universitetet på sin hjemmeside.I sin forskning fokuserer professoren på, hvordan man kan bruge maskinlæring til at udvikle strømbesparende løsninger indenfor optisk kommunikation og intelligente optiske systemer.» Maskinlæring og andre intelligente systemer kan spille en nøglerolle, og det er derfor nødvendigt, at vi forsker i det felt, hvis vi skal nå FN's Verdensmål om bæredygtig udvikling og nedbringe verdens CO2-udslip. De næste generationer af optiske kommunikationssystemer bliver så komplekse, at maskinlæring vil være en relativt hurtig måde at finde frem til løsninger, hvor vi kan transportere enorme mængder data på den mest energieffektive måde, « fortæller Darko Zibar til DTU.Siden 2019 har han stået i spidsen for gruppen 'Machine Learning in Photonics Systems', som var blandt de første til at bruge maskinlæring og kunstig intelligens i optisk kommunikationsteknologi.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2021-02-11
          &nbsp;·&nbsp; e81f4edc
          &nbsp;·&nbsp; #47
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.981</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.691</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.578</kbd>
        </footer>
      </article>
      <article>
        <h4>Deep learning erstatter dyre objektiver hos Novo Nordisk</h4>
        <div>
          Tungt, kompleks og dyrt. Det er tre ord, som oftest går igen, når talen falder på visionsystemer til kvalitetskontrol i industrien. Det er uanset, om man skal finde fejl på små metalkomponenter til bilindustrien eller insulinpenne til diabetespatienter. Alle tænkelige fejl skal findes og sorteres fra, før produktet ender hos slutbrugerne.Den teknologi-beskrivelse bliver i disse tider kraftigt udfordret af nye visionsystemer, der er baseret på deep learning i stedet for mere klassiske regelbaserede computervision-algoritmer.Et af de systemer er udviklet af danske software-virksomhed Criterion AI, som arbejder inden for den farmaceutiske industri og blandt andet hjælper Novo Nordisk med at effektivisere kvalitetskontrollen med billedgenkendelse.»I dag føder man emnerne ind i store vision-maskiner, hvor der sidder 5-6 kameraer, der tager billeder, der så køres ind i klassiske computervision-algoritmer. De er ikke altid stærke nok til at finde alle fejl, og det forsøger man at kompensere for med meget dyre objektiver og ved at bruge mange ressourcer på at skabe det bedst mulige lys. Målet er at kontrollere billedprocessen, så billederne bliver så knivskarpe og dermed nemmere at genkende for algoritmerne,« fortalte Sebastian Brandes, medstifter af Criterion AI, på konferencen Big Data, AI &amp; Analytics - Hvad skal vi med al den data, som Dansk Automationsselskab afholdt tidligere i maj.Det gør industrielle visionsystemer komplekse og dyre. Men hvis man kan forbedre algoritmerne, der genkender billeder, så behøver man måske ikke dyre objektiver til kameraer og perfekt lyssætning på fabriksgulvet.»Vi arbejder med en mere datapræget tilgang, hvor algoritmerne er stærkere, og så har vi ikke samme høje krav til billederne. Det betyder, at man kan bruge billigere og mindre kameraer, der kan sættes op i selve produktionsmiljøet,« sagde Sebastian Brandes.Criterion AI bruger deep learning, en serie algoritmer der er bedre i stand til at lære mønstre ud af rå data end mere konventionelle machine learning-algoritmer, hvor algoritmerne skal trænes manuelt på forhånd.Men det lyder næsten som en lidt for god salgstale, når man vil øge kvaliteten for færre ressourcer.Sebastian Brandes, medstifter af softwaer-virksomheden Criterion AI, fortalteom deep learning på Dau-konferencen om Big dataKraftige grafikkort genopliver gamle algoritmerDet er ikke, fordi Criterion AI eller andre virksomheder, der udvikler nye løsninger baseret på kunstig intelligens, har udviklet vidunder-algoritmer fra den ene dag til den anden. Faktisk er det snarere en række af teknologiske fremskridt inden for hardware, der har revitaliseret deep learning-metoderne.De matematiske modeller, der ligger bag deep learning-algoritmerne, blev nemlig udviklet for over 30 år siden. Men mangel på processorkraft og datasæt satte en stopper for udbredelsen af algoritmerne.»I slutningen af 80'erne havde man ikke den nødvendige computerkraft og digitale data til at køre algoritmerne, og gejsten omkring deep learning døde delvist i 90'erne. Det var først, da chip-producenten Nvidia lancerede et nyt grafikkort og udviklerværktøjet Cuda i 2007, at deep learning fik et nyt gennembrud,« fortalte Sebastian Brandes.Det var altså ny hardware, i form af chips, der har boostet brugen af deep learning.»Grafikkort er blevet så stærke, at selvom vi banker 3.000 billeder ind i minuttet på en server, så kommer grafikkortet ikke over 52 grader. For selvom de kraftige grafikkort ikke kan så meget som et traditionelt CPU, så er de er vanvittigt gode til at lave matrix-operationer parallelt, så man kan træne neurale netværk på meget kort tid. Og det er vigtigt til billedanalyse i industrien,« fortalte Sebastian Brandes.Den store forskel på klassisk machine learning og deep learning er, at man med machine learning skal bruge mere tid på at forberede sine produktionsdata, før de kan smides ind i en algoritme, der kan afgøre, om produktet er godkendt eller skal kasseres.»Med deep learning skal man lave langt mindre præ-processering, og vi kan føde rådata ind, uden at vise algoritmen hvad sammenhængen er,« sagde Sebastian Brandes.Forskellen på machine learning og deep learning.600 emner i minuttetCriterion AI har hjulpet Novo Nordisk med at ændre deres visionsystemer, så det kun er de dårlige produkter, der reelt bliver sorteret fra. For kombinationen af mange emner og ekstreme kvalitetskrav gør, at visionsystemer bliver centrale i produktionen.»Når man er en farmaceutisk virksomhed, skal man kunne identificere alle produkter, især når man producerer produkter, der skydes ind i blodet. Man må simpelthen ikke frigive et produkt, uden at det er gennemtestet for eventuelle fejl. Når man producerer 800 millioner emner om året, kan det godt blive trægt at kigge dem alle sammen igen, især hvis det tager mellem 30-60 sekunder pr. emne,« sagde Sebastian Brandes.Novo Nordisk har arbejdet med automatisering af kvalitetskontrol ved hjælp af klassiske regelbaserede algoritmer i over 25 år.»Nu er man nået til et punkt, hvor det er svært at vride mere ud af den teknologi. Vi har hjulpet Novo Nordisk med at kigge på deep learning som et nyt skridt til hurtigere og bedre vision. På tværs af alle produktkategorier har vi boostet fejlfindingsraten, og som et tillæg har vi sænket antallet af produkter der kasseres ved en fejl. Det er en fordel, når man som Novo Nordisk er under et prispres på markedet,« sagde Sebastian Brandes.Bruger eksisterende teknologierCriterion AI bruger de eksisterende vision-kameraer, som allerede er i drift hos Novo Nordisk, og tager så de billeder og fodrer ind i deres deep learning-algoritme, som vurderer kvaliteten af produktet. Selve algoritmen arbejder lokalt i produktionen for at sikre hastigheden.»Når man kører batches med 500.000 emner ad gangen, hvor der tages fem billeder af hvert emne, som hver fylder 2 Mb, så er det ikke rentabelt at sende i skyen.« Hvor mange af de traditionelle industrielle visionsystemer er specialfremstillede til den konkrete produktion, så bruger Criterion AI stort set kun hyldevarer i deres deep learning-system.De bruger eksempelvis en SaaS-platform fra virksomheden Bigfinite, der kører på AWS, mens selve algoritmerne køres igennem Googles open source-bibliotek TensorFlow.»Vi har lavet en simpel grænseflade, så operatører i produktionen ikke skal have erfaring med Python eller andre programmeringssprog,« sagde Sebastian Brandes.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2019-05-16
          &nbsp;·&nbsp; e7334ead
          &nbsp;·&nbsp; #48
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.97</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.832</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.657</kbd>
        </footer>
      </article>
      <article>
        <h4>OpenAI: Evolutionær maskinlæring skalerer overraskende godt i arkadespil</h4>
        <div>
          Når computeren slår dig i Pong eller en anden arkadeklassiker, så kan du give evolution skylden. Helt præcist har det ikke meget med biologisk evolution at gøre, men et gammelt forslag til optimering af modeller inden for kunstig intelligens har vist sig at være overraskende effektiv til oplæring i blandt andet arkadespil.Kunstig intelligens eller machine learning handler i bund og grund om at finde de mest effektive måder at lade en softwarealgoritme prøve sig frem, indtil det lykkes den at løse en opgave. Men når man arbejder med algoritmer, hvor funktionen har én million parametre, så er det ikke ligegyldigt, hvordan man når frem til den bedste model.Oplæring af algoritmerMed machine learning opbygger man en model ved at lade algoritmen arbejde med et datasæt. Men det er ikke alle datasæt, der er lige egnede til alle metoder til oplæring, og derfor arbejder man inden for machine learning med forskellige principper:Supervised Learning: Her har man et datasæt, hvor der er tilknyttet rigtige svar. Det kan eksempelvis være en database med fotos, hvor der er tilknyttet beskrivelser af, hvad billederne forestiller. Algoritmen opbygger en model ved at forsøge at forudsige et resultat, som kan evalueres ud fra de kendte, korrekte svar. På den måde kan algoritmen forbedre modellen.Der er flere metoder til denne type oplæring, heriblandt support vector machine, logistic regression, back propagation neural network og evolution strategies.Unsupervised Learning: Når et datasæt ikke er katalogiseret med etiketter, og du altså ikke kender de korrekte svar, så bygger strategierne på at finde frem til mulige strukturer i datasættet, men der er ingen mulighed for at lade algoritmen forsøge at evaluere, om ét bud er bedre end et andet, ud fra en facitliste.Denne type machine learning kan blandt andet anvendes til anomaly detection og clustering.kilde: Machinelearningmastery.comDet koster nemlig regnekraft og tid, og derfor har forskerne hos OpenAI taget et ekstra kig på en metode kaldet Evolution Strategies.Den går meget overordnet ud på at finde den bedste variant af en funktion alene ud fra kvaliteten af resultatet og inputtet.Enkel og skalerer godtEvolution Strategies kan ifølge OpenAI-forskerne være et alternativ til Reinforcement Learning, som er populær til oplæring af algoritmer inden for eksempelvis billedanalyse.Evolution Strategies er ikke den bedste metode til alle formål, men fordi den er ret enkel, så kan den skalere ganske effektivt.I stedet for at udveksle en komplet vektor med parametre mellem hver regneenhed, så kan man nøjes med nogle få skalarer, hvilket gør det nemmere at foretage parallelle beregninger.En af de centrale forskelle på Reinforcement Learning og Evolution Strategies er, at i den første arbejder man med tilfældige mutationer af hver enkelt 'regel'.I Evolution Strategies forsøger man at finde det optimale punkt for hver regel, så man skyder sig ind på den bedste værdi, lidt på samme måde som Newtons metode.Det har altså vist sig at være en god metode til arkadespil, hvor inputtet er et billede. Algoritmen ser altså, hvad der sker på skærmen.Nem succesmålingLigesom et menneske skal algoritmen så finde ud af, om det eksempelvis er bedst at gå til højre eller venstre. I et spil som eksempelvis Pong er det nemt at måle resultatet: Hvis algoritmen misser bolden, så dumper dén variant, men hvis bolden rammes, og den ryger forbi modstanderen, så er algoritmen på vej mod et optimum.Forskellen mellem de to typer læring ligger i matematikken, og det er også derfor, at Evolution Strategies ikke altid er bedre end Reinforcement Learning.Til gengæld er Evolution Strategies altså i visse tilfælde hurtigere at oplære, fordi udregningerne er enklere i kraft af, at algoritmen ikke evaluerer ved at se på, hvad der skete 'inde'i algoritmen, men blot på resultatet.Ifølge OpenAI betød det i undersøgelsen af arkadespillene, at algoritmen kunne oplæres to til tre gange hurtigere med mindre kode, og det var ikke nødvendigt at gemme så mange data.Undersøgelsen bestod blandt andet i test af 51 Atari 2600-spil, hvor algoritmerne blev oplært på én milliard frames fra hvert spil ved at køre parallelt på 720 processorer på Amazons EC2.Der er et aber dabeiMetoden er ikke altid bedre - faktisk klarede Reinforcement Learning med metoden A3C worker sig bedre i 28 af spillene, men til gengæld var Evolution Strategies mere tolerant over for, hvor mange frames man sprang over i hver gennemkørsel.Forskerne konkluderer altså, at Evolution Strategies er endnu en farbar vej inden for machine learning, som især har en fordel, hvis man har behov for at kunne parallelisere, når modellen skal oplæres.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2017-04-20
          &nbsp;·&nbsp; e638060f
          &nbsp;·&nbsp; #49
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.996</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.995</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.694</kbd>
        </footer>
      </article>
    </main>
  </body>
</html>
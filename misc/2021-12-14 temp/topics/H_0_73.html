<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Infomedia Articles</title>
    <style type="text/css">
/*!
 * Pico.css v1.3.3 (https://picocss.com)
 * Copyright 2019-2021 - Licensed under MIT
 */:root{--font-family:system-ui,-apple-system,"Segoe UI","Roboto","Ubuntu","Cantarell","Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";--line-height:1.5;--font-weight:400;--font-size:16px;--border-radius:.25rem;--border-width:1px;--outline-width:3px;--spacing:1rem;--typography-spacing-vertical:1.5rem;--block-spacing-vertical:calc(var(--spacing) * 2);--block-spacing-horizontal:var(--spacing);--grid-spacing-vertical:0;--grid-spacing-horizontal:var(--spacing);--form-element-spacing-vertical:.75rem;--form-element-spacing-horizontal:1rem;--transition:.2s ease-in-out}@media (min-width:576px){:root{--font-size:17px}}@media (min-width:768px){:root{--font-size:18px}}@media (min-width:992px){:root{--font-size:19px}}@media (min-width:1200px){:root{--font-size:20px}}@media (min-width:576px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 2.5)}}@media (min-width:768px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 3)}}@media (min-width:992px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 3.5)}}@media (min-width:1200px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 4)}}@media (min-width:576px){article{--block-spacing-horizontal:calc(var(--spacing) * 1.25)}}@media (min-width:768px){article{--block-spacing-horizontal:calc(var(--spacing) * 1.5)}}@media (min-width:992px){article{--block-spacing-horizontal:calc(var(--spacing) * 1.75)}}@media (min-width:1200px){article{--block-spacing-horizontal:calc(var(--spacing) * 2)}}a{--text-decoration:none}a.contrast,a.secondary{--text-decoration:underline}small{--font-size:0.875em}h1,h2,h3,h4,h5,h6{--font-weight:700}h1{--font-size:2rem;--typography-spacing-vertical:3rem}h2{--font-size:1.75rem;--typography-spacing-vertical:2.625rem}h3{--font-size:1.5rem;--typography-spacing-vertical:2.25rem}h4{--font-size:1.25rem;--typography-spacing-vertical:1.874rem}h5{--font-size:1.125rem;--typography-spacing-vertical:1.6875rem}[type=checkbox],[type=radio]{--border-width:2px}[type=checkbox][role=switch]{--border-width:3px}thead td,thead th{--border-width:3px}:not(thead)>*>td{--font-size:0.875em}code,kbd,pre,samp{--font-family:"Menlo","Consolas","Roboto Mono","Ubuntu Monospace","Noto Mono","Oxygen Mono","Liberation Mono",monospace,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji"}kbd{--font-weight:bolder}:root:not([data-theme=dark]),[data-theme=light]{color-scheme:light;--background-color:#FFF;--color:#415462;--h1-color:#1b2832;--h2-color:#23333e;--h3-color:#2c3d49;--h4-color:#374956;--h5-color:#415462;--h6-color:#4d606d;--muted-color:#73828c;--muted-border-color:#edf0f3;--primary:#1095c1;--primary-hover:#08769b;--primary-focus:rgba(16,149,193,0.125);--primary-inverse:#FFF;--secondary:#596b78;--secondary-hover:#415462;--secondary-focus:rgba(89,107,120,0.125);--secondary-inverse:#FFF;--contrast:#1b2832;--contrast-hover:#000;--contrast-focus:rgba(89,107,120,0.125);--contrast-inverse:#FFF;--mark-background-color:#fff2ca;--mark-color:#543a25;--ins-color:#388E3C;--del-color:#C62828;--blockquote-border-color:var(--muted-border-color);--blockquote-footer-color:var(--muted-color);--button-box-shadow:0 0 0 rgba(0,0,0,0);--button-hover-box-shadow:0 0 0 rgba(0,0,0,0);--form-element-background-color:transparent;--form-element-border-color:#a2afb9;--form-element-color:var(--color);--form-element-placeholder-color:var(--muted-color);--form-element-active-background-color:transparent;--form-element-active-border-color:var(--primary);--form-element-focus-color:var(--primary-focus);--form-element-disabled-background-color:#d5dce2;--form-element-disabled-border-color:#a2afb9;--form-element-disabled-opacity:.5;--form-element-invalid-border-color:#C62828;--form-element-invalid-active-border-color:#B71C1C;--form-element-valid-border-color:#388E3C;--form-element-valid-active-border-color:#2E7D32;--switch-background-color:#bbc6ce;--switch-color:var(--primary-inverse);--switch-checked-background-color:var(--primary);--range-border-color:#d5dce2;--range-active-border-color:#bbc6ce;--range-thumb-border-color:var(--background-color);--range-thumb-color:var(--secondary);--range-thumb-hover-color:var(--secondary-hover);--range-thumb-active-color:var(--primary);--table-border-color:var(--muted-border-color);--table-row-stripped-background-color:#f6f8f9;--code-background-color:#edf0f3;--code-color:var(--muted-color);--code-kbd-background-color:var(--contrast);--code-kbd-color:var(--contrast-inverse);--code-tag-color:#b34d80;--code-property-color:#3d888f;--code-value-color:#998866;--code-comment-color:#a2afb9;--accordion-border-color:var(--muted-border-color);--accordion-close-summary-color:var(--color);--accordion-open-summary-color:var(--muted-color);--card-background-color:var(--background-color);--card-border-color:var(--muted-border-color);--card-box-shadow:0 0.125rem 1rem rgba(27,40,50,0.04),0 0.125rem 2rem rgba(27,40,50,0.08),0 0 0 0.0625rem rgba(27,40,50,0.024);--card-sectionning-background-color:#fafbfc;--progress-background-color:#d5dce2;--progress-color:var(--primary);--loading-spinner-opacity:.5;--tooltip-background-color:var(--contrast);--tooltip-color:var(--contrast-inverse);--icon-chevron:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");--icon-date:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");--icon-time:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");--icon-search:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");--icon-checkbox:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-minus:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");--icon-valid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(56, 142, 60, 0.999)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-invalid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(198, 40, 40, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E")}@media only screen and (prefers-color-scheme:dark){:root:not([data-theme=light]){color-scheme:dark;--background-color:#11191f;--color:#bbc6ce;--h1-color:#edf0f3;--h2-color:#e1e6ea;--h3-color:#d5dce2;--h4-color:#c8d1d8;--h5-color:#bbc6ce;--h6-color:#aebbc3;--muted-color:#73828c;--muted-border-color:#1f2d38;--primary:#1095c1;--primary-hover:#1ab3e6;--primary-focus:rgba(16,149,193,0.25);--primary-inverse:#FFF;--secondary:#596b78;--secondary-hover:#73828c;--secondary-focus:rgba(115,130,140,0.25);--secondary-inverse:#FFF;--contrast:#edf0f3;--contrast-hover:#FFF;--contrast-focus:rgba(115,130,140,0.25);--contrast-inverse:#000;--mark-background-color:#d0c284;--mark-color:#11191f;--ins-color:#388E3C;--del-color:#C62828;--blockquote-border-color:var(--muted-border-color);--blockquote-footer-color:var(--muted-color);--button-box-shadow:0 0 0 rgba(0,0,0,0);--button-hover-box-shadow:0 0 0 rgba(0,0,0,0);--form-element-background-color:#11191f;--form-element-border-color:#374956;--form-element-color:var(--color);--form-element-placeholder-color:var(--muted-color);--form-element-active-background-color:var(--form-element-background-color);--form-element-active-border-color:var(--primary);--form-element-focus-color:var(--primary-focus);--form-element-disabled-background-color:#2c3d49;--form-element-disabled-border-color:#415462;--form-element-disabled-opacity:.5;--form-element-invalid-border-color:#B71C1C;--form-element-invalid-active-border-color:#C62828;--form-element-valid-border-color:#2E7D32;--form-element-valid-active-border-color:#388E3C;--switch-background-color:#374956;--switch-color:var(--primary-inverse);--switch-checked-background-color:var(--primary);--range-border-color:#23333e;--range-active-border-color:#2c3d49;--range-thumb-border-color:var(--background-color);--range-thumb-color:var(--secondary);--range-thumb-hover-color:var(--secondary-hover);--range-thumb-active-color:var(--primary);--table-border-color:var(--muted-border-color);--table-row-stripped-background-color:rgba(115,130,140,0.05);--code-background-color:#17232c;--code-color:var(--muted-color);--code-kbd-background-color:var(--contrast);--code-kbd-color:var(--contrast-inverse);--code-tag-color:#a65980;--code-property-color:#599fa6;--code-value-color:#8c8473;--code-comment-color:#4d606d;--accordion-border-color:var(--muted-border-color);--accordion-active-summary-color:var(--primary);--accordion-close-summary-color:var(--color);--accordion-open-summary-color:var(--muted-color);--card-background-color:#141e25;--card-border-color:#11191f;--card-box-shadow:0 0.125rem 1rem rgba(0,0,0,0.06),0 0.125rem 2rem rgba(0,0,0,0.12),0 0 0 0.0625rem rgba(0,0,0,0.036);--card-sectionning-background-color:#17232c;--progress-background-color:#23333e;--progress-color:var(--primary);--loading-spinner-opacity:.5;--tooltip-background-color:var(--contrast);--tooltip-color:var(--contrast-inverse);--icon-chevron:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");--icon-date:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");--icon-time:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");--icon-search:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");--icon-checkbox:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-minus:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");--icon-valid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(46, 125, 50, 0.999)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-invalid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(183, 28, 28, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E")}}[data-theme=dark]{color-scheme:dark;--background-color:#11191f;--color:#bbc6ce;--h1-color:#edf0f3;--h2-color:#e1e6ea;--h3-color:#d5dce2;--h4-color:#c8d1d8;--h5-color:#bbc6ce;--h6-color:#aebbc3;--muted-color:#73828c;--muted-border-color:#1f2d38;--primary:#1095c1;--primary-hover:#1ab3e6;--primary-focus:rgba(16,149,193,0.25);--primary-inverse:#FFF;--secondary:#596b78;--secondary-hover:#73828c;--secondary-focus:rgba(115,130,140,0.25);--secondary-inverse:#FFF;--contrast:#edf0f3;--contrast-hover:#FFF;--contrast-focus:rgba(115,130,140,0.25);--contrast-inverse:#000;--mark-background-color:#d0c284;--mark-color:#11191f;--ins-color:#388E3C;--del-color:#C62828;--blockquote-border-color:var(--muted-border-color);--blockquote-footer-color:var(--muted-color);--button-box-shadow:0 0 0 rgba(0,0,0,0);--button-hover-box-shadow:0 0 0 rgba(0,0,0,0);--form-element-background-color:#11191f;--form-element-border-color:#374956;--form-element-color:var(--color);--form-element-placeholder-color:var(--muted-color);--form-element-active-background-color:var(--form-element-background-color);--form-element-active-border-color:var(--primary);--form-element-focus-color:var(--primary-focus);--form-element-disabled-background-color:#2c3d49;--form-element-disabled-border-color:#415462;--form-element-disabled-opacity:.5;--form-element-invalid-border-color:#B71C1C;--form-element-invalid-active-border-color:#C62828;--form-element-valid-border-color:#2E7D32;--form-element-valid-active-border-color:#388E3C;--switch-background-color:#374956;--switch-color:var(--primary-inverse);--switch-checked-background-color:var(--primary);--range-border-color:#23333e;--range-active-border-color:#2c3d49;--range-thumb-border-color:var(--background-color);--range-thumb-color:var(--secondary);--range-thumb-hover-color:var(--secondary-hover);--range-thumb-active-color:var(--primary);--table-border-color:var(--muted-border-color);--table-row-stripped-background-color:rgba(115,130,140,0.05);--code-background-color:#17232c;--code-color:var(--muted-color);--code-kbd-background-color:var(--contrast);--code-kbd-color:var(--contrast-inverse);--code-tag-color:#a65980;--code-property-color:#599fa6;--code-value-color:#8c8473;--code-comment-color:#4d606d;--accordion-border-color:var(--muted-border-color);--accordion-active-summary-color:var(--primary);--accordion-close-summary-color:var(--color);--accordion-open-summary-color:var(--muted-color);--card-background-color:#141e25;--card-border-color:#11191f;--card-box-shadow:0 0.125rem 1rem rgba(0,0,0,0.06),0 0.125rem 2rem rgba(0,0,0,0.12),0 0 0 0.0625rem rgba(0,0,0,0.036);--card-sectionning-background-color:#17232c;--progress-background-color:#23333e;--progress-color:var(--primary);--loading-spinner-opacity:.5;--tooltip-background-color:var(--contrast);--tooltip-color:var(--contrast-inverse);--icon-chevron:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");--icon-date:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");--icon-time:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");--icon-search:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");--icon-checkbox:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-minus:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");--icon-valid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(46, 125, 50, 0.999)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-invalid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(183, 28, 28, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E")}*,:after,:before{box-sizing:border-box}:after,:before{text-decoration:inherit;vertical-align:inherit}html{-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:rgba(0,0,0,0);-moz-tab-size:4;-ms-text-size-adjust:100%;background-color:var(--background-color);color:var(--color);font-family:var(--font-family);font-size:var(--font-size);font-weight:var(--font-weight);line-height:var(--line-height);text-rendering:optimizeLegibility;cursor:default}main{display:block}body{width:100%;margin:0}body>footer,body>header,body>main{width:100%;margin-right:auto;margin-left:auto;padding:var(--block-spacing-vertical) 0}.container,.container-fluid{width:100%;margin-right:auto;margin-left:auto;padding-right:var(--spacing);padding-left:var(--spacing)}@media (min-width:576px){.container{max-width:510px;padding-right:0;padding-left:0}}@media (min-width:768px){.container{max-width:700px}}@media (min-width:992px){.container{max-width:920px}}@media (min-width:1200px){.container{max-width:1130px}}section{margin-bottom:var(--block-spacing-vertical)}.grid{grid-column-gap:var(--grid-spacing-horizontal);grid-row-gap:var(--grid-spacing-vertical);display:grid;grid-template-columns:1fr;margin:0}@media (min-width:992px){.grid{grid-template-columns:repeat(auto-fit,minmax(0%,1fr))}}.grid>*{min-width:0}figure{display:block;margin:0;padding:0;overflow-x:auto}figure figcaption{padding:calc(var(--spacing) / 2) 0;color:var(--muted-color)}b,strong{font-weight:bolder}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-0.25em}sup{top:-0.5em}dl dl,dl ol,dl ul,ol dl,ul dl{margin:0}ol ol,ol ul,ul ol,ul ul{margin:0}address,blockquote,dl,figure,form,ol,p,pre,table,ul{margin-top:0;margin-bottom:var(--typography-spacing-vertical);color:var(--color);font-size:1rem;font-style:normal}a{--color:var(--primary);--background-color:transparent;outline:none;background-color:var(--background-color);color:var(--color);text-decoration:var(--text-decoration);transition:background-color var(--transition),color var(--transition),text-decoration var(--transition),box-shadow var(--transition)}a:active,a:focus,a:hover{--color:var(--primary-hover);--text-decoration:underline}a:focus{--background-color:var(--primary-focus)}a.secondary{--color:var(--secondary)}a.secondary:active,a.secondary:focus,a.secondary:hover{--color:var(--secondary-hover)}a.secondary:focus{--background-color:var(--secondary-focus)}a.contrast{--color:var(--contrast)}a.contrast:active,a.contrast:focus,a.contrast:hover{--color:var(--contrast-hover)}a.contrast:focus{--background-color:var(--contrast-focus)}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:var(--typography-spacing-vertical);color:var(--color);font-family:var(--font-family);font-size:var(--font-size);font-weight:var(--font-weight)}h1{--color:var(--h1-color)}h2{--color:var(--h2-color)}h3{--color:var(--h3-color)}h4{--color:var(--h4-color)}h5{--color:var(--h5-color)}h6{--color:var(--h6-color)}address~h1,address~h2,address~h3,address~h4,address~h5,address~h6,blockquote~h1,blockquote~h2,blockquote~h3,blockquote~h4,blockquote~h5,blockquote~h6,dl~h1,dl~h2,dl~h3,dl~h4,dl~h5,dl~h6,figure~h1,figure~h2,figure~h3,figure~h4,figure~h5,figure~h6,form~h1,form~h2,form~h3,form~h4,form~h5,form~h6,ol~h1,ol~h2,ol~h3,ol~h4,ol~h5,ol~h6,pre~h1,pre~h2,pre~h3,pre~h4,pre~h5,pre~h6,p~h1,p~h2,p~h3,p~h4,p~h5,p~h6,table~h1,table~h2,table~h3,table~h4,table~h5,table~h6,ul~h1,ul~h2,ul~h3,ul~h4,ul~h5,ul~h6{margin-top:var(--typography-spacing-vertical)}hgroup{margin-bottom:var(--typography-spacing-vertical)}hgroup>*{margin-bottom:0}hgroup>:last-child{--color:var(--muted-color);--font-weight:unset;font-family:unset;font-size:1rem}p{margin-bottom:var(--typography-spacing-vertical)}small{font-size:var(--font-size)}ol,ul{padding-left:var(--spacing)}ol li,ul li{margin-bottom:calc(var(--typography-spacing-vertical) / 4)}ul li{list-style:square}mark{padding:.125rem .25rem;background-color:var(--mark-background-color);color:var(--mark-color);vertical-align:middle}blockquote{display:block;margin:var(--typography-spacing-vertical) 0;padding:var(--spacing);border-left:0.25rem solid var(--blockquote-border-color)}blockquote footer{margin-top:calc(var(--typography-spacing-vertical) / 2);color:var(--blockquote-footer-color)}abbr[title]{border-bottom:1px dotted;text-decoration:none;cursor:help}ins{color:var(--ins-color);text-decoration:none}del{color:var(--del-color)}::selection{background-color:var(--primary-focus)}audio,canvas,iframe,img,svg,video{vertical-align:middle}audio,video{display:inline-block}audio:not([controls]){display:none;height:0}iframe{border-style:none}img{max-width:100%;height:auto;border-style:none}svg:not([fill]){fill:currentColor}svg:not(:root){overflow:hidden}button{margin:0;overflow:visible;font-family:inherit;text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{padding:0;border-style:none}button{display:block;width:100%;margin-bottom:var(--spacing)}a[role=button]{display:inline-block;text-decoration:none}a[role=button],button,input[type=button],input[type=reset],input[type=submit]{--background-color:var(--primary);--border-color:var(--primary);--color:var(--primary-inverse);--box-shadow:var(--button-box-shadow,0 0 0 rgba(0,0,0,0));padding:var(--form-element-spacing-vertical) var(--form-element-spacing-horizontal);border:var(--border-width) solid var(--border-color);border-radius:var(--border-radius);outline:none;background-color:var(--background-color);box-shadow:var(--box-shadow);color:var(--color);font-size:1rem;font-weight:var(--font-weight);line-height:var(--line-height);text-align:center;cursor:pointer;transition:background-color var(--transition),border-color var(--transition),color var(--transition),box-shadow var(--transition)}a[role=button]:active,a[role=button]:focus,a[role=button]:hover,button:active,button:focus,button:hover,input[type=button]:active,input[type=button]:focus,input[type=button]:hover,input[type=reset]:active,input[type=reset]:focus,input[type=reset]:hover,input[type=submit]:active,input[type=submit]:focus,input[type=submit]:hover{--background-color:var(--primary-hover);--border-color:var(--primary-hover);--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0))}a[role=button]:focus,button:focus,input[type=button]:focus,input[type=reset]:focus,input[type=submit]:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--primary-focus)}input[type=reset]{--background-color:var(--secondary);--border-color:var(--secondary);--color:var(--secondary-inverse);cursor:pointer}input[type=reset]:active,input[type=reset]:focus,input[type=reset]:hover{--background-color:var(--secondary-hover);--border-color:var(--secondary-hover)}input[type=reset]:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--secondary-focus)}a[role=button].secondary,button.secondary,input[type=button].secondary,input[type=reset].secondary,input[type=submit].secondary{--background-color:var(--secondary);--border-color:var(--secondary);--color:var(--secondary-inverse);cursor:pointer}a[role=button].secondary:active,a[role=button].secondary:focus,a[role=button].secondary:hover,button.secondary:active,button.secondary:focus,button.secondary:hover,input[type=button].secondary:active,input[type=button].secondary:focus,input[type=button].secondary:hover,input[type=reset].secondary:active,input[type=reset].secondary:focus,input[type=reset].secondary:hover,input[type=submit].secondary:active,input[type=submit].secondary:focus,input[type=submit].secondary:hover{--background-color:var(--secondary-hover);--border-color:var(--secondary-hover)}a[role=button].secondary:focus,button.secondary:focus,input[type=button].secondary:focus,input[type=reset].secondary:focus,input[type=submit].secondary:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--secondary-focus)}a[role=button].contrast,button.contrast,input[type=button].contrast,input[type=reset].contrast,input[type=submit].contrast{--background-color:var(--contrast);--border-color:var(--contrast);--color:var(--contrast-inverse)}a[role=button].contrast:active,a[role=button].contrast:focus,a[role=button].contrast:hover,button.contrast:active,button.contrast:focus,button.contrast:hover,input[type=button].contrast:active,input[type=button].contrast:focus,input[type=button].contrast:hover,input[type=reset].contrast:active,input[type=reset].contrast:focus,input[type=reset].contrast:hover,input[type=submit].contrast:active,input[type=submit].contrast:focus,input[type=submit].contrast:hover{--background-color:var(--contrast-hover);--border-color:var(--contrast-hover)}a[role=button].contrast:focus,button.contrast:focus,input[type=button].contrast:focus,input[type=reset].contrast:focus,input[type=submit].contrast:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--contrast-focus)}a[role=button].outline,button.outline,input[type=button].outline,input[type=reset].outline,input[type=submit].outline{--background-color:transparent;--color:var(--primary)}a[role=button].outline:active,a[role=button].outline:focus,a[role=button].outline:hover,button.outline:active,button.outline:focus,button.outline:hover,input[type=button].outline:active,input[type=button].outline:focus,input[type=button].outline:hover,input[type=reset].outline:active,input[type=reset].outline:focus,input[type=reset].outline:hover,input[type=submit].outline:active,input[type=submit].outline:focus,input[type=submit].outline:hover{--background-color:transparent;--color:var(--primary-hover)}a[role=button].outline.secondary,button.outline.secondary,input[type=button].outline.secondary,input[type=reset].outline.secondary,input[type=submit].outline.secondary{--color:var(--secondary)}a[role=button].outline.secondary:active,a[role=button].outline.secondary:focus,a[role=button].outline.secondary:hover,button.outline.secondary:active,button.outline.secondary:focus,button.outline.secondary:hover,input[type=button].outline.secondary:active,input[type=button].outline.secondary:focus,input[type=button].outline.secondary:hover,input[type=reset].outline.secondary:active,input[type=reset].outline.secondary:focus,input[type=reset].outline.secondary:hover,input[type=submit].outline.secondary:active,input[type=submit].outline.secondary:focus,input[type=submit].outline.secondary:hover{--color:var(--secondary-hover)}a[role=button].outline.contrast,button.outline.contrast,input[type=button].outline.contrast,input[type=reset].outline.contrast,input[type=submit].outline.contrast{--color:var(--contrast)}a[role=button].outline.contrast:active,a[role=button].outline.contrast:focus,a[role=button].outline.contrast:hover,button.outline.contrast:active,button.outline.contrast:focus,button.outline.contrast:hover,input[type=button].outline.contrast:active,input[type=button].outline.contrast:focus,input[type=button].outline.contrast:hover,input[type=reset].outline.contrast:active,input[type=reset].outline.contrast:focus,input[type=reset].outline.contrast:hover,input[type=submit].outline.contrast:active,input[type=submit].outline.contrast:focus,input[type=submit].outline.contrast:hover{--color:var(--contrast-hover)}a[role=button][disabled],button[disabled],input[type=button][disabled],input[type=reset][disabled],input[type=submit][disabled]{opacity:.5;pointer-events:none}input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:1rem;letter-spacing:inherit;line-height:var(--line-height)}input{overflow:visible}select{text-transform:none}legend{max-width:100%;padding:0;color:inherit;white-space:normal}textarea{overflow:auto}[type=checkbox],[type=radio]{padding:0}::-webkit-inner-spin-button,::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}::-moz-focus-inner{padding:0;border-style:none}:-moz-focusring{outline:none}:-moz-ui-invalid{box-shadow:none}::-ms-expand{display:none}[type=file],[type=range]{padding:0;border-width:0}input:not([type=checkbox]):not([type=radio]):not([type=range]){height:calc((1rem * var(--line-height)) + (var(--form-element-spacing-vertical) * 2) + (var(--border-width) * 2))}fieldset{margin:0;margin-bottom:var(--spacing);padding:0;border:0}fieldset legend,label{display:block;margin-bottom:calc(var(--spacing) / 4);vertical-align:middle}input:not([type=checkbox]):not([type=radio]),select,textarea{display:block;width:100%}input:not([type=checkbox]):not([type=radio]):not([type=range]):not([type=file]),select,textarea{-webkit-appearance:none;-moz-appearance:none;appearance:none;padding:var(--form-element-spacing-vertical) var(--form-element-spacing-horizontal);vertical-align:middle}input,select,textarea{--background-color:var(--form-element-background-color);--border-color:var(--form-element-border-color);--color:var(--form-element-color);--box-shadow:none;border:var(--border-width) solid var(--border-color);border-radius:var(--border-radius);outline:none;background-color:var(--background-color);box-shadow:var(--box-shadow);color:var(--color);font-weight:var(--font-weight);transition:background-color var(--transition),border-color var(--transition),color var(--transition),box-shadow var(--transition)}input:not([type=submit]):not([type=button]):not([type=reset]):not([type=checkbox]):not([type=radio]):not([readonly]):active,input:not([type=submit]):not([type=button]):not([type=reset]):not([type=checkbox]):not([type=radio]):not([readonly]):focus,select:active,select:focus,textarea:active,textarea:focus{--background-color:var(--form-element-active-background-color)}input:not([type=submit]):not([type=button]):not([type=reset]):not([role=switch]):not([readonly]):active,input:not([type=submit]):not([type=button]):not([type=reset]):not([role=switch]):not([readonly]):focus,select:active,select:focus,textarea:active,textarea:focus{--border-color:var(--form-element-active-border-color)}input:not([type=submit]):not([type=button]):not([type=reset]):not([type=range]):not([type=file]):not([readonly]):focus,select:focus,textarea:focus{--box-shadow:0 0 0 var(--outline-width) var(--form-element-focus-color)}input:not([type=submit]):not([type=button]):not([type=reset])[disabled],select[disabled],textarea[disabled]{--background-color:var(--form-element-disabled-background-color);--border-color:var(--form-element-disabled-border-color);opacity:var(--form-element-disabled-opacity)}input[aria-invalid],select[aria-invalid],textarea[aria-invalid]{padding-right:2rem;background-position:center right .75rem;background-repeat:no-repeat;background-size:1rem auto}input[aria-invalid=false],select[aria-invalid=false],textarea[aria-invalid=false]{--border-color:var(--form-element-valid-border-color);background-image:var(--icon-valid)}input[aria-invalid=false]:active,input[aria-invalid=false]:focus,select[aria-invalid=false]:active,select[aria-invalid=false]:focus,textarea[aria-invalid=false]:active,textarea[aria-invalid=false]:focus{--border-color:var(--form-element-valid-active-border-color)!important}input[aria-invalid=true],select[aria-invalid=true],textarea[aria-invalid=true]{--border-color:var(--form-element-invalid-border-color);background-image:var(--icon-invalid)}input[aria-invalid=true]:active,input[aria-invalid=true]:focus,select[aria-invalid=true]:active,select[aria-invalid=true]:focus,textarea[aria-invalid=true]:active,textarea[aria-invalid=true]:focus{--border-color:var(--form-element-invalid-active-border-color)!important}input::-webkit-input-placeholder,input::placeholder,select:invalid,textarea::-webkit-input-placeholder,textarea::placeholder{color:var(--form-element-placeholder-color);opacity:1}input:not([type=checkbox]):not([type=radio]),select,textarea{margin-bottom:var(--spacing)}select::-ms-expand{border:0;background-color:transparent}select:not([multiple]):not([size]){padding-right:calc(var(--form-element-spacing-horizontal) + 1.5rem);background-image:var(--icon-chevron);background-position:center right .75rem;background-repeat:no-repeat;background-size:1rem auto}input+small,select+small,textarea+small{display:block;width:100%;margin-top:calc(var(--spacing) * -0.75);margin-bottom:var(--spacing);color:var(--muted-color)}label>input,label>select,label>textarea{margin-top:calc(var(--spacing) / 4)}[type=checkbox],[type=radio]{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:inline-block;width:1.25em;height:1.25em;margin-top:-.125em;margin-right:.375em;border-width:var(--border-width);vertical-align:middle;cursor:pointer}[type=checkbox]::-ms-check,[type=radio]::-ms-check{display:none}[type=checkbox]:checked,[type=checkbox]:checked:active,[type=checkbox]:checked:focus,[type=radio]:checked,[type=radio]:checked:active,[type=radio]:checked:focus{--background-color:var(--primary);--border-color:var(--primary);background-image:var(--icon-checkbox);background-position:center;background-repeat:no-repeat;background-size:.75em auto}[type=checkbox]~label,[type=radio]~label{display:inline-block;margin-right:.375em;margin-bottom:0;cursor:pointer}[type=checkbox]:indeterminate{--background-color:var(--primary);--border-color:var(--primary);background-image:var(--icon-minus);background-position:center;background-repeat:no-repeat;background-size:.75em auto}[type=radio]{border-radius:50%}[type=radio]:checked,[type=radio]:checked:active,[type=radio]:checked:focus{--background-color:var(--primary-inverse);border-width:.35em;background-image:none}[type=checkbox][role=switch]{--background-color:var(--switch-background-color);--border-color:var(--switch-background-color);--color:var(--switch-color);width:2.25em;height:1.25em;border:var(--border-width) solid var(--border-color);border-radius:1.25em;background-color:var(--background-color);line-height:1.25em}[type=checkbox][role=switch]:focus{--background-color:var(--switch-background-color);--border-color:var(--switch-background-color)}[type=checkbox][role=switch]:checked{--background-color:var(--switch-checked-background-color);--border-color:var(--switch-checked-background-color)}[type=checkbox][role=switch]:before{display:block;width:calc(1.25em - (var(--border-width) * 2));height:100%;border-radius:50%;background-color:var(--color);content:'';transition:margin 0.1s ease-in-out}[type=checkbox][role=switch]:checked{background-image:none}[type=checkbox][role=switch]:checked:before{margin-right:0;margin-left:calc(1.125em - var(--border-width))}[type=color]::-webkit-color-swatch-wrapper{padding:0}[type=color]::-moz-focus-inner{padding:0}[type=color]::-webkit-color-swatch{border:none;border-radius:calc(var(--border-radius) / 2)}[type=color]::-moz-color-swatch{border:none;border-radius:calc(var(--border-radius) / 2)}[type=date],[type=datetime-local],[type=month],[type=time],[type=week]{background-image:var(--icon-date);background-position:center right .75rem;background-repeat:no-repeat;background-size:1rem auto}[type=date]::-webkit-calendar-picker-indicator,[type=datetime-local]::-webkit-calendar-picker-indicator,[type=month]::-webkit-calendar-picker-indicator,[type=time]::-webkit-calendar-picker-indicator,[type=week]::-webkit-calendar-picker-indicator{opacity:0}[type=time]{background-image:var(--icon-time)}[type=file]{--color:var(--muted-color);padding:calc(var(--form-element-spacing-vertical)/2) 0;border:none;border-radius:0;background:none}[type=file]::-webkit-file-upload-button{--background-color:var(--secondary);--border-color:var(--secondary);--color:var(--secondary-inverse);margin-right:calc(var(--spacing) / 2);padding:calc(var(--form-element-spacing-vertical) / 2) calc(var(--form-element-spacing-horizontal) / 2);border:var(--border-width) solid var(--border-color);border-radius:var(--border-radius);outline:none;background-color:var(--background-color);box-shadow:var(--box-shadow);color:var(--color);font-size:1rem;font-weight:var(--font-weight);line-height:var(--line-height);text-align:center;cursor:pointer;transition:background-color var(--transition),border-color var(--transition),color var(--transition),box-shadow var(--transition)}[type=file]:active,[type=file]:focus,[type=file]:hover{--color:var(--color);border:none;background:none}[type=file]:active::-webkit-file-upload-button,[type=file]:focus::-webkit-file-upload-button,[type=file]:hover::-webkit-file-upload-button{--background-color:var(--secondary-hover);--border-color:var(--secondary-hover)}[type=range]{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:block;width:100%;height:1.25rem;background:transparent}[type=range]::-webkit-slider-runnable-track{width:100%;height:0.25rem;border-radius:var(--border-radius);background-color:var(--range-border-color);transition:background-color var(--transition),box-shadow var(--transition)}[type=range]::-moz-range-track{width:100%;height:0.25rem;border-radius:var(--border-radius);background-color:var(--range-border-color);transition:background-color var(--transition),box-shadow var(--transition)}[type=range]::-ms-track{width:100%;height:0.25rem;border-radius:var(--border-radius);background-color:var(--range-border-color);transition:background-color var(--transition),box-shadow var(--transition)}[type=range]::-ms-fill-lower{background-color:var(--border-radius)}[type=range]::-webkit-slider-thumb{-webkit-appearance:none;width:1.25rem;height:1.25rem;margin-top:-0.5rem;border:2px solid var(--range-thumb-border-color);border-radius:50%;background-color:var(--range-thumb-color);cursor:pointer;transition:background-color var(--transition),transform var(--transition)}[type=range]::-moz-range-thumb{-webkit-appearance:none;width:1.25rem;height:1.25rem;margin-top:-0.5rem;border:2px solid var(--range-thumb-border-color);border-radius:50%;background-color:var(--range-thumb-color);cursor:pointer;transition:background-color var(--transition),transform var(--transition)}[type=range]::-ms-thumb{-webkit-appearance:none;width:1.25rem;height:1.25rem;margin-top:-0.5rem;border:2px solid var(--range-thumb-border-color);border-radius:50%;background-color:var(--range-thumb-color);cursor:pointer;transition:background-color var(--transition),transform var(--transition)}[type=range]:focus,[type=range]:hover{--range-border-color:var(--range-active-border-color);--range-thumb-color:var(--range-thumb-hover-color)}[type=range]:active{--range-thumb-color:var(--range-thumb-active-color)}[type=range]:active::-webkit-slider-thumb{transform:scale(1.25)}[type=range]:active::-moz-range-thumb{transform:scale(1.25)}[type=range]:active::-ms-thumb{transform:scale(1.25)}[type=search]{border-radius:5rem;padding-left:calc(var(--form-element-spacing-horizontal) + 1.75rem)!important;background-image:var(--icon-search);background-position:center left 1.125rem;background-repeat:no-repeat;background-size:1rem auto}[type=search]::-webkit-search-cancel-button{-webkit-appearance:none;display:none}table{width:100%;border-color:inherit;border-collapse:collapse;border-spacing:0;text-indent:0}td,th{padding:calc(var(--spacing) / 2) var(--spacing);border-bottom:var(--border-width) solid var(--table-border-color);color:var(--color);font-size:var(--font-size);font-weight:var(--font-weight);text-align:left}tr{background-color:var(--background-color)}table[role=grid] tbody tr:nth-child(odd){--background-color:var(--table-row-stripped-background-color)}code,kbd,pre,samp{font-family:var(--font-family);font-size:.875rem}pre{-ms-overflow-style:scrollbar;overflow:auto}code,kbd,pre{background:var(--code-background-color);color:var(--code-color);font-weight:var(--font-weight);line-height:initial}code,kbd{display:inline-block;padding:.375rem .5rem;border-radius:var(--border-radius)}pre{display:block;margin-bottom:var(--spacing);padding:var(--spacing);overflow-x:auto;background:var(--code-background-color)}pre>code{display:block;padding:0;background:transparent;font-size:14px;line-height:var(--line-height)}code b{color:var(--code-tag-color);font-weight:var(--font-weight)}code i{color:var(--code-property-color);font-style:normal}code u{color:var(--code-value-color);text-decoration:none}code em{color:var(--code-comment-color);font-style:normal}kbd{background-color:var(--code-kbd-background-color);color:var(--code-kbd-color);vertical-align:middle}hr{box-sizing:content-box;height:0;overflow:visible;border:none;border-top:1px solid var(--muted-border-color)}[hidden],template{display:none}dialog{display:block;position:absolute;right:0;left:0;width:-moz-fit-content;width:-webkit-fit-content;width:fit-content;height:-moz-fit-content;height:-webkit-fit-content;height:fit-content;margin:auto;padding:1em;border:solid;background-color:white;color:black}dialog:not([open]){display:none}canvas{display:inline-block}details{display:block;margin-bottom:var(--spacing);padding-bottom:calc(var(--spacing) / 2);border-bottom:var(--border-width) solid var(--accordion-border-color)}details summary{color:var(--accordion-close-summary-color);line-height:1rem;list-style-type:none;list-style-type:none;cursor:pointer;transition:color var(--transition)}details summary::-webkit-details-marker{display:none}details summary::marker{display:none}details summary::-moz-list-bullet{list-style-type:none}details summary:after{display:inline-block;width:1rem;height:1rem;float:right;transform:rotate(-90deg);background-image:var(--icon-chevron);background-position:center;background-repeat:no-repeat;background-size:1rem auto;content:'';transition:transform var(--transition)}details summary:focus{outline:none;color:var(--accordion-active-summary-color)}details summary~*{margin-top:calc(var(--spacing) / 2)}details summary~*~*{margin-top:0}details[open]>summary{margin-bottom:calc(var(--spacing) / 4)}details[open]>summary:not(:focus){color:var(--accordion-open-summary-color)}details[open]>summary:after{transform:rotate(0)}article{margin:var(--block-spacing-vertical) 0;padding:var(--block-spacing-vertical) var(--block-spacing-horizontal);overflow:hidden;border-radius:var(--border-radius);background:var(--card-background-color);box-shadow:var(--card-box-shadow)}article>footer,article>header,article>pre{margin-right:calc(var(--block-spacing-horizontal) * -1);margin-left:calc(var(--block-spacing-horizontal) * -1);padding:calc(var(--block-spacing-vertical) / 1.5) var(--block-spacing-horizontal);background-color:var(--card-sectionning-background-color)}article>header{margin-top:calc(var(--block-spacing-vertical) * -1);margin-bottom:var(--block-spacing-vertical);border-bottom:var(--border-width) solid var(--card-border-color)}article>footer,article>pre{margin-top:var(--block-spacing-vertical);margin-bottom:calc(var(--block-spacing-vertical) * -1);border-top:var(--border-width) solid var(--card-border-color)}nav,nav ul{display:flex}nav{justify-content:space-between}nav ol,nav ul{align-items:center;margin-bottom:0;padding:0;list-style:none}nav ol:first-of-type,nav ul:first-of-type{margin-left:calc(var(--spacing) * -0.5)}nav ol:last-of-type,nav ul:last-of-type{margin-right:calc(var(--spacing) * -0.5)}nav li{display:inline-block;margin:0;padding:var(--spacing) calc(var(--spacing) / 2)}nav li>*,nav li>input:not([type=checkbox]):not([type=radio]){margin-bottom:0}nav a{display:block;margin:calc(var(--spacing) * -1) calc(var(--spacing) * -0.5);padding:var(--spacing) calc(var(--spacing) / 2);border-radius:var(--border-radius);text-decoration:none}nav a:active,nav a:focus,nav a:hover{text-decoration:none}aside li,aside nav,aside ol,aside ul{display:block}aside li{padding:calc(var(--spacing) / 2)}aside li a{margin:calc(var(--spacing) * -0.5);padding:calc(var(--spacing) / 2)}progress{display:inline-block;vertical-align:baseline}progress{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:inline-block;width:100%;height:.5rem;margin-bottom:calc(var(--spacing) / 2);overflow:hidden;border:0;border-radius:var(--border-radius);background-color:var(--progress-background-color);color:var(--progress-color)}progress::-webkit-progress-bar{border-radius:var(--border-radius);background:transparent}progress[value]::-webkit-progress-value{background-color:var(--progress-color)}progress::-moz-progress-bar{background-color:var(--progress-color)}@media (prefers-reduced-motion:no-preference){progress:indeterminate{background:var(--progress-background-color) linear-gradient(to right,var(--progress-color) 30%,var(--progress-background-color) 30%) top left/150% 150% no-repeat;animation:progressIndeterminate 1s linear infinite}progress:indeterminate[value]::-webkit-progress-value{background-color:transparent}progress:indeterminate::-moz-progress-bar{background-color:transparent}}@keyframes progressIndeterminate{0%{background-position:200% 0}to{background-position:-200% 0}}[aria-busy=true]{cursor:progress}[aria-busy=true]:not(input):not(select):not(textarea):before{display:inline-block;width:1em;height:1em;border:0.1875em solid currentColor;border-radius:1em;border-right-color:transparent;vertical-align:text-bottom;vertical-align:-.125em;animation:spinner 0.75s linear infinite;content:'';opacity:var(--loading-spinner-opacity)}[aria-busy=true]:not(input):not(select):not(textarea):not(:empty):before{margin-right:calc(var(--spacing) / 2)}[aria-busy=true]:not(input):not(select):not(textarea):empty{text-align:center}a[aria-busy=true],button[aria-busy=true],input[type=button][aria-busy=true],input[type=reset][aria-busy=true],input[type=submit][aria-busy=true]{pointer-events:none}@keyframes spinner{to{transform:rotate(360deg)}}[data-tooltip]{position:relative}[data-tooltip]:not(a):not(button):not(input){border-bottom:1px dotted;text-decoration:none;cursor:help}[data-tooltip]:after,[data-tooltip]:before{display:block;z-index:99;position:absolute;bottom:100%;left:50%;padding:.25rem .5rem;overflow:hidden;transform:translate(-50%,-0.25rem);border-radius:var(--border-radius);background:var(--tooltip-background-color);color:var(--tooltip-color);font-size:.875rem;font-style:normal;font-weight:var(--font-weight);text-decoration:none;text-overflow:ellipsis;white-space:nowrap;content:attr(data-tooltip);opacity:0;pointer-events:none}[data-tooltip]:after{padding:0;transform:translate(-50%,0rem);border-top:.3rem solid;border-right:.3rem solid transparent;border-left:.3rem solid transparent;border-radius:0;background-color:transparent;color:var(--tooltip-background-color);content:''}[data-tooltip]:focus:after,[data-tooltip]:focus:before,[data-tooltip]:hover:after,[data-tooltip]:hover:before{opacity:1;animation-name:slide;animation-duration:.2s}[data-tooltip]:focus:after,[data-tooltip]:hover:after{animation-name:slideCaret}@keyframes slide{0%{transform:translate(-50%,0.75rem);opacity:0}to{transform:translate(-50%,-0.25rem);opacity:1}}@keyframes slideCaret{0%{opacity:0}50%{transform:translate(-50%,-0.25rem);opacity:0}to{transform:translate(-50%,0rem);opacity:1}}[aria-controls]{cursor:pointer}[aria-disabled=true],[disabled]{cursor:not-allowed}[aria-hidden=false][hidden]{display:initial}[aria-hidden=false][hidden]:not(:focus){clip:rect(0,0,0,0);position:absolute}[tabindex],a,area,button,input,label,select,summary,textarea{-ms-touch-action:manipulation}@media (prefers-reduced-motion:reduce){:not([aria-busy=true]),:not([aria-busy=true]):after,:not([aria-busy=true]):before{background-attachment:initial!important;animation-duration:1ms!important;animation-delay:-1ms!important;animation-iteration-count:1!important;scroll-behavior:auto!important;transition-delay:0s!important;transition-duration:0s!important}}
    </style>
    <style type="text/css">
      article div {
        font-size: 1.15em;
        line-height: 1.6em;
      }
    </style>
  </head>
  <body style="background-color: #f9fafb;">
    <main class="container">
      <nav>
        <ul>
          <li><a href="../index.html"> Topic list</a></li>
        </ul>
      </nav>
      <!-- <h1>Infomedia Articles Selection: 50 articles</h1> -->
      <h1>H_0_73 <kbd>H_0_73</kbd></h1>
      <h3>Words (top 25)</h3>
      <div style="margin:0px -12px">
        <span style="font-size:11.32pt; padding:0px 12px"><strong>model</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>features</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>modellen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>parametrene</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>performance</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>metoder</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>udviklere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kompleksiteten</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>open</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>genkende</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>trne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>edge</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>softwaresystemer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>maskinlring</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>latency</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>teknikker</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>network</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>regnekraften</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sandsynligheder</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>beslutningstr</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>rafal</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ai-systemer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>scientist</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>feature</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>datasttet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>stningen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fejlrate</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>case</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>input</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>networks</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>trnet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>slutbrugeren</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>billedanalyse</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ghosh</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>cpu</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>protein</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>computerkraft</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>differentialligninger</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ml</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>iteration</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>udfra</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>learning-modellen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>datast</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>neuralt</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>neurale</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>bias</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>oplring</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>skalerer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>variabel</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>inputs</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>lsbar</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>reproduceres</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>detektion</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>object</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>memory</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>processeres</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sebastian</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>hukommelsen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>detekterer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>visionsystemer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>udlede</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>metoderne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>genkendelse</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>output</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>validering</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>cleve</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>trnes</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>embedded</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>visualisere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>slutbrugerne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>lego-klodser</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>maskinlringsalgoritmer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ai-software</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>klassificering</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fintune</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>estimere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>practice</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>funktionelle</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>statiske</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>oplre</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>datalogiprofessor</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>benchmarks</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>generalisere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>netvrkene</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>goals</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>annotere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>moores</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sekvensen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>grammatisk</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>opstilling</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>tensor</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>tilgngeligheden</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>stikprver</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ieee</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ai-teknologien</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>programmren</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>generator</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>angry</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>billeddata</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>optimeringer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>numerisk</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>cornell</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>explainable</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>marin</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kompilere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kolonner</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>iterationer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>convolutional</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>vector</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>skvhed</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>outputtet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>goodwin</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>license</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>teknikkerne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>tunet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>cay</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>binr</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>modellere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>gruppere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>billedgenkendelse</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>bi</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>bachelorer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>udtrkke</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>lommeregneren</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>niko</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>rsonnement</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>modellernes</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>rescue</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>trningsst</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>vektor</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>processere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>supervised</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>inputtet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ng</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>gpu-er</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>tagge</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>additive</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>klassificere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>udviklernes</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kai</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>singh</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>spark</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ai-applikationer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>medtage</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>label</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>synonymer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>molekyle</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>implementeringer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>klodser</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>erhvervs-ph.d</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>succesraten</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>indkomne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>kodebase</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fejlslutninger</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ansigtsmimik</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>informationssystemer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>statistiker</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>brandes</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>lex</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>elements</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>jean-philippe</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>datakvaliteten</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>lstm</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ai-modellen</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fpga</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>goldberg</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>mainframe</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>grafikprocessor</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>sensitiv</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>ai-systemerne</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>array</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fejlagtig</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>write</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>klassificeres</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>geer</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>osten</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>konfigurere</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>gans</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>delmngde</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>morfologi</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>proof-of-concept</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>scalable</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>easyjet</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>visualiseres</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>tidsserier</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>overreprsentation</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>hao</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>aasa</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>fuzzy</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>crow</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>switch</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>securitas</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>mierswa</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>hrushikesh</strong>&nbsp;<span style="font-size:.5em">1</span></span>
        <span style="font-size:11.32pt; padding:0px 12px"><strong>gioia</strong>&nbsp;<span style="font-size:.5em">1</span></span>
      </div>
      <br><br>
      <h3>Articles (top 50)</h3>
      Query:
      <pre>SELECT * FROM articles WHERE articles.dupeKeep=1 AND articles.sizeKeep=1 ORDER BY H_0_73 DESC LIMIT 50</pre>
      <article>
        <h4>OpenAI lancerer Safety Gym til reinforcement learning</h4>
        <div>
          Safety Gym er en ny rkke vktjer fra OpenAI, der skal hjlpe udviklere med bygge AI-systemer, der respekterer sikkerhedsbegrnsninger, nr de trnes. Det skriver Venture Beat Safety Gym er spicifikt designet til brug for reinforcemnet learning for at styre, at agenten ikke foretager desideret farlige handlinger i frsg p at optimere belnningen. Redaktionen
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2019-11-25
          &nbsp;&nbsp; e775d044
          &nbsp;&nbsp; #0
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.936</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.919</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.647</kbd>
        </footer>
      </article>
      <article>
        <h4>Google gr AI-modelsger til open source</h4>
        <div>
          Tensorflow-vrktj sammenstter p egen hnd deep learning-modeller. Et hold fra Google Research har udsendt vrktjet Model Search som open source. Det er en automatiseret machine learning-platform beregnet p at udvikle deep learning-modeller, skriver InfoqEksperimentelle resultater viser, at systemet kan producere modeller, der overgr de bedste designs fra menneskelig hnd, med frre trnings-iterationer og modelparametre.Forskerne Hanna Mazzawi og Xavi Gonzalvo har beskrevet systemet i et blogindlg . Model Search er implementeret med Googles Tensorflow-teknologi og sammenstter et dybt neuralt netvrk, som er neurale netvrk med mange skjulte lag, ud fra komponenter, der eksempelvis kan vre transformere eller LSTM-lag (Long Short-Term Memory).Systemet trner og evaluerer et st kandidatmodeller, der hver bestr af flere blokke. En sgealgoritme vlger derefter den mest effektive model og 'muterer' den. Denne proces gentages iterativt, indtil den bedste model er fundet.Google-teamet har angiveligt brugt Model Search til at oprette deep learning-systemer til talebehandling, der med kun 60 procent af parametrene overgr dagens bedst ydende modeller.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2021-03-11
          &nbsp;&nbsp; e829b984
          &nbsp;&nbsp; #1
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.978</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.891</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.558</kbd>
        </footer>
      </article>
      <article>
        <h4>Hybrid mellem neuralt net og beslutningstr giver forklarlig deep learning</h4>
        <div>
          Neurale net arrangeret som beslutningstr giver bde forklarlighed og prcision, mener AI-forskere. Beslutningstrer er den gyldne standard, hvis en model skal vre bde forklarlig og intuitiv. Men p komplekse opgaver som at klassificere billeder fejler trerne med en prcision, der er vsentligt ringere end et neuralt netvrk. Men med et nyt koncept, udviklet af forskere fra Berkleys center for AI-forskning, kan man f det bedste af begge verdener. Neural-Backed Decision Trees (NBDT) tager den overordnede, intuitive gennesigtighed fra beslutningstrer, men bruger neurale netvrk til at tage beslutninger. Resultatet er iflge Berkeley-forskerne en model, der kan matche almindelige neurale netvrk i prcision, men hvor en almindelig bruger kan aflse, hvordan modellen kom frem til sin beslutning. NBDT-modellen bestr af et beslutningstr, hvor hver node er et neuralt netvrk. P billede-datasts CIFAR10, CIFAR100, og TinyImageNet200 slr den kombination andre forklarlige, trbaserede metoder med en betydelig margin. Og forbliver indenfor omkring 1 procent i nrheden af performance af neurale netvrk. Forklaringen giver srligt menig, nr modellen skal klassificere billeder med indhold, den ikk har set fr. CIFAR10-modellen har f.eks. aldrig set et Zebra, men gennem NBDT-modellen kan vi se, at modellen korrekt identificere at der er tale om et hovdyr, fr den gtter p hest. Bedre performance betyder mere forstlig Ideen er simpel, men det er ikke helt simpelt, at omdanne et neuralt netvrk til et beslutningstr. Processen krver blandt andet, hvad forskerne kalder induced hierarchy, der afgr, hvilke st af klasser - f.eks. hund eller kat - noderne modellen skal tage stilling til. Hierarkiet bliver bygget ud fra vgtene i et prtrnet neuralt netvrk, og med en clustering-teknik finder man frem til hvilke klassifikationer br have en flles 'forldre'-node. De noder kan efterflgende testes kvantitativt. Hvis man f.eks. antager, at en node afgr om billedet forestiller dyr eller fartj, kan man teste det ved at lbe en masse billeder af dyr og fartjer gennem modellen. Og p den mde kan man give hver node - som effektivt er en underdel af et lag i det samlede neurale netvrk - en semantisk betydning. I forskernes prpublicerede artikel bemrker de en positiv sammenhng mellem det neurale netvrks prcision og hvor semantisk fornuftig hierakiet i stidste ende virker. We believe that higher-accuracy models exhibit more semantically-sound weight spaces. Thus, unlike previous work, NBDTs feature better interpretability with higher accuracy, instead of sacrificing one for the other.  Fugl eller fly Eksisterende metoder til at forklare belsutningerne fra et neuralt netvrk, har sin mangler, ppeger Alvin Wan, der er en af forskerne bag projektet og pt. skriver sin ph.d. i AI ved Berkeley, i en blog Saliency maps, som kan bruges til at forst klassifikationer af billeder, kan f.eks. ikke bruges, nr et netvrk kommer frem til forkerte beslutninger, men fokuserer p det rigtige - som f.eks. nr en fugl klassificeres som et fly. Endnu er NBDT-modellen kun brugt p de klassiske billede-klassifikationsdatabaser. Det er derfor uvist, hvor meget klarhed NBDT-modellen kan bringe til situationer, hvor den logiske vej til en beslutning ikke er s simpel som at skelne dyr fra kretjer - f.eks. nr et neuralt netvrk skal spotte brystkrft. Ikke desto mindre er der givet situationer, hvor kombinationer af et effektivt neuralt netvrk og et visuelt, intuitivt beslutningstr er attraktivt. Man kan afprve prtrnede NBDT-modeller her , hvor man ogs kan hente koden.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2020-05-28
          &nbsp;&nbsp; e7b9f4fe
          &nbsp;&nbsp; #2
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.969</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.973</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.665</kbd>
        </footer>
      </article>
      <article>
        <h4>Ph.d.-forsvar: P jagt i krft-data</h4>
        <div>
           Tobias Madsen holder ph.d.-forsvar torsdag 30. november om &quot;Robuste statistiske metoder til signifikans evaluering med anvendelser indenfor detektion af cancer-drivende mutationer og biomarkrer&quot;.Det sker kl. 12 i bygning 1110, lokale 223, BiRC, Aarhus Universitet, C.F. Mllers Alle 8, Aarhus C. Der er offentlig adgang.I forbindelse med sin forskning har Tobias Madsen udviklet nye statistiske metoder til at analysere store genomiske datast. Han og hans forskningskollegaer har taget del i et stort internationalt cancerkonsortium med adgang til mere end 2500 cancergenomer. Adgangen til denne hidtil strste database af sin art giver mulighed for nye fund indenfor krftforskningen. P den anden side giver de store datast ogs store udfordringer: For det frste kan de metoder, man bruger til mindre datast, vre for grove til at anvende p strre datast. For det andet er det vanskeligt at udvikle algoritmer, der skalerer til disse data sdan, at analyserne kan blive gennemfrt p overskuelig tid. Den proteinkodende del af genomet er velstuderet, og metoderne, som Tobias Madsen har udviklet, er blevet brugt til at finde elementer udenfor det proteinkodende genom impliceret i udviklingen af cancer.
        </div>
        <footer>
          <em>Stiften.dk (rhus Stiftstidende)</em>
          &nbsp;&nbsp; 2017-11-29
          &nbsp;&nbsp; e685ff91
          &nbsp;&nbsp; #3
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.928</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.625</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.606</kbd>
        </footer>
      </article>
      <article>
        <h4>Lego-sortering med kunstig intelligens</h4>
        <div>
          Australier har bygget en sorteringsmaskine til Lego-klodser. Ved hjlp af neurale netvrk og open source-databaser kan den trnes til at genkende alle eksisterende Lego-klodser.De fleste kender problemet fra brnevrelset: Jo mere Lego, der kommer ind i huset, desto mere uoverskueligt bliver det at finde de rigtige klodser. Da jeg var barn, l al mit Lego i kasser, og jeg husker den evindelige kamp med at finde de rette klodser - isr de sm havde det med at gemme sig nede p bunden af kassen.Derfor virker det oplagt med en sorteringsmaskine. Sdan en har australieren Daniel West bygget - af Lego, eller nrmere bestemt cirka 10.000 klodser.Umiddelbart tnker man, at der er brug for et avanceret vision-system for at kunne genkende de mange forskellige klodser. Men problemet er, at der eksisterer omkring 10.000 forskellige klodser, og det ville vre umuligt at f traditionel billedegenkendelses-software til at genkende klodser, som passerer forbi i drlig belysning. Derfor har Daniel West taget et neuralt netvrk i brug.Men inden da skal der bygges et automationssystem, der kan hndtere en spandfuld Lego-klodser. Til det har han opdelt maskinen i tre dele: en fder, som klodserne kan hldes ned i, og et bltesystem, som frer dem videre til et vibrationssystem. Her bruger han Legos hurtigste motor til at vibrere klodserne, s de ikke ligger oven p hinanden, men bliver frt videre n ad gangen.Nste skridt er selve scanneren. Der har tidligere vret byggeprojekter til at sortere Lego-klodser, men Daniel West mener, at hans er det frste, som kan hndtere alle klodser, der nogensinde er blevet produceret af Lego. For at det kan lade sig gre, bruger han AI og en database med CAD-modeller af klodserne. Det er ikke noget, som Lego selv har offentliggjort, men brugere har over en rrkke opbygget databaser som LDraw.org og Rebrickable.AI kan trnes p databasenI systemet bliver klodsen scannet, en Raspberry Pi-computer registrerer scanningen og sender billedet videre til en pc, som krer en variant af neurale netvrk kaldet convolutional neural network. Softwaren sammenligner hver enkelt Lego-klods med databasen og fr derefter et nummer ud.Daniel West siger, at han kan sortere 3.000 forskellige klodser, men potentielt kan maskinen klare alle klodser, ogs dem, den ikke har set endnu. Den kan nemlig trnes blot ved at bruge databaserne med klodser.Det nummer, som hver enkel klods fr tildelt, sendes tilbage til sorteringsmaskinen, som s kan fordele klodserne i 18 forskellige bokse. Antallet af bokse kan udvides uendeligt, det krver bare en strre maskine. Maskinen er i stand til at hndtere en klods p to sekunder.Det tog seks mneder at bygge sorteringsmaskinen, og den bestr af seks Lego-motorer, en rkke servoer, en Raspberry Pi, lysstning, et kamera og en pc til at kre AI-softwaren - og s alts cirka 10.000 Lego-klodser.
        </div>
        <footer>
          <em>Ing.dk (Ingeniren)</em>
          &nbsp;&nbsp; 2019-12-15
          &nbsp;&nbsp; e77f3dc8
          &nbsp;&nbsp; #4
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.964</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.991</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.719</kbd>
        </footer>
      </article>
      <article>
        <h4>Android fr bedre machine learning-muligheder</h4>
        <div>
            ML Kit er ikke lngere syet sammen med Firebase. Android-udviklingsholdet tilfjer nye funktioner til sit machine learning-bibliotek 'ML Kit,' der i bruges i over 25.000 iOS- og Android-apps. Det skriver mediet SD Times ML Kit er virksomhedens lsning til at integrere maskinlring i mobile applikationer. Det blev lanceret i 2018. Det opdaterede bibliotek er ikke lngere afhngig af Googles Firebase-milj, som den originale version af ML Kit gjorde. Feedback fra brugerne pegede p, at der var et nske om strre fleksibilitet. Udviklere har dog stadig muligheden for at bruge ML Kit sammen med Firebase. Fordelene ved at benytte machine learning p selve enheden i forhold til at bruge en servertjeneste er hastighed, muligheden for at arbejde offline og mere privatliv, skriver SD Times.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2020-06-26
          &nbsp;&nbsp; e7c4f360
          &nbsp;&nbsp; #5
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.713</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.814</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.591</kbd>
        </footer>
      </article>
      <article>
        <h4>Lego-sortering med TensorFlow og syntetisk trningsdata</h4>
        <div>
          Australier har bygget en sorteringsmaskine til Lego-klodser. Ved hjlp af neurale netvrk og open source-databaser kan den trnes til at genkende alle eksisterende Lego-klodser. ING.DK : De fleste kender problemet fra brnevrelset: Jo mere Lego, der kommer ind i huset, desto mere uoverskueligt bliver det at finde de rigtige klodser. Da jeg var barn, l al mit Lego i kasser, og jeg husker den evindelige kamp med at finde de rette klodser - isr de sm havde det med at gemme sig nede p bunden af kassen. Derfor virker det oplagt med en sorteringsmaskine. Sdan en har australieren Daniel West bygget - af Lego, eller nrmere bestemt cirka 10.000 klodser. Det skriver Gizmodo Umiddelbart tnker man, at der er brug for et avanceret vision-system for at kunne genkende de mange forskellige klodser. Men problemet er, at der eksisterer omkring 10.000 forskellige klodser, og det ville vre umuligt at f traditionel billedegenkendelses-software til at genkende klodser, som passerer forbi i drlig belysning. Derfor har Daniel West taget et neuralt netvrk i brug. Men inden da skal der bygges et automationssystem, der kan hndtere en spandfuld Lego-klodser. Til det har han opdelt maskinen i tre dele: en fder, som klodserne kan hldes ned i, og et bltesystem, som frer dem videre til et vibrationssystem. Her bruger han Legos hurtigste motor til at vibrere klodserne, s de ikke ligger oven p hinanden, men bliver frt videre n ad gangen. Nste skridt er selve scanneren. Der har tidligere vret byggeprojekter til at sortere Lego-klodser, men Daniel West mener, at hans er det frste, som kan hndtere alle klodser, der nogensinde er blevet produceret af Lego. Syntetisk trningsdata I systemet bliver klodsen scannet, en Raspberry Pi-computer registrerer scanningen og sender billedet videre til en pc, som krer et convolutional neural network bygget i TensorFlow. Softwaren sammenligner hver enkelt Lego-klods med databasen og fr derefter et nummer ud. For at det kan lade sig gre, bruger han AI og en database med CAD-modeller af klodserne. Det er ikke noget, som Lego selv har offentliggjort, men brugere har over en rrkke opbygget databaser som LDraw.org og Rebrickable Udfra CAD-modellerne, der er 3D-reprsentationer af hver enkelt klods, kunne Daniel West skabe syntetisk trningsdata til sit netvrk. Med den data har Daniel West brugt en teknik kaldet Domain Randomization , som indbygger tilfldigheder i genereringen af den kunstige trningsdata, som skaber variation i trningsdata og gr modellen mere robust. Endelig er modellen fintunet med et mindre sample af manuelt annoterede billeder. Daniel West siger, at han kan sortere 3.000 forskellige klodser, men potentielt kan maskinen klare alle klodser, ogs dem, den ikke har set endnu. Den kan nemlig trnes blot ved at bruge databaserne med klodser. Det nummer, som hver enkel klods fr tildelt, sendes tilbage til sorteringsmaskinen, som s kan fordele klodserne i 18 forskellige bokse. Antallet af bokse kan udvides uendeligt, det krver bare en strre maskine. Maskinen er i stand til at hndtere en klods p to sekunder. Det tog seks mneder at bygge sorteringsmaskinen, og den bestr af seks Lego-motorer, en rkke servoer, en Raspberry Pi, lysstning, et kamera og en pc til at kre AI-softwaren - og s alts cirka 10.000 Lego-klodser.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2019-12-18
          &nbsp;&nbsp; e780e55d
          &nbsp;&nbsp; #6
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.969</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.992</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.709</kbd>
        </footer>
      </article>
      <article>
        <h4>Microsoft gr ekstra dybt med neuralt netvrk med 152 lag</h4>
        <div>
          Microsofts neurale netvrk indeholder 20 gange flere lag end almindelige dybe neurale netvrk og har netop vundet en konkurrence for computersyn.Den bedste algoritme til at genkende en banjo eller en blskimmelost p et vilkrligt foto er lige nu Microsofts 'deep residual network', som har vundet konkurrencen for computerdrevet billedgenkendelse, ImageNet. Men faktisk er der tale om et uhrt komplekst neuralt netvrk, skriver Wired .Microsoft benytter maskinlringsmetoden deep learning, hvor flere lag af algoritmer bruges til eksempelvis at genkende bestemte objekter p billeder. Normalt anvender denne type neurale netvrk seks eller syv lag - i visse tilflde op til 30 lag - men Microsofts netvrk benytter hele 152 lag.Normalt vil det ikke vre en fordel at anvende s mange lag, fordi signalet s at sige bliver mudret til undervejs gennem lagene. Microsoft har lst dette problem ved at implementere metoder til at springe visse lag over, som ikke er ndvendige for den aktuelle krsel.Nr du springer over lag p denne mde, s bevarer du signalstyrken meget lngere, og det viser sig at have en enorm positiv indvirkning p prcisionen, siger forskningschef Peter Lee fra Microsoft Research til Wired.En anden udfordring ved s stort et antal lag er arbejdet ved at udvlge de specifikke algoritmer i hvert lag. Her har Microsoft brugt en teknik, som er blevet mere almindelig for dybe neurale netvrk, nemlig at give netvrket et bedste bud p et st algoritmer og derefter lade det afprve forskellige varianter for at finde frem til en konfiguration, der giver de bedste resultater.Teknikkerne har vret kendt lnge inden for feltet, men de er gjort mulige i praksis takket vre muligheden for at afvikle algoritmerne p grafikprocessorer, som gr det muligt at oplre det neurale netvrk p enorme datast.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2016-01-14
          &nbsp;&nbsp; e574ba97
          &nbsp;&nbsp; #7
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.938</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.876</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.692</kbd>
        </footer>
      </article>
      <article>
        <h4>IBM har udviklet AI-malware, der venter med at angribe til det rette jeblik</h4>
        <div>
          IBM har udviklet proof-of-concept malware baseret p et 'convolutional neural network', som kan forblive i ro indtil helt specifikke betingelser er opfyldtKonceptet hedder DeepLocker og bliver i dag prsenteret p sikkerhedskonferencen Black Hat USA, som bliver afholdt i Las Vegas.Det skriver The Register.Ved at bruge et krypteret payload og samtidig lade et neuralt netvrk afgre, hvornr det skal aktiveres, kan konceptet gre det vsentligt svrere for sikkerhedsforskere og anti-virus-vrktjer at stoppe malwaren, skriver The Register.IBM har demonstreret konceptet ved at kryptere og gemme en kopi af Wannacry-ransomwaren i en videokommunikations-app sammen med kode, der bruger et neuralt netvrk til at afgre, hvornr en krypteringsngle skal frigives.Det neurale netvrk, var blevet trnet til at vente indtil et bestemt ansigt blev opfanget p video-appen. Da den rette person satte sig foran PC'en genkendte koden ansigtet, nglen blev frigivet, payload krt og systemets dokumenter taget til gidsel.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2018-08-09
          &nbsp;&nbsp; e6da5664
          &nbsp;&nbsp; #8
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.815</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.639</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.65</kbd>
        </footer>
      </article>
      <article>
        <h4>Danske forskere bruger deep learning til at finde stemmer i en hstak af stj</h4>
        <div>
          Brdtekst Den menneskelige evne til at lytte efter en enkelt stemme, nr du har en samtale i et rum fuld af konkurrerende samtaler, er enorm svr at efterligne med en algoritme.I arbejdet med avanceret lydanalyse er det skaldte cocktailparty-problem stadig ulst. Nu har danske forskere taget skridtet nrmere en lsning med deep learning.Udfordringen er, hvordan man fjerner unskede stjkilder, nr du optager i et stjfuldt rum med en enkelt mikrofon, forklarer Morten Kolbk, der netop har skrevet sin ph.d. om emnet ved Aalborg Universitet.Nr man kender et lydbillede p forhnd, som i et klinisk test-setup, kan algoritmer identificere en enkelt taler lige s godt som et menneske. Men hvis teknikken skal anvendes i fx. hreapparater, er det ikke nok. Modellen m kunne identificere en ukendt taler blandt en ukendt mngde af talere i en situation med en ukendt mngde baggrundsstj.Uden forudgende kendskab er den menneskelige hjerne stadig den bedste maskine, siger Morten Kolbk.Label permutationUdfordringen ved at f en algoritme til at separere lyden fra to talere - der ikke er kendt p forhnd - er, hvad litteraturen kalder 'label permutation'-problemet.Basalt set gr problemet ud p, at man gerne vil have et output fra modellen med en kanal for hver taler. Men du ved ikke p forhnd, hvilken stemme, der kommer ud af hvilken kanal.Det er en udfordring, nr man trner modellen, forklarer Morten Kolbk, fordi du med supervised learning skal sammenligne modellens output med det rigtige resultat - her i form af lyden fra de to separate talere.Med andre ord: Hvis taler A bliver separeret ud af modellen som output B, men trningsmodellen forventede, at taleren kom i output A, vil det fremst som et forkert resultat.P den mde kan man ikke trne modellen, fordi du ikke kan guide det neurale netvrk, siger Morten Kolbk.Problemet lste de danske forskere ved at ndre lidt i trningsalgoritmen, og essentielt gre rkkeflgen af talere ligegyldig under trning.Ved at gre det, s lser vi label permutation-problemet. Det betyder, at man relativt simpelt kan trne et neuralt netvrk til at separere talere fra hinanden. Det er noget, som man ikke kunne gre fr, siger forskeren.Algoritmen er demonstreret i flgende video:
        </div>
        <footer>
          <em>Pro.ing.dk/industrytech</em>
          &nbsp;&nbsp; 2019-01-10
          &nbsp;&nbsp; e709c0a4
          &nbsp;&nbsp; #9
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.991</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.803</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.665</kbd>
        </footer>
      </article>
      <article>
        <h4>Microsoft finder software-fejl med kunstig intelligens</h4>
        <div>
            Model kan genkende sikkerhedsfejl i 99 procent af tilfldende. Microsoft har indsamlet 13 millioner arbejdsopgaver og fejl siden 2001 og har brugt disse data til at oprette en maskinlringsmodel til at f has p softwarebugs.Iflge virksomheden kan modellen udpege fejl, som har at gre med sikkerhed i 99 procent af tilfldene. Tillige identificeres de vigtigste fejl 97 procent af tiden. Det skriver SD Times Hos Microsoft skaber 47.000 udviklere nsten 30.000 fejl om mneden. De gemmes p over 100 AzureDevOps- og Github-lagre. For bedre at opmrke og prioritere programfejl i den skala kunne vi ikke bare anvende flere mennesker til problemet. Store mngder af semi-kuraterede data er perfekte til maskinlring,  skriver Microsoft i et blogindlg
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2020-04-21
          &nbsp;&nbsp; e7ac5530
          &nbsp;&nbsp; #10
          <br>
          <br>
            <kbd data-tooltip="Tech industry &amp; regulation">L02_BIGTEC&nbsp;0.538</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.612</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.563</kbd>
        </footer>
      </article>
      <article>
        <h4>Facebooks glemsomme AI skal gre Transformers mere effektive</h4>
        <div>
          Facebooks nye deep learning-metode giver alle input en udlbsdato alt efter, hvor relevant informationen er. BrdtekstFacebook har udviklet en ny deep learning-metode, der lader modeller huske den vigtigste information - og glemme resten.Expire Span - som lsningen hedder - fungere grundlggende ved at give al indkommende data en udlbsdato baseret p en prdiktion af, hvor relevant den bliver for at lse en given opgave. Nr tindtrffer bliver data'en smidt ud som den sure mlk i kleskabet.Mlet er at gre den notorisk beregningstunge Transformer-model bedre til at udnytte regnekraften p den mest relevante mde.Evnen til at glemmeDet kritiske ved den menneskelige hukommelse er ikke bare evnen til at huske, skriver AI-forskerne fra Facebook Research i en artikel, der er optaget p dette rs ICML. Tricket er samtidig at glemme stjen for at kunne bruge bndbredde p de vsentlig detaljer.Det er en evne, som machine learning-modeller mangler generelt.Transformer-arkitekturen store styrke ligger i Attention-mekanismen, der lader modellen fokusere p en mindre del af inputtet ved at give systemet adgang til de skaldte hidden states. Men nr inputtet vokser sig rigtig stort - som f.eks. en hel bog - eksplodere den ndvendige mngde computerkraft p grund af antallet af hidden states modellen holder styr p.Ved at lade en Transformer-model glemme input, der ikke lngere er relevante, kan man skalere modellen op til at kunne hndtere meget lange input som f.eks. video, pointerer Facebook-forskerne i en blog.Hvis man f.eks. beder en standard Transformers model om at finde en gul dr i en video af en korridor med mange dre, vil den gemme informationen i hver frame. Hvis hver frame bliver vurderet og forkastet, hvis de ikke er relevante for opgaven med at finde den gule dr, kan modellen processorer en langt lngere video inden hukommelsen bliver fyldt op.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2021-05-20
          &nbsp;&nbsp; e84620cf
          &nbsp;&nbsp; #11
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.891</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.857</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.684</kbd>
        </footer>
      </article>
      <article>
        <h4>Forskere advarer: AI-forklaringsteknikker som Shap og Lime kan snydes</h4>
        <div>
          Et hold amerikanske forskere har demonstreret, at udbredte metoder til at bne black box-modeller rent faktisk kan snydes, s indbygget bias kan skjules. I arbejdet med at gre black box-machine learning til at forst bliver frameworks som Shap og Lime brugt mere og mere. Men teknikkerne er faktisk ikke plidelige, nr det handler om at afslre ellers skjult bias i ML-modellerne. Det mener et hold amerikanske forskere fra Harvard University og University of California. I en forskningsartikel , som blev offentliggjort i november, demonstrerer forskerne, at det er muligt at opbygge en klassifikationsmodel til at have en bias mod f.eks. race, men hvor forklaringer fra Lime og Shap ser uskyldige ud: In particular, our results show that the explanations of these classifiers generated using off-the-shelf implementations of Lime and Shap do not flag any of the relevant sensitive attributes (e.g., race) as important features of the classifier, thus demonstrating that the adversarial classifiers successfully fooled these explanation methods.  Forklaringsteknikker er ikke undersgt Shap og Lime er begge teknikker til at forklare et specifikt resultat fra en model, som ellers ikke er umiddelbart aflselig, som f.eks. en random forest. Modellen estimerer det bidrag, som den enkelte variabel giver til det endelige resultat. Det sker med en teknik, der kaldes 'input perturbations', hvilket grundlggende gr ud p at lave syntetisk data, som varierer inputtet for at se, hvad det betyder for resultatet, og p den mde afgr, hvilken del af inputtet er vigtigt for resultatet. Teknikkerne er blevet udbredt i takt med, at black box-modeller tages i brug til beslutningssttte. Med Shap kan en radiolog sledes f at vide, prcis hvilke dele af et billede der har fet deep learning-modellen til at mene, at patienten har en tumor. Eller en rekrutteringsalgoritme kan vise, hvilke dele af ansgerens CV der gr kandidaten interessant. Og i forlngelse deraf kan teknikken sledes ogs vise, om modellen fokuserer p noget, der ikke hensigtsmssigt. However, there has been little analysis of the reliability and robustness of these explanation techniques, especially in the adversarial setting, making their utility for critical applications unclear,  skriver forskerne. Med andre ord er sprgsmlet, hvor meget teknikkerne er vrd, hvis skaberne af modellen prver at snyde. Og her er svaret iflge de amerikanske forskere alts ikke oplftende. Klassifikation med stillads Forskerne forestiller sig at have et incitament til at bruge en model, der har en indbygget bias, men omvendt er underlagt regulatoriske krav om at lade modellen blive analyseret med teknikker som Shap og Lime. I artiklen prsenterer forskerne et framework, der som input har den diskriminerende klassifikationsmodel samt et sample af den data, som modellen skal bruges p. Med det input bygger frameworket, hvad forskerne kalder et stillads (scaffold) rundt om en klassifikationsmodel. Modellen med stilladset udnytter det faktum, at Lime og Shap bruger syntetisk data for at teste variablernes betydning. Distributionen i den syntetiske data er nemlig tilpas anderledes end den gte data, til at den ondsindede model kan skelne mellem, hvornr den bliver brugt, og hvornr den bliver testet. By being able to differentiate between data points coming from the input distribution and instances generated via perturbation, an adversary can create an adversarial classifier (scaffolding) that behaves like the original classifier (perhaps be extremely discriminatory) on the input data points, but behaves arbitrarily differently (looks unbiased and fair) on the perturbed instances, thus effectively fooling Lime or Shap into generating innocuous explanations,  skriver forskerne. Lime godkender kreditvurdering ud fra kn alene Artiklen giver to eksempler, hvor godt det virker i praksis. Forskerne bygger tre modeller: to, der p forskellige datast skal forudsige, om kriminelle vil beg ny kriminalitet alene baseret p race, og n model, der godkender ln alene baseret p kn. I alle tre tilflde kunne modellen snyde Lime til at lave forklaringer, der ikke afslrer modellernes bias. I Shap er forklaringen mere blandet. En af modellerne formede at snyde Shap i 100 procent af tilldene, mens Shap afslrer de andre to modellers bias i omkring 15 procent af tilfldene. Our findings suggest that existing post hoc explanation techniques are not sufficiently robust for ascertaining discriminatory behavior of classifiers in sensitive applications,  skriver forskerne, der foreslr, at man udvikler nye teknikker til at bne black box-modeller, som ikke kan narres. Professor: Drop black box-modeller De amerikanske forskere er ikke de eneste, der er skeptiske over for praksissen med at tilfje et forklaringslag til en black box-model. I en kommentar , der er udgivet i maj og senest opdateret i september, advokerer Cynthia Rudin, der er datalogiprofessor ved Duke University, for at bruge modeller, der i sig selv kan forsts og fortolkes, som f.eks. beslutningstrer. Rather than trying to create models that are inherently interpretable, there has been a recent explosion of work on 'Explainable ML', where a second (posthoc) model is created to explain the first black box model. This is problematic. Explanations are often not reliable, and can be misleading,  skriver hun. Selv hvis bde black box-modellen og den efterflgende model til forklaring gr deres arbejde efter hensigten, s er det alt for lidt information, der komme ud af det, argumenterer Rudin. Hun nvner som eksempel saliency maps, der kan bruges til at forst, hvad en computer vision-model egentlig ser p i et billede. Her demonstrerer Rudin, at et saliency map, der kategoriserer en hund som en fljte, essentielt ser ligedan ud, nr hunden kategorises korrekt. Fra Cynthia Rudins synsvinkel skal brugen af black box-modeller i kritiske miljer helt undgs. Trying to explain black box models, rather than creating models that are interpretable in the first place, is likely to perpetuate bad practices and can potentially cause catastrophic harm to society. 
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2019-12-10
          &nbsp;&nbsp; e77bda69
          &nbsp;&nbsp; #12
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.996</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.659</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.544</kbd>
        </footer>
      </article>
      <article>
        <h4>Javascript genkender ansigter i browseren</h4>
        <div>
          Nu kan Javascript-udviklere bygge ansigtsgenkendelse i webapps. Face-api.js er et Javascript-api til ansigtsgenkendelse i browseren implementeret oven p Googles Tensorflow.js, som er en Javascript-implementering af firmaets populre machine learning teknologi til browsere og Node.js-miljet.Til teknologibloggen Infoq forklarer Vincent Mhler, som er skaberen af Face-api.js motivationen bag:Jeg havde et andet bibliotek, som var i stand til at detektere ansigter og udfre ansigtsgenkendelse med Node.js. P et tidspunkt opdagede jeg Tensorflow.js og blev interesseret i maskinlring i browseren. Jeg var nysgerrig p, om det var muligt at flytte eksisterende modeller til ansigtsgenkendelse og ansigtsgenkendelse til Tensorflow.js, og det fungerede ganske godt. Face-api.js kommer med tre modeller: SSD Mobilenet V1, Tiny Face Detector og MTCNN.Tiny Face Detector er trnet p et brugerdefineret datast med 14.000 billeder. Apps med begrnsede resurser br bruge denne model.Til ansigtsgenkendelse benyttes en model baseret p en ResNet-34-lignende arkitektur, til at beregne en ansigtsbeskrivelse ud fra et billede. Denne model er ikke begrnset til det st ansigter, der bruges til trning, hvilket betyder, at udviklere kan bruge det til genkendelse af alle personernes ansigter. Det er muligt at bestemme ligheden mellem to vilkrlige ansigter, ved at sammenligne deres ansigtsbeskrivelser.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2018-11-14
          &nbsp;&nbsp; e6f8ed73
          &nbsp;&nbsp; #13
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.977</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.912</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.665</kbd>
        </footer>
      </article>
      <article>
        <h4>Sebastian Siem Bach-Nielsen ny som machine learning-specialist i IIH Nordic</h4>
        <div>
          Sebastian Siem Bach-Nielsen er ansat som machine learning specialist i Analytics teamet hos datakonsulenthuset IIH Nordic. Sebastian er uddannet Cand. Scient. i Medialogi fra Aalborg Universitet og har tidligere arbejdet for KMD og Falck Healthcare som studentermedhjlper. star Log ind eller prv 3 ugers gratis prveabonnement for at lse videre
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2018-08-13
          &nbsp;&nbsp; e6db7357
          &nbsp;&nbsp; #14
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.941</kbd>
            <kbd data-tooltip="AI &amp; innovation">L05_INNOAI&nbsp;0.694</kbd>
        </footer>
      </article>
      <article>
        <h4>PRM / Huawei lancerer verdens kraftigste AI-processor</h4>
        <div>
          KbenhavnPressemeddelelse fra HuaweiAscend 910, der har mere computerkraft end nogen anden AI-processor i verden, er en del af Huaweis serie af Ascend-Max-chipst. Huawei offentliggjorde de planlagte specifikationer for processoren ved Huawei Connect, en af virksomhedens strste events sidste r. Efter et r med lbende udvikling viser testresultater nu, at Ascend 910-processoren leverer sine resultater med et langt lavere strmforbrug end frst antaget.Modeltrning af kunsting intelligens bliver dobbelt s hurtig Ascend 910 bruges til modeltrning til kunstig intelligens. Under en typisk trning er kombinationen af Ascend 910 og MindSpore cirka dobbelt s hurtig til at trne AI-modeller end konventionelle trningskort, der bruger TensorFlow.- Ascend 910 prsterer langt bedre, end vi forventede, og har uden tvivl mere computerkraft end nogen anden AI-processor i verden. Vi lovede en full-stack AI-porteflje til alle scenarier. Det har vi nu leveret med lanceringen af Ascend 910 og MindSpore, siger Eric Xu, Rotating Chairmand hos Huawei.MindSpore er navnet p det AI-framework, som Huawei lancerede sammen med Ascend 910. Det nye AI-framework understtter udvikling af AI-applikationer i alle scenarier - p tvrs af enheder, edge og cloudmiljer - og tilbyder on-demand samspil mellem dem.ger udvikleres effektivitetMindSpore vil vre open source fra januar til og med marts i 2020, og dets designkoncept, AI Algorithm As Code, giver udviklere mulighed for nemt at udvikle avancerede AI-applikationer og trne modeller hurtigere. I et typisk, neuralt netvrk til behandling af naturlige sprog (NLP) har MindSpore 20 procent frre linjer med kernekode end frende frameworks p markedet. Det kan ge effektiviteten hos udviklere med mere end 50 procent.AI-frameworks er afgrende for lettere udvikling af AI-applikationer, for at gre AI-applikationer mere udbredte og tilgngelige samt for at sikre beskyttelse af personlige oplysninger. Gennem framework-innovation samt optimering af MindSpore- og Ascend-processorer kan Huaweis lsning hjlpe udviklere med mere effektivt at tackle udfordringer p komplekse AI-projekter og imdekomme behovet for alsidig computerkraft til forskellige applikationer.Ud over Ascend-processorer understtter MindSpore ogs GPU'er, CPU'er og andre processortyper.Iflge Huawei er deres frste full-stack AI-porteflje til alle scenarier et bevis p virksomhedens engagement i at opbygge et mere robust og dynamisk kosystem for kunstig intelligens.Om Huaweis AI-portefljeHuaweis AI-porteflje dkker alle installationsscenarier, herunder offentlig cloud, privat cloud, edge computing, IoT-enheder og forbrugerenheder. Portefljen er ogs full-stack: Den omfatter Ascend IP og chip-serien, CANN (Compute Architecture for Neural Networks), trnings- og inferensplatformen MindSpore samt en applikationsplatform, der kaldes ModelArts.Kontakt:For yderligere information: Huawei Denmark Public Affairs and Communications Department: liuyinhanxiao@huawei.comLs hele pressemeddelelsen p Via Ritzau her: https://via.ritzau.dk/pressemeddelelse/huawei-lancerer-verdens-kraftigste-ai-processor?releaseId=13578451
        </div>
        <footer>
          <em>Ritzaus Bureau</em>
          &nbsp;&nbsp; 2019-08-30
          &nbsp;&nbsp; e75294b1
          &nbsp;&nbsp; #15
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.626</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.588</kbd>
        </footer>
      </article>
      <article>
        <h4>Transparens og prcision: SHAP-analyse forklarer, hvad der foregr i black-box-modeller</h4>
        <div>
          Et nyt vrktj til arbejdet med komplekse machine learning-modeller gr det muligt at bne den sorte kasse og forklare, hvordan modellen kom frem til en bestemt forudsigelse. SHAP-vrktjet - SHapley Additive exPlanation - bner for, at virksomheder ikke behver at ofre prcision for at kunne forsvare algoritmens forudsigelse.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2018-10-02
          &nbsp;&nbsp; e6eb61b6
          &nbsp;&nbsp; #16
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.899</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.837</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.608</kbd>
        </footer>
      </article>
      <article>
        <h4>Tester du?</h4>
        <div>
          Test i data science gr lidt ondt i starten, men man ender op med en solid, produktionsklar kodebase man kan stole p, skriver Anders Bogsnes. Det var en gang hvor datascientists mdtes, og snakken gik p algoritmer - hvad var nyt og hot? I disse dage gr snakken mere p software-udfordringer. Hvordan fr vi denne model i produktion? Hvordan sikrer vi datakvalitet? Hvordan overvger vi modellerne? Algoritmerne er stadig en vigtig del af hverdagen, men vi begynder nu at indse, at den bedste model er den, der kan komme i produktion. Datascience er nu en teamsport Datascience er blevet mere modent - mere produktionsstning og mindre POC. Der er flere datascience-teams frem for ensomme ulve og krav til, at man kan arbejde sammen i en kodebase. Det kan man ikke, hvis kodebasen ikke er lsbar, testet og produktionsklar! Uden automatiserede tests, er det svrt at ndre i en delt kodebase - det er som at spille Klodsmajor men uden, at man m se trnet, nr man trkker brikkerne ud. Til trods for at alle er enige om, at det er vigtigt, s sker det alt for tit, at datascience kode ender med ikke at have tests. For at komme i gang vil jeg foresl fire forskellige teststrategier: Pipeline testing Runtime testing Property-based testing Example-based testing Pipeline testing Som jeg har skrevet om tidligere , s handler machine learning om meget mere end bare modellen. Hver eneste del af din pipeline op til modellen br have unit-tests. Din transformationsfunktion der konverter fdselsdato til alder skal have en test. Din funktion der finder ud af hvornr en kunde sidst har kbt baseret p solgte produkter skal have en test! Disse er typisk nemme at teste. Giv din funktion et input, hvor du kender svaret, og tjek at resultatet af din funktion matcher det kendte svar. Jeg vil anbefale pytest som test framework. Det er ved at vre standard for testing i Python efterhnden, og er nemt at komme i gang med. Runtime testing En machine learning-pipeline handler typisk om at behandle meget data over tid. Har I tests der tjekker, om den nye data har ndret sig? Ville I opdage, hvis der mangler en kolonne, en kolonne har skiftet datatype eller der mangler en dato? Hvad med dataens karakteristika? Har gennemsnittet ndret sig markant siden sidste load? Max- og min vrdier? Har nye kategorier sneget sig ind? Det er meget bedre at fange disse typer ndringer og fejl, fr man begynder at trne modellen! Jeg vil anbefale bulwark great expectations eller pandera afhngig af strrelsen af projektet. De er alle biblioteker lavet til validering af datapipelines, hvor bulwark og pandera er mere lightweight end great expectations, men har til gengld ikke lige s mange features. Kig p dem alle og vurder, hvad der giver mening for jeres projekt! Property-based testing Nr man arbejder med kode, hvor det ikke er nemt at vide njagtig, hvad det forventede output burde vre, s kan vi bruge property-based testing i stedet for &quot;traditionel&quot; testing (eller sammen med). Property-based-testing betyder, at man definerer, hvordan input data kan se ud. F.eks. definerer vi input til modellen som et array med 6 kolonner, 5 tal og en string. Vi erklrer s, hvilke &quot;properties&quot; dit output skal have efter den har vret gennem din funktion. F.eks. kunne din pipeline indeholde en skaleringsfunktion, der skalerer alle numeriske vrdier til mellem 0 og 1 og en One-Hot Encoding til strings. S dit output vil have flgende &quot;properties&quot;: output skal ikke indeholde strings output skal have flere vrdier end input (pga One Hot encodingen) output skal ikke indeholde tal strre end 1 og mindre en 0 output skal kun indeholde floats Et bibliotek som hypothesis definerer mange strategier for at erklre disse &quot;properties&quot;, og prver at finde kombinationer af input vrdier, der gr at output ikke lngere overholder vores definerede &quot;properties&quot;. Den vil prve sig frem med alle mulige mrkelige vrdier, meget store tal, negative tal, unicode symboler osv, og nr den finder en fejl, s vil hypothesis finde den simpleste version af inputs, der skaber fejlen. Det er som at skrive 100 tests i et hug! Derved fr man bde en sikkerhed i, at man har tnkt p hjrnetilflde, men man slipper ogs for at &quot;opfinde&quot; testinput data, der ligner reel data. Man skal bare beskrive hvordan det ser ud, og hypothesis gr bare i gang. Example-based testing Vi har nu fet en god testdkningsgrad p vores data pipeline, men hvad med modellen? Det er svrere at bruge traditionelle unit-testing metoder, da modeller ofte ikke er deterministiske - der er randomiserede hndelser i trningen af en model. For at teste en given model, kan man sammenligne resultater med kendte eksempler - nr man forstr sin model, s har man ogs en ide om hvilke features der er udslagsgivende. Givet at vores model skal forudsige huspriser, s kunne en god test vre, at hvis input er et hus p 200 kvm p Frederiksberg, s skal output vre over 5 millioner. Fra vores domneviden ved vi, at det altid er tilfldet, s hvis vores model ikke kan fange den &quot;nemme&quot;, s er der nok noget galt! Man kunne ogs have en test p, at et hus i Frederiksberg er dyrere end hvis vi tager det samme hus, men ndrer kommune-kolonnen til Lolland. Jeres domneeksperter kan meget hurtigt finde nogle eksempler der er sund fornuft, som I kan inkorporere i jeres test-suite. Man kan ogs inkludere tests p om modellens metrikker er bedre end en fast baseline. Det kan vre at et af acceptkravene er, at modellen skal vre bedre end 50/50 eller, at den skal performe bedre end et menneske, eller mske bare bedre end den forrige model? Den frste gr mest ondt Vi har nu gennemget 4 forskellige mder at teste datascience kode p. Det svre er at bygge det ind som en fast rutine i hverdagen og tvinge sig selv til at f skrevet de frste par tests. Som med s meget andet godt i livet, s gr det lidt ondt i starten, men nr man ender op med en solid, produktionsklar kodebase man kan stole p, er det det hele vrd!
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2019-12-11
          &nbsp;&nbsp; e77d563a
          &nbsp;&nbsp; #17
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.996</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.898</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.653</kbd>
        </footer>
      </article>
      <article>
        <h4>Danske forskere bruger deep learning til at finde stemmer i en hstak af stj</h4>
        <div>
          Artiklen er originalt bragt p DataTechDen menneskelige evne til at lytte efter en enkelt stemme, nr du har en samtale i et rum fuld af konkurrerende samtaler, er enorm svr at efterligne med en algoritme.I arbejdet med avanceret lydanalyse er det skaldte cocktailparty-problem stadig ulst. Nu har danske forskere taget skridtet nrmere en lsning med deep learning.Udfordringen er, hvordan man fjerner unskede stjkilder, nr du optager i et stjfuldt rum med en enkelt mikrofon, forklarer Morten Kolbk, der netop har skrevet sin ph.d. om emnet ved Aalborg Universitet.Nr man kender et lydbillede p forhnd, som i et klinisk test-setup, kan algoritmer identificere en enkelt taler lige s godt som et menneske. Men hvis teknikken skal anvendes i fx. hreapparater, er det ikke nok. Modellen m kunne identificere en ukendt taler blandt en ukendt mngde af talere i en situation med en ukendt mngde baggrundsstj.DataTechArtiklen her er fra DataTech, et nyt PRO-medie fra Ingeniren om data og analytics. Vi giver dig inspirerende cases, nyheder og debat om alt fra machine learning-modeller til dataetik.Flg med p pro.ing.dk/datatechUden forudgende kendskab er den menneskelige hjerne stadig den bedste maskine, siger Morten Kolbk.Label permutationUdfordringen ved at f en algoritme til at separere lyden fra to talere - der ikke er kendt p forhnd - er, hvad litteraturen kalder 'label permutation'-problemet.Basalt set gr problemet ud p, at man gerne vil have et output fra modellen med en kanal for hver taler. Men du ved ikke p forhnd, hvilken stemme, der kommer ud af hvilken kanal.Det er en udfordring, nr man trner modellen, forklarer Morten Kolbk, fordi du med supervised learning skal sammenligne modellens output med det rigtige resultat - her i form af lyden fra de to separate talere.Med andre ord: Hvis taler A bliver separeret ud af modellen som output B, men trningsmodellen forventede, at taleren kom i output A, vil det fremst som et forkert resultat.P den mde kan man ikke trne modellen, fordi du ikke kan guide det neurale netvrk, siger Morten Kolbk.Problemet lste de danske forskere ved at ndre lidt i trningsalgoritmen, og essentielt gre rkkeflgen af talere ligegyldig under trning.Ved at gre det, s lser vi label permutation-problemet. Det betyder, at man relativt simpelt kan trne et neuralt netvrk til at separere talere fra hinanden. Det er noget, som man ikke kunne gre fr, siger forskeren.Algoritmen er demonstreret i flgende video:
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2019-01-08
          &nbsp;&nbsp; e708eac2
          &nbsp;&nbsp; #18
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.918</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.812</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.648</kbd>
        </footer>
      </article>
      <article>
        <h4>RapidMiner-boss: Pas p den skjulte sorte boks i AutoML</h4>
        <div>
          Brdtekst Automatiseret machine learning er et glimrende vrktj til at gre data scientists mere produktive. Men hvis du ikke kigger AutoML-systemerne efter i kortene, vil du ikke kunne stole p, at systemet ikke producere modeller med kritiske fejl.Sdan lyder budskabet fra RapidMiner-grundlgger Ingo Mierswa, der opfordrer til en open source-tilgang til AutoML, som kan ge tilliden til vrktjerne.Det er den samme open source-id, vi ser inden for it-sikkerhed. Hvis nok mennesker har kigget p koden og ikke fundet huller, s kan vi nok stole p det, forklarer han, da DataTech mder ham i London.Men det krver stadig en form for open source-tilgang eller -attitude over for det her. At du rent faktisk bner op. Det er ikke alle leverandrer af systemer til automatiseret machine learning-systemer, der vlger den tilgang. Og den strategi er Ingo Mierswa skeptisk over for.Stort set alt inden for data science er i forvejen drevet af open source, pointerer han.De fleste rigtig gode machine learning-modeller er open source, der er Python og R, der er TensorFlow. Vi har som softwareselskab stadig delelementer, der er closed source - vi vil stadig gerne tjene penge, det skal der ikke vre tvivl om. Men p samme tid er data scientists s vant til benhed, at det ikke er en god strategi at vre lukket omkring det her. S jeg forstr ikke hemmelighedskrmmeriet, siger Ingo Mierswa.Uden benhed ingen tillidP samme mde som open source skaber tillid til softwareprodukter, fordi tilstrkkeligt mange kigger koden igennem, skal benhed i AutoML-vrktjer sikre tillid til de computerskabte modeller.Jo flere, der rent faktisk kigger efter, desto hjere vil tillidsniveauet blive. Og fr eller siden vil tillidsniveauet vre s hjt, at behovet for at kigge ind i det her vil blive mindre og mindre, siger Ingo Mierswa.Men det vil kun vre sandt for leverandrer, der har den her bne tilgang. Hvis man ikke deler, hvordan modellen bliver bygget, hvordan kan man s stole p det? For de leverandrer vil det tillidsproblem, nok altid hnge ved, vurderer han.I RapidMiner har man - ikke overraskende - valgt at g efter mest mulig transparens i platformens Automodeller-funktion, der kan bygge ML-modeller for brugeren.Brugeren kan blandt andet f indsigt i, hvordan modellen fungerer gennem simulering. Her kan brugeren g ind i modellen og justere p parametre og p den mde validere, at modellen opererer som forventet. RapidMiner har desuden implementeret en version af Lime-frameworket, der kan vise, hvilke parametre der understtter et givent resultat, og hvilke der modsiger det.Skjult sort boksUden benhed skabes, hvad Ingo Mierswa kalder skjulte sorte bokse - det vil sige modeller, hvor modelbyggeren ikke selv ved, hvordan modellen blev til.De skjulte sort bokse skal aldrig accepteres, siger Ingo Mierswa fra scenen p Gartners Data &amp; Analytics Summit, der fandt sted i London tidligere p mneden.Du har ingen id om, hvordan modellen er blevet skabt. Du har bare klikket p fem knapper. Men hvad gjorde du med data, hvordan optimerede du modellen, hvordan validerede du modellen. Ud fra hvad du ved, kan modellen vre resultatet af en tilfldig proces - eller en proces, der lkkede valideringsdata ind i trningsdata, hvilket er en absolut no-go i data science, siger han og fortstter:Du skal i det mindste vre i stand til at se alle detaljerne omkring, hvordan data er blevet prpareret, hvordan modellen blev optimeret, og hvordan den blev valideret. Det gr de fleste AutoML-vrktjer ikke, og de fleste citizen data scientist har ikke nok erfaring med at stte sprgsmlstegn ved det. Lsningen er foruden den ndvendige benhed i AutoML-vrktjerne, at en citizen data scientist fr sine modeller tjekket igennem af en data scientist, hvis han eller hun ikke selv har kompetencerne.S du kan vre sikker p, at du ikke laver dumme fejl, siger Ingo Mierswa.Tillidskrisebenheden har til forml at gre det muligt, at g systemet efter i smmene og dermed skabe bund for tillid til modellerne, det skaber. Manglende tillid er nemlig det strste problem for data science i dag, mener Ingo Mierswa og henviser til tal fra Gartner:60 procent af alle modeller, der er tnkt til at blive sat i produktion, bliver faktisk aldrig operationaliseret. En model, der ikke sttes i produktion, giver ingen vrdi, s hvorfor bygge den i frste omgang? sprger han retorisk.Jeg tror, at problemet er, at data scientist ofte arbejder i et vakuum. Og nr de kommer med komplekse matematiske formler, har forretningen ikke vret en del af processen. De forstr det ikke, og dermed stoler de ikke p det. Ingo Mierswa sammenligner det med at hyre en person, du ikke deler et sprog med, til at udfre en vigtig opgave.Data scientists skal generelt fokusere mindre p prcision og fejlrate og mere p, om en model kan forklares og forsts, siger RapidMiner-bossen.Du skal bruge lige s meget tid p at forklare modeller, som p at skabe dem, understreger han.Som regel er det sdan i machine learning, at jo bedre en model er, des mere kompleks bliver den. Selv en liner model kan vre svr at forst, og lad os slet ikke tale om neurale netvrk. Det er den situation, vi str i. Men hvis man ofrer lsbarhed for prcision, risikerer man, at forretningen ikke har tillid til modellen - og dermed at modellen aldrig sttes i produktion. Og nr modellen bliver skrottet, er det lige meget, hvor god den er, fastslr Ingo Mierswa.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2019-03-26
          &nbsp;&nbsp; e721847a
          &nbsp;&nbsp; #19
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.98</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.996</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.663</kbd>
        </footer>
      </article>
      <article>
        <h4>Google gr sprog-AI til open source</h4>
        <div>
          Med udgivelsen, som hedder BERT (Bidirectional Encoder Representations from Transformers), kan man trne modeller til &quot;sprgsml-og-svar-systemer&quot;, tillige med andre modeller. Det tager cirka 30 minutter p Googles specielle processorer til maskinlring eller et par timer p en grafik-processor.Udgivelsen indeholder kildekode som er bygget oven p Googles populre AI-bibliotek Tensorflow og kommer med en rkke fortrnede sprogmodeller.I en videnskabelig artikel viser Googles forskere, hvordan de med modellerne kan f resultater, som er sammenlignelige med det bedste i forskningsverdenen, p blandt andet Stanford Question Answering Dataset (SQuAD v1.1), som benyttes til at vurdere forskellige AI-algoritmers frdigheder i forhold til hinanden.En af de udfordringerne inden for sprogbehandling, ogs kaldet NLP (Natural Language Processing), er manglen p trningsdata.Da NLP er et bredt felt med mange forskellige opgaver, indeholder de fleste opgave-specifikke datast kun et par tusind eller et par hundrede tusind trningseksempler, som er opmrket af mennesker.Skaldte deep learning-modeller, der benytter neurale netvrk med mange 'hidden layers', benytter fordelene ved strre mngder data, der forbedres, nr de trnes p millioner eller milliarder af trningseksempler.For at lukke dette hul i datamngden, har forskerne udviklet en rkke teknikker til at trne sprogmodeller rettet mod generelle anvendelser ved hjlp af den enorme mngde ikke-opmrket tekst p internettet.Den fortrnede model kan derefter finjusteres til NLP-opgaver p mindre datast, til forml som at svare p sprgsml samt 'sentiment'-analyse, hvor eksempelvis filmanmeldelser opdeles i positive og negative. Teknikken skulle resultere i betydelige njagtige forbedringer, i forhold til trning p disse datast fra bunden.I modstning til tidligere modeller kan BERT gennemskue den sammenhng, som et ord indgr i, og er trnet p tekst fra Wikipedia.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2018-11-26
          &nbsp;&nbsp; e6fcd4cd
          &nbsp;&nbsp; #20
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.976</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.86</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.64</kbd>
        </footer>
      </article>
      <article>
        <h4>Amazon lukker op for meget mere machine learning</h4>
        <div>
          Bunkevis af nye ML-vrktjer fra cloudgiganten p produktkonference. Den ombruste ehandel- og cloudleverandr Amazon holdt i sidste uge konferencen Reinvent for at sl p tromme for egne produkter.Det var frste gang, at der blev givet en selvstndig hovedtale om machine learning (krver login) p konferencen, der naturligt nok var af den virtuelle slags, og som ufrivilligt humoristisk var garneret med kunstige klapsalver, der nppe krvede machine learning.Tjlerne blev holdt af Swami Sivasubramanian, som er vicechef i Amazon Machine Learning. Han indledte med at fortlle, hvordan ML ikke lngere er et niche-produkt. Eksempelvis behandler bilfabrikanten BMW 7 petabyte data med Sagemaker, som er Amazons ML-platform. Firmaet mener selv, at det dominerer p cloud-markedet for Tensorflow- og Pytorch-baseret ML med markedsandele p lige over 90 procent, ld det.Blandt de mange nyheder for Sagemaker-platformen, som blev lagt for dagen, var Managed Data Parallelism, som skal gre det nemmere at trne p store datast, i strrelsen hundrede- til tusindvis af gigabyte, og 40 procent hurtigere end fr, ld det glade budskab.Teknikken bestr i at opdele trningsst i mini-batches, som fordeles over alle GPU'er. Med jvne mellemrum udveksler GPU'erne gradient-data mellem hinanden eller til en central server, der opdaterer GPU'erne.Automat-vaskDen nste produktnyhed i talen var Data Wrangler, der skal prve at lse de tidskrvende problemer med datafangst, transformering samt datavask og -rens.Produktet gr det muligt at indhente data fra Amazons egne storage- og database-produkter tillige med CSV-filer og database-tabeller. Mere end 300 indbyggede transformationer kan benyttes, for eksempelvis at konvertere en kolonnes type fra tekst til tal eller interpolere manglende data med gennemsnit eller median. Man kan ogs skrive sine egne transformationer med eksempelvis SQL.Dernst kan data visualiseres, ogs uden at skulle skrive kode. Til sidst kan det tjekkes, om data vil producere en korrekt model. Hele forlbet kan konverteres til en notebook eller et script og anvendes i produktion.Feature Store er et andet nyt produkt, der som navnet antyder er en store for features - ingen overraskelser der. Mere prcist kan features gemmes og tilgs p en mde, s det er nemmere at navngive og organisere dem og anvende samme features i trning og til inferens, uden at skulle skrive kode eller benytte manuelle processer.Tjek af biasBias er altid et varmt emne i AI og ML, og her skal gigant-leverandrerne naturligvis ogs vre med. Amazons nye produkt p denne front hedder Clarify, og det skal finde bias under forberedelse af data, efter trning af model, og i den udrullede model baseret p attributter. Man kan eksempelvis tjekke for aldersrelateret bias i indledende datast eller i en trnet model, hvor slutresultatet er en rapport, der stter tal p forskellige slags mulig bias.Produktet, som er integreret med det tidligere nvnte Data Wrangler-vrktj, kan ogs visualisere vigtigheden af forskellige features i grafer, som kan forklare modellens forudsigelser og identificere problemer. Det kan ogs anvendes med frdige modeller, hvor man eksempelvis kan se, hvorfor en model giver negative svar oftere for en gruppe end en anden.DebuggerEn anden ny produktnyhed i Sagemaker-familien er Debugger, som skal give ML-udviklere de samme slags vrktjer, som forretningsprogrammrer benytter til fejlretning. Hvis man trner modeller med kode udviklet til Tensorflow, Keras, Pytorch og andre miljer, kan man benytte et debugger-udviklerkit til p bestemte punkter at gemme modellens tilstand i Amazons S3-storagetjeneste.Tilstanden bestr af de parametre, som modellen lrer, ssom vgte for neurale netvrk, gradienter, optimeringsparametre, skalarvrdier som accuracy og loss samt output fra hvert layer.Ved hjlp af regler skrevet i Python kan man kigge efter unskede problemer. Et st af frdiglavede regler kan eksempelvis holde je med parametre, der giver NaN- eller nul-vrdier, samt loss, der ikke ndrer vrdi og mere til. Der er ogs mulighed for at skrive egne regler.Macine learning fra SQL og graf-databaserEn rkke nyheder bygger ML oven p eksisterende Amazon-produkter. Amazon Redshift ML gr det muligt at trne og udrulle modeller fra SQL-databaser i Redshift, som er Amazons datawarehouse-tjeneste. Det kan anvendes til eksempelvis churn prediction og svindel-detektering, lyder det.I samme genre findes Neptune ML, der ogs bygger oven p et eksisterende produkt, nemlig graf-databasen Neptune. Det skulle give bedre accuracy end ved andre fremgangsmder ssom XGBoost.Pipelines er ogs et nyt produkt, som er en continuous integration-tjeneste (CI/CD) til ML, der kan orkestrere hele pipelinen og holde styr p udviklings- og udrulningsscyklussen, som det kendes fra CI/CD til forretningsprogrammering.I BI-genren var nyheden Quicksight Q, som i GPT-3-stil overstter foresprgsler i naturligt sprog til sgninger. Det kan vre sprgsml som What is my year-to-date year-over-year sales growth? ellerWhich products grew the most year-over-year? der genererer et svar uden SQL-kode eller andre mellemliggende krumspring.Edge og industriel machine learningOgs for edge-behandling kunne Amazon vise en lang rkke nyheder. Edge Manager er en slags fldestyring for edge-enheder, hvor fordelen skulle vre, at man kan anvende de samme vrktjer p cloud som p edge-enhederne. Samtidig bliver det muligt at overvge og forbedre modeller p enheder.Derudover er der fem nye tjenester til industriel ML med navne som Amazon Monitron, Amazon Lookout for Equipment, AWS Panorama Appliance, AWS Panorama SDK og Amazon Lookout for Vision. De fem tjenester skal hjlpe industri og produktion med at forbedre driftseffektivitet, kvalitetskontrol og sikkerhed p arbejdspladsen. Om det ogs handler om sikkerheden for Amazons egne medarbejdere, vides ikke.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2020-12-17
          &nbsp;&nbsp; e80a1b20
          &nbsp;&nbsp; #21
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.706</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.831</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.664</kbd>
        </footer>
      </article>
      <article>
        <h4>Video: Sdan kan man lave billedgenkendelse hos Baidu - uden kode</h4>
        <div>
          Nu er blgen ogs net til maskinlring.Den kinesiske sgemaskinegigant Baidu har sendt sit bud p gaden under navnet EZDL (&quot;nem deep learning.&quot;) Det skriver ADTMag.EZDL anvender en fire-trins proces til projektudvikling og implementering af brugerdefinerede maskinlrings-modeller: Opret en model, upload og opmrk billeder eller andre ting, trn og test modellen og implementer resultatet med et cloud-API eller et offline udviklingsvrktj (SDK).Iflge Baidu er vrktjet mlrettet mod sm og mellemstore virksomheder.Selvom du ikke har haft nogen erfaring med programmering, kan du hurtigt bygge modeller p denne platform uden barrierer, siger Yongkang Xie, som er teknologichef for Baidu EZDL.EZDL kan hjlpe virksomheder med begrnset AI-ekspertise og it-ressourcer til hurtigt og effektivt at gennemfre trning med deep learning og implementering, selv med kun en lille mngde data. Baidu fremhver tre slags brugsscenarier:En model til automatisk klassificering af billeder med brugerdefinerede klasse til opgaver som: Klassificering af billeder af boliger, genkendelse af kinesisk urtemedicin, vilde fugle og frer, samt industriel kvalitetskontrol i forbindelse med identifikation af defekte produkter.En model til automatisk detektering af objekter i billeder og optlling af antal objekter efter klasse, til opgaver som eksempelvis optlling af celler inden for medicin.En klassifikationsmodel til at genkende forskellige typer lydtyper eller detektere klasser af begivenheder, beregnet til opgaver som sikkerhedsovervgning og videnskabelig forskning.EZDL er en del af dets kunstig intelligensprojekt, der gr under navnet Baidu Brain.P videoen herunder kan man se anvendelsen af EZDL.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2018-09-20
          &nbsp;&nbsp; e6e7d057
          &nbsp;&nbsp; #22
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.833</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.851</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.614</kbd>
        </footer>
      </article>
      <article>
        <h4>IBM hopper med p vognen og open sourcer system til kunstig intelligens</h4>
        <div>
          IBM har lanceret sit machine learning system SystemML som open source i klvandet p lignende trk fra bde Facebook og Google.Det er benbart blevet populrt blandt it-giganterne at frigive deres machine learning-software, som kan bruges til at udvikle selvlrende systemer.Frst frigav Facebook machine learning-systemet Torch, og siden hen fulgte Google trop med systemet TensorFlow, som blandt andet str bag de avancerede algoritmer som sgemaskinen bruger til at forudsige, hvad du vil sge p, mens du skriver.Nu har IBM s lanceret SystemML som open source, hvilket gr valgmulighederne endnu strre for virksomheder, der vil forsge sig med machine learning.Platformen er tilgngelig p Github .Silicon Angle skriver :The SystemML technology emerged from IBM-s development of Watson, and integrates closely with another Apache project, Spark. SystemML helps Watson to keep up to date by providing a language that directly exposes the capabilities of the artificial intelligence so data scientists can harvest it. Queries are written in syntax modeled after the popular R statistical programming framework, before being executed according to the most efficient mode of operation for the specific workload and operational characteristics of a Spark cluster.&quot;SystemML provides declarative large-scale machine learning (ML) that aims at flexible specification of ML algorithms and automatic generation of hybrid runtime plans ranging from single node, in-memory computations, to distributed computations on Apache Hadoop and Apache Spark. ML algorithms are expressed in a R or Python syntax, that includes linear algebra primitives, statistical functions, and ML-specific constructs. This high-level language significantly increases the productivity of data scientists as it provides (1) full flexibility in expressing custom analytics, and (2) data independence from the underlying input formats and physical data representations. Automatic optimization according to data characteristics such as distribution on the disk file system, and sparsity as well as processing characteristics in the distributed environment like number of nodes, CPU, memory per node, ensures both efficiency and scalability.-IBM said it would be donating SystemML to The Apache Foundation back in June this year, and the project has already hit a significant number of milestones since then, including more than 320 patches including APIs, Data Ingestion, Optimizations and Additional Algorithms. There have also been more than 90 contributions to the Apache Spark project from IBM-s engineers, aimed at making Machine Learning compatible with Spark.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2015-11-25
          &nbsp;&nbsp; e5550c02
          &nbsp;&nbsp; #23
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.925</kbd>
            <kbd data-tooltip="AI &amp; innovation">L05_INNOAI&nbsp;0.659</kbd>
        </footer>
      </article>
      <article>
        <h4>VIDEO: Forst hvorfor man bruger grafikkort til kunstig intelligens</h4>
        <div>
          Grafikkort er den foretrukne computerkraft bag kunstig intelligens, men hvorfor?Grafikkort er eftertragtede af kryptovaluta 'minere', der flyver dem rundt i hele verden, for at kunne skrabe endnu flere digitale mnter til sig. Kortene er dog ikke kun brugt til computerspil og kryptovaluta. De er ogs den foretrukne form for computerkraft bag kunstig intelligens, machine learning og neurale netvrk. Men hvorfor?Ls ogs den mere tekniske forklaring her p Version2.
        </div>
        <footer>
          <em>Ing.dk (Ingeniren)</em>
          &nbsp;&nbsp; 2018-02-06
          &nbsp;&nbsp; e69b610f
          &nbsp;&nbsp; #24
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.959</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.642</kbd>
        </footer>
      </article>
      <article>
        <h4>DeepMind-forskere tackler black box-problem i algoritme, der spotter jensygdomme</h4>
        <div>
          Googles DeepMind-afdeling for sundhed har skabt en model, der kan aflse jen-skanninger og spotte akutte sager med samme prcision som en trnet specialist. Systemet vil i fremtiden gre det muligt at redde synet for flere patienter, mener man p det specialiserede Moorfields Eye Hospital i England, der har samarbejdet med DeepMind-forskerne om projektet.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2018-09-18
          &nbsp;&nbsp; e6e6e235
          &nbsp;&nbsp; #25
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.918</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.833</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.648</kbd>
        </footer>
      </article>
      <article>
        <h4>Hvad er maskinlring</h4>
        <div>
          KGE: Hvad er maskinlring og kunstig intelligens? P to timer kan du f et indblik i, hvad maskinlring er, hvordan kunstig intelligens virker og hvilke konsekvenser maskinlring allerede har for fremtidens samfund. Det skriver Kge Bibliotek: -Maskinlring findes overalt i vores samfund. Du oplever det anvendt i blandt andet anbefalingssystemer som Netflix, i ansigts-, stemme-og billedgenkendelse, i computerspil og meget mere, fortller bibliotekar Stine Kjr Schmidt, der str for workshoppen p Kge Bibliotek tirsdag 14. januar kl. 16. Her vil hun blandt andet fortlle om teknologiens muligheder og begrnsninger.Hvad er maskinlring og hvorfor skulle det vre interessant for mig, tnker du mske? Ja, netop derfor br du komme denne eftermiddag, hvor du ogs fr lejlighed til selv at prve -helt konkret og praktisk -at trne en algoritme, s du kan opleve, hvordan maskinlring virker i praksis. Alle er velkomne.Der krves ingen digitale forudstninger for at deltage i arrangementet, som er gratis.Biblioteket stiller computere til rdighed. Tilmelding anbefales og kan ske via koegebib.dk eller p det lokale bibliotek.
        </div>
        <footer>
          <em>Kge Onsdag</em>
          &nbsp;&nbsp; 2020-01-07
          &nbsp;&nbsp; e787b16d
          &nbsp;&nbsp; #26
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.844</kbd>
            <kbd data-tooltip="Art, Sci-Fi and AI">L05_SCIFI&nbsp;0.67</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.568</kbd>
        </footer>
      </article>
      <article>
        <h4>Sdan kan kvantecomputere lse ikke-linere differentialligninger</h4>
        <div>
          Mange problemer inden for naturvidenskab og teknisk videnskab drejer sig om at lse differentialligninger. Kvantecomputere har potentialet til ogs at kunne udfre sdanne beregninger. Der er udviklet algoritmer, der hndterer linere differentialligninger, men kvantecomputere har vanskeligt ved at klare ikke-linere differentialligninger, som optrder mske steder inden for f.eks. strmningsmekanik. Det skyldes, at kvantemekanik er et linert system. To forskergrupper har nu fundet en udvej til, hvordan kvantecomputere alligevel i visse tilflde kan hndtere ikke-linere differentialligninger. En artikel i Quanta Magazine beskriver, hvorfor kvantecomputere generelt har svrt ved at lse ikke-linere problemer, og den mde man forsger at omg dette problem.
        </div>
        <footer>
          <em>Ing.dk (Ingeniren)</em>
          &nbsp;&nbsp; 2021-01-06
          &nbsp;&nbsp; e80f98dc
          &nbsp;&nbsp; #27
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.971</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.965</kbd>
            <kbd data-tooltip="Problem solving AI">L80_SOLVAI&nbsp;0.556</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.615</kbd>
        </footer>
      </article>
      <article>
        <h4>Transfer learning hos Amazon: Alexa lrer japansk af engelsk sprogdata</h4>
        <div>
          Brdtekst For Amazons digitale assistent Alexa er evnen til at erobre nye markeder mere eller mindre lig evnen til at lre nye sprog.Men god sprogdata til at trne de neurale netvrk er notorisk svre eller dyre at f fat p, hvorfor Alexa-udviklerne har kastet deres krfter p transfer learning. Med andre ord at lade systemet overfre viden om t sprog til et andet sprog for at lre det hurtigere og bedre.Strategien er effektiv, fortller Research &amp; Development Program Manager ved Amazon Alexa AI Lucie Flekova p konferencen Women in Data Science, der fandt sted i sidste uge.Cross lingual transfer learning er brugbart i bde lille og stor skala, kan forbedre prstationen bde p stnings- og ordniveau, og det kan i vores tilflde spare os mere end halvdelen af trningsdata, siger Lucie Flekova om erfaringerne indtil videre.Fra stort til lille datastTransfer learning er typisk brugbar i situationer, hvor du har et stort datast og et datast, der i sig selv er for lille til at trne en model.Det store datast hjlper dig med at lre noget, og overfre det til det mindre datast uden at lre det igen, forklarer Lucie Flekova.I Alexas tilflde er det store datast - kaldet source - typisk engelsk sprogdata, hvor mngderne af trningsdata er massive, mens det mindre datast - kaldet target - f.eks. kunne vre tysk eller japansk.I praksis betyder det, at man frst trner modellen p source-datasttet (engelsk) og herefter bruger target-datasttet til at finetune netvrket. Dermed fr man en model, der forstr target-sproget bedre, end hvis den kun var trnet p target-datasttet.Tidligere forskning har peget p, at vrdien af transfer learning falder, nr sprogene er lingvistisk forskellige. Men vores erfaring er, at transfer learning mellem japansk og engelsk virker lige s godt som mellem tysk og engelsk, sagde Lucie Flekova p konferencen.Halvering af trningsdataSelv hvis du har adgang til et relativt stort datast fra dit target-sprog, er der gevinst at hente ved at starte med at trne p det sprog, hvor der er trningsdata i overflod.Vi har set p, hvad grnserne er for, hvor meget data der skal vre i dit target datast. Om der er en grnse, hvor det giver bedre mening at trne modellen alene p target-sproget. Det, vi fandt, var, at det var der faktisk ikke, siger Lucie Flekova.Modellen lrer stadig mere, hvis du starter med informationen fra source-sproget. Alexa-udviklerne udgav tidligere p mneden en forskningsartikel om arbejdet med transfer learning fra t sprog til et andet. Her skelner udviklerne frst og fremmest mellem intention classification - formlet med en stning - og skaldt slot tagging - de dataemner, som stningen handler om.Hvis en Alexa-bruger siger &quot;Alexa, play 'High Hopes' by Panic! at the Disco,&quot; er intentionen PlayMusic, og &quot;High Hopes&quot; og &quot;Panic! at the Disco&quot; udfylder de to slots SongName og ArtistName, forklarer udviklerne i en blog.Af udviklernes arbejde fremgr det, at et trningsst med en million engelske udsagn og 10.000 tyske udsagn skabte en model, der var bedre i stand til at forst intentionen med en tysk stning, end en model trnet alene p 20.000 tyske udsagn.Nr det handlede om at forst, hvad der blev talt om - slots tagging - klarede modellen sig fire procent bedre, hvis den frst blev trnet p source-datasttet, uanset om udviklerne efterflgende brugte de 10.000 eller 20.000 tyske udsagn som target-datast.Flere klasser krver mere dataAlt i alt baner teknikken vejen for at overfre Alexa til nye sprog med mindre tningsdata, noterer udviklerne.Hvor meget trningsdata, man egentlig har brug for fra target-sproget, afhnger af opgaven, understreger Lucie Flekova.Det afhnger af, hvor mange klasser du i sidste ende vil kunne klassificere. Hvis du har tusindvis af klassifikationer, skal du gerne have flere stninger, end du har kategorier. Det varierer ogs meget fra sprog til sprog, understreger hun.Alexa er i skrivende stund tilgngelig p engelsk, tysk, japansk, fransk, spansk, italiensk og yderligere seks varianter af de sprog. Flekova ville p konferencen ikke afslre, hvilke sprog Amazon har i pipelinen for Alexa.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2019-04-25
          &nbsp;&nbsp; e72c50ca
          &nbsp;&nbsp; #28
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.971</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.856</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.645</kbd>
        </footer>
      </article>
      <article>
        <h4>Gratis vrktjer skal spotte algoritmernes fordomme</h4>
        <div>
          Bias, fordomme og diskrimination er ikke bare noget der foregr i den fysiske verden. Det finder i den grad ogs sted i de algoritmer, der blandt andet bruges til ansigtsgenkendelse og en lang rkke beslutningsprocesser.Nu har IBM lanceret en vrktjskasse med navnet 'Fairness 360', som scanner for tegn p bias i algoritmer.I den frste udgivelse af Fairness 360, ogs navngivet AIF360 Python Package, finder man ni forskellige algoritmer, hvis ml er at afbde bias. Det er et st af fairness- mlinger p datast og machine learning-modeller.bner den sorte boksBehovet for nye former for indsigt i algoritmerne skyldes blandt andet, at udviklere ofte ikke ved, hvilke beslutninger der tages med deres kunstige intelligens og hvorfor.Kunstig intelligens er kendt som en black box, en sort boks. IBM's vrktj vil gre AI-beslutninger mere gennemsigtige, s udviklere kan se, hvilke faktorer der bruges i den kunstige intelligens.Softwaren er cloud-baseret og open source, og den virker til de mest kendte AI-frameworks, inklusiv Watson, Tensorflow, SparkML, AWS SageMaker og AzureMLDu kan finde Fairness 360 p Github
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2018-09-27
          &nbsp;&nbsp; e6ea1676
          &nbsp;&nbsp; #29
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.985</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.862</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.642</kbd>
        </footer>
      </article>
      <article>
        <h4>Metoder inden for Explainable AI (XAI)</h4>
        <div>
          Explainable AI (XAI), alts forklarlig kunstig intelligens, har meget fokus i jeblikket, fordi maskinlringsmodeller bliver mere ugennemskuelige og komplekse, og fordi datadrevne modeller bliver brugt mere til kritiske beslutninger og af ikke-ekspertbrugere. Der findes dog mange forskellige mder at lave forklarlig kunstig intelligens p og dermed ogs et hav af forskellige metoder. Ved at definere egenskaber og typer af metoder og forklaringer og ved at give et overblik over de mest kendte metoder, vil vi hjlpe med at finde rundt i junglen af XAI-metoder.Bekymringer om forklarlighed vedrrende systemer baseret p kunstig intelligens er ikke noget nyt, se f.eks. 'ekspertsystemer' [1], 'case-based reasoning' [2, 3] eller, for et historisk overblik, se reviewet der blev lavet som del af DARPAs XAI projekt [4]. Men i de sidste 2-3 r er der kommet et hav af nye metoder til at lave forklarlig kunstig intelligens.Hvad er forskellen mellem de forskellige metoder? Hvilke typer af forklaringer generer de? Og hvilke metoder passer i hvilken situation, til hvilke type data eller modeller? I dette blogindlg giver vi et overblik over forskellige metoder og grupperer dem ved at definere en taksonomi af XAI-metoder. Taksonomien og inddelingen i forskellige grupper er inspireret af diagrammet fra IBM's AIX360 open-source bibliotek, Christoph Molnars e-bog og forskellige artikler om XAI-metoder [5, 6, 7, 8, 9, 10, 11, 12].Helt generelt kan man adskille metoder p mden, man interagerer med dem. De kan vre statiske eller interaktive (fr man bare en eller flere forklaringer, eller kan man ogs ''sprge'' ind til en anden eller dybere forklaring). Der findes dog os bekendt ingen interaktive metoder, s vi fokuserer her udelukkende p statiske metoder.Desuden kan man gruppere XAI-metoder efter hvilken type af data, de er egnet til, og efter hvilke typer af forklaring de genererer. Der findes bde metoder, der kan forklare data, og metoder, der forklarer modellerne. Sidstnvnte kan videre separeres p 1) hvilket omrde forklaringerne virker p, alts forklarer de dele af modellen (global ) eller modellens resultater (lokal ), 2) om det er modeller, der kan forklare sig selv (iboende ) eller metoder, der forklarer en ugennemsigtig model (post-hoc ), og 3) om de er lavet til en specifik type af model.I det flgende vil vi beskrive, lidt mere i dybden, hvilke typer af data der kan forekomme, hvilke typer af forklaringer der eksisterer, og hvad iboende, post-hoc, lokal og global egentlig betyder, samt nvne nogle eksempler p XAI-metoder i hver kategori. Til sidst giver vi et overblik over et udvalg af metoder i form af et taksonomitr.Typer af dataForklaringer og XAI-metoder er afhngige af den datatype, som modellen er udviklet til. De fleste anvendelser af datadrevne modeller er lavet til tabel-, billede-, tekstdata eller tidsserier.TabeldataTabeldata data er data, der kan beskrives i form af en tabel, hvor hver kolonne reprsenterer en variabel eller feature, og hver rkke reprsenterer et eksempel eller datapunkt. Denne type data er brugt i de mest klassiske anvendelser af maskinlring, ssom fraud detection eller churn prediction. Desuden kan mange andre datakilder tit udtrykkes som en tabel gennem skaldt feature extraction.BilleddataBilleddata er den type data, der forekommer i computer vision-opgaver, ssom object detection, optical character recognition eller image segmentation. Hvert billede i datasttet reprsenterer et eksempel eller datapunkt. Man kan bruge dybe neurale netvrk (convolutional neural networks) til billeddata, eller ekstrahere nogle features fra et billede s datasttet kan udtrykkes som en tabel.TekstdataTekstdata er den type data, der forekommer i NLP-opgaver (natural language processing), som f.eks. named entity recognition, speech to text, eller at analysere toner i debatten. Hver tekst, ssom stninger, afsnit eller dokumenter, i datasttet reprsenterer et eksempel eller datapunkt. Man kan bruge dybe neurale netvrk (recurrent neural networks) til tekstdata, eller ekstrahere nogle features fra tekster s datasttet kan udtrykkes som tabel.TidsserierTidsserier bliver tit udtrykt som tabeldata, s det kan bruges til maskinlring. Derfor kan alle XAI-metoder, der arbejder p tabeldata, normalt ogs bruges p tidsserier.Typer af forklaringerForklarlighed skal altid defineres i en given kontekst. Denne kontekst indeholder ml og andre dimensioner, der er afhngige af tidsbegrnsninger og slutbrugerens ekspertise i forhold til maskinlring [5] (se ogs vores andet blogindlg om forklarlighed ).Tiden, en bruger har til at forst eller kigge p en forklaring, kan vre begrnset i en given applikation, som stter begrnsninger p forklarligheden. Yderligere begrnsninger og krav er givet fra den type bruger, der interagerer med modellen. Brugerens ekspertise kan vre alt imellem en beslutningstager uden teknisk baggrund og hje domneviden, som lger, dommere, eller planlggere, over forskere eller ingenirer med en basis, teknisk viden, hen til data scientists og maskinlringseksperter med en dyb viden om selve modellen. Forskellige typer af brugere har brug for forskellige typer af forklaringer. I den her del af blogindlgget vil vi gerne komme det nrmere, hvilke typer af forklaringer, der findes, og hvordan de udmnter sig. Det er dog ikke en udtmmende liste, og det er vigtigt at bemrke, at nogle gange kan en brugers behov lses gennem UX-design eller forklaringer, der ikke er automatisk genererede.EksemplerEn mde at generere forklaringer p er ved at bruge eksempler. Fordelen ved forklaringer gennem eksempler er, at det er let forsteligt for slutbrugeren eller domneeksperten, da eksempler, og dermed forklaringer, kommer fra selve datadomnet. Desuden bruger mennesker tit eksempler til at trffe en beslutning, skaldt cased-based reasoning [2, 3]. For eksempel nr en lge stiller en diagnose, er det baseret p symptomer, og de erfaringer han har med patienter, der har udvist lignende symptomer. Eller nr en data-scientist skal lse en opgave, s husker han en opgave, han har lst tidligere, og hvilke metoder og modeller der virkede bedst til at lse opgaven.Dog giver det kun mening at bruge eksempler som forklaring, hvis selve data let kan reprsenteres og er forsteligt. Det glder for eksempel for billeder eller tekst, som mennesker kan give en mening til. Det kan ogs virke for tabeldata, men det krver, at kolonner (variabler) har en mening, som pris, antal vrelser eller hustype for et hus-datast, og at der kun er en hndfuld kolonner, ellers er enkelte datapunkter ikke gennemskuelige.PrototyperEksemplerne kan bde bruges som forklaring af selve data eller for at forklare en models resultat. For at forklare data sger man efter de eksempler i et datast, der bedst reprsenterer datasttet, skaldte prototyper. Nr man har et datast med forskellige grupper (klassifikationsproblem), vil man som regel finde prototyper for hver klasse.Udover prototyper er det ogs vigtig at kunne afgrnse datasttet, alts finde de datapunkter der ligger p grnsen af datasttet eller lngst vk fra prototyperne, skaldt criticisms. Det blev frst prsenteret fra Kim et al. sammen med deres MMD-critic metode[13]. ProtoDash er en anden metode til at finde prototyper og criticisms og er en viderefrelse af 'MMD-critic' lavet af en IBM-forsker [14].Udover at finde reprsentative datapunkter i et datast findes der ogs modeller, der sammen med deres output giver en prototype-forklaring [15, 16].Eksempler fra trningsdataEksempler kan ikke kun bruges til at forklare data, men ogs til at forklare et bestemt resultat af modellen [17]. En mde at gre det p er at finde de eksempler fra trningsdata, der havde mest indflydelse p modellens beslutning [18]. Det krver, at man definerer en skaldt influencer-funktion, der kan beregne indflydelsen.En klassisk maskinlringsmodel, der trffer beslutninger baseret direkte p eksempler fra trningsdata, er k-nearest neighbour (k-NN ). Her fr man forklaringer som eksempler ''gratis'' sammen med modellens resultat. Der findes ogs forskning til at bruge k-NN sammen med et dybt neural netvrk til at bde lre komplekse sammenhng i data og f en forklaring [19].CounterfactualsEn anden mde at bruge eksempler som en beslutningsforklaring p er at finde counterfactuals [20]. Counterfactuals undersger, hvad der ville vre sket, hvis udgangspunktet havde vret anderledes, alts hvilke fakta-ndringer der ville have srget for et modsat resultat. Hvis man for eksempel fr afvist et ln, s kan det vre, at man ville have fet det, hvis man havde en hjere indkomst. Den form for kontrastiv forklaring er ogs tit brugt af mennesker [21].Der findes forskellige metoder til at generere counterfactuals p, bde til tabeldata [22], billeddata [23] og forskellige datatyper [24, 25].ReglerRegel-baserede modeller, skaldte ekspertsystemer, har vret mden at lave forklarlige modeller p og var meget populre i 80'erne. I disse systemer bliver regler defineret af domneeksperter, og s kan de bruges til en automatisk beslutning. Disse regler har en hvis-s form, f.eks. hvis der er skyer, og gulvet er vdt, s har det regnet. Reglerne kan have flere betingelser (''der er skyer'', ''gulvet er vdt''), men kun maksimalt to resultater (''det regnede'', ''det regnede ikke''). Reglerne kan kombineres med hinanden og udfres efter hinanden, dvs. en regel bestemmer hvilken regel, der skal bruges i nste trin.Udover ekspertsystemer findes der ogs maskinlringsmodeller, der automatisk genererer regler baseret p sammenhnge i data [26, 27, 28]. En bestemt form af disse modeller er beslutningstrer, hvor regler er binre (en betingelse og to veje) og kombineret i et tr. Beslutninger bliver s lavet ved at starte i roden af tret og flge regler igennem, indtil man lander i et blad, som udgr resultatet.Regler kan bde bruges til at forklare hele modellen gennem alle reglerne, modellen bestr af, og som lokal forklaring ved at give de regler der var afgrende for en bestemt beslutning [29].Feature attributionsFeature attributions er den type forklaring, der er mest udbredt i de metoder, der er blevet udviklet for nyligt, og som der er mest hype omkring. Feature attributions beskriver for hver variabel, hvor vigtig den er for modellens resultat. Det kan bde vre globalt, alts hvilke variabler er grundsatslig vigtige, eller lokalt, alts hvilke variabler var mest afgrende for en bestemt beslutning.Nr man kigger i junglen af maskinlringsmodeller s findes der en gruppe af skaldt linere modeller: liner regression, logistisk regression, Generalized Linear Models (GLMs) og Generalized Additive Models (GAMs). P grund af deres struktur er det muligt at f bde en global eller lokal forklaring i form af feature attributions (ls mere ved at klikke p links). Der har vret en del udvikling i den seneste tid af algoritmer til at lave linere modeller, der har lige s god eller bedre performance end mere komplekse black-box-modeller, f.eks. GA2M [30] eller SLIM [31].Der findes ogs metoder, der kan generere feature attributions for en ikke-liner black-box-model, f.eks. SHAP [32], som er baseret p skaldte shapley values [33], LIME [34], DeepLIFT[35], Grad-CAM [36] eller LRP [37]. De sidstnvnte (DeepLIFT, Grad-CAM og LRP) er specielt lavet til dybe neurale netvrk, og her er iden blandt andet, at outputtet af netvrket bliver frt tilbage til inputtet igennem netvrket for at vise, hvilke dele af inputtet der var mest betydningsfulde. De fleste af disse metoder virker p alle typer af data, og vi vil gerne beskrive i lidt flere detaljer, hvordan feature attributions kan se ud p billede- eller tekstdata.BillederFeatures i billeder er de enkelte pixels i billedet eller dele af billedet. S nr vi bruger feature attributions p billeddata, handler det om at markere de pixels eller omrder i billedet, som var mest betydningsfulde for modellens resultat.TekstFeatures i tekst er de enkelte ord eller stninger i teksten. S nr vi bruger feature attributions p tekstdata, handler det om at markere de ord, som var mest betydningsfulde for modellens resultat.VisualiseringerVisualiseringer er en god mde at reprsentere komplekse sammenhnge p, og er den foretrukne mde for data scientists, statistikere og analytikere til at forst data og modeller. Desuden er smarte visualiseringer hjertet af business intelligence-lsninger. Visualiseringer er derfor ogs en god mde at forklare data eller modeller p.Her vil vi kort beskrive forskellige mder at bruge visualiseringer som forklaring p. Vr opmrksom p at nogle af de tidligere prsenterede typer af forklaringer (regler og feature attributions) ogs skal visualiseres, men der findes mange forskellige mder at gre det p, hvorimod de visualiseringer, vi beskriver her, hnger tt sammen med metoden.DatavisualiseringerLigesom med andre typer forklaringer, s kan man bde forklare data og modeller. Visualiseringer bliver som regel brugt til at forst data, inden man begynder at designe og trne en model. Det er forholdsvis nemt at visualisere enkelte eksempler p tekst- og billeddata, da deres form allerede er en visualisering i sig selv. Der er dog udfordringer med at visualisere et helt datast. Her bruger man tit en form af 'manifold visualisering', f.eks. t-SNE.For tabeldata krves det frst, at man reducerer dimensionen af de enkelte datapunkter til 2 eller 3 variabler, da data s kan visualiseres i et 2D eller 3D plot. Principal component analysis (PCA ) er en kendt metode til reducering af dimensioner. Yellowbrick er et godt Python-bibliotek, der samler forskellige visualiserings- og dimensionsreducerings-metoder.Partial dependence plot (PDP)Partial Dependence Plots (PDPs ) er en mde til at forklare en model. Selve plotsene viser, hvordan vrdien af en enkelt variabel, eller vrdierne af et par af variablerne, ndrer modellens resultat. Det er Jerome H. Friedman, der frst prsenterede PDP i 2001 [38].Goldstein et al. videreudviklede metoden til Individual Conditional Expectation (ICE) plots, hvor man ogs kan se effekten for et eller flere udvalgte datapunkter, udover at kun se den samlede effekt [39]. ICE plots kan dog kun laves for en enkelt variabel ad gangen.Neuron-visualiseringerDybe neurale netvrk bestr af hundrede eller tusindvis af neuroner, der er forbundet til hinanden og organiseret i en grafstruktur med forskellige lag. Hvert lag eller gruppe af lag transformerer data fra selve inputtet til outputtet af modellen igennem mere og mere abstrakte reprsentationer, jo dybere (tttere p output) man kommer ned i netvrket.Der findes forskellige metoder til at visualisere disse abstrakte reprsentationer, som modellen har lrt [40]. Metoderne er begrnset p billed- eller tekstdata, da visualiseringer som billed eller tekst intuitivt kan forsts. Med tabeldata er det svrt at forst abstrakte reprsentationer, da de ikke direkte relaterer tilbage til input-domnet eller specifikke attributter.Det er for eksempel brugbart til at visualisere, hvordan netvrket ''ser'' et bestemt input i de forskellige lag [40, 41, 42], eller til at visualisere hvad forskellige neuroner eller lag i netvrket detekterer eller ekstraherer generelt fra dataene [43, 44, 45, 46].KoncepterKoncepter er det, der kommer tttest p, hvordan vi som mennesker forstr verden. Nr vi ser et objekt med hjul, s tnker vi nok, at man kan kre med det, selvom vi mske ikke kender selve objektet. Nr vi ser et dyr med vinger, s vil vi nok genkende det som en fugl, ogs hvis vi ikke har set den type fugl fr. Ved at interagere med vores omverden og ved at lse bger, se film, g i skole osv. lrer vi koncepter, der kan hjlpe ogs med at forst nye ting.Nuvrende modeller brugt i maskinlring, der bliver trnet med data, lrer ikke koncepter eller kausale sammenhnge, men en korrelation mellem input- og output-variabler. Der er derfor en aktiv forskning, der handler om, hvordan vi kan skabe modeller, der faktisk har lrt koncepter, f.eks. causal inference [47] (se ogs DoWhy eller CausalNex Python-biblioteker) eller kognitive modeller [48]. Men forskningen er bare pbegyndt og er ikke moden nok til at blive brugt i industrien, selvom der er nogle lovende resultater inden for bde NLP [49] og computer vision (Neuro-Symbolic Concept Learner ).Nr vi s snakker om koncepter her, s handler det stadig om modeller, der lrer en korrelation, men som ved hjlp af vrktjer kan generere en forklaring, der kommer tt p koncept-tanken og adskiller sig fra de vrige typer af forklaringer, vi har beskrevet i dette indlg.En mde at f konceptforklaringer p er at annotere datasttet, s hvert datapunkt ogs har en konceptlignende forklaring givet af en domneekspert, og s trne en model der bde genererer et output og en forklaring [50].En anden mde er ved at definere koncepter gennem eksempel-datapunkter og undersge sensitiviteten overfor disse datapunkter for hver af modellens output i et klassificerings-problem [51]. For eksempel kan man undersge om en model til at klassificere billeder er sensitiv overfor konceptet ''striber'', nr den klassificerer en zebra. Ghorbani et al. automatiserer denne tilgang, s koncepterne bliver genereret automatisk for et givent billede [52].Det er ogs muligt at trne en model, s den kan svare p sprgsml i forhold til et billede, skaldt visual question answering [53, 54, 55]. Her handler det om, at modellen forstr de koncepter, der er til stede i sprgsmlene og billedet.Global eller lokal - Post-hoc eller iboendeI ovenstende afsnit har vi set, at forklaringsmetoder kan grupperes afhngigt af, hvilken type forklaring de genererer. En anden mde at adskille metoderne, der forklarer modeller p, er baseret p deres virkningsomrde. Typisk adskiller man mellem global og lokal [5, 56, 57].Global forklarlighed gr det muligt at forst hele logikken bag, hvordan en model virker og at flge dens rsonnement for alle mulige prdiktioner [5]. Global forklarlighed kan videre separeres i transparens [10], som man ogs kalder iboende, global forklarlighed, og post-hoc global forklarlighed [56]. Hvor transparens er en direkte egenskab, der er bygget ind i modellen, er post-hoc global forklarlighed som regel udfrt ved at bruge en metode, der forklarer hvilke mnstre, en model har lrt [56].Lokal forklarlighed giver yderligere informationer og forklaringer om en enkelt models prdiktion. Ligesom ved global forklarlighed kan man igen adskille imellem iboende lokal forklarlighed og post-hoc lokal forklarlighed [10, 56].Global forklarlighedDatadrevne modeller, isr dem baseret p maskinlring og deep learning, er tit beskrevet som ugennemskuelige ''black boxes'', hvor det selv for eksperter er svrt at forst modellens indre logikker. Global forklarlighed kan forsts som en modstning til en black box. Global forklarlighed er evnet til at forklare hele modellens logik og at flge dens beslutning hele vejen igennem fra input-data til modellens prdiktion [5]. Det kan opns ved at bygge en model, der har iboende global forklarlighed (transparent) eller ved at bruge en post-hoc model til at forklare en black box-models logik.TransparensTransparens er defineret som evnen til direkte at forst hele modellen. Algoritmer eller metoder til at generere en transparent model, kan man gruppere under ''transparent design'' [5].Men hvad er transparens egentlig? Z. C. Lipton beskriver forskellige typer af transparens: simulatibility (simulerbarhed), decomposability (nedbrydelighed) og algoritmisk transparens [10]:Flger man Liptons definition af transparens, er linere regressionsmodeller, beslutningstrer og regel-baserede modeller alle sammen transparente, da man ''nemt'' kan forst og beregne de underliggende mekanismer. Men disse modeller kan hurtigt blive store (antal af parametre, dybden og bredden af tret, antal af regler). S hvornr er de sm nok til stadig at glde som global forklarlige? En mulighed for at undg problemet er at tilfje begrnsninger i trningsprocessen, der minimerer strrelsen og kompleksiteten af modellen. Den strategi kan bruges bde til ''enkle'' modeller, som linere regressioner og beslutningstrer, men ogs til black box-modeller som neurale netvrk [58].Transparens kan ogs defineres som en grad af transparens fra black box til fuld transparens, hvor nogle dele af modellen er transparente og nogen andre er uigennemskuelige.Post-hoc global forklarlighedPost-hoc global forklarlighed opns ved at anvende metoder p black box-modeller for at gre dem global forklarlige. For eksempel kan man vise, hvor meget forskellige input-variabler og deres vrdier har indflydelse p modellens prdiktion (PDP [38], ICE [39], permutation test ).For dybe neurale netvrk (DNN) ligesom convolutional neural networks (CNN) eller recurrent neural networks (RNN) (tit brugt sammen med billed- eller tekstdata), findes der srlige post-hoc metoder. Disse metoder prver at ekstrahere, hvilke reprsentationer et dyb neuralt netvrk har lrt af data [40, 43, 44, 45, 46]. Reprsentationer er en implicit abstraktion fra den ''r'' data (billede eller tekst), lrt af de frste lag af et netvrk, for eksempel lag der genkender kanter i et billede [46]. Desuden findes der metoder til at undersge, om modellen har lrt bestemte koncepter [51].Disse typer af post-hoc globale forklaringsmetoder, der kan bruges til at f indsigt i black box-modellen ved at belyse dele af dens logik, kalder Guidotti et al. ''black box-inspektions''-metoder [5]. Det er dog ikke den eneste type af metoder til post-hoc global forklarlighed. Der findes ogs de skaldte ''surrogat-model''-metoder.Surrogat-modellerSurrogat-model-metoder, eller model-forklaringsmetoder (model explanation) [5], bygger en model til at erstatte black box-modellen, hvor black box-modellen er brugt til prdiktioner og surrogat-modellen til at generere forklaringer. Sidstnvnte model skal virke p samme mde som den originale black box-model, alts generere prdiktioner s tt som muligt p black box-modellens prdiktioner. Hvis det ikke er tilfldet, s forklarer denne model ikke black box-modellen, men kun sig selv. Selvflgelig vil surrogat-modellen altid vre forskellig, dvs. have en ringere performance en black box-modellen, da man ellers kunne erstatte black box-modellen fuldstndig med surrogat-modellen.Surrogat-modeller tager som regel form af de klassiske transparente modeller, ligesom linere modeller [59], beslutningstrer [60, 61], eller regel-baserede modeller [62], men kan ogs vre et simpel neuralt netvrk [63].Lokal forklarlighedI de fleste tilflde vil det vre svrt at bruge en transparent model til at opn global forklarlighed, men det er tit nok til at forklare en bestemt prdiktion. Man kan faktisk argumentere for, at der skabes en mental reprsentation af modellen, nr man interagerer med en model lnge nok og samtidig fr lokale forklaringer. Jo mere den mentale reprsentation afspejler den faktiske model, jo mere global forklarlig er modellen for brugeren.Forklaringer, der er genereret af lokal forklarlige metoder, kan vre tekst, visualiseringer, eksempler i trningsdata eller feature attributions [10]. Ligesom med global forklarlighed kan man adskille mellem iboende lokal forklarlighed og post-hoc lokal forklarlighed [56].Iboende lokal forklarlighedModeller, der har iboende global forklarlighed, er som regel ogs lokal forklarlige, ligesom linere modeller, beslutningstrer eller regel-basered modeller. Der findes dog ogs modeller, der opnr lokal forklarlighed ved at tilfje dele til en model, der genererer en forklaring [15, 52, 64], hvor forklaringer er en del af trningsdata [50], eller hvor selve konceptet er, at prdikationer er baseret p eksempler (k-NN ). I alle tilflde er modellen bygget, s den genererer en forklaring sammen med en prdiktion.Nr vi kigger p dybe neurale netvrk, s kan man for eksempel tilfje srlige lag, der genererer (og lrer) forklaringer [15, 16, 52, 64, 65, 66]. Det kan vre i form af eksempler eller prototyper [15, 16], koncepter [52], tekst [65] eller feature attribution [64, 66]. Og s findes der ogs en metode, der kombinerer neurale netvrk, der hver isr genkender dele af et billede til et beslutningstr og dermed opnr forklarlighed (Neural-Backed Decision Tree ) [67].Post-hoc lokal forklarlighedMetoder til post-hoc lokal forklarlighed gr modeller forklarlige gennem en separat proces efter prdiktionen. Det ligner mden, den menneskelige hjerne virker p, hvor der er forskellige processer til at trffe en beslutning og at forklare den.Metoder til post-hoc lokal forklarlighed, ogs kaldt ''resultat-forklaring'' (outcome explanation) [5], kan fungere p forskellige mder. Det kan for eksempel vre metoder, der arbejder primrt med et eksempel-datast og modellens output til at finde lignende eller betydningsfulde eksempler [14, 18], eller metoder der finder counterfactuals [22, 23, 24, 25]. Andre metoder udnytter modellens struktur, f.eks. at det er et neuralt netvrk [35, 36, 37], bruger iden om shapley values [32, 68, 69], eller bygger en transparent model for et lokalt omrde [29, 34].Fordelen ved post-hoc lokal forklarlighed er, at man ikke behver at pille ved selve modellen, og at mange metoder fungerer med forskellige typer af black box-modeller. Tit har de dog brug for adgang til modelstrukturen for at udnytte den til at generere forklaringer hurtigere og mere njagtigt.ModeltypeModeller, der er transparente eller har en iboende lokal forklarlighed, har en bestemt type. Det kan vre linere modeller, regel-baserede modeller, beslutningstrer, versioner af k-NN eller neurale netvrk [15, 16, 52, 58, 64, 65, 66] eller kombinationer af det [67].Post-hoc metoder derimod virker i forbindelse med en black box-model til at gre den forklarlig. Typen af model kan have en betydning for, hvilken post-hoc metode man kan bruge. De typer af black box-modeller, man typisk ser, er dybe neural netvrk, enten med convolutional layers eller recurrent layers, ensemble-modeller bestende af beslutningstrer (Random Forest, Gradient Boosting [70, 71], eller ensemblemodeller sat sammen af forskellige andre typer af modeller.Der findes post-hoc metoder, der er model-agnostiske, dvs. de virker med alle typer black box-modeller, da de bare skal have mulighed for at f modellens resultater for et givent input [14, 24, 25, 29, 32, 39, 59]. Andre metoder er lavet specifikt til dybe neurale netvrk [72, 73] og krver, at man har adgang til selve netvrket, da de udnytter netvrksstrukturen [23, 36, 51, 63], bruger en lignende proces til at generere forklaringer, som man bruger til at trne af netvrket [35, 37], eller viser hvad netvrket har lrt [40, 43, 44, 45, 46].Nogle metoder eksisterer kun til tr-baserede modeller eller er en variant af en model-agnostisk metode optimeret til trer [74], og andre krver, at man har adgang til en gradient, man ogs bruger i trningsprocessen [18].TaksonomitrEfter vi nu har vret inde over datatyper, typer af forklaringer og typer af XAI-metoder, samt hvordan nogle modeller er lavet til en bestemt type black box-modeller, vil vi nu give et overblik over forskellige XAI-metoder i form af et taksonomitr.Tret viser ikke alle metoder, der findes, men metoderne er valgt, s de, s vidt muligt, afdkker alle typer af forklaringer, data og black box-modeller. Hvis der er flere metoder i en kategori, s har vi udvalgt den mest udbredte, bedst dokumenterede eller den metode, hvor der findes en god open source-implementering. For hver metode indikerer farverige kasser, hvilken type data de er egnet til, og farven af metoden viser, om de er til en bestemt type black box-model.Her kan du lse Christoph Molnars e-bog for hver metode.Tak for fordi du lste med!Dette synspunkt blev oprindeligt bragt i Medium.Bibliografi[1] Peter Jackson, Introduction to Expert Systems, Harlow: Addison-Wesley Longman, 1990.[2] A. Kofod-Petersen, J. Cassens og A. Aamodt, Explanatory Capabilities in the CREEK Knowledge-Intensive Case-Based Reasoner, Proceedings of SCAI 2008, pp. 28-35, 2008.[3] A. Aamodt og E. Plaza, Case-Based Reasoning: Foundational Issues, Methodological Variations, and System Approaches, AI Communications 7(1), pp. 39-59, 1994.[4] S. T. Mueller, R. R. Hoffman, W. Clancey et al., Explanation in Artificial Intelligence Systems: An Historical Perspective, Explanation in Human-AI Systems: A Literature Meta-Review, Synopsis of Key Ideas and Publications, and Bibliography for Explainable AI, DARPA XAI Program, pp. 43-70, 2019.[5] R. Guidotti, A. Monreale, S Ruggieri et al., A Survey Of Methods For Explaining Black Box Models, arXiv:1802.01933v3 [cs.CY], 2018.[6] B. Mittelstadt, C. Russell og S. Wachter, Explaining Explanations in AI, arXiv:1811.01439v1[cs.AI], 2018.[7] G. Ras, M. van Gerven og P. Haselager, Explanation Methods in Deep Learning: Users, Values, Concerns and Challenges, arXiv:1803.07517v2 [cs.AI], 2018.[8] A. Adadi og M. Berrada, Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI), IEEE Access 6, pp. 52138-52160, 2018.[9] M. Du, N. Liu og X. Hu, Techniques for Interpretable Machine Learning, arXiv:1808.00033v3[cs.LG], 2019.[10] Z. C. Lipton, The Mythos of Model Interpretability, arXiv:1606.03490v3 [cs.LG], 2017.[11] S. Chakraborty, R. Tomsett, R. Raghavendra et al., Interpretability of deep learning models: A survey of results, IEEE 2017 SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI, pp. 1-6, 2017.[12] G. Vilone og L. Longo, Explainable Artificial Intelligence: a Systematic Review, arXiv:2006.00093 [cs.AI], 2020.[13] B. Kim, R. Khanna og O. O. Koyejo, Examples are not enough, learn to criticize! Criticism for Interpretability, NIPS 2016, pp. 2280-2288, 2016.[14] K. S. Gurumoorthy, A. Dhurandhar, G. Cecchi et al., Efficient Data Representation by Selecting Prototypes with Importance Weights, arXiv:1707.01212 [stat.ML], 2019.[15] C. Chen, O. Li, C. Tao et al., This Looks Like That: Deep Learning for Interpretable Image Recognition, arXiv:1806.10574v5 [cs.LG], 28 december 2019.[16] S. O. Arik og T. Pfister, ProtoAttend: Attention-Based Prototypical Learning, arXiv:1902.06292 [cs.LG], 2019.[17] C. J. Cai, J. Jongejan og J. Holbrook, The Effects of Example-Based Explanations in a Machine Learning Interface, IUI '19, pp. 258-262, 2019.[18] P. W. Koh og P. Liang, Understanding Black-box Predictions via Influence Functions, arXiv:1703.04730 [stat.ML], 2017.[19] N. Papernot og P. McDaniel, Deep k-Nearest Neighbors: Towards Confident, Interpretable and Robust Deep Learning, arXiv:1803.04765 [cs.LG], 2018.[20] S. Wachter, B. Mittelstadt og C. Russell, Counterfactual Explanations without Opening the Black Box: Automated Decisions and the GDPR, arXiv:1711.00399 [cs.AI], 2017.[21] Tim Miller, Explanation in Artificial Intelligence: Insights from the Social Sciences, arXiv:1706.07269 [cs.AI], 2017.[22] R. K. Mothilal, A. Sharma og C. Tan, Explaining machine learning classifiers through diverse counterfactual explanations, FAT* 2020, pp. 607-617, 2020.[23] Y. Goyal, Z. Wu, J. Ernst et al., Counterfactual Visual Explanations, Proceedings of the 36th ICML, pp. 2376-2384, 2019.[24] S. Sharma, J. Henderson og J. Ghosh, CERTIFAI: Counterfactual Explanations for Robustness, Transparency, Interpretability, and Fairness of Artificial Intelligence models, arXiv:1905.07857 [cs.LG], 2019.[25] A. Dhurandhar, P.-Y. Chen, R. Luss et al., Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives, NIPS 2018, pp. 592-603, 2018.[26] C. Chen og C. Rudin, An Optimization Approach to Learning Falling Rule Lists, arXiv:1710.02572 [cs.LG], 2017.[27] H. Lakkaraju, S. H. Bach og J. Leskovec, Interpretable Decision Sets: A Joint Framework for Description and Prediction, KDD'16, pp. 1675-1684, 2016.[28] J. H. Friedman og B. E. Popescu, Predictive learning via rule ensembles, Ann. Appl. Stat. 2 (3), pp. 916-954, 2008.[29] M. T. Ribeiro, S. Singh og C. Guestrin, Anchors: High-Precision Model-Agnostic Explanations, AAAI 2018, 2018.[30] 
. Lou, R. Caruana, J. Gehrke at al., Accurate intelligible models with pairwise interactions, KDD'13, pp. 623-631, 2013.[31] B. Ustun og C. Rudin, Supersparse Linear Integer Models for Optimized Medical Scoring Systems, arXiv:1502.04269 [stat.ML], 2015.[32] S. M. Lundberg og S.-I. Lee, A Unified Approach to Interpreting Model Predictions, NIPS 2018, pp. 4765-4774, 2017.[33] M. Sundararajan og A. Najmi, The Many Shapley Values for Model Explanation, ICML 2020, 2020.[34] M. T. Ribeiro, S. Singh og C. Guestrin, ''Why should i trust you?'': Explaining the predictions of any classifier, KDD'16, pp. 1135-1144, 2016.[35] A. Shrikumar, P. Greenside og A. Kundaje, Learning Important Features Through Propagating Activation Differences, arXiv:1704.02685 [cs.CV], 2017.[36] R. R. Selvaraju, M. Cogswell, A. Das et al., Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization, ICCV'17, pp. 618-626, 2017.[37] S. Bach, A. Binder, G. Montavon et al., On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation, PLOS ONE 10(7): e0130140, 2015.[38] Jerome H. Friedman, Greedy Function Approximation: A Gradient Boosting Machine, The Annals of Statistics 29(5), pp. 1189-1232, 2001.[39] A. Goldstein, A. Kapelner, J. Bleich et al., Peeking Inside the Black Box: Visualizing Statistical Learning With Plots of Individual Conditional Expectation, Journal of Computational and Graphical Statistics, pp. 44-65, 2015.[40] C. Olah, A. Satyanarayan, I. Johnson et al., The Building Blocks of Interpretability, Distill, 2018.[41] H. Strobelt, S. Gehrmann, H. Pfister et al., LSTMVis: A Tool for Visual Analysis of Hidden State Dynamics in Recurrent Neural Networks, arXiv:1606.07461 [cs.CL], 2016.[42] L. Arras, F. Horn, G. Montavon et al., ''What is Relevant in a Text Document?'': An Interpretable Machine Learning Approach, arXiv:1612.07843 [cs.CL], 2016.[43] C. Olah, A. Mordvintsev og L. Schubert, Feature Visualization, Distill, 2017.[44] A. Nguyen, A. Dosovitskiy, J. Yosinski et al., Synthesizing the preferred inputs for neurons in neural networks via deep generator networks, NIPS 2016, pp. 3387-3395, 2016.[45] A. Karpathy, J. Johnson og L. Fei-Fei, Visualizing and Understanding Recurrent Networks, arXiv:1506.02078 [cs.LG], 2015.[46] M. D. Zeiler og R. Fergus, Visualizing and Understanding Convolutional Networks, arXiv:1311.2901v3 [cs.CV], 2013.[47] Bernhard Schlkopf, Causality for Machine Learning, arXiv:1911.10500 [cs.LG], 2019.[48] Gary Marcus, The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence, arXiv:2002.06177 [cs.AI], 2020.[49] P. Clark, O. Etzioni, D. Khashabi et al., From 'F' to 'A' on the N.Y. Regents Science Exams: An Overview of the Aristo Project, arXiv:1909.01958 [cs.CL], 2019.[50] M. Hind, D. Wei, M. Campbell et al., TED: Teaching AI to Explain its Decisions, AIES'19, pp. 123-129, 2019.[51] B. Kim, M. Wattenberg, J. Gilmer et al., Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV), arXiv:1711.11279[stat.ML], 2017.[52] A. Ghorbani, J. Wexler, J. Y. Zou et al., Towards Automatic Concept-based Explanations, NIPS 2019, pp. 9277-9286, 2019.[53] Y. Goyal, T. Khot, A. Agrawal et al., Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering, International Journal of Computer Vision 127, pp. 398-414, 2019.[54] R. Hu, J. Andreas, M. Rohrbach et al., Learning to Reason: End-To-End Module Networks for Visual Question Answering, ICCV 2017, pp. 804-813, 2017.[55] J. Mao, C. Gan, P. Kohli et al., The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences from Natural Supervision, arXiv:1904.12584 [cs.CV], 2019.[56] M. Nu, N. Liu og X. Hu, Techniques for Interpretable Machine Learning, arXiv:1808.00033v2 [cs.LG], 2018.[57] Adrian Weller, Challenges for Transparency, arXiv:1708.01870v1 [cs.CY], 2017.[58] Q. Zhang, Y. N. Wu, S.-C. Zhu, Interpretable CNNs, arXiv:1901.02413v1 [cs.LG], 2019.[59] S. Tan, R. Caruana, G. Hooker et al., Distill-and-Compare: Auditing Black-Box Models Using Transparent Model Distillation, AIES'18, pp. 303-310, 2018.[60] C. Yang, A. Rangarajan og S. Ranka, Global Model Interpretation via Recursive Partitioning, arXiv:1802.04253 [cs.LG], 2018.[61] O. Bastani, C. Kim og H. Bastani, Interpretability via Model Extraction, arXiv:1706.09773[cs.LG], 2017.[62] W. J. Murdoch og A. Szlam, Automatic Rule Extraction from Long Short Term Memory Networks, arXiv:1702.02540 [cs.CL], 2017.[63] A. Dhurandhar, K. Shanmugam, R. Luss et al., Improving Simple Models with Confidence Profiles, NIPS 2018, pp. 10296-10306, 2018.[64] E. Choi, M. T. Bahadori, J. A. Kulas et al., RETAIN: An Interpretable Predictive Model for Healthcare using Reverse Time Attention Mechanism, arXiv:1608.05745v4 [cs.LG], 2017.[65] K. Xu, J. Ba, R. Kiros et al., Show, Attend and Tell: Neural Image Caption Genereation with Visual Attention, arXiv:1502.03044v3 [cs.LG], 2016.[66] Amirhossein Tavanaei, Embedded Encoder-Decoder in Convolutional Networks Towards Explainable AI, arXiv:2007.06712 [cs.CV], 2020.[67] A. Wan, L. Dunlap, D. Ho et al., NBDT: Neural-Backed Decision Tree, arXiv:2004.00221[cs.CV], 2020.[68] K. Aas, M. Jullum og A. Lland, Explaining individual predictions when features are dependent: More accurate approximations to Shapley values, arXiv:1903.10464[stat.ML], 2019.[69] M. Sundararajan og A. Najmi, The many Shapley values for model explanation, arXiv:1908.08474 [cs.AI], 2019.[70] T. Chen og C. Guestrin, XGBoost: A Scalable Tree Boosting System, KDD'16, pp. 785-794, 2016.[71] G. Ke, Q. Meng, T. Finley et al., LightGBM: A Highly Efficient Gradient Boosting Decision Tree, NIPS 2017, pp. 3146-3154, 2017.[72] G. Montavon, W. Samek og K.-R. Mller, Methods for interpreting and understanding deep neural networks, Digital Signal Processing 73, pp. 1-15, 2018.[73] W. Samek, G. Montavon, A. Vedaldi, L. K. Hansen og K.-R. Mller (Eds.), Explainable AI: Interpreting, Explaining and Visualizing Deep Learning, Springer, 2019.[74] S. M. Lundberg, G. Erion, H. Chen et al., From local explanations to global understanding with explainable AI for trees, Nature Machine Intelligence 2, pp. 56-67, 2020.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2020-11-26
          &nbsp;&nbsp; e80203c1
          &nbsp;&nbsp; #30
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.981</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.725</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.54</kbd>
        </footer>
      </article>
      <article>
        <h4>Facebook bner kildekoden til kunstig intelligens-vrktjer</h4>
        <div>
          Programmrer kan nu selv lege med en rkke vrktjer til maskinlring, som har gjort den sociale medie-virksomhed i stand til at udvikle store neurale netvrk p kort tid.Af Elas Christian Lundstrm Tirsdag, 20. januar 2015 - 15:30Facebooks egen forskningsgruppe Facebook AI Research har frigivet kildekoden til en rkke udviklingsvrktjer, som selskabet selv har udviklet og bruger til maskinlring. Det skriver det norske teknologiemedie Digi.no .Vrktjerne er moduler til Torch, som er et bent kildekodebaseret rammenetvrk for videnskabelig databehandling og maskinlring.Facebooks vrktjer gr samlet under navnet fbcunn og skulle efter sigende vre hurtigere end standardmodulerne til Torch, hvilket har gjort det muligt for det sociale medie at trne strre neurale netvrk p kortere tid iflge det norske medie.Fremskridt inden for videnskab og teknologi accelereres, nr forskere ikke bare deler deres resultater, men ogs deres vrktj og metoder, skriver Facebook-forskeren Soumith Chintala i et blogindlg .Vrktjerne er blandt andet optimeret til at bruge grafikprocessorerne til at bygge visse typer netvrksmodeller, som man for eksempel bruger, nr man skal behandle naturlige sprog.Torch bruges iflge Facebook af bde Google, AMD, Intel, Twitter og flere store akademiske institutioner.Via: Digi.noLs ogsFacebook lancerer beta-udgave af Facebook til arbejdet
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2015-01-20
          &nbsp;&nbsp; e4c852c7
          &nbsp;&nbsp; #31
          <br>
          <br>
            <kbd data-tooltip="Tech industry &amp; regulation">L02_BIGTEC&nbsp;0.698</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.614</kbd>
        </footer>
      </article>
      <article>
        <h4>Google forskere: Hrdt brug for bedre dokumentation af ML-modeller</h4>
        <div>
          Der eksisterer i dag ingen standarder for, hvordan udviklere dokumenterer de machine learning-modeller de trner og skabe. Hvad var modellens oprindelige forml? Hvad er dens begrnsninger? Disse sprgsml bliver typisk ikke besvaret, nr modellerne bliver frigivet til brug.Og det er et problem, mener et hold forskere fra Google. Srligt nr modellerne bruges p omrder, hvor de kan have alvorlig indvirkning p personers liv - som i sundhedssektoren samt inden for beskftigelse, uddannelse og retsvsen.Eksempler p systematisk bias i algoritmer er efterhnden talrige, skriver de ni forskere i en artikel, der i slutningen af denne mned bliver prsenteret p konferencen Fairness, Accountability and Transparency (ACM FAT* ) i Atlanta, USA.However, these systematic errors were only exposed after models were put into use, and negatively affected users reported their experiences. MIT-studerende Joy Buolamwini fandt f.eks. ud af, at kommercielle lsninger til ansigtsgenkendelse klarede sig signifikant drligere p mrke kvinder end p hvide mnd.Men i dokumentationen for modellerne om deres performance og use cases er der meget lidt information om den type svagheder, bemrker forskerne.This highlights the need to have detailed documentation accompanying trained machine learning models, including metrics that capture bias, fairness and inclusion considerations, lyder konklusionen.Brug ikke denne model...Lsningen, som Google-forskerne foreslr, er en dokumentationsstandard, de har dbt Model Cards - n til to siders information om kritiske aspekter af ML-modellen. Informationen skal kunne bruges af brugere og udviklere svel som lovgivere og personer, der mtte vre pvirket af en ML-model og gerne vil forst den bedre.The proposal of &quot;Model Cards&quot; specifically aims to standardize ethical practice and reporting - allowing stakeholders to compare candidate models for deployment across not only traditional evaluation metrics but also along the axes of ethical, inclusive, and fair considerations, skriver forskerne.Om forskningen:Artiklen 'Model Cards for Model Reporting'er skrevet af en rkke forskere ved Google.Forfatterne er Margaret Mitchell, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer, Inioluwa Deborah Raji og Timnit Gebru.Artiklen bliver prsenteret i slutningen af januar p Fairness, Accountability and Transparency (ACM FAT) i Atlanta, USA.This goes further than current solutions to aid stakeholders in different contexts. For example, to aid policy makers and regulators on questions to ask of a model, and known benchmarks around the suitability of a model in a given setting. Model-kortet, som forskerne foreslr, skal frst og fremmest rumme basal information om modellen ssom dato og udviklere. Dette punkt br ogs rumme information om trningsalgoritmer og parametre.Under punktet Intended Use anfres, hvilke brugere og use cases udviklerne forestillede sig under udvikling, samt hvilke uses case, man ikke anbefaler. Sidstnvnte element sammenligner forskerne med advarsler p legetj og madvarer. En sdan varsel p en ML-model kunne f.eks. vre &quot;Brug kun modellen p billeder i sort-hvid.&quot;Performance p tvrs af kn og aldersgrupperUnder punktet Factors skal udviklere notere, hvordan modellen klarer sig p tvrs af f.eks. befolkningsgrupper og miljer. En analyse af et billede kan f.eks. vre pvirket af kameraets hardware, lysforhold og - ikke mindst - personen p billedets kn, alder og race.DataTechArtiklen her er fra DataTech, et nyt PRO-medie fra Ingeniren om data og analytics. Vi giver dig inspirerende cases, nyheder og debat om alt fra machine learning-modeller til dataetik.Flg med p pro.ing.dk/datatechModel-kortet skal desuden indeholde punktet Metrics, som skal rumme de parametre, som modellen er blevet bedmt efter og hvorfor. Dette vil variere mellem forskellige model-typer, bemrker forskerne - ligesom vurderingen af, hvilke paramtre, der er vigtige, vil afhnge af formlet og konteksten:For example, in a surveillance scenario, surveillors may value a low false negative rate (or the rate at which the surveillance system fails to detect a person or an object when it should have). On the other hand, those being surveilled may value a low false positive rate (or the rate at which the surveillance system detects a person or an object when it should not have). We recommend listing all values and providing context about which were prioritized during development and why. I forlngelse af de to punkter vil forskerholdet have, at hver model udstyres med en kvantitativ analyse, der viser, hvordan modellen s performer p de forskellige parametre for hver gruppe.Hvis algoritmen sledes skal gtte p om en person smiler - se eksempel lngere nede - skal modelkortet vise, hvor godt den klarer sig p tvrs af kn og aldersgrupper.Kan ikke st aleneFor at gre det muligt at verificere modellen, foreslr forskerholdet, at man deler datasttet som modellen er evalueret med. Tilsvarende vil modelkortet ideelt set indeholde s meget information om trningsdata, som der kan lade sig gre.Endelig skal udviklere skrive, hvilke etiske overvejelser der flger med modellen, og hvilke forbehold de vil tage sig. Dette kan f.eks. handle om, hvorvidt modellen bruger flsom persondata, samt risici ved at bruge modellen.Selvom modelkortet kan ge transparens inden for machine learning-systemer, ser forskerne det ikke som sandsynligt, at vrktjet bliver gjort til en standard inden for den nrmeste fremtid.It is therefore important to consider model cards as one transparency tool among many, which could include, for example, algorithmic auditing by third-parties (both quantitative and qualitative), &quot;adversarial testing&quot; by technical and non-technical analysts, and more inclusive user feedback mechanisms, skriver forskerne.Denne artikel stammer fra PRO-mediet DataTech. Ls den fulde version her. (krver abonnement)
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2019-01-24
          &nbsp;&nbsp; e70def43
          &nbsp;&nbsp; #32
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.939</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.64</kbd>
        </footer>
      </article>
      <article>
        <h4>Mske tnker computere bare bedre uden vores hjlp</h4>
        <div>
          Tag mennesket ud af modellen: Ny forskning indikerer, at det vsentligste succesparameter for kunstig intelligens ikke er selve computermodellen, men kolde trningsdata og r computerkraft.BrdtekstGPT-3 kan skrive tekster, AlphaGo Zero kan spille Go, og AlphaFold 2 kan folde proteiner. Tre eksempler fra den nyeste forskning i kunstig intelligens (AI) p simple, minimalt forudindtagede modeller trnet p enorme mngder data og med enorme mngder computerkraft.Den markante succes for blandt andre disse modeller har rettet opmrksomheden mod et essay, som en af pionererne inden for skaldt reinforcement learning tilbage i 2019 udgav p sin blog 'Incomplete Ideas':'The Bitter Lesson' hed essayet, og i det uddrog Richard Sutton, AI-forsker og manden bag den frende tekstbog i reinforcement learning, hvad han kaldte den strste lrestning fra 70 rs AI-research, nemlig atgenerelle, skalerbare metoder i sidste ende er de mest effektive, og med en stor margin i forhold til specialiserede modeller med en hj grad af menneskeligt input.En stor del af forklaringen er iflge Richard Sutton Moores lov, der som bekendt siger, at antallet af transistorer, det er muligt at rumme i et integreret kredslb, fordobles hvert andet r. En lignende eksponentiel lov kan siges at glde for tilgngeligheden af data.Richard Suttons pointe er, at hvis vi antager, at bde transistor- og datatilgngelighed vedbliver med at flge en eksponentielt opadgende kurve, vil det ogs i fremtiden vre fornuftigt at basere vores modeller p metoder, der skalerer med computerkraft - og undlade at blande mennesker ind i oplringen.En formel med stor succesIkke alle p omrdet er enige med Richard Sutton - det vender vi tilbage til - men frst kigger vi nrmere p en af de aktrer, der har anvendt hans formel med stor succes.Google-ejede DeepMinds computerprogram AlphaGo slog i 2016 verdensmesteren Lee Sedol i det kinesiske spil Go. AlphaGo blev indledningsvist trnet mod menneskelige amatrer og eksperter, men det var overgangen til self-play - en strategi, hvor computeren spiller mod sig selv - som sendte computerens prstationsevne p himmelflugt.Den logiske konklusion p udviklingen var programmet AlphaGo Zero. Med denne model fjernede forskerne alt menneskeligt input fra modellen. Med kun Go-reglerne som input, ugevis af lring via self-play og 5.000 skaldte TPU'er - specialiserede kredslb til neurale netvrk - outperformede AlphaGo Zero alle tidligere modeller inklusive AlphaGo.Samme formel blev fulgt, da DeepMind i 2020 proklamerede at have lst det 50 r gamle proteinfoldningsproblem ved at opn en score p over 92,4 i CASP-konkurrencen (Critical Assessment of protein Structure Prediction). Den nye model, AlphaFold 2, erstattede fysikkomponenten i AlphaFold 1 med ren mnstergenkendelse og firedoblede det proteinkorpus, der blev trnet p, relativt til forgngeren. AlphaFold 2 kunne derudover med sine 128 TPU'er trkke p to strrelsesordenener mere computerkraft end Baker-gruppen, som blev 2'er i konkurrencen.Den mske mest demonstrative succes i nyere tid opnet ved rendyrket opskalering af simple modeller skal dog findes i firmaet OpenAI's GPT-chatbotter. Den oprindelige chatbot, GPT-1, krvede kostelig menneskelig hndkraft til annotering af data. Den vsentligt bedre prsterende GPT-2 var derimod funktionsdygtig udelukkende via ren usuperviseret lring, hvilket tillod en opskalering til 1,5 milliarder parametre.Den seneste model fra 2020, GPT-3, hvis output kun svrt adskilles fra menneskeskrevet tekst, kan bryste sig af en model med hele 175 milliarder parametre. Konklusionen, vi kan drage af OpenAI's resultater, er, at skala i sidste ende opvejer for stj i datasttet.Iflge Richard Sutton er vi dog endnu ikke get vidt nok. Vi har endnu ikke lrt den bitre lektie, at det i det lange lb ikke hjlper at bygge vores ideer om, hvordan mennesker tnker, ind i vores modeller. For selvom OpenAI og DeepMind har prsenteret succes p succes, mener Richard Sutton, at folkene bag kun modvilligt har trukket mennesket ud af modellerne. Hans tese er, at AlphaFold 2 givetvis kunne vre skabt fr AlphaFold 1, og AlphaGo Zero fr AlphaGo. Data, computerkraft og den historiske viden om fortidens bitre resultater var synligt tilgngelige for forskerne.En twist p en vedvarende debatLangt fra alle forskere p omrdet mener dog, at sagen er s simpel, som Richard Sutton fremlgger den.David Silver, Lead Researcher p AlphaGo-projektet, har i et interview med AI-forskeren Lex Fridman sagt, at det lige fra starten var vores ml at bygge et system baseret udelukkende p self-play, og for os var menneskelige data et skridt, der kunne hjlpe os med at n vores ml hurtigere. Ls ogs: Dansk startup vil bygge ML med sund fornuft: Der er et fundamentalt problem i de metodologier, vi normalt brugerOgs datalogen Max Welling ser med skeptiske jne p Richard Suttons tese. I et offentligt modsvar, 'Do we still need models or just more data and compute?', vedstr han, at det historisk set har vret tilfldet, at vores modeller er blevet simplere, i takt med at get computerkraft er blevet tilgngelig. Men s lnge relevante data mangler, er specialiserede, fintunede modeller en ndvendighed, uanset computerkraft.Mske kan en computer uden supervision lre en model med meget lidt indkodet menneskelig viden og med stor computerkraft. P den mde er jeg enig med Sutton, skriver Welling.Men vi kan ikke tale om nyttigheden af menneskeligt designede modeller uden ogs at tale om tilgngeligheden af data. Richard Sutton p sin side ser kritikken fra Welling Max og David Silver som en misforstelse og uddyber over for Ingeniren i en e-mail:Den bitre erkendelse er ikke, at computerkraft er alt, der betyder noget, og at vi skal glemme alt om at forsge at modellere verden. Den bitre erkendelse er, at metoder, som skalerer med computerkraft, er alt, der betyder noget. Modellering af verden er alts stadig vigtig, mener han:Det er bare maskinerne, der skal gre det, og ikke os. Ls ogs: Bayesian ML vs. aktiemarkedet: Det giver os meget information, nr modellen ikke ved, hvad den skal greI sidste ende er det et sprgsml om omkostninger. Vil det vise sig, at der er problemer, hvor det p sigt er mere omkostningstungt at lade en computer trne sig frem til en lsning p et problem, end det er at bruge menneskelig hndkraft til at indkode lsningen p problemet i modellen?Eller er der simpelthen modeller, som uanset datatilgngelighed og computerkraft er mere effektive at skrive i computersproget C end i et neuralt netvrk?n ting, man vel kan tage med i sine overvejelser, nr man diskuterer dette sprgsml, er diskonteringssatsen for lringsalgoritmer. Den menneskelige hjerne er det klareste eksempel. For selvom hjernen krer p blot 20 watt, er mngden af energi, evolutionen har brugt p trning af synapsforbindelser, enorm.Hvis samme gunstige omregning gr sig gldende for kunstige, neurale netvrk, bnes dren sledes for, at generelle lringsmodeller p sigt er de mest effektive over hele spektret af lselige problemer. Og iflge et nyt studie fra OpenAI er effektiviteten af neurale netvrk netop eksponentielt stigende.Richard Suttons logik hviler dog i sidste ende p en antagelse om, at Moores lov fortstter. Selv er han sikker p, at vi endnu ikke har indhentet Moores lov. Vi har ganske simpelt ikke net den fysiske grnse for, hvor sm transistorer kan blive.Pessimisterne har ikke fet ret endnu, skriver Sutton i sit svar til Ingeniren:I sidste ende vil de f ret, men de vil tage fejl mange rtier endnu. Mange er dog uenige med Richard Sutton i den vurdering, og det vil vise sig, om den bitre erkendelse er, at Sutton i sidste ende tager fejl. Det vil i s fald betyde, at vi ikke kan klare os uden omkostningstung menneskelig hndkraft forelbig.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2021-03-15
          &nbsp;&nbsp; e82af284
          &nbsp;&nbsp; #33
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.965</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.736</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.617</kbd>
        </footer>
      </article>
      <article>
        <h4>Google bringer maskinlring til mobilen</h4>
        <div>
          Googles kodebibliotek TensorFlow til maskinlring flyttes til Android i Lite-udgaveNu kommer maskinlring til Android-udviklerne. P den nyligt afholdte Google I/O-konference meddelte David Burke, som er n af Android-projektets udviklingschefer, at firmaets kodebibliotekTensorflow til maskinlring og kunstig intelligens vil blive flyttet til mobilsystemet i en letvgtsudgave.Maskinlring kan krve store mngder af hukommelse og CPU-forbrug, noget som ikke spiller godt sammen med mobile enheders begrnsninger i kapacitet og batteri, med mindre den tunge databehandling foregr i skyen.Med Tensorflow Lite, som er optimeret til mobile enheder, bliver det muligt at skabe anvendelser som ellers ville vre problematiske p sm enheder.Mobil-hardware med indbygget AIIflge Google vil Tensorflow Lite spille sammen med specifikke hardware-komponenter.P sigt forventer vi at se DSP-chips som er specielt designet til behandling og trning af neurale netvrk. Vi mener at disse nye funktioner vil hjlpe med til, p selve enheden, at drive den nste generation af talegenkendelse, visuel sgning, 'augmented reality,'i modstning til i skyen, siger David Burke.Tidligere p ret meddelte chip-designeren Qualcomm at firmaet vil tilfje understttelse af Tensorflow til deres kommende Snapdragon 835 mobilchip. Det skulle resultere vsentlige forbedringer i bde afvikling samt strmforbrug af programmer med maskinlring.Tensorflow blev udviklet som en del af Googles med henblik p maskinlring og forskning i skaldt dybe neurale netvrk, men systemet er generelt nok til at kunne benyttes i en lang rkke sammenhnge.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2017-05-29
          &nbsp;&nbsp; e6463684
          &nbsp;&nbsp; #34
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.869</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.707</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.651</kbd>
        </footer>
      </article>
      <article>
        <h4>Maskinlring kommer til mobilen: Googles Tensorflow klar til iOS</h4>
        <div>
          Machine learning krver normalt en del regnekraft, men alligevel er Google nu klar med en udgave af Tensorflow til bde Android og iOS.Googles software til machine learning, TensorFlow, er nu frigivet i den frste nsten-frdige udgave til Apples mobilstyresystem iOS. Det skriver CNet.Google har i forvejen en udgave af Tensorflow til Android, og nu findes maskinlringssoftwaren alts til de to strste smartphone-platforme. Det er interessant, fordi machine learning normalt er en disciplin, der krver betydelig regnekraft.Derfor har machine learning p smartphones normalt vret afhngig af, at applikationerne har kunnet trkke p maskinlring i skyen. Sdan kommer det ogs primrt til at foreg et stykke tid endnu til de mere krvende opgaver, men der findes visse typer oplring af de neurale netvrk, der kan foreg p en smartphone.Det kan eksempelvis vre begrnset ansigtsgenkendelse eller andre opgaver med computer vision baseret p neurale netvrk.TensorFlow er t af en rkke populre open source-vrktjer til maskinlring, som bliver brugt ikke bare af Google men af mange andre it-virksomheder og forskere. Ved at lave mobile udgaver af softwaren bliver det muligt for app-udviklere at inkludere neurale netvrk i deres applikationer.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2016-06-09
          &nbsp;&nbsp; e5bfc5e7
          &nbsp;&nbsp; #35
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.841</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.807</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.688</kbd>
        </footer>
      </article>
      <article>
        <h4>Blogindlg: Dybe neurale net</h4>
        <div>
          Som nvnt sidste gang er dybe net tidens hotte omrde inden for kunstig intelligens. Anvendelsen af dette st af maskinlringsteknikker har lst mange problemer som fagfeltet har kmpet med i mange r. Men hvad er de der dybe net egentlig, hvordan fungerer de, og hvad kan de bruges til? Jeg skal forsge at give en kort introduktion. Specielt interesserede henvises til e.g. Schmidhubers eller Bengios oversigtsartikler.Dybe net er et st af metoder som alle deler den underliggende id om at man kan lre et hjt abstraktionsniveau af data ved at benytte mange lag af forbundne knuder som kan beregne ikke-linere funktioner. Et klassisk, og efterhnden lidt banalt eksempel er at man kan trne et netvrk til at genkende katte (hjt abstraktionsniveau) fra pixler i et billede (lavt abstraktionsniveau). P vej fra pixler til kat vil lagene lre hjere og hjere abstraktionsniveauer.Dybe net er, som de fleste (hvis ikke alle) AI metoder, ikke en ny opfindelse som er opstet ud af det bl. Hvis vi vlger at ignorere alle de tidligere arbejder fra mange fagfelter som har vret inspirationer, er det frste eksempel p dybe net nok fra 1979 udfrt af Fukushima.Grunde til at dybe net har fet et renssance er delvist at vi i dag har adgang til meget store datast og kraftige maskiner (typisk stakke af GPU-er). Men der er ogs sket en hel del metodeudvikling.Som nvnt sidste gang er kernen i flade net at man tager noget data som man s bruger til at trne sin model. Derefter bruger man denne model p ny og ukendt data. En af de store udfordringer er det at vlge hvilke inputparametre (features) man skal bruge. Dette refereres ofte til som -feature engineering-, er delvist en videnskab og delvist sort magi.I tillg bruger flade net typisk overvget lring (supervised learning), alts at man har et trningsst bestende af kendte forbindelser mellem input og output (labelled dataset).Alts vil man have behov for et kendt trningsst samt kunne udfre kunsten af feature engineering. Dette er ikke altid trivielt.De dybe net kan bruges til ikke-overvget lring (og overvget lring) som kan bruge store datast uden kendt klassificering (unlabelled) for at finde strukturer og mnstre i disse data. Eller mindske udfordringen med at vlge inputparametre (features). Generelt kan man sige at de er gode til mnstergenkendelse og feature- og reprsentationslring.Hvordan fungere dybe net s?Lad os starte med knuderne i et netvrk. De er af samme type som i flade net. Alts en ikke-liner aktiveringsfunktion som overstter inputvrdier til outputvrdier. Man starter med et inputlag og afslutter med et output lag. Hvor flade net typisk ikke har mange skjulte lag, vil et dybt net have rigtig mange.Man kan s trne dybe net, enten p fundamentalt samme mde som med flade net, alts som overvget lring via f.eks. backpropagation. Man kan ogs vlge at g for ikke-overvget lring (unsupervised).Overvget lring forsger at forudsige en vektor, som er kendt i forvejen, ved a ud fra en matrix af input. Ikke-overvget lring forsger at finde mnstre som ikke er kendte i forvejen. F.eks. autoencoderen, som forsger at lre at reproducere den samme matrix som bruges som input. Derfor har et sdan net samme antal inputknuder og outputknuder som strrelse p inputmatricen. De skjulte lag vil i sagens natur have frre knuder. Dette bliver et net med en klassisk timeglasform (se figur). Figuren viser et net som lrer at genkende hndskrift.Det virker fordi man trner vgtene i hvert lag. Hvert lag er en ikke-liner kombination af laget over, og ogs en ikke-liner projektion ind i frre dimensioner. En projektion ind i frre dimensioner kan man ogs betragte som en hjere abstraktion (som med eksemplet med katte ovenfor).Dybe net er som nvnt et st af metoder, og de kommer derfor i mange afskygninger. Eksemplet ovenfor er, som nvnt, en bestemt version som kaldes en -autoencoder-. Der findes en helt rkke andre afskygninger, s som -convolutional net-, -deep belief network-, og -recurrent networks-.Teoretisk kan et feed-forward netvrk med et skjult lag approksimere enhver funktion. S man kan jo sprge sig hvorfor man skulle bruge et dybt net. Der er to argumenter for dette: det frste er at et dybt net kan approksimere funktioner ved brug af frre knuder, det andet og mske bedre er at det er en langt mere praktisk lsning.
        </div>
        <footer>
          <em>Ing.dk (Ingeniren)</em>
          &nbsp;&nbsp; 2016-06-07
          &nbsp;&nbsp; e5bee433
          &nbsp;&nbsp; #36
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.993</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.993</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.71</kbd>
        </footer>
      </article>
      <article>
        <h4>Google tager specialudviklet 180 teraflops processor i brug til machine learning i skyen</h4>
        <div>
          Googles TensorFlow fr nu specialbygget hardware til rdighed p Googles sky, som skal gre det hurtigere at oplre machine learning-modeller p store datast.Oplring af machine learning-modeller kan vre ekstremt beregningstungt p modeller for store datast, og til tider er det endda ikke tilstrkkeligt at benytte grafikprocessorer for ekstra regnekraft. Det mener i hvert fald Google, som nu har tilfjet en specialbygget processor til selskabets cloud, der er optimeret til Googles Tensorflow-framework.Google Tensor Processing Unit. Foto: GoogleGoogle har selv tidligere brugt den specialbyggede processor, men nu bliver den nste videreudvikling alts tilgngelig som en del af Google Compute Engine, hvor man vil kunne kbe kapacitet p Tensor Processing Units (TPU), ligesom det er muligt at blande dem med almindelige processorer og grafikprocessorer, oplyser Google i et blogindlg.Iflge Google har hver af disse TPU'er en regnekraft svarende til 180 teraflops, og de er samlet i'pods', der til sammen har en regnekraft p 11,5 petaflops. Det er i princippet nok til at vre i top 10 for supercomputere, men tallene for en TPU eller GPU er ikke direkte sammenlignelig med den generelle kapacitet for en gte supercomputer.TPU-erne optimeret Tensorflow-frameworkTPU'erne er optimeret til oplring af machine learning-algoritmer og specifikt Googles eget Tensorflow-framework.At der er forskel p regnekraften ved denne type specialiserede processorer og en supercomputer afspejler sig blandt andet i, at Googles nste skridt er at opdatere infrastrukturen i selskabets cloud-datacentre for at storage og netvrk kan flge med.De kraftige, specialiserede processorer skal fodres med store datast, og Googles plan med TPU'erne er, at de skal gre det muligt at oplre machine learning-modeller hurtigt p meget store st af produktionsdata.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2017-05-18
          &nbsp;&nbsp; e6429bd7
          &nbsp;&nbsp; #37
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.683</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.578</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.672</kbd>
        </footer>
      </article>
      <article>
        <h4>Transfer learning hos Amazon: Alexa lrer japansk af engelsk sprogdata</h4>
        <div>
          For Amazons digitale assistent Alexa er evnen til at erobre nye markeder mere eller mindre lig evnen til at lre nye sprog.Men god sprogdata til at trne de neurale netvrk er notorisk svre eller dyre at f fat p, hvorfor Alexa-udviklerne har kastet deres krfter p transfer learning. Med andre ord at lade systemet overfre viden om t sprog til et andet sprog for at lre det hurtigere og bedre.Strategien er effektiv, fortller Research &amp; Development Program Manager ved Amazon Alexa AI Lucie Flekova p konferencen Women in Data Science, der fandt sted i sidste uge.Cross lingual transfer learning er brugbart i bde lille og stor skala, kan forbedre prstationen bde p stnings- og ordniveau, og det kan i vores tilflde spare os mere end halvdelen af trningsdata, siger Lucie Flekova om erfaringerne indtil videre.Relateret jobannonce: Data business analystFra stort til lille datastTransfer learning er typisk brugbar i situationer, hvor du har et stort datast og et datast, der i sig selv er for lille til at trne en model.Det store datast hjlper dig med at lre noget, og overfre det til det mindre datast uden at lre det igen, forklarer Lucie Flekova.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2019-05-02
          &nbsp;&nbsp; e72ea4ec
          &nbsp;&nbsp; #38
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.959</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.908</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.616</kbd>
        </footer>
      </article>
      <article>
        <h4>Booz Allen lancerer 'app store' til AI</h4>
        <div>
            Booz Allen Hammilton er i frd med at lancere en markedsplads for AI-software i stil med en app-butik. Konsulentfirmaet kalder platformen for Modzy, skriver Fortune Modzy vil rumme prtrnede AI-modeller til specifikke opgaver s som at genkende bygninger i luftfotos, og de vil vre tilgngelige under en simpel licens, hvor man betaler efter brug, skriver mediet. Redaktionen
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2019-11-06
          &nbsp;&nbsp; e76d7c37
          &nbsp;&nbsp; #39
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.67</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.799</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.672</kbd>
        </footer>
      </article>
      <article>
        <h4>Forskere skaber syntetiske trningsdata med deep learning</h4>
        <div>
          En af de store udfordringer ved at bruge deep learning i sundhedssektoren er mangel p plidelige data til at trne de neurale netvrk. Det forsger forskere nu at lse ved at bruge Generative Adversarial Networks (GAN) til at generere syntetiske hjernescanninger til trningsdata.Udfordringen med trningsdata er ikke kun et sprgsml om datasttets strrelse, lyder budskabet fra forskerholdet, der er sammensat af eksperter fra NVIDIA, Center for Clinical Data Science i Boston og Mayo-klinikken i Rochester, Minnesota.Data-diversitet er kritisk for succesen, nr det handler om at trne deep learning-modeller, fremgr det af forskningsartiklen, der udkom i sidste uge.Datast med medicinske billeder er ofte ubalancerede, fordi antallet af billeder, der reelt indikerer sygdom, generelt er sjldne. Nr modellen skal trnes, er der sledes ganske f datapunkter, der viser, hvad den reelt skal lede efter.Lsningen er ofte at stte lger til at optegne billeder for at lave et datast, der kan lre en algoritme at segmentere et billede - f.eks. for at skelne mellem tumor og rask vv.Men det er en krvende metode, ppegede Nicola Rieka, der arbejder med deep learning i sundhedssektoren hos NVIDIA, da hun gstede konferencen Nordic.AI Health i sidste uge.I computer vision kan du f enhver til at udpege et objekt - her er en hund, her er en kat. I sundhedssektoren er det ikke s nemt. Hvis du skal markere en tumor, skal du bruge en ekspert, hvilket gr det dyrere, sagde hun.Automatiseret og billigI GAN bruger man to deep learning-netvrk: en generator og en diskriminator.Generatoren trnes til at producere den syntetiske data - i dette tilflde en falsk hjernescanning komplet med skaldt grey matter. Diskriminatoren har efterflgende til opgave at gtte, om scanningen er gte eller syntetisk.P den mde kan de to modeller trne hinanden. Resultatet er en metode til at fabrikere 'anormale' hjernescanninger, som ellers skulle optegnes manuelt.Dette giver en automatiseret, billig kilde til forskelligartede data, der kan bruges til at supplere trningssttet, skriver forskerne, der har anvendt PyTorch-frameworket sammen med to offentligt tilgngelige datast med hjernescanninger - ADNI og BRATS15 Challenge.For eksempel kan vi ndre en tumors strrelse, ndre dens placering eller placere en tumor i en ellers sund hjerne for systematisk at have billedet og den korresponderende annotation. Ingen privacy-problemer med falsk dataDen falske data kan ikke st alene, understreger forskerne, der har fet de bedste resultater ved frst at trne modellen p 100 procent syntetisk data og efterflgende fintune med omkring 10 procent af den gte data tilfldigt udvalgt. Her kan modellen mle sig med en model udelukkende trnet p gte hjernescanninger.I dette tilflde leverer den syntestiske data en slags for-trning, hvilket efterflgende krver langt mindre 'gte' data for at opn en sammenlignelig performance,  str der i artiklen.Det kan igen betyde, at man, selv hvis man som klinik kun har begrnsede data til rdighed, stadig kan have succes med at trne en deep learning-model. Under normale omstndigheder ville det vre vanskeligt at hente data andre steder fra pga. de naturlige krav til databeskyttelse og privacy.Men da de syntetiske data ikke er knyttet til en bestemt person, er der i sagens natur ingen personer bag hjernescanningen, og data kan derfor uden problemer deles med andre forskere og hospitaler.Du kan se koden til forskernes GAN p GitHub.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2018-09-20
          &nbsp;&nbsp; e6e79ea6
          &nbsp;&nbsp; #40
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.99</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.993</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.624</kbd>
        </footer>
      </article>
      <article>
        <h4>Lingvistisk gr forud for machine learning hos tekstanalyse-specialist</h4>
        <div>
          For tiden kan man f indtryk af, at maskinlring er svaret p det meste. Det kan utvivlsomt bruges til meget, men samtidig er maskinlring ofte afhngig af store datamngder. Det har man ikke altid, for eksempel nr mlet er at hente viden ud af ustrukturerede data, for eksempel dokumentsamlinger i relativt sm virksomheder.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2018-11-20
          &nbsp;&nbsp; e6faf228
          &nbsp;&nbsp; #41
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.819</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.792</kbd>
            <kbd data-tooltip="New technologies">L80_NEWTEC&nbsp;0.593</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.746</kbd>
        </footer>
      </article>
      <article>
        <h4>Det svreste problem i Machine Learning</h4>
        <div>
          En af de helt store udfordringer inden for Machine Learning er, hvordan man laver et produkt af noget, der lever p en laptop, mener Anders Bogsnes, der er Tech Lead for Analytics og Machine Learning ved Alm. Brand. Han gennemgr her, hvordan Alm. Brand arbejder med udfordringen.En af de svreste problemer indenfor machine learning er ikke, hvordan man trner den nyeste ''state of the art'' Deep Learning model, eller hvordan man tuner sin gamle churn model - det er, hvordan man tager noget, der lever p en laptop og laver et produkt ud af det.Jeg kommer til at gennemg den ''typiske'' deployment og sammenligne med den lsning, vi arbejder med i Alm Brand.''Over muren'' deployment modellenDen ''typiske'' workflow starter med, at dine datascientists finder et problem, de synes er spndende. De har fundet noget nyt data, bruger en mned p at tune, trne og teste og ender op med en model, de er tilfreds med. S bliver den smidt ''over muren'' til IT, der fr opgaven med at produktionsstte modellen. Denne fremgangsmde har et par problemer:Problem 1: SprogbarrierenIT arbejder typisk ikke i samme sprog som dine datascientists - det er typisk Java, C++ eller lignenede ''enterprise'' sprog, mens machine learning typisk sker i Python eller R. S for at kunne produktionsstte modellen, s skal modellen kodes om til noget der passer ind i ITs deployment processer, vel og mrke uden at ndre i hvordan modellen fungerer.Problem 2: Produktionsklar kodeMange datascientists kommer fra en akademikerbaggrund - statistikere, forskere, geologer osv. De har ikke ndvendigvis en software engineering baggrund, og fokus er mere p optimere modellen end at gre koden produktionsklar.Best practice ifht funktioner, DRY, SOLID, unittesting, CI og andre flotte forkortelser, som software engineers tager som en selvflge, er ikke ndvendigvis fulgt. Fr modellen kan sttes i produktion, s er man ndt til at implementere disse best practice, ellers risikerer man at ende op med en kodebase, ingen kan navigere rundt i.Problem 3: UdviklingshastighedDatascience er en iterativ proces, og man kan hele tiden finde sm forbedringer til modellerne. IT investerer en masse ressourcer i at omkode modellen i Java, implementeret unittests og ellers gjort koden produktionsklar.Mneden efter kommer datascience teamet tilbage og siger, at de nu har forbedret modellen med 0.5 ROCAUC, og kan vi ikke implementere denne nye model? Det br vre en positiv ting at man forbedrer sine modeller lbende, men det bliver hurtig en negativ oplevelse, hvor man hele tiden skal afveje, om forbedringen er vrd omkostningen.Alm Brands deployment modelVi har valgt at angribe denne problemstilling fra nogle forskellige vinkler:Lsning 1: Hele stacken i PythonEn af fordelene ved at vi koder modeller i Python, er, at vi har tilgang til mange ''produktionsressourcer''. Det betyder, at vi kan kode hele stacken i Python, fra model til API. Ved at bruge Docker er det nemt at levere en frdigindpakket model til produktion, hvor datascience-teamet kan styre hele processsen fra start til slut - IT skal bare starte en ny container, de behver ikke at bekymre sig om, hvad der er indeni. Datascience teamet tager nu ejerskab for modellen og dens udvikling, mens IT tager ejerskab for drifting af server og lignende.Lsning 2: Byg vores eget ML frameworkFor at drive best practice s har vi bygget vores eget framework, der standardiserer best practice for teamet.Vores framework er bygget ovenp scikit-learn, s det er nemt og kendt materiale for datascientists og indeholder mange af de lringer, vi har gjort indenfor machine learning.Nr vi tester f.eks en ny metode for feature selection, s testes det p ''Data science mden'' - eksperimenter for at afgre om det skaber en reel forbedring i modelperformance. Nr vi er enige i, at det er den korrekte mde at lave feature selection p, s opdaterer vi frameworket til at indeholde denne nye funktionalitet. Nu er vi i ''produktionskodemodus'', hvor vi srger for at skrive en omfattende testsuite, vi skriver dokumentation, vi kigger p optimeringer som parallelisering, og det arbejdes ind i et sammehngende API, s det er genkendeligt og kompatibelt med resten af vores kodebase.Den sidste viktige komponent er, at det er datascience teamet selv, der skriver og vedligeholder vores framework. Det er slutbrugeren, der bestemmer, hvordan skal APIet se ud, hvilke features der skal prioriteres, og hvilke bugs der br lses frst. Det giver ogs en forstelse for software engineering verden, s datascientist teamet fr et bedre fundament indenfor kodning, og hvordan det kan gres bedre.P denne mde fr vi det bedste af begger verdener - den hurtige eksperimentering, men ogs den bundsolide implementering.Lsning 3: StandardiseringVed at bruge vores eget framework fr vi ogs den kmpe fordel, at vi standardiserer API til modellerne. Det gr, at nr vi skal produktionsstte vores modeller, s starter vi ikke forfra i at definere, hvordan modellen skal tilg data, eller hvordan REST apiet skal sprge om en prdiktion - det er det samme hver gang. Det gr, at vi kan standardisere resten af vores pipeline og give kontrollen end-to-end til datascience teamet. S nr teamet nste mned laver en bedre model, s behver vi ikke balancere gevinsten af den bedre model mod kosten af implementation - vi pusher bare den nye model til master, og CI serveren bygger en ny model og stter den i produktion!KonklusionFor at undg ''Over Muren'' deployment modellen anbefaler vi flgende:Ved at inddrage datascience teamet i at bygge sine egne vrktjer og bruge ITs ekspertise til at standardisere og drifte bliver modelprocessen bliver smidigere, og vi kan agere hurtigere. Best practice for modellering bliver standardiseret og testet ved at samles i frameworket, s man ikke genimplementerer den dybe tallerken p fem forskellige mder.Datascience teamet skal ikke vre software engineers, men en forstelse for best practice og end-to-end processen vil gre produktionsstning meget smidigere og modellerne mere robuste.Standardiser lsningerJo mere der kan standardiseres i deployment processen, jo hurtigere kan man iterere og prve ting af - det bedste eksperiment gres live!Dette synspunkt blev oprindeligt bragt p Anders Bogsnes egen blog.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2020-12-01
          &nbsp;&nbsp; e803b3b3
          &nbsp;&nbsp; #42
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.997</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.91</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.611</kbd>
        </footer>
      </article>
      <article>
        <h4>Deep learning erstatter dyre objektiver hos Novo Nordisk</h4>
        <div>
          Tungt, kompleks og dyrt. Det er tre ord, som oftest gr igen, nr talen falder p visionsystemer til kvalitetskontrol i industrien. Det er uanset, om man skal finde fejl p sm metalkomponenter til bilindustrien eller insulinpenne til diabetespatienter. Alle tnkelige fejl skal findes og sorteres fra, fr produktet ender hos slutbrugerne.Den teknologi-beskrivelse bliver i disse tider kraftigt udfordret af nye visionsystemer, der er baseret p deep learning i stedet for mere klassiske regelbaserede computervision-algoritmer.Et af de systemer er udviklet af danske software-virksomhed Criterion AI, som arbejder inden for den farmaceutiske industri og blandt andet hjlper Novo Nordisk med at effektivisere kvalitetskontrollen med billedgenkendelse.I dag fder man emnerne ind i store vision-maskiner, hvor der sidder 5-6 kameraer, der tager billeder, der s kres ind i klassiske computervision-algoritmer. De er ikke altid strke nok til at finde alle fejl, og det forsger man at kompensere for med meget dyre objektiver og ved at bruge mange ressourcer p at skabe det bedst mulige lys. Mlet er at kontrollere billedprocessen, s billederne bliver s knivskarpe og dermed nemmere at genkende for algoritmerne, fortalte Sebastian Brandes, medstifter af Criterion AI, p konferencen Big Data, AI &amp; Analytics - Hvad skal vi med al den data, som Dansk Automationsselskab afholdt tidligere i maj.Det gr industrielle visionsystemer komplekse og dyre. Men hvis man kan forbedre algoritmerne, der genkender billeder, s behver man mske ikke dyre objektiver til kameraer og perfekt lysstning p fabriksgulvet.Vi arbejder med en mere dataprget tilgang, hvor algoritmerne er strkere, og s har vi ikke samme hje krav til billederne. Det betyder, at man kan bruge billigere og mindre kameraer, der kan sttes op i selve produktionsmiljet, sagde Sebastian Brandes.Criterion AI bruger deep learning, en serie algoritmer der er bedre i stand til at lre mnstre ud af r data end mere konventionelle machine learning-algoritmer, hvor algoritmerne skal trnes manuelt p forhnd.Men det lyder nsten som en lidt for god salgstale, nr man vil ge kvaliteten for frre ressourcer.Kraftige grafikkort genopliver gamle algoritmerDet er ikke, fordi Criterion AI eller andre virksomheder, der udvikler nye lsninger baseret p kunstig intelligens, har udviklet vidunder-algoritmer fra den ene dag til den anden. Faktisk er det snarere en rkke af teknologiske fremskridt inden for hardware, der har revitaliseret deep learning-metoderne.De matematiske modeller, der ligger bag deep learning-algoritmerne, blev nemlig udviklet for over 30 r siden. Men mangel p processorkraft og datast satte en stopper for udbredelsen af algoritmerne.I slutningen af 80'erne havde man ikke den ndvendige computerkraft og digitale data til at kre algoritmerne, og gejsten omkring deep learning dde delvist i 90'erne. Det var frst, da chip-producenten Nvidia lancerede et nyt grafikkort og udviklervrktjet Cuda i 2007, at deep learning fik et nyt gennembrud, fortalte Sebastian Brandes.Det var alts ny hardware, i form af chips, der har boostet brugen af deep learning.Grafikkort er blevet s strke, at selvom vi banker 3.000 billeder ind i minuttet p en server, s kommer grafikkortet ikke over 52 grader. For selvom de kraftige grafikkort ikke kan s meget som et traditionelt CPU, s er de er vanvittigt gode til at lave matrix-operationer parallelt, s man kan trne neurale netvrk p meget kort tid. Og det er vigtigt til billedanalyse i industrien, fortalte Sebastian Brandes.Den store forskel p klassisk machine learning og deep learning er, at man med machine learning skal bruge mere tid p at forberede sine produktionsdata, fr de kan smides ind i en algoritme, der kan afgre, om produktet er godkendt eller skal kasseres.Med deep learning skal man lave langt mindre pr-processering, og vi kan fde rdata ind, uden at vise algoritmen hvad sammenhngen er, sagde Sebastian Brandes.
        </div>
        <footer>
          <em>Pro.ing.dk/industrytech</em>
          &nbsp;&nbsp; 2019-05-14
          &nbsp;&nbsp; e7327cb4
          &nbsp;&nbsp; #43
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.994</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.864</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.651</kbd>
        </footer>
      </article>
      <article>
        <h4>Dataminimering og privacy-bevarende teknikker i AI-systemer</h4>
        <div>
           Generelt krver AI-systemer store mngder data. Men organisationer skal ogs overholde 'minimeringsprincippet' under databeskyttelseslovgivningen, hvis de bruger personlige data. Det betyder, at de skal sikre, at alle personlige data er tilstrkkelige, relevante og begrnset til det, der er ndvendigt til det forml, de processeres til. Hvad der er tilstrkkeligt, relevant og ndvendigt i relation til AI-systemer vil afhnge af use-casen. Der er dog flere teknikker, som organisationer kan benytte sig af i udviklingen af AI-systemer, der processerer s f personlige data som muligt, men stadig er funktionelle. I dette blogindlg ser vi p nogle af de mest relevante teknikker til superviserede machine learning (ML)-systemer, som i jeblikket er den mest brugte type AI. Internt i en organisation bliver de personer, der er ansvarlige for risikohndtering og compliance, nr det glder AI-systemer, ndt til at vre opmrksomme p, at sdanne teknikker eksisterer, og de skal kunne diskutere forskellige tilgange med deres tekniske medarbejdere. Default-tilgangen, som data scientists har, nr de designer og bygger AI-systemer, betyder, at de ikke ndvendigvis vil tage dataminimeringsbegrnsninger i betragtning. Organisationer skal derfor have praksisser relateret til risikohndtering p plads for at sikre, at dataminimeringskrav og alle relevante minimeringsteknikker er indtnkt fra designfasen eller - hvis AI-systemerne kbes eller opereres af tredjeparter - som en del af den rettidige omhu i indkbsprocessen. Men dataminimeringsteknikker vil ikke helt udrydde risici. Og mens nogle teknikker ikke vil krve kompromiser for at levere dataminimeringsfordele, s vil andre krve, at organisationer balancerer dataminimering med anden compliance eller brugsml, f.eks. at lave mere njagtige og ikke-diskriminerende ML-modeller. Det frste skridt, organisationer br tage mod overholdelse af dataminimering, er at forst og kortlgge alle de ML-processer, i hvilke personlige data kan blive brugt. Sdan bruges personlige data i ML-modeller Superviserede ML-algoritmer kan trnes til at identificere mnstre og skabe modeller ud fra datast ('trningsdata'), hvilket inkluderer tidligere eksempler p den type tilflde, modellen vil blive bedt om at klassificere eller forudsige. Specifikt indeholder trningsdataene bde 'ml-variablen', alts det, som modellen stiler mod at forudsige eller klassificere, og forskellige 'forudsigelses'-variabler, f.eks. det input, der bruges til at lave forudsigelsen. For eksempel kan forudsigelsesvariablen i trningsdataene for en banks ML-model om kreditrisiko inkludere alderen, indkomsten, stillingen og lokationen for forskellige kunder, mens mlvariablen er, om kunderne tilbagebetalte deres ln eller ej. Nr ML-systemerne frst er trnet, kan de klassificere og lave forudsigelser baseret p nye data, der indeholder eksempler, som systemet aldrig har set fr. En foresprgsel (query) bliver sendt til ML-modellen, og den indeholder forudsigelsevariablerne for et nyt tilflde (f.eks. en ny kundes alders, indkomst, stilling mv.) Modellen svarer med sit bedste gt mht. mlvariablen for dette nye tilflde (f.eks. om kunden vil tilbagebetale sit ln). Superviserede ML-tilgange bruger derfor data i to hovedfaser: Trningsfasen, hvor data bruges til at udvikle modeller baseret p tidligere eksempler, og Flgeslutningsfasen, hvor modellen bruges til at lave en forudsigelse eller klassificering af nye tilflde Hvis modellen bruges til at lave forudsigelser eller klassificeringer af individer , s er det meget sandsynligt, at personlige data vil blive brugt i bde trnings- og flgeslutningsfasen. Teknikker til at minimere personlige data Nr data scientists designer og bygger ML-applikationer, vil de generelt formode, at al data, der bruges i trningen, testen og operationen af systemet, vil vre indsamlet centralt og beholdt i sin fulde og originale form af en enkelt enhed gennem hele AI'ens livscyklus. Men der er faktisk forskellige tilgange og flere teknikker, som kan bruges i stedet, og som minimerer den mngde data, en organisation har brug for for at indsamle og processere, eller minimerer, i hvor hj grad dataene er identificerbare i forhold til bestemte individer. Dataminimering i trningsfasen Udvalg af oplysninger Som vi har forklaret, involverer trningsfasen en lringsalgoritme til et datast, der indeholder et st oplysninger ('features') for hvert individ, som bruges til at generere forudsigelsen eller klassificeringen. Men ikke alle oplysninger inkluderet i et datast vil ndvendigvis vre relevante for opgaven. For eksempel vil ikke alle finansielle og konomiske oplysninger vre brugbare i forhold til at forudsige en kreditrisiko. Der er flere forskellige standardmetoder til at udvlge oplysninger , som data scientists bruger til at vlge oplysninger, som vil vre brugbare at inkludere i en model. Disse metoder er 'good practice' i data science, men er ogs i nogen grad et skridt p vejen til at overholde dataminimeringsprincippet. Som man kan lse i en tidligere rapport (PDF) fra ICO (Information Commissioner's Office, den britiske databeskyttelsesvagthund, red. ) om AI og big data, er det faktum, at nogle data senere i processen kan vise sig brugbare til at lave forudsigelser, ikke nok til at fastsl ndvendigheden af det aktuelle forml, og det retfrdiggr heller ikke med bagudvirkende kraft indsamling, brug eller lagring af data. Privacy-bevarende metoder Der er ogs flere teknikker, som bevarer privacy, og som kan bruges til at minimere dataprocessering i trningsfasen. Nogle af disse teknikker involverer modificering af trningsdataene for at reducere, i hvor hj grad de kan spores tilbage til specifikke individer, mens de stadig er brugbare i forhold til at trne velprsterende modeller. Dette kunne f.eks. involvere tilfldig ndring af datapunkters vrdi - det kendes ogs som 'forstyrrelse' af data eller at fje 'stj' til data - p en mde, der bevarer nogle af disse oplysningers statistiske egenskaber (se f.eks. Rappor-algoritmen) Disse typer privacy-bevarende teknikker kan anvendes p trningsdataene, efter de allerede er blevet indsamlet. Men nr det er muligt, br de anvendes fr indsamlingen af personlige data for at undg, at der overhovedet skabes store personlige datast. For eksempel er automatiske tekstforudsigelser i smartphones baseret p de ord, brugeren tidligere har skrevet. Frem for altid at indsamle en brugers faktiske tastaturtryk kunne systemet designes til at skabe 'stjende', alts falske ord, tilfldigt. Dette ville betyde, at en organisation ikke ville kunne vre sikker p, hvilke ord der var 'stj', og hvilke der faktisk blev skrevet af en specifik bruger. Selv om data ville vre mindre njagtige p individniveau, kunne mnstre stadig opfanges og brugt til at trne ML'er p indsamlingsniveau. Hvor effektive disse privacy-bevarende teknikker er, nr det glder balancen mellem individers privatliv og brugbarheden af et ML-system, kan mles matematisk ved at bruge en metode som 'differential privacy'. Det er en mde, hvorp man kan mle, om en model skabt af en ML-algoritme er afhngig af dataene for ethvert individ, der bruges til at trne det. En relateret privacy-bevarende teknik er 'federated learning' (forbundet lring). Dette gr det muligt, at flere forskellige parter trner deres modeller p deres egne data ('lokale' modeller) og s kombinerer nogle af de mnstre, som disse modeller har identificeret (kendt som 'gradienter'), til en enkelt, mere njagtig 'global' model uden at skulle dele trningsdata med hinanden. Federated learning er ret nyt og har flere storskala-egenskaber. Disse inkluderer automatisk rettelse og tekstforudsigelser i smartphones, men ogs i forhold til medicinsk forskning, der involverer analyser p tvrs af flere patientdatabaser. Mens det at dele gradienten, der er opnet med en lokalt trnet model, betyder en lavere privacy-risiko end at dele selve trningsdataene, kan en gradient stadig afslre personlig information relateret til dataobjekterne, den kom fra, isr hvis modellen er kompleks med en masse finkornede variabler. Data controllere vil derfor stadig skulle vurdere risikoen for re-identificering. Ved federated learning vil deltagende organisationer hjst sandsynligt bliver anset som vrende flles data controllers, selv om de ikke har adgang til hinandens data. Minimering af personlige data p flgeslutningsstadiet For at lave en forudsigelse om eller klassificering af et individ behver ML- modeller sdvanligvis et fuldt st forudsigelsesvariabler for personen, der skal vre med i foresprgslen. Ligesom i trningsfasen er der flere forskellige teknikker, som kan bruges til at minimere data p flgeslutningsstadiet. Her dkker vi et par af de mest lovende tilgange. Konvertering af data til mindre let forstelige ('human readable') formater I mange tilflde kan processen med at konvertere data til et format, hvor de kan klassificeres af en model, bringe dem flere skridt p vejen mod at minimere dem. R personlige data vil som oftest frst skulle konverteres til et mere abstrakt format, hvis der skal forudsiges p dem. For eksempel ville letforstelige ord normalt blive oversat til en serie tal (kaldet en 'feature vector'). Dette betyder, at organisationen, der benytter sig af en AI-model, mske ikke behver at processere den for mennesker forstelige version af de personlige data indeholdt i foresprgslen, for eksempel hvis konverteringen sker p brugerens enhed. Men det faktum, at det ikke lngere er let forsteligt af mennesker, betyder ikke, at de konverterede data ikke lngere er personlige. Tnk bare p ansigtsgenkendelsesteknologi, Facial Recognition Technology (FRT). For at en ansigtsgenkendelsesteknologimodel skal fungere, skal digitale billeder af ansigterne, der klassificeres, konverteres til 'ansigtsaftryk'. Dette er de matematiske reprsentationer af de geometriske egenskaber, som de underliggende ansigter har - f.eks. afstanden mellem en persons nse og overlbe. Frem for at sende selve ansigtsbillederne til en organisations server kunne fotos blive konverteret til ansigtsaftryk direkte p enheden, som tager billederne, fr de sendes til modellen med henblik p en foresprgsel. Disse ansigtsaftryk kunne vre mindre henfrbare til en bestemt person end ansigtsfotos. Men ansigtsaftrykkene er stadig personlige (faktisk biometriske) data og derfor i hj grad identificerbare inden for konteksten af de ansigtsgenkendelsesmodeller, der bruger dem. Lokalt skabte flgeslutninger En anden metode til at undg risiciene involveret i deling af forudsigelsesvariabler er at hoste modellen p den enhed, foresprgslen er genereret p, og som allerede indsamler og lagrer dataobjektets personlige data. For eksempel kunne en ML-model installeres p brugerens egen enhed og lave flgeslutninger 'lokalt' frem for at blive hosted p en cloud-server. Eksempelvis kunne modellerne, der skal forudsige, hvilke annoncer en bruger kunne vre interesseret i, kres lokalt p brugerens smartphone (se PrivAd og MobiAd for proof of concept-eksempler). Nr en annonceringsmulighed opstod, kunne flere forskellige annoncer blive afsendt fra et annoncenetvrk, og den lokale model kunne udvlge den mest relevante at vise brugeren uden at afslre brugerens faktiske personlige vaner eller profilinformation for annoncrerne. Begrnsningen er, at ML-modeller bliver ndt til at vre tilstrkkeligt sm og computermssigt effektive nok til at kre p brugerens egen hardware. Den nylige udvikling inden for specialbygget hardware til smartphones og indlejrede enheder betyder, at dette er en mere og mere gennemfrlig mulighed. Det er vigtigt at gre opmrksom p, at lokal processering ikke ndvendigvis er uden for databeskyttelseslovgivningens omrde. Selv hvis den personlige data involveret i trningen processeres p brugerens egen enhed, s vil organisationen, som skaber og distribuerer modellen, stadig vre data controller, idet de bestemmer, hvordan processeringen skal foreg og med hvilket forml. Privacy-bevarende foresprgselstilgange Hvis det ikke er muligt at anvende modellen lokalt, eksisterer der andre privacy-bevarende teknikker [1], der kan minimere de data, der afslres i en foresprgsel sendt til en ML-model (se f.eks. TAPAS). Disse tillader, at en af parterne henter en forudsigelse eller klassificering uden at afslre al denne information til parten, der krer modellen. Kort og godt: De tillader, at du fr et svar uden helt at behve at afslre dit sprgsml. Anonymisering Der er konceptuelle og tekniske ligheder mellem dataminimering og anonymisering. I visse tilflde betyder brugen af privacy-bevarende teknikker, at nogle data brugt i ML-systemer bliver pseudonyme eller anonyme. ICO's Anonymisation Code of Practice kan give organisationer information om disse koncepter. ICO er ogs i jeblikket i gang med at udvikle nye opdaterede guides om anonymisering, der skal medtage nylige udviklinger og teknikker p dette omrde. [1] Du kan finde et overblik over disse i kapitel 11 af 'The Algorithmic Foundations of Differential Privacy' (PDF). Blogindlgget blev oprindeligt publiceret p ico.org.uk.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2019-09-10
          &nbsp;&nbsp; e7562277
          &nbsp;&nbsp; #44
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.966</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.972</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.646</kbd>
        </footer>
      </article>
      <article>
        <h4>28. jun 04:18</h4>
        <div>
          Alexandra Instituttet og NVIDIA Deep Learning Institue (DLI) afholder dette endagskursus for udviklere og dataanalytikere. P kurser vil der vre undervisning i det grundlggende ved deep learning gennem trning og implementering af neurale netvrk. Kurset er mlrettet applikationer indenfor automatisk billedgenkendelse.Den rlige KDD-konference er en stor tvrfaglig konference, der samler forskere og praktikere fra datalogi, dataudvinding, analytics p stor skala og big data. I lbet ad de fem dage konferencen varer vil der vre skiftende fokus p forskellige brancher, for eksempel sundhedssektoren og deep learning.
        </div>
        <footer>
          <em>Pro.ing.dk/Gridtech</em>
          &nbsp;&nbsp; 2018-06-28
          &nbsp;&nbsp; e6ce6de6
          &nbsp;&nbsp; #45
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.954</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.829</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.522</kbd>
        </footer>
      </article>
      <article>
        <h4>NLP-specialisterne hos Hugging Face barsler med Automatisk NLP</h4>
        <div>
          AutoNLP gr det muligt at lave et hurtigt proof-of-concept, men egner sig ikke til en enterprise-lsning, vurderer data scientist.BrdtekstDet ledende NLP-startup Hugging Face har p f r formet at skabe et stort open source-milj omkring udvikling af NLP-teknologi - ikke mindst Transformer-biblioteket, som bruges af virksomheder som Google, Microsoft og Facebook.Nu tilfjer selskabet automatisk NLP til portefljen med systemet AutoNLP - en automatiseret metode til at trne og udrulle state-of-the-art NLP-modeller.Lsningen, der stadig er i beta, kan automatisk udvlge model, trne, fintune og gre modellen tilgngelig via et API.Og det vil vre et effektivt vrktj i nogle sammenhnge, men ikke hvis man som virksomhed skal bygge et NLP-produkt til produktion, vurderer Malte Hjmark-Bertelsen, der er data scientist hos KMD og selv har udviklet den danske sprogmodel lctra.Ls ogs: Udvikler bag ny dansk sprogmodel: Hrdt brug for dansk evaluerings-standard Der er sikkert nogle firmaer, hvor det er favorabelt, at man slet ikke skal tnke p at hoste eller deploye sin model, og man bare skal kalde en API og f en prdiktion, siger han.Men lige s snart, man kommer dertil, hvor man arbejder med flsom data, som skal hndteres fornuftigt, s er det ikke fedt, at man har trnet sin model, og den ligger i en cloud-tjeneste, man ikke rigtig har adgang til. Krver mere explainabilityIndtil videre understtter AutoNLP binr og multi-klasse klassifikationer samt entity recognition. Og flere muligheder bliver tilfjet p ugentlig basis, lover Hugging Face.Hugging Face-udvikler Abhishek Thakur forklarer her, hvordan systemet kan bruges:Derudover er det fortsat smt med information om, hvad AutoNLP-systemet egentlig er, mener Malte Hjmark-Bertelsen.Fordi du uploader dine data, skal der typisk laves databehandleraftaler med Hugging Face. Det krver mere gennemsigtighed omkring, hvordan de data, man trner p, bliver behandlet. Og yderligere kommer der et etisk ansvar, nr vi udvikler AI, om at gre det ordentligt. Til det har vi brug for forklarbarhed, og det virker ikke p nogen mde til at vre integreret her. Malte Hjmark-Bertelsen pointerer, at brugen af AutoML skaber endnu et lag, som har brug for en forklaring:Hvis du f.eks laver en lsning, der kategoriserer e-mails som spam eller ej, vil du gerne kunne se, hvorfor en specifik mail bliver klassificeret, som den gr. P samme mde vil en data scientist, der bruger en AutoNLP-lsning ogs gerne se, hvilke beslutninger der er blevet truffet i det her framework, hvordan hyperparametre ser ud og s videre. Hurtig MVP og APIDer hvor AutoNLP til gengld kan f lov til at brillere, er i de tilflde, hvor du vil teste noget hurtigt af p ikke-sensitive data, fortller Malte Hjmark-Bertelsen.Hvis du har et bent datast, og du har brug for at f et Minimum Viable Product op at st og kalde en model gennem et hurtigt API, s vil AutoNLP kunne fjerne en masse af de problemer, man ellers ville stde ind i, ved at stte sdan en lsning op. En anden oplagt opgave at overlade til et AutoNLP-system er iflge Malte Hjmark-Bertelsen arbejdet med at f de forskellige frameworks og miljer til at spille sammen, og f forbinde med de forskellige GPU'er eller TPU'er, der mtte vre brug for.Det kunne lfte nogle af de trlse opgaver fra data scientist. Men jeg tror ikke, at AutoNLP er god til at vlge modellen, der skal trnes. Det er muligt, at den kan trne en model til sentiment-detection. Men jeg vil mene, at det krver en data scientists forretningsviden og domneviden at vide, hvilken slags sentiment detection der er brug for. Skal det f.eks. vre binrt, eller skal det vre p en gradient? Det krver mere specifik domneviden og indsigt i kundens nsker. Open source er et must for dansk NLPMalte Hjmark-Bertelsen understreger, at han er generelt begejstret for Hugging Faces arbejde med at facilitere et open-source NLP-milj med vrktjer, der gr det nemt for den gngse data scientist eller hobby-koder at f lavet en pipeline, hvor man kan bygge meget komplicerede modeller rigtigt nemt.Hugging Faces open source-tilgang er ogs den, som vi i KMD er interesseret i. Det er noget af det, der krves for at lfte mulighederne inden for NLP, isr inden for dansk NLP. 
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2021-03-04
          &nbsp;&nbsp; e826d204
          &nbsp;&nbsp; #46
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.86</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.814</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.697</kbd>
        </footer>
      </article>
      <article>
        <h4>Ny professor p DTU: Styrker forskning for maskinlring til bredygtige forml</h4>
        <div>
          DTU styrker forskningen indenfor maskinlring med udnvnelsen af Darko Zibar, gruppeleder ved DTU Fotonik, til professor, skriver universitetet p sin hjemmeside.I sin forskning fokuserer professoren p, hvordan man kan bruge maskinlring til at udvikle strmbesparende lsninger indenfor optisk kommunikation og intelligente optiske systemer. Maskinlring og andre intelligente systemer kan spille en nglerolle, og det er derfor ndvendigt, at vi forsker i det felt, hvis vi skal n FN's Verdensml om bredygtig udvikling og nedbringe verdens CO2-udslip. De nste generationer af optiske kommunikationssystemer bliver s komplekse, at maskinlring vil vre en relativt hurtig mde at finde frem til lsninger, hvor vi kan transportere enorme mngder data p den mest energieffektive mde,  fortller Darko Zibar til DTU.Siden 2019 har han stet i spidsen for gruppen 'Machine Learning in Photonics Systems', som var blandt de frste til at bruge maskinlring og kunstig intelligens i optisk kommunikationsteknologi.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2021-02-11
          &nbsp;&nbsp; e81f4edc
          &nbsp;&nbsp; #47
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.981</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.691</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.578</kbd>
        </footer>
      </article>
      <article>
        <h4>Deep learning erstatter dyre objektiver hos Novo Nordisk</h4>
        <div>
          Tungt, kompleks og dyrt. Det er tre ord, som oftest gr igen, nr talen falder p visionsystemer til kvalitetskontrol i industrien. Det er uanset, om man skal finde fejl p sm metalkomponenter til bilindustrien eller insulinpenne til diabetespatienter. Alle tnkelige fejl skal findes og sorteres fra, fr produktet ender hos slutbrugerne.Den teknologi-beskrivelse bliver i disse tider kraftigt udfordret af nye visionsystemer, der er baseret p deep learning i stedet for mere klassiske regelbaserede computervision-algoritmer.Et af de systemer er udviklet af danske software-virksomhed Criterion AI, som arbejder inden for den farmaceutiske industri og blandt andet hjlper Novo Nordisk med at effektivisere kvalitetskontrollen med billedgenkendelse.I dag fder man emnerne ind i store vision-maskiner, hvor der sidder 5-6 kameraer, der tager billeder, der s kres ind i klassiske computervision-algoritmer. De er ikke altid strke nok til at finde alle fejl, og det forsger man at kompensere for med meget dyre objektiver og ved at bruge mange ressourcer p at skabe det bedst mulige lys. Mlet er at kontrollere billedprocessen, s billederne bliver s knivskarpe og dermed nemmere at genkende for algoritmerne, fortalte Sebastian Brandes, medstifter af Criterion AI, p konferencen Big Data, AI &amp; Analytics - Hvad skal vi med al den data, som Dansk Automationsselskab afholdt tidligere i maj.Det gr industrielle visionsystemer komplekse og dyre. Men hvis man kan forbedre algoritmerne, der genkender billeder, s behver man mske ikke dyre objektiver til kameraer og perfekt lysstning p fabriksgulvet.Vi arbejder med en mere dataprget tilgang, hvor algoritmerne er strkere, og s har vi ikke samme hje krav til billederne. Det betyder, at man kan bruge billigere og mindre kameraer, der kan sttes op i selve produktionsmiljet, sagde Sebastian Brandes.Criterion AI bruger deep learning, en serie algoritmer der er bedre i stand til at lre mnstre ud af r data end mere konventionelle machine learning-algoritmer, hvor algoritmerne skal trnes manuelt p forhnd.Men det lyder nsten som en lidt for god salgstale, nr man vil ge kvaliteten for frre ressourcer.Sebastian Brandes, medstifter af softwaer-virksomheden Criterion AI, fortalteom deep learning p Dau-konferencen om Big dataKraftige grafikkort genopliver gamle algoritmerDet er ikke, fordi Criterion AI eller andre virksomheder, der udvikler nye lsninger baseret p kunstig intelligens, har udviklet vidunder-algoritmer fra den ene dag til den anden. Faktisk er det snarere en rkke af teknologiske fremskridt inden for hardware, der har revitaliseret deep learning-metoderne.De matematiske modeller, der ligger bag deep learning-algoritmerne, blev nemlig udviklet for over 30 r siden. Men mangel p processorkraft og datast satte en stopper for udbredelsen af algoritmerne.I slutningen af 80'erne havde man ikke den ndvendige computerkraft og digitale data til at kre algoritmerne, og gejsten omkring deep learning dde delvist i 90'erne. Det var frst, da chip-producenten Nvidia lancerede et nyt grafikkort og udviklervrktjet Cuda i 2007, at deep learning fik et nyt gennembrud, fortalte Sebastian Brandes.Det var alts ny hardware, i form af chips, der har boostet brugen af deep learning.Grafikkort er blevet s strke, at selvom vi banker 3.000 billeder ind i minuttet p en server, s kommer grafikkortet ikke over 52 grader. For selvom de kraftige grafikkort ikke kan s meget som et traditionelt CPU, s er de er vanvittigt gode til at lave matrix-operationer parallelt, s man kan trne neurale netvrk p meget kort tid. Og det er vigtigt til billedanalyse i industrien, fortalte Sebastian Brandes.Den store forskel p klassisk machine learning og deep learning er, at man med machine learning skal bruge mere tid p at forberede sine produktionsdata, fr de kan smides ind i en algoritme, der kan afgre, om produktet er godkendt eller skal kasseres.Med deep learning skal man lave langt mindre pr-processering, og vi kan fde rdata ind, uden at vise algoritmen hvad sammenhngen er, sagde Sebastian Brandes.Forskellen p machine learning og deep learning.600 emner i minuttetCriterion AI har hjulpet Novo Nordisk med at ndre deres visionsystemer, s det kun er de drlige produkter, der reelt bliver sorteret fra. For kombinationen af mange emner og ekstreme kvalitetskrav gr, at visionsystemer bliver centrale i produktionen.Nr man er en farmaceutisk virksomhed, skal man kunne identificere alle produkter, isr nr man producerer produkter, der skydes ind i blodet. Man m simpelthen ikke frigive et produkt, uden at det er gennemtestet for eventuelle fejl. Nr man producerer 800 millioner emner om ret, kan det godt blive trgt at kigge dem alle sammen igen, isr hvis det tager mellem 30-60 sekunder pr. emne, sagde Sebastian Brandes.Novo Nordisk har arbejdet med automatisering af kvalitetskontrol ved hjlp af klassiske regelbaserede algoritmer i over 25 r.Nu er man net til et punkt, hvor det er svrt at vride mere ud af den teknologi. Vi har hjulpet Novo Nordisk med at kigge p deep learning som et nyt skridt til hurtigere og bedre vision. P tvrs af alle produktkategorier har vi boostet fejlfindingsraten, og som et tillg har vi snket antallet af produkter der kasseres ved en fejl. Det er en fordel, nr man som Novo Nordisk er under et prispres p markedet, sagde Sebastian Brandes.Bruger eksisterende teknologierCriterion AI bruger de eksisterende vision-kameraer, som allerede er i drift hos Novo Nordisk, og tager s de billeder og fodrer ind i deres deep learning-algoritme, som vurderer kvaliteten af produktet. Selve algoritmen arbejder lokalt i produktionen for at sikre hastigheden.Nr man krer batches med 500.000 emner ad gangen, hvor der tages fem billeder af hvert emne, som hver fylder 2 Mb, s er det ikke rentabelt at sende i skyen. Hvor mange af de traditionelle industrielle visionsystemer er specialfremstillede til den konkrete produktion, s bruger Criterion AI stort set kun hyldevarer i deres deep learning-system.De bruger eksempelvis en SaaS-platform fra virksomheden Bigfinite, der krer p AWS, mens selve algoritmerne kres igennem Googles open source-bibliotek TensorFlow.Vi har lavet en simpel grnseflade, s operatrer i produktionen ikke skal have erfaring med Python eller andre programmeringssprog, sagde Sebastian Brandes.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;&nbsp; 2019-05-16
          &nbsp;&nbsp; e7334ead
          &nbsp;&nbsp; #48
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.97</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.832</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.657</kbd>
        </footer>
      </article>
      <article>
        <h4>OpenAI: Evolutionr maskinlring skalerer overraskende godt i arkadespil</h4>
        <div>
          Nr computeren slr dig i Pong eller en anden arkadeklassiker, s kan du give evolution skylden. Helt prcist har det ikke meget med biologisk evolution at gre, men et gammelt forslag til optimering af modeller inden for kunstig intelligens har vist sig at vre overraskende effektiv til oplring i blandt andet arkadespil.Kunstig intelligens eller machine learning handler i bund og grund om at finde de mest effektive mder at lade en softwarealgoritme prve sig frem, indtil det lykkes den at lse en opgave. Men nr man arbejder med algoritmer, hvor funktionen har n million parametre, s er det ikke ligegyldigt, hvordan man nr frem til den bedste model.Oplring af algoritmerMed machine learning opbygger man en model ved at lade algoritmen arbejde med et datast. Men det er ikke alle datast, der er lige egnede til alle metoder til oplring, og derfor arbejder man inden for machine learning med forskellige principper:Supervised Learning: Her har man et datast, hvor der er tilknyttet rigtige svar. Det kan eksempelvis vre en database med fotos, hvor der er tilknyttet beskrivelser af, hvad billederne forestiller. Algoritmen opbygger en model ved at forsge at forudsige et resultat, som kan evalueres ud fra de kendte, korrekte svar. P den mde kan algoritmen forbedre modellen.Der er flere metoder til denne type oplring, heriblandt support vector machine, logistic regression, back propagation neural network og evolution strategies.Unsupervised Learning: Nr et datast ikke er katalogiseret med etiketter, og du alts ikke kender de korrekte svar, s bygger strategierne p at finde frem til mulige strukturer i datasttet, men der er ingen mulighed for at lade algoritmen forsge at evaluere, om t bud er bedre end et andet, ud fra en facitliste.Denne type machine learning kan blandt andet anvendes til anomaly detection og clustering.kilde: Machinelearningmastery.comDet koster nemlig regnekraft og tid, og derfor har forskerne hos OpenAI taget et ekstra kig p en metode kaldet Evolution Strategies.Den gr meget overordnet ud p at finde den bedste variant af en funktion alene ud fra kvaliteten af resultatet og inputtet.Enkel og skalerer godtEvolution Strategies kan iflge OpenAI-forskerne vre et alternativ til Reinforcement Learning, som er populr til oplring af algoritmer inden for eksempelvis billedanalyse.Evolution Strategies er ikke den bedste metode til alle forml, men fordi den er ret enkel, s kan den skalere ganske effektivt.I stedet for at udveksle en komplet vektor med parametre mellem hver regneenhed, s kan man njes med nogle f skalarer, hvilket gr det nemmere at foretage parallelle beregninger.En af de centrale forskelle p Reinforcement Learning og Evolution Strategies er, at i den frste arbejder man med tilfldige mutationer af hver enkelt 'regel'.I Evolution Strategies forsger man at finde det optimale punkt for hver regel, s man skyder sig ind p den bedste vrdi, lidt p samme mde som Newtons metode.Det har alts vist sig at vre en god metode til arkadespil, hvor inputtet er et billede. Algoritmen ser alts, hvad der sker p skrmen.Nem succesmlingLigesom et menneske skal algoritmen s finde ud af, om det eksempelvis er bedst at g til hjre eller venstre. I et spil som eksempelvis Pong er det nemt at mle resultatet: Hvis algoritmen misser bolden, s dumper dn variant, men hvis bolden rammes, og den ryger forbi modstanderen, s er algoritmen p vej mod et optimum.Forskellen mellem de to typer lring ligger i matematikken, og det er ogs derfor, at Evolution Strategies ikke altid er bedre end Reinforcement Learning.Til gengld er Evolution Strategies alts i visse tilflde hurtigere at oplre, fordi udregningerne er enklere i kraft af, at algoritmen ikke evaluerer ved at se p, hvad der skete 'inde'i algoritmen, men blot p resultatet.Iflge OpenAI betd det i undersgelsen af arkadespillene, at algoritmen kunne oplres to til tre gange hurtigere med mindre kode, og det var ikke ndvendigt at gemme s mange data.Undersgelsen bestod blandt andet i test af 51 Atari 2600-spil, hvor algoritmerne blev oplrt p n milliard frames fra hvert spil ved at kre parallelt p 720 processorer p Amazons EC2.Der er et aber dabeiMetoden er ikke altid bedre - faktisk klarede Reinforcement Learning med metoden A3C worker sig bedre i 28 af spillene, men til gengld var Evolution Strategies mere tolerant over for, hvor mange frames man sprang over i hver gennemkrsel.Forskerne konkluderer alts, at Evolution Strategies er endnu en farbar vej inden for machine learning, som isr har en fordel, hvis man har behov for at kunne parallelisere, nr modellen skal oplres.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;&nbsp; 2017-04-20
          &nbsp;&nbsp; e638060f
          &nbsp;&nbsp; #49
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.996</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.995</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.694</kbd>
        </footer>
      </article>
    </main>
  </body>
</html>
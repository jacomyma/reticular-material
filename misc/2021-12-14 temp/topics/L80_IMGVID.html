<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Infomedia Articles</title>
    <style type="text/css">
/*!
 * Pico.css v1.3.3 (https://picocss.com)
 * Copyright 2019-2021 - Licensed under MIT
 */:root{--font-family:system-ui,-apple-system,"Segoe UI","Roboto","Ubuntu","Cantarell","Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";--line-height:1.5;--font-weight:400;--font-size:16px;--border-radius:.25rem;--border-width:1px;--outline-width:3px;--spacing:1rem;--typography-spacing-vertical:1.5rem;--block-spacing-vertical:calc(var(--spacing) * 2);--block-spacing-horizontal:var(--spacing);--grid-spacing-vertical:0;--grid-spacing-horizontal:var(--spacing);--form-element-spacing-vertical:.75rem;--form-element-spacing-horizontal:1rem;--transition:.2s ease-in-out}@media (min-width:576px){:root{--font-size:17px}}@media (min-width:768px){:root{--font-size:18px}}@media (min-width:992px){:root{--font-size:19px}}@media (min-width:1200px){:root{--font-size:20px}}@media (min-width:576px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 2.5)}}@media (min-width:768px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 3)}}@media (min-width:992px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 3.5)}}@media (min-width:1200px){body>footer,body>header,body>main,section{--block-spacing-vertical:calc(var(--spacing) * 4)}}@media (min-width:576px){article{--block-spacing-horizontal:calc(var(--spacing) * 1.25)}}@media (min-width:768px){article{--block-spacing-horizontal:calc(var(--spacing) * 1.5)}}@media (min-width:992px){article{--block-spacing-horizontal:calc(var(--spacing) * 1.75)}}@media (min-width:1200px){article{--block-spacing-horizontal:calc(var(--spacing) * 2)}}a{--text-decoration:none}a.contrast,a.secondary{--text-decoration:underline}small{--font-size:0.875em}h1,h2,h3,h4,h5,h6{--font-weight:700}h1{--font-size:2rem;--typography-spacing-vertical:3rem}h2{--font-size:1.75rem;--typography-spacing-vertical:2.625rem}h3{--font-size:1.5rem;--typography-spacing-vertical:2.25rem}h4{--font-size:1.25rem;--typography-spacing-vertical:1.874rem}h5{--font-size:1.125rem;--typography-spacing-vertical:1.6875rem}[type=checkbox],[type=radio]{--border-width:2px}[type=checkbox][role=switch]{--border-width:3px}thead td,thead th{--border-width:3px}:not(thead)>*>td{--font-size:0.875em}code,kbd,pre,samp{--font-family:"Menlo","Consolas","Roboto Mono","Ubuntu Monospace","Noto Mono","Oxygen Mono","Liberation Mono",monospace,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji"}kbd{--font-weight:bolder}:root:not([data-theme=dark]),[data-theme=light]{color-scheme:light;--background-color:#FFF;--color:#415462;--h1-color:#1b2832;--h2-color:#23333e;--h3-color:#2c3d49;--h4-color:#374956;--h5-color:#415462;--h6-color:#4d606d;--muted-color:#73828c;--muted-border-color:#edf0f3;--primary:#1095c1;--primary-hover:#08769b;--primary-focus:rgba(16,149,193,0.125);--primary-inverse:#FFF;--secondary:#596b78;--secondary-hover:#415462;--secondary-focus:rgba(89,107,120,0.125);--secondary-inverse:#FFF;--contrast:#1b2832;--contrast-hover:#000;--contrast-focus:rgba(89,107,120,0.125);--contrast-inverse:#FFF;--mark-background-color:#fff2ca;--mark-color:#543a25;--ins-color:#388E3C;--del-color:#C62828;--blockquote-border-color:var(--muted-border-color);--blockquote-footer-color:var(--muted-color);--button-box-shadow:0 0 0 rgba(0,0,0,0);--button-hover-box-shadow:0 0 0 rgba(0,0,0,0);--form-element-background-color:transparent;--form-element-border-color:#a2afb9;--form-element-color:var(--color);--form-element-placeholder-color:var(--muted-color);--form-element-active-background-color:transparent;--form-element-active-border-color:var(--primary);--form-element-focus-color:var(--primary-focus);--form-element-disabled-background-color:#d5dce2;--form-element-disabled-border-color:#a2afb9;--form-element-disabled-opacity:.5;--form-element-invalid-border-color:#C62828;--form-element-invalid-active-border-color:#B71C1C;--form-element-valid-border-color:#388E3C;--form-element-valid-active-border-color:#2E7D32;--switch-background-color:#bbc6ce;--switch-color:var(--primary-inverse);--switch-checked-background-color:var(--primary);--range-border-color:#d5dce2;--range-active-border-color:#bbc6ce;--range-thumb-border-color:var(--background-color);--range-thumb-color:var(--secondary);--range-thumb-hover-color:var(--secondary-hover);--range-thumb-active-color:var(--primary);--table-border-color:var(--muted-border-color);--table-row-stripped-background-color:#f6f8f9;--code-background-color:#edf0f3;--code-color:var(--muted-color);--code-kbd-background-color:var(--contrast);--code-kbd-color:var(--contrast-inverse);--code-tag-color:#b34d80;--code-property-color:#3d888f;--code-value-color:#998866;--code-comment-color:#a2afb9;--accordion-border-color:var(--muted-border-color);--accordion-close-summary-color:var(--color);--accordion-open-summary-color:var(--muted-color);--card-background-color:var(--background-color);--card-border-color:var(--muted-border-color);--card-box-shadow:0 0.125rem 1rem rgba(27,40,50,0.04),0 0.125rem 2rem rgba(27,40,50,0.08),0 0 0 0.0625rem rgba(27,40,50,0.024);--card-sectionning-background-color:#fafbfc;--progress-background-color:#d5dce2;--progress-color:var(--primary);--loading-spinner-opacity:.5;--tooltip-background-color:var(--contrast);--tooltip-color:var(--contrast-inverse);--icon-chevron:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");--icon-date:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");--icon-time:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");--icon-search:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(65, 84, 98, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");--icon-checkbox:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-minus:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");--icon-valid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(56, 142, 60, 0.999)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-invalid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(198, 40, 40, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E")}@media only screen and (prefers-color-scheme:dark){:root:not([data-theme=light]){color-scheme:dark;--background-color:#11191f;--color:#bbc6ce;--h1-color:#edf0f3;--h2-color:#e1e6ea;--h3-color:#d5dce2;--h4-color:#c8d1d8;--h5-color:#bbc6ce;--h6-color:#aebbc3;--muted-color:#73828c;--muted-border-color:#1f2d38;--primary:#1095c1;--primary-hover:#1ab3e6;--primary-focus:rgba(16,149,193,0.25);--primary-inverse:#FFF;--secondary:#596b78;--secondary-hover:#73828c;--secondary-focus:rgba(115,130,140,0.25);--secondary-inverse:#FFF;--contrast:#edf0f3;--contrast-hover:#FFF;--contrast-focus:rgba(115,130,140,0.25);--contrast-inverse:#000;--mark-background-color:#d0c284;--mark-color:#11191f;--ins-color:#388E3C;--del-color:#C62828;--blockquote-border-color:var(--muted-border-color);--blockquote-footer-color:var(--muted-color);--button-box-shadow:0 0 0 rgba(0,0,0,0);--button-hover-box-shadow:0 0 0 rgba(0,0,0,0);--form-element-background-color:#11191f;--form-element-border-color:#374956;--form-element-color:var(--color);--form-element-placeholder-color:var(--muted-color);--form-element-active-background-color:var(--form-element-background-color);--form-element-active-border-color:var(--primary);--form-element-focus-color:var(--primary-focus);--form-element-disabled-background-color:#2c3d49;--form-element-disabled-border-color:#415462;--form-element-disabled-opacity:.5;--form-element-invalid-border-color:#B71C1C;--form-element-invalid-active-border-color:#C62828;--form-element-valid-border-color:#2E7D32;--form-element-valid-active-border-color:#388E3C;--switch-background-color:#374956;--switch-color:var(--primary-inverse);--switch-checked-background-color:var(--primary);--range-border-color:#23333e;--range-active-border-color:#2c3d49;--range-thumb-border-color:var(--background-color);--range-thumb-color:var(--secondary);--range-thumb-hover-color:var(--secondary-hover);--range-thumb-active-color:var(--primary);--table-border-color:var(--muted-border-color);--table-row-stripped-background-color:rgba(115,130,140,0.05);--code-background-color:#17232c;--code-color:var(--muted-color);--code-kbd-background-color:var(--contrast);--code-kbd-color:var(--contrast-inverse);--code-tag-color:#a65980;--code-property-color:#599fa6;--code-value-color:#8c8473;--code-comment-color:#4d606d;--accordion-border-color:var(--muted-border-color);--accordion-active-summary-color:var(--primary);--accordion-close-summary-color:var(--color);--accordion-open-summary-color:var(--muted-color);--card-background-color:#141e25;--card-border-color:#11191f;--card-box-shadow:0 0.125rem 1rem rgba(0,0,0,0.06),0 0.125rem 2rem rgba(0,0,0,0.12),0 0 0 0.0625rem rgba(0,0,0,0.036);--card-sectionning-background-color:#17232c;--progress-background-color:#23333e;--progress-color:var(--primary);--loading-spinner-opacity:.5;--tooltip-background-color:var(--contrast);--tooltip-color:var(--contrast-inverse);--icon-chevron:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");--icon-date:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");--icon-time:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");--icon-search:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");--icon-checkbox:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-minus:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");--icon-valid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(46, 125, 50, 0.999)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-invalid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(183, 28, 28, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E")}}[data-theme=dark]{color-scheme:dark;--background-color:#11191f;--color:#bbc6ce;--h1-color:#edf0f3;--h2-color:#e1e6ea;--h3-color:#d5dce2;--h4-color:#c8d1d8;--h5-color:#bbc6ce;--h6-color:#aebbc3;--muted-color:#73828c;--muted-border-color:#1f2d38;--primary:#1095c1;--primary-hover:#1ab3e6;--primary-focus:rgba(16,149,193,0.25);--primary-inverse:#FFF;--secondary:#596b78;--secondary-hover:#73828c;--secondary-focus:rgba(115,130,140,0.25);--secondary-inverse:#FFF;--contrast:#edf0f3;--contrast-hover:#FFF;--contrast-focus:rgba(115,130,140,0.25);--contrast-inverse:#000;--mark-background-color:#d0c284;--mark-color:#11191f;--ins-color:#388E3C;--del-color:#C62828;--blockquote-border-color:var(--muted-border-color);--blockquote-footer-color:var(--muted-color);--button-box-shadow:0 0 0 rgba(0,0,0,0);--button-hover-box-shadow:0 0 0 rgba(0,0,0,0);--form-element-background-color:#11191f;--form-element-border-color:#374956;--form-element-color:var(--color);--form-element-placeholder-color:var(--muted-color);--form-element-active-background-color:var(--form-element-background-color);--form-element-active-border-color:var(--primary);--form-element-focus-color:var(--primary-focus);--form-element-disabled-background-color:#2c3d49;--form-element-disabled-border-color:#415462;--form-element-disabled-opacity:.5;--form-element-invalid-border-color:#B71C1C;--form-element-invalid-active-border-color:#C62828;--form-element-valid-border-color:#2E7D32;--form-element-valid-active-border-color:#388E3C;--switch-background-color:#374956;--switch-color:var(--primary-inverse);--switch-checked-background-color:var(--primary);--range-border-color:#23333e;--range-active-border-color:#2c3d49;--range-thumb-border-color:var(--background-color);--range-thumb-color:var(--secondary);--range-thumb-hover-color:var(--secondary-hover);--range-thumb-active-color:var(--primary);--table-border-color:var(--muted-border-color);--table-row-stripped-background-color:rgba(115,130,140,0.05);--code-background-color:#17232c;--code-color:var(--muted-color);--code-kbd-background-color:var(--contrast);--code-kbd-color:var(--contrast-inverse);--code-tag-color:#a65980;--code-property-color:#599fa6;--code-value-color:#8c8473;--code-comment-color:#4d606d;--accordion-border-color:var(--muted-border-color);--accordion-active-summary-color:var(--primary);--accordion-close-summary-color:var(--color);--accordion-open-summary-color:var(--muted-color);--card-background-color:#141e25;--card-border-color:#11191f;--card-box-shadow:0 0.125rem 1rem rgba(0,0,0,0.06),0 0.125rem 2rem rgba(0,0,0,0.12),0 0 0 0.0625rem rgba(0,0,0,0.036);--card-sectionning-background-color:#17232c;--progress-background-color:#23333e;--progress-color:var(--primary);--loading-spinner-opacity:.5;--tooltip-background-color:var(--contrast);--tooltip-color:var(--contrast-inverse);--icon-chevron:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");--icon-date:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");--icon-time:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");--icon-search:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(162, 175, 185, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");--icon-checkbox:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-minus:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='%23FFF' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");--icon-valid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(46, 125, 50, 0.999)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");--icon-invalid:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgba(183, 28, 28, 0.999)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E")}*,:after,:before{box-sizing:border-box}:after,:before{text-decoration:inherit;vertical-align:inherit}html{-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:rgba(0,0,0,0);-moz-tab-size:4;-ms-text-size-adjust:100%;background-color:var(--background-color);color:var(--color);font-family:var(--font-family);font-size:var(--font-size);font-weight:var(--font-weight);line-height:var(--line-height);text-rendering:optimizeLegibility;cursor:default}main{display:block}body{width:100%;margin:0}body>footer,body>header,body>main{width:100%;margin-right:auto;margin-left:auto;padding:var(--block-spacing-vertical) 0}.container,.container-fluid{width:100%;margin-right:auto;margin-left:auto;padding-right:var(--spacing);padding-left:var(--spacing)}@media (min-width:576px){.container{max-width:510px;padding-right:0;padding-left:0}}@media (min-width:768px){.container{max-width:700px}}@media (min-width:992px){.container{max-width:920px}}@media (min-width:1200px){.container{max-width:1130px}}section{margin-bottom:var(--block-spacing-vertical)}.grid{grid-column-gap:var(--grid-spacing-horizontal);grid-row-gap:var(--grid-spacing-vertical);display:grid;grid-template-columns:1fr;margin:0}@media (min-width:992px){.grid{grid-template-columns:repeat(auto-fit,minmax(0%,1fr))}}.grid>*{min-width:0}figure{display:block;margin:0;padding:0;overflow-x:auto}figure figcaption{padding:calc(var(--spacing) / 2) 0;color:var(--muted-color)}b,strong{font-weight:bolder}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-0.25em}sup{top:-0.5em}dl dl,dl ol,dl ul,ol dl,ul dl{margin:0}ol ol,ol ul,ul ol,ul ul{margin:0}address,blockquote,dl,figure,form,ol,p,pre,table,ul{margin-top:0;margin-bottom:var(--typography-spacing-vertical);color:var(--color);font-size:1rem;font-style:normal}a{--color:var(--primary);--background-color:transparent;outline:none;background-color:var(--background-color);color:var(--color);text-decoration:var(--text-decoration);transition:background-color var(--transition),color var(--transition),text-decoration var(--transition),box-shadow var(--transition)}a:active,a:focus,a:hover{--color:var(--primary-hover);--text-decoration:underline}a:focus{--background-color:var(--primary-focus)}a.secondary{--color:var(--secondary)}a.secondary:active,a.secondary:focus,a.secondary:hover{--color:var(--secondary-hover)}a.secondary:focus{--background-color:var(--secondary-focus)}a.contrast{--color:var(--contrast)}a.contrast:active,a.contrast:focus,a.contrast:hover{--color:var(--contrast-hover)}a.contrast:focus{--background-color:var(--contrast-focus)}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:var(--typography-spacing-vertical);color:var(--color);font-family:var(--font-family);font-size:var(--font-size);font-weight:var(--font-weight)}h1{--color:var(--h1-color)}h2{--color:var(--h2-color)}h3{--color:var(--h3-color)}h4{--color:var(--h4-color)}h5{--color:var(--h5-color)}h6{--color:var(--h6-color)}address~h1,address~h2,address~h3,address~h4,address~h5,address~h6,blockquote~h1,blockquote~h2,blockquote~h3,blockquote~h4,blockquote~h5,blockquote~h6,dl~h1,dl~h2,dl~h3,dl~h4,dl~h5,dl~h6,figure~h1,figure~h2,figure~h3,figure~h4,figure~h5,figure~h6,form~h1,form~h2,form~h3,form~h4,form~h5,form~h6,ol~h1,ol~h2,ol~h3,ol~h4,ol~h5,ol~h6,pre~h1,pre~h2,pre~h3,pre~h4,pre~h5,pre~h6,p~h1,p~h2,p~h3,p~h4,p~h5,p~h6,table~h1,table~h2,table~h3,table~h4,table~h5,table~h6,ul~h1,ul~h2,ul~h3,ul~h4,ul~h5,ul~h6{margin-top:var(--typography-spacing-vertical)}hgroup{margin-bottom:var(--typography-spacing-vertical)}hgroup>*{margin-bottom:0}hgroup>:last-child{--color:var(--muted-color);--font-weight:unset;font-family:unset;font-size:1rem}p{margin-bottom:var(--typography-spacing-vertical)}small{font-size:var(--font-size)}ol,ul{padding-left:var(--spacing)}ol li,ul li{margin-bottom:calc(var(--typography-spacing-vertical) / 4)}ul li{list-style:square}mark{padding:.125rem .25rem;background-color:var(--mark-background-color);color:var(--mark-color);vertical-align:middle}blockquote{display:block;margin:var(--typography-spacing-vertical) 0;padding:var(--spacing);border-left:0.25rem solid var(--blockquote-border-color)}blockquote footer{margin-top:calc(var(--typography-spacing-vertical) / 2);color:var(--blockquote-footer-color)}abbr[title]{border-bottom:1px dotted;text-decoration:none;cursor:help}ins{color:var(--ins-color);text-decoration:none}del{color:var(--del-color)}::selection{background-color:var(--primary-focus)}audio,canvas,iframe,img,svg,video{vertical-align:middle}audio,video{display:inline-block}audio:not([controls]){display:none;height:0}iframe{border-style:none}img{max-width:100%;height:auto;border-style:none}svg:not([fill]){fill:currentColor}svg:not(:root){overflow:hidden}button{margin:0;overflow:visible;font-family:inherit;text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{padding:0;border-style:none}button{display:block;width:100%;margin-bottom:var(--spacing)}a[role=button]{display:inline-block;text-decoration:none}a[role=button],button,input[type=button],input[type=reset],input[type=submit]{--background-color:var(--primary);--border-color:var(--primary);--color:var(--primary-inverse);--box-shadow:var(--button-box-shadow,0 0 0 rgba(0,0,0,0));padding:var(--form-element-spacing-vertical) var(--form-element-spacing-horizontal);border:var(--border-width) solid var(--border-color);border-radius:var(--border-radius);outline:none;background-color:var(--background-color);box-shadow:var(--box-shadow);color:var(--color);font-size:1rem;font-weight:var(--font-weight);line-height:var(--line-height);text-align:center;cursor:pointer;transition:background-color var(--transition),border-color var(--transition),color var(--transition),box-shadow var(--transition)}a[role=button]:active,a[role=button]:focus,a[role=button]:hover,button:active,button:focus,button:hover,input[type=button]:active,input[type=button]:focus,input[type=button]:hover,input[type=reset]:active,input[type=reset]:focus,input[type=reset]:hover,input[type=submit]:active,input[type=submit]:focus,input[type=submit]:hover{--background-color:var(--primary-hover);--border-color:var(--primary-hover);--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0))}a[role=button]:focus,button:focus,input[type=button]:focus,input[type=reset]:focus,input[type=submit]:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--primary-focus)}input[type=reset]{--background-color:var(--secondary);--border-color:var(--secondary);--color:var(--secondary-inverse);cursor:pointer}input[type=reset]:active,input[type=reset]:focus,input[type=reset]:hover{--background-color:var(--secondary-hover);--border-color:var(--secondary-hover)}input[type=reset]:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--secondary-focus)}a[role=button].secondary,button.secondary,input[type=button].secondary,input[type=reset].secondary,input[type=submit].secondary{--background-color:var(--secondary);--border-color:var(--secondary);--color:var(--secondary-inverse);cursor:pointer}a[role=button].secondary:active,a[role=button].secondary:focus,a[role=button].secondary:hover,button.secondary:active,button.secondary:focus,button.secondary:hover,input[type=button].secondary:active,input[type=button].secondary:focus,input[type=button].secondary:hover,input[type=reset].secondary:active,input[type=reset].secondary:focus,input[type=reset].secondary:hover,input[type=submit].secondary:active,input[type=submit].secondary:focus,input[type=submit].secondary:hover{--background-color:var(--secondary-hover);--border-color:var(--secondary-hover)}a[role=button].secondary:focus,button.secondary:focus,input[type=button].secondary:focus,input[type=reset].secondary:focus,input[type=submit].secondary:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--secondary-focus)}a[role=button].contrast,button.contrast,input[type=button].contrast,input[type=reset].contrast,input[type=submit].contrast{--background-color:var(--contrast);--border-color:var(--contrast);--color:var(--contrast-inverse)}a[role=button].contrast:active,a[role=button].contrast:focus,a[role=button].contrast:hover,button.contrast:active,button.contrast:focus,button.contrast:hover,input[type=button].contrast:active,input[type=button].contrast:focus,input[type=button].contrast:hover,input[type=reset].contrast:active,input[type=reset].contrast:focus,input[type=reset].contrast:hover,input[type=submit].contrast:active,input[type=submit].contrast:focus,input[type=submit].contrast:hover{--background-color:var(--contrast-hover);--border-color:var(--contrast-hover)}a[role=button].contrast:focus,button.contrast:focus,input[type=button].contrast:focus,input[type=reset].contrast:focus,input[type=submit].contrast:focus{--box-shadow:var(--button-hover-box-shadow,0 0 0 rgba(0,0,0,0)),0 0 0 var(--outline-width) var(--contrast-focus)}a[role=button].outline,button.outline,input[type=button].outline,input[type=reset].outline,input[type=submit].outline{--background-color:transparent;--color:var(--primary)}a[role=button].outline:active,a[role=button].outline:focus,a[role=button].outline:hover,button.outline:active,button.outline:focus,button.outline:hover,input[type=button].outline:active,input[type=button].outline:focus,input[type=button].outline:hover,input[type=reset].outline:active,input[type=reset].outline:focus,input[type=reset].outline:hover,input[type=submit].outline:active,input[type=submit].outline:focus,input[type=submit].outline:hover{--background-color:transparent;--color:var(--primary-hover)}a[role=button].outline.secondary,button.outline.secondary,input[type=button].outline.secondary,input[type=reset].outline.secondary,input[type=submit].outline.secondary{--color:var(--secondary)}a[role=button].outline.secondary:active,a[role=button].outline.secondary:focus,a[role=button].outline.secondary:hover,button.outline.secondary:active,button.outline.secondary:focus,button.outline.secondary:hover,input[type=button].outline.secondary:active,input[type=button].outline.secondary:focus,input[type=button].outline.secondary:hover,input[type=reset].outline.secondary:active,input[type=reset].outline.secondary:focus,input[type=reset].outline.secondary:hover,input[type=submit].outline.secondary:active,input[type=submit].outline.secondary:focus,input[type=submit].outline.secondary:hover{--color:var(--secondary-hover)}a[role=button].outline.contrast,button.outline.contrast,input[type=button].outline.contrast,input[type=reset].outline.contrast,input[type=submit].outline.contrast{--color:var(--contrast)}a[role=button].outline.contrast:active,a[role=button].outline.contrast:focus,a[role=button].outline.contrast:hover,button.outline.contrast:active,button.outline.contrast:focus,button.outline.contrast:hover,input[type=button].outline.contrast:active,input[type=button].outline.contrast:focus,input[type=button].outline.contrast:hover,input[type=reset].outline.contrast:active,input[type=reset].outline.contrast:focus,input[type=reset].outline.contrast:hover,input[type=submit].outline.contrast:active,input[type=submit].outline.contrast:focus,input[type=submit].outline.contrast:hover{--color:var(--contrast-hover)}a[role=button][disabled],button[disabled],input[type=button][disabled],input[type=reset][disabled],input[type=submit][disabled]{opacity:.5;pointer-events:none}input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:1rem;letter-spacing:inherit;line-height:var(--line-height)}input{overflow:visible}select{text-transform:none}legend{max-width:100%;padding:0;color:inherit;white-space:normal}textarea{overflow:auto}[type=checkbox],[type=radio]{padding:0}::-webkit-inner-spin-button,::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}::-moz-focus-inner{padding:0;border-style:none}:-moz-focusring{outline:none}:-moz-ui-invalid{box-shadow:none}::-ms-expand{display:none}[type=file],[type=range]{padding:0;border-width:0}input:not([type=checkbox]):not([type=radio]):not([type=range]){height:calc((1rem * var(--line-height)) + (var(--form-element-spacing-vertical) * 2) + (var(--border-width) * 2))}fieldset{margin:0;margin-bottom:var(--spacing);padding:0;border:0}fieldset legend,label{display:block;margin-bottom:calc(var(--spacing) / 4);vertical-align:middle}input:not([type=checkbox]):not([type=radio]),select,textarea{display:block;width:100%}input:not([type=checkbox]):not([type=radio]):not([type=range]):not([type=file]),select,textarea{-webkit-appearance:none;-moz-appearance:none;appearance:none;padding:var(--form-element-spacing-vertical) var(--form-element-spacing-horizontal);vertical-align:middle}input,select,textarea{--background-color:var(--form-element-background-color);--border-color:var(--form-element-border-color);--color:var(--form-element-color);--box-shadow:none;border:var(--border-width) solid var(--border-color);border-radius:var(--border-radius);outline:none;background-color:var(--background-color);box-shadow:var(--box-shadow);color:var(--color);font-weight:var(--font-weight);transition:background-color var(--transition),border-color var(--transition),color var(--transition),box-shadow var(--transition)}input:not([type=submit]):not([type=button]):not([type=reset]):not([type=checkbox]):not([type=radio]):not([readonly]):active,input:not([type=submit]):not([type=button]):not([type=reset]):not([type=checkbox]):not([type=radio]):not([readonly]):focus,select:active,select:focus,textarea:active,textarea:focus{--background-color:var(--form-element-active-background-color)}input:not([type=submit]):not([type=button]):not([type=reset]):not([role=switch]):not([readonly]):active,input:not([type=submit]):not([type=button]):not([type=reset]):not([role=switch]):not([readonly]):focus,select:active,select:focus,textarea:active,textarea:focus{--border-color:var(--form-element-active-border-color)}input:not([type=submit]):not([type=button]):not([type=reset]):not([type=range]):not([type=file]):not([readonly]):focus,select:focus,textarea:focus{--box-shadow:0 0 0 var(--outline-width) var(--form-element-focus-color)}input:not([type=submit]):not([type=button]):not([type=reset])[disabled],select[disabled],textarea[disabled]{--background-color:var(--form-element-disabled-background-color);--border-color:var(--form-element-disabled-border-color);opacity:var(--form-element-disabled-opacity)}input[aria-invalid],select[aria-invalid],textarea[aria-invalid]{padding-right:2rem;background-position:center right .75rem;background-repeat:no-repeat;background-size:1rem auto}input[aria-invalid=false],select[aria-invalid=false],textarea[aria-invalid=false]{--border-color:var(--form-element-valid-border-color);background-image:var(--icon-valid)}input[aria-invalid=false]:active,input[aria-invalid=false]:focus,select[aria-invalid=false]:active,select[aria-invalid=false]:focus,textarea[aria-invalid=false]:active,textarea[aria-invalid=false]:focus{--border-color:var(--form-element-valid-active-border-color)!important}input[aria-invalid=true],select[aria-invalid=true],textarea[aria-invalid=true]{--border-color:var(--form-element-invalid-border-color);background-image:var(--icon-invalid)}input[aria-invalid=true]:active,input[aria-invalid=true]:focus,select[aria-invalid=true]:active,select[aria-invalid=true]:focus,textarea[aria-invalid=true]:active,textarea[aria-invalid=true]:focus{--border-color:var(--form-element-invalid-active-border-color)!important}input::-webkit-input-placeholder,input::placeholder,select:invalid,textarea::-webkit-input-placeholder,textarea::placeholder{color:var(--form-element-placeholder-color);opacity:1}input:not([type=checkbox]):not([type=radio]),select,textarea{margin-bottom:var(--spacing)}select::-ms-expand{border:0;background-color:transparent}select:not([multiple]):not([size]){padding-right:calc(var(--form-element-spacing-horizontal) + 1.5rem);background-image:var(--icon-chevron);background-position:center right .75rem;background-repeat:no-repeat;background-size:1rem auto}input+small,select+small,textarea+small{display:block;width:100%;margin-top:calc(var(--spacing) * -0.75);margin-bottom:var(--spacing);color:var(--muted-color)}label>input,label>select,label>textarea{margin-top:calc(var(--spacing) / 4)}[type=checkbox],[type=radio]{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:inline-block;width:1.25em;height:1.25em;margin-top:-.125em;margin-right:.375em;border-width:var(--border-width);vertical-align:middle;cursor:pointer}[type=checkbox]::-ms-check,[type=radio]::-ms-check{display:none}[type=checkbox]:checked,[type=checkbox]:checked:active,[type=checkbox]:checked:focus,[type=radio]:checked,[type=radio]:checked:active,[type=radio]:checked:focus{--background-color:var(--primary);--border-color:var(--primary);background-image:var(--icon-checkbox);background-position:center;background-repeat:no-repeat;background-size:.75em auto}[type=checkbox]~label,[type=radio]~label{display:inline-block;margin-right:.375em;margin-bottom:0;cursor:pointer}[type=checkbox]:indeterminate{--background-color:var(--primary);--border-color:var(--primary);background-image:var(--icon-minus);background-position:center;background-repeat:no-repeat;background-size:.75em auto}[type=radio]{border-radius:50%}[type=radio]:checked,[type=radio]:checked:active,[type=radio]:checked:focus{--background-color:var(--primary-inverse);border-width:.35em;background-image:none}[type=checkbox][role=switch]{--background-color:var(--switch-background-color);--border-color:var(--switch-background-color);--color:var(--switch-color);width:2.25em;height:1.25em;border:var(--border-width) solid var(--border-color);border-radius:1.25em;background-color:var(--background-color);line-height:1.25em}[type=checkbox][role=switch]:focus{--background-color:var(--switch-background-color);--border-color:var(--switch-background-color)}[type=checkbox][role=switch]:checked{--background-color:var(--switch-checked-background-color);--border-color:var(--switch-checked-background-color)}[type=checkbox][role=switch]:before{display:block;width:calc(1.25em - (var(--border-width) * 2));height:100%;border-radius:50%;background-color:var(--color);content:'';transition:margin 0.1s ease-in-out}[type=checkbox][role=switch]:checked{background-image:none}[type=checkbox][role=switch]:checked:before{margin-right:0;margin-left:calc(1.125em - var(--border-width))}[type=color]::-webkit-color-swatch-wrapper{padding:0}[type=color]::-moz-focus-inner{padding:0}[type=color]::-webkit-color-swatch{border:none;border-radius:calc(var(--border-radius) / 2)}[type=color]::-moz-color-swatch{border:none;border-radius:calc(var(--border-radius) / 2)}[type=date],[type=datetime-local],[type=month],[type=time],[type=week]{background-image:var(--icon-date);background-position:center right .75rem;background-repeat:no-repeat;background-size:1rem auto}[type=date]::-webkit-calendar-picker-indicator,[type=datetime-local]::-webkit-calendar-picker-indicator,[type=month]::-webkit-calendar-picker-indicator,[type=time]::-webkit-calendar-picker-indicator,[type=week]::-webkit-calendar-picker-indicator{opacity:0}[type=time]{background-image:var(--icon-time)}[type=file]{--color:var(--muted-color);padding:calc(var(--form-element-spacing-vertical)/2) 0;border:none;border-radius:0;background:none}[type=file]::-webkit-file-upload-button{--background-color:var(--secondary);--border-color:var(--secondary);--color:var(--secondary-inverse);margin-right:calc(var(--spacing) / 2);padding:calc(var(--form-element-spacing-vertical) / 2) calc(var(--form-element-spacing-horizontal) / 2);border:var(--border-width) solid var(--border-color);border-radius:var(--border-radius);outline:none;background-color:var(--background-color);box-shadow:var(--box-shadow);color:var(--color);font-size:1rem;font-weight:var(--font-weight);line-height:var(--line-height);text-align:center;cursor:pointer;transition:background-color var(--transition),border-color var(--transition),color var(--transition),box-shadow var(--transition)}[type=file]:active,[type=file]:focus,[type=file]:hover{--color:var(--color);border:none;background:none}[type=file]:active::-webkit-file-upload-button,[type=file]:focus::-webkit-file-upload-button,[type=file]:hover::-webkit-file-upload-button{--background-color:var(--secondary-hover);--border-color:var(--secondary-hover)}[type=range]{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:block;width:100%;height:1.25rem;background:transparent}[type=range]::-webkit-slider-runnable-track{width:100%;height:0.25rem;border-radius:var(--border-radius);background-color:var(--range-border-color);transition:background-color var(--transition),box-shadow var(--transition)}[type=range]::-moz-range-track{width:100%;height:0.25rem;border-radius:var(--border-radius);background-color:var(--range-border-color);transition:background-color var(--transition),box-shadow var(--transition)}[type=range]::-ms-track{width:100%;height:0.25rem;border-radius:var(--border-radius);background-color:var(--range-border-color);transition:background-color var(--transition),box-shadow var(--transition)}[type=range]::-ms-fill-lower{background-color:var(--border-radius)}[type=range]::-webkit-slider-thumb{-webkit-appearance:none;width:1.25rem;height:1.25rem;margin-top:-0.5rem;border:2px solid var(--range-thumb-border-color);border-radius:50%;background-color:var(--range-thumb-color);cursor:pointer;transition:background-color var(--transition),transform var(--transition)}[type=range]::-moz-range-thumb{-webkit-appearance:none;width:1.25rem;height:1.25rem;margin-top:-0.5rem;border:2px solid var(--range-thumb-border-color);border-radius:50%;background-color:var(--range-thumb-color);cursor:pointer;transition:background-color var(--transition),transform var(--transition)}[type=range]::-ms-thumb{-webkit-appearance:none;width:1.25rem;height:1.25rem;margin-top:-0.5rem;border:2px solid var(--range-thumb-border-color);border-radius:50%;background-color:var(--range-thumb-color);cursor:pointer;transition:background-color var(--transition),transform var(--transition)}[type=range]:focus,[type=range]:hover{--range-border-color:var(--range-active-border-color);--range-thumb-color:var(--range-thumb-hover-color)}[type=range]:active{--range-thumb-color:var(--range-thumb-active-color)}[type=range]:active::-webkit-slider-thumb{transform:scale(1.25)}[type=range]:active::-moz-range-thumb{transform:scale(1.25)}[type=range]:active::-ms-thumb{transform:scale(1.25)}[type=search]{border-radius:5rem;padding-left:calc(var(--form-element-spacing-horizontal) + 1.75rem)!important;background-image:var(--icon-search);background-position:center left 1.125rem;background-repeat:no-repeat;background-size:1rem auto}[type=search]::-webkit-search-cancel-button{-webkit-appearance:none;display:none}table{width:100%;border-color:inherit;border-collapse:collapse;border-spacing:0;text-indent:0}td,th{padding:calc(var(--spacing) / 2) var(--spacing);border-bottom:var(--border-width) solid var(--table-border-color);color:var(--color);font-size:var(--font-size);font-weight:var(--font-weight);text-align:left}tr{background-color:var(--background-color)}table[role=grid] tbody tr:nth-child(odd){--background-color:var(--table-row-stripped-background-color)}code,kbd,pre,samp{font-family:var(--font-family);font-size:.875rem}pre{-ms-overflow-style:scrollbar;overflow:auto}code,kbd,pre{background:var(--code-background-color);color:var(--code-color);font-weight:var(--font-weight);line-height:initial}code,kbd{display:inline-block;padding:.375rem .5rem;border-radius:var(--border-radius)}pre{display:block;margin-bottom:var(--spacing);padding:var(--spacing);overflow-x:auto;background:var(--code-background-color)}pre>code{display:block;padding:0;background:transparent;font-size:14px;line-height:var(--line-height)}code b{color:var(--code-tag-color);font-weight:var(--font-weight)}code i{color:var(--code-property-color);font-style:normal}code u{color:var(--code-value-color);text-decoration:none}code em{color:var(--code-comment-color);font-style:normal}kbd{background-color:var(--code-kbd-background-color);color:var(--code-kbd-color);vertical-align:middle}hr{box-sizing:content-box;height:0;overflow:visible;border:none;border-top:1px solid var(--muted-border-color)}[hidden],template{display:none}dialog{display:block;position:absolute;right:0;left:0;width:-moz-fit-content;width:-webkit-fit-content;width:fit-content;height:-moz-fit-content;height:-webkit-fit-content;height:fit-content;margin:auto;padding:1em;border:solid;background-color:white;color:black}dialog:not([open]){display:none}canvas{display:inline-block}details{display:block;margin-bottom:var(--spacing);padding-bottom:calc(var(--spacing) / 2);border-bottom:var(--border-width) solid var(--accordion-border-color)}details summary{color:var(--accordion-close-summary-color);line-height:1rem;list-style-type:none;list-style-type:none;cursor:pointer;transition:color var(--transition)}details summary::-webkit-details-marker{display:none}details summary::marker{display:none}details summary::-moz-list-bullet{list-style-type:none}details summary:after{display:inline-block;width:1rem;height:1rem;float:right;transform:rotate(-90deg);background-image:var(--icon-chevron);background-position:center;background-repeat:no-repeat;background-size:1rem auto;content:'';transition:transform var(--transition)}details summary:focus{outline:none;color:var(--accordion-active-summary-color)}details summary~*{margin-top:calc(var(--spacing) / 2)}details summary~*~*{margin-top:0}details[open]>summary{margin-bottom:calc(var(--spacing) / 4)}details[open]>summary:not(:focus){color:var(--accordion-open-summary-color)}details[open]>summary:after{transform:rotate(0)}article{margin:var(--block-spacing-vertical) 0;padding:var(--block-spacing-vertical) var(--block-spacing-horizontal);overflow:hidden;border-radius:var(--border-radius);background:var(--card-background-color);box-shadow:var(--card-box-shadow)}article>footer,article>header,article>pre{margin-right:calc(var(--block-spacing-horizontal) * -1);margin-left:calc(var(--block-spacing-horizontal) * -1);padding:calc(var(--block-spacing-vertical) / 1.5) var(--block-spacing-horizontal);background-color:var(--card-sectionning-background-color)}article>header{margin-top:calc(var(--block-spacing-vertical) * -1);margin-bottom:var(--block-spacing-vertical);border-bottom:var(--border-width) solid var(--card-border-color)}article>footer,article>pre{margin-top:var(--block-spacing-vertical);margin-bottom:calc(var(--block-spacing-vertical) * -1);border-top:var(--border-width) solid var(--card-border-color)}nav,nav ul{display:flex}nav{justify-content:space-between}nav ol,nav ul{align-items:center;margin-bottom:0;padding:0;list-style:none}nav ol:first-of-type,nav ul:first-of-type{margin-left:calc(var(--spacing) * -0.5)}nav ol:last-of-type,nav ul:last-of-type{margin-right:calc(var(--spacing) * -0.5)}nav li{display:inline-block;margin:0;padding:var(--spacing) calc(var(--spacing) / 2)}nav li>*,nav li>input:not([type=checkbox]):not([type=radio]){margin-bottom:0}nav a{display:block;margin:calc(var(--spacing) * -1) calc(var(--spacing) * -0.5);padding:var(--spacing) calc(var(--spacing) / 2);border-radius:var(--border-radius);text-decoration:none}nav a:active,nav a:focus,nav a:hover{text-decoration:none}aside li,aside nav,aside ol,aside ul{display:block}aside li{padding:calc(var(--spacing) / 2)}aside li a{margin:calc(var(--spacing) * -0.5);padding:calc(var(--spacing) / 2)}progress{display:inline-block;vertical-align:baseline}progress{-webkit-appearance:none;-moz-appearance:none;appearance:none;display:inline-block;width:100%;height:.5rem;margin-bottom:calc(var(--spacing) / 2);overflow:hidden;border:0;border-radius:var(--border-radius);background-color:var(--progress-background-color);color:var(--progress-color)}progress::-webkit-progress-bar{border-radius:var(--border-radius);background:transparent}progress[value]::-webkit-progress-value{background-color:var(--progress-color)}progress::-moz-progress-bar{background-color:var(--progress-color)}@media (prefers-reduced-motion:no-preference){progress:indeterminate{background:var(--progress-background-color) linear-gradient(to right,var(--progress-color) 30%,var(--progress-background-color) 30%) top left/150% 150% no-repeat;animation:progressIndeterminate 1s linear infinite}progress:indeterminate[value]::-webkit-progress-value{background-color:transparent}progress:indeterminate::-moz-progress-bar{background-color:transparent}}@keyframes progressIndeterminate{0%{background-position:200% 0}to{background-position:-200% 0}}[aria-busy=true]{cursor:progress}[aria-busy=true]:not(input):not(select):not(textarea):before{display:inline-block;width:1em;height:1em;border:0.1875em solid currentColor;border-radius:1em;border-right-color:transparent;vertical-align:text-bottom;vertical-align:-.125em;animation:spinner 0.75s linear infinite;content:'';opacity:var(--loading-spinner-opacity)}[aria-busy=true]:not(input):not(select):not(textarea):not(:empty):before{margin-right:calc(var(--spacing) / 2)}[aria-busy=true]:not(input):not(select):not(textarea):empty{text-align:center}a[aria-busy=true],button[aria-busy=true],input[type=button][aria-busy=true],input[type=reset][aria-busy=true],input[type=submit][aria-busy=true]{pointer-events:none}@keyframes spinner{to{transform:rotate(360deg)}}[data-tooltip]{position:relative}[data-tooltip]:not(a):not(button):not(input){border-bottom:1px dotted;text-decoration:none;cursor:help}[data-tooltip]:after,[data-tooltip]:before{display:block;z-index:99;position:absolute;bottom:100%;left:50%;padding:.25rem .5rem;overflow:hidden;transform:translate(-50%,-0.25rem);border-radius:var(--border-radius);background:var(--tooltip-background-color);color:var(--tooltip-color);font-size:.875rem;font-style:normal;font-weight:var(--font-weight);text-decoration:none;text-overflow:ellipsis;white-space:nowrap;content:attr(data-tooltip);opacity:0;pointer-events:none}[data-tooltip]:after{padding:0;transform:translate(-50%,0rem);border-top:.3rem solid;border-right:.3rem solid transparent;border-left:.3rem solid transparent;border-radius:0;background-color:transparent;color:var(--tooltip-background-color);content:''}[data-tooltip]:focus:after,[data-tooltip]:focus:before,[data-tooltip]:hover:after,[data-tooltip]:hover:before{opacity:1;animation-name:slide;animation-duration:.2s}[data-tooltip]:focus:after,[data-tooltip]:hover:after{animation-name:slideCaret}@keyframes slide{0%{transform:translate(-50%,0.75rem);opacity:0}to{transform:translate(-50%,-0.25rem);opacity:1}}@keyframes slideCaret{0%{opacity:0}50%{transform:translate(-50%,-0.25rem);opacity:0}to{transform:translate(-50%,0rem);opacity:1}}[aria-controls]{cursor:pointer}[aria-disabled=true],[disabled]{cursor:not-allowed}[aria-hidden=false][hidden]{display:initial}[aria-hidden=false][hidden]:not(:focus){clip:rect(0,0,0,0);position:absolute}[tabindex],a,area,button,input,label,select,summary,textarea{-ms-touch-action:manipulation}@media (prefers-reduced-motion:reduce){:not([aria-busy=true]),:not([aria-busy=true]):after,:not([aria-busy=true]):before{background-attachment:initial!important;animation-duration:1ms!important;animation-delay:-1ms!important;animation-iteration-count:1!important;scroll-behavior:auto!important;transition-delay:0s!important;transition-duration:0s!important}}
    </style>
    <style type="text/css">
      article div {
        font-size: 1.15em;
        line-height: 1.6em;
      }
    </style>
  </head>
  <body style="background-color: #f9fafb;">
    <main class="container">
      <nav>
        <ul>
          <li><a href="../index.html">← Topic list</a></li>
        </ul>
      </nav>
      <!-- <h1>Infomedia Articles Selection: 50 articles</h1> -->
      <h1>Images, video &amp; 3D <kbd>L80_IMGVID</kbd></h1>
      <h3>Words (top 25)</h3>
      <div style="margin:0px -12px">
        <span style="font-size:35.25pt; padding:0px 12px"><strong>billeder</strong>&nbsp;<span style="font-size:.5em">5881</span></span>
        <span style="font-size:26.33pt; padding:0px 12px"><strong>sørensen</strong>&nbsp;<span style="font-size:.5em">2350</span></span>
        <span style="font-size:25.80pt; padding:0px 12px"><strong>billede</strong>&nbsp;<span style="font-size:.5em">2189</span></span>
        <span style="font-size:23.67pt; padding:0px 12px"><strong>netværk</strong>&nbsp;<span style="font-size:.5em">1606</span></span>
        <span style="font-size:23.21pt; padding:0px 12px"><strong>billedet</strong>&nbsp;<span style="font-size:.5em">1490</span></span>
        <span style="font-size:23.00pt; padding:0px 12px"><strong>video</strong>&nbsp;<span style="font-size:.5em">1439</span></span>
        <span style="font-size:22.94pt; padding:0px 12px"><strong>3d</strong>&nbsp;<span style="font-size:.5em">1427</span></span>
        <span style="font-size:19.41pt; padding:0px 12px"><strong>videoer</strong>&nbsp;<span style="font-size:.5em">707</span></span>
        <span style="font-size:19.40pt; padding:0px 12px"><strong>forskellige</strong>&nbsp;<span style="font-size:.5em">705</span></span>
        <span style="font-size:18.20pt; padding:0px 12px"><strong>instagram</strong>&nbsp;<span style="font-size:.5em">518</span></span>
        <span style="font-size:17.83pt; padding:0px 12px"><strong>muligt</strong>&nbsp;<span style="font-size:.5em">467</span></span>
        <span style="font-size:17.27pt; padding:0px 12px"><strong>000</strong>&nbsp;<span style="font-size:.5em">393</span></span>
        <span style="font-size:17.25pt; padding:0px 12px"><strong>bruger</strong>&nbsp;<span style="font-size:.5em">391</span></span>
        <span style="font-size:16.70pt; padding:0px 12px"><strong>form</strong>&nbsp;<span style="font-size:.5em">325</span></span>
        <span style="font-size:16.65pt; padding:0px 12px"><strong>foto</strong>&nbsp;<span style="font-size:.5em">319</span></span>
        <span style="font-size:16.48pt; padding:0px 12px"><strong>taget</strong>&nbsp;<span style="font-size:.5em">300</span></span>
        <span style="font-size:16.40pt; padding:0px 12px"><strong>lægge</strong>&nbsp;<span style="font-size:.5em">291</span></span>
        <span style="font-size:16.12pt; padding:0px 12px"><strong>brug</strong>&nbsp;<span style="font-size:.5em">262</span></span>
        <span style="font-size:15.87pt; padding:0px 12px"><strong>bruge</strong>&nbsp;<span style="font-size:.5em">237</span></span>
        <span style="font-size:15.71pt; padding:0px 12px"><strong>små</strong>&nbsp;<span style="font-size:.5em">222</span></span>
        <span style="font-size:15.67pt; padding:0px 12px"><strong>hvert</strong>&nbsp;<span style="font-size:.5em">218</span></span>
        <span style="font-size:15.63pt; padding:0px 12px"><strong>både</strong>&nbsp;<span style="font-size:.5em">214</span></span>
        <span style="font-size:15.62pt; padding:0px 12px"><strong>viser</strong>&nbsp;<span style="font-size:.5em">214</span></span>
        <span style="font-size:15.52pt; padding:0px 12px"><strong>fået</strong>&nbsp;<span style="font-size:.5em">204</span></span>
        <span style="font-size:15.31pt; padding:0px 12px"><strong>giver</strong>&nbsp;<span style="font-size:.5em">186</span></span>
      </div>
      <br><br>
      <h3>Articles (top 50)</h3>
      Query:
      <pre>SELECT * FROM articles WHERE articles.dupeKeep=1 AND articles.sizeKeep=1 ORDER BY L80_IMGVID DESC LIMIT 50</pre>
      <article>
        <h4>PROFESSIONEL 3D-PROJEKTOR</h4>
        <div>
          PROFESSIONEL 3D-PROJEKTOR Sony Professional har lanceret en 3D-projektor, VPL-VW95ES, med skarpe, klare og levende billeder, som egner sig særligt til at vise film. Den har en billedkvalitet med dynamisk kontrast ( 150.000: 1) og et nyt 3D-mode, som er baseret på en algoritme til at vise 3Deffekter fra enhver 2D-kilde. Hukommelsen af billedindstillingen bevarer aspect ratio, så brugerne får en oplevelse som på et biograflærred. Herudover er Sonys 3D-briller blevet opgraderet og blevet væsentligt lettere, ligesom senderen er blevet placeret omkring linsen.Tlf. 43 55 70 00 www.sony.dk.
        </div>
        <footer>
          <em>Ingeniøren</em>
          &nbsp;·&nbsp; 2011-12-02
          &nbsp;·&nbsp; e2fe27c7
          &nbsp;·&nbsp; #0
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.848</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.808</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.644</kbd>
        </footer>
      </article>
      <article>
        <h4>Computer kan påvise rygerlunger</h4>
        <div>
          Dansk forsker har udviklet program, der kan konkurrere med lægens vurdering af rygerlunger.10.000 lunger scannet i 3D. Sådan et stort materiale er en sjælden gave for en datalog.Lauge Sørensen, postdoc ved Datalogisk Institut, Københavns Universitet, greb muligheden og genbrugte et materiale, der oprindelig var indsamlet for at undersøge, om screening kan redde flere mennesker fra lungekræft, til at træne en computer i at diagnosticere rygerlunger, også kaldet KOL.De 10.000 3D-billeder af lunger er såkaldte CT-scanninger og viser både sygt og rask væv.Computeren registrerer ændringerComputeralgoritmen har lært at kende forskel på strukturer i lungevævet, så et program bagefter kan tegne et kort over lungen, der viser, hvor der er sygt lungevæv.»Algoritmen kan registrere meget små ændringer i strukturen i lungevævet og angive sandsynligheden for sygdom i vævet tidligt i sygdommen,« forklarer Lauge Sørensen.LÆS OGSÅ PÅ VIDENSKAB.DK: 3D-printer skal bygge et hjerteComputeren betyder højt tempoTeknologiske fremskridt betyder, at datamængden i sundhedsindustrien vokser. Derfor mener Lauge Sørensen, det er oplagt at tage computeren i brug til analyse af materiale.»10.000 scanninger ville man aldrig sætte en læge til at aflæse, men det kan computeren gøre fuldautomatisk, og hvis man har adgang til en supercomputer, kan det gøres i et højt tempo,« forklarer han.Algoritmen skærer en kube ud af 3D-billedet af hele lungen og analyserer strukturen i dette stykke. Analyseresultaterne fra en række kuber bruges til at udregne, i hvor høj grad lungerne er beskadigede.Algoritmen oplyser et tal, der afspejler sandsynligheden for, at lungerne er syge. Et program tegner derefter et sandsynlighedskort over lungerne.De strukturændringer, der viser sig tidligt ved lungesygdomme, er ikke nemme at få øje på med det blotte øje, men kan potentielt registreres af computeren. Derfor har algoritmen potentiale til at konkurrere med lægens vurdering af graden af sygdom, mener Lauge Sørensen.Tredimensionel afbildning af lungerne. De blå felter viser tilfældigt udvalgte kuber, som computeren bruger til analyse af lungerne. Illustration: Lauge Sørensen/Videnskab.dk. 
        </div>
        <footer>
          <em>Jp.dk (Jyllands-Posten)</em>
          &nbsp;·&nbsp; 2011-04-12
          &nbsp;·&nbsp; e2a098b2
          &nbsp;·&nbsp; #1
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.973</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.792</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.673</kbd>
        </footer>
      </article>
      <article>
        <h4>Videokurser i foråret</h4>
        <div>
          Lær at producere din egen video på din mobiltelefon -bliv din egen mobilvideofotograf og bliv synlig på de sociale medier.Både mennesker og algoritmer foretrækker levende billeder, når de skal forstå noget eller få tillid til et budskab, et produkt eller en virksomhed. Video bringer afsender og modtagere tættere på hinanden - online - og video får flere visninger og delinger på SoMe end tekst og foto.I foråret afholder vi flere videokurser for både nybegyndere og øvede - læs mere og tilmeld dig på www.odsforum.dk/ arrangementer.
        </div>
        <footer>
          <em>Ugeavisen Odsherred</em>
          &nbsp;·&nbsp; 2021-01-13
          &nbsp;·&nbsp; e811dbf4
          &nbsp;·&nbsp; #2
          <br>
          <br>
            <kbd data-tooltip="Tech industry &amp; regulation">L02_BIGTEC&nbsp;0.668</kbd>
            <kbd data-tooltip="Facebook, fake news &amp; Trump">L05_FBTRUM&nbsp;0.77</kbd>
            <kbd data-tooltip="Social media &amp; well being">L10_SOMEWB&nbsp;0.552</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.539</kbd>
        </footer>
      </article>
      <article>
        <h4>Find billeder, som går godt sammen</h4>
        <div>
          Picky Album (iOS/ Android, gratis) En af de klare fordele ved vores moderne telefoner er det indbyggede kamera. Men samtidig har vi fået problemet overflod.Vi har typisk alt for mange billeder liggende, og selvom vi af og til gør os umage for manuelt at finde et til Facebook eller til at sende til mormor, er det at kigge sine billeder igennem ofte pinefuldt og fuld af gentagelser.Picky Album er en smart app, som går ind og benytter sig af nogle algoritmer som, angiveligt, skulle resultere i æstetisk, velsammenhængende billedkollektioner pr. &quot; pick&quot;, lige til at videreformidle over mail, socialt eller tilbage på rullen som et miniaturenedslag i din visuelle verden.Det er faktisk ganske sjovt at se, hvad den finder frem, når du sætter den til at vælge ud fra over 100 billeder.Resultatet kan gemmes i enten 1x1, 2x2, 3x3 eller 4x4, og du kan flytte rundt på placeringen af hvert enkelt valgte billede, før du gemmer samlingen.Og er der taget flere billeder i samme tidsrum med et lignende motiv, figurerer disse også ved hvert billede i trådnettet, så du selv kan suboptimere robottens hårde arbejde, ligesom en række indbyggede filtre kan lægge en sidste hånd på farvekorrektion og lignende, før dine ni bedste billeder fra Spanien rammer Facebook.
        </div>
        <footer>
          <em>Fyens Stiftstidende</em>
          &nbsp;·&nbsp; 2016-12-23
          &nbsp;·&nbsp; e60a3072
          &nbsp;·&nbsp; #3
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.857</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.879</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.65</kbd>
        </footer>
      </article>
      <article>
        <h4>Her er resultatet, når neurale netværk får frit spil på fotos</h4>
        <div>
          Et billede af en ridder, udsat for 'dyregenkendelse' i et neuralt netværk. Netværket er blevet bedt om at finde dyr i billedet, hvorefter de elementer, netværket har fundet, er blevet forstærket. Derefter er processen kørt igen og igen. (Foto: Google)Neurale netværk, der er trænet til at se på billeder, kan faktisk også skabe billeder. Det viser et interessant   nogle vil måske sige foruroligende   eksperiment fra Googles forskningsafdeling.Af 11. jul 2015 kl. 14:00Internetgiganten Google bruger neurale netværk til billedgenkendelse, bl.a. i sin nye fototjeneste Google Photos. Men hvor imponerende det end kan være, at disse netværk kan 'se' på en mængde billeder og finde dem med en 'hund' eller en 'banan', så står det faktisk ikke helt klart for forskerne, hvordan det foregår.Derfor har softwareingeniører hos Google prøvet at vende processen på hovedet: I stedet for f.eks. at vise netværket millioner af billeder af bananer, indtil det er i stand til at genkende én, så har de taget et gråmeleret billede bestående af tilfældig støj og bedt netværket om at se efter bananer.Når netværket mente at have set noget, der lignede en banan, forstærkede forskerne det fundne en lille smule og sendte så det nye billede ind i netværket igen   og så videre, og så videre, indtil der opstod billeder, der begyndte at ligne noget:Eksempler på, hvad Googles neurale netværk kan få ud af et billede med grå støj, hvis det bliver bedt om at se efter forskellige genstande som f.eks. søstjerner, skruer eller koantiloper (hartebeest). (Foto: Google)Som forskerne skriver i deres blogindlæg om forsøget , er det lærerigt at vende processen på hovedet, fordi det kan afsløre, om netværket nu også fokuserer på de rigtige karakteristika, når det kigger efter en banan, en søstjerne eller en skrue.Frie fortolkningerNeurale netværk består af flere 'lag', der i forbindelse med billedgenkendelse ser efter stadigt mere komplicerede elementer. Hvis man beder et af de lavere lag om at 'gå i selvsving' på billeder, der rent faktisk forestiller noget, vil de producere fortolkninger, der typisk indeholder forstærkede linjer eller ornamenteringer af forlægget.Til venstre et originalfoto af Zachi Evenor, til højre behandlet i Googles neurale netværk af softwareingeniør Günther Noack. (Foto: Google)Er det i stedet et af de højere lag i netværket, der bearbejder et billede, kan der opstå mere komplekse elementer eller objekter. Som Google-ingeniørerne forklarer i blogindlægget beder de igen bare netværket om 'mere af det samme': 'Hvis en sky har en smule lighed med en fugl, vil netværket få den til at ligne en fugl endnu mere. Det vil få netværket til at genkende fuglen endnu nemmere næste gang, indtil et meget detaljeret billede af en fugl kommer frem   tilsyneladende ud af ingenting.' Som i eksemplet herunder:Fugle opstået ud af 'ingenting' i et foto af en blå himmel med skyer. (Foto: Google)Forskerne mener, at teknikken kan give en kvalitativ forståelse af det abstraktionsniveau, et givet lag i et neuralt netværk har udviklet i sin forståelse af billeder. De kalder teknikken 'inceptionism' og har samlet et helt galleri over eksempler på, hvilke billeder, der kan hentes ud af et neuralt netværk. Som f.eks. denne gruppe af billeder, der alle er skabt ved at lade et neuralt netværk oplært af MIT Computer Science and AI Laboratory til at genkende steder tygge på grå billeder af tilfældig støj, rigtig mange gange:Fantasier over bygninger   skabt ud fra grå støj af et neuralt netværk. (Foto: Google)Efter det første blogindlæg om deres eksperimenter har forskerne nu valgt at lægge deres kode ud open source, så andre kan forsøge at eftergøre dem kunsten   og de opfordrer folk, der gør det, til at tagge deres billeder #deepdream.
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2015-07-11
          &nbsp;·&nbsp; e51ee60c
          &nbsp;·&nbsp; #4
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.907</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.727</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.648</kbd>
        </footer>
      </article>
      <article>
        <h4>Googles jpg-dræber: WebP viser billedet før det er hentet</h4>
        <div>
          Se billederne: Google vil skubbe det traditionelle billedformat JPEG ud i grøften med open source-billedformat WebP, som giver brugeren mulighed for at se billedet, før det er fuldt downloadet.Af Anne Lykke ukomprimeret foto i PNG-formatGoogle forsøger nu at mane det traditionelle billedformat JPEG i jorden med det nye billedformat WebP. WebP giver lossy komprimering af fotografier, men fylder 39,8 procent mindre end Jpeg-billeder af samme kvalitet.Læs også: Google vil slanke billed-formater: Klar med afløser for JPEGDerudover gør en helt ny feature, at WebP-billeder trinvist kan dekodes, mens computeren downloader billedet fra websiden, hvilket gør browseren i stand til at vise billedet, før hele filen faktisk er downloaded. Denne feature virker allerede i Chrome 12. Det skriver Googles produktchef Richard Rabbat og softwareudvikler Pascal Massimino på Chromium blog.Yderligere har WebP også fået integreret en 'fancy upsampler', som reducerer pixeleringen af stærke kanter. Som det ses på billedet af klodserne, er kanterne i billedet med 'fancy upsampling' mindre pixelerede end uden 'fancy upsampling', hvor der forekommer trappeagtige konturer.På kodnings-siden har Google fokuseret på at forbedre kvaliteten ved at indføre et filter, der kan inddele billedet i ens områder, som komprimeres på samme måde. Mens nogle dele af billedet let kan komprimeres meget, uden at det går ud over kvaliteten, vil andre områder kræve flere bits. Disse kaldes svære områder, som man kan se på det sidste billede.Derved kan WebP bevare mange af detaljerne fra det oprindelige billede i modsætning til Jpeg, hvor der kan forekomme såkaldte omringende elementer i billedet. Disse omringende elementer kan være forstyrrende farver eller prikker, der danner en ring om billedet ved for dårlig komprimering.WebP er bklandt andet sat sammen af algoritmerne bag videoformatet VP8, som Google har gjort gratis at bruge under navnet WebM.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2011-05-23
          &nbsp;·&nbsp; e2b18abf
          &nbsp;·&nbsp; #5
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.809</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.796</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.685</kbd>
        </footer>
      </article>
      <article>
        <h4>AI kan reparere og gøre slørede billeder skarpe</h4>
        <div>
          Uden at benytte andre billeder som inspiration, kan helisk neuralt netværk gøre billeder bedre.Et dybt helisk neuralt netværk kan gøre uskarpe billeder blive skarpe, ved kun at bruge information fra selve billedet. Effekten er dog mindre synlig her på grund af Version2's CMS-system. Photo: Dmitry UlyanovDet er fup og fidus, men det virker: Kunstig intelligens kan genskabe billedinformation, så resultatet til forveksling ligner originalen.Teknologien har været fremme i et stykke tid, men nu har tre russiske forskere skabt en algoritme, der siger spar to til tidligere forsøg. Det er de såkaldte 'dybe heliske neurale netværk'(deep convolutional neural networks, CNN) som er velegnede til opgaver af denne type. Det skriver Bleeping Computer.Deep Image Prior, som algoritmen er navngivet, adskiller sig fra andre tilsvarende algoritmer, ved at benytte billedets egen information til reparationsopgaverne, i stedet for at bygge på et træningssæt med andre billeder til udbedring af fejl og mangler.Det kan blandt andet benyttes til at gøre slørede billeder skarpe, til at fjerne støj af forskellig art og til føje manglende dele af et billede.Algoritmen EnhanceNet-PAT kan skabe et billede (nr. 3 fra venstre) ud fra en sløret original (nr. 1), så det til forveksling ligner originalen (th). Photo: Mehdi S. M. SajjadiKoden bag er skrevet i Python og kan hentes hos Github.Deep Image Prior er ikke den eneste nye algoritme, der kan genskabe informationer i billeder, så det næppe er til at se. En anden ny algoritme, EnhanceNet-PAT, benytter i modsætning til Deep Image Prior et testsæt til at gætte på den manglende information. Teknologien kan blandt andet anvendes til at skabe billeder med højere opløsning end originalen.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2018-01-03
          &nbsp;·&nbsp; e6904d2d
          &nbsp;·&nbsp; #6
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.987</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.986</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.61</kbd>
        </footer>
      </article>
      <article>
        <h4>Techtopia #76: Sådan kommer danske virksomheder i gang med 3D-print i produktion</h4>
        <div>
          Techtopia er vært på en paneldebat på AM Summit, hvis formål er, at hjælpe små og mellemstore virksomheder i gang med 3D-print og additive manufacturing.Hør ledende 3D-print-pionerer som Stratasys/Makerbot og Autodesk fortælle om at uddanne virksomheder i England til at omstille deres produktion.Mød 3D Hubs, der gør det muligt at 3D printe helt uden at have en printer. Man kan ved hjælp af maskinlæring designe og bestille sit produkt på firmaets webside og få det tilsendt.3D-print kan måske ligefrem redde verden, fordi teknologien gør det muligt at bruge færre materialer, at genbruge materialer og produkter og at producere lokalt, så man sparer transporten.Og så kan du høre Simon Spiess spille saxofon med et 3D-printet mundstykke.Medvirkende:Märtha Rehnberg Co-founder &amp; Partner, DareDisruptAndy Middleton President EMEA, Stratasys &amp; MakerbotMads Kjøller Damkjær CEO, Dansk AM HubBrian Garret Co-founder &amp; CPO, 3D HubsAsif Moghal Senior Manufacturing Industry Manager, AutodeskLinks:AM SummitAM HubStratasys and MakerbotAutodesk3D HubsMärtha RehnbergNæste episode af Techtopia kommer mandag den 5. novemberDu kan finde alle episoder af Techtopia og Ingeniørens øvrige podcasts HER.Hør også: Techtopia #75: Forstå kunstig intelligens på 29 minutter
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2018-10-29
          &nbsp;·&nbsp; e6f40312
          &nbsp;·&nbsp; #7
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.87</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.579</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.527</kbd>
        </footer>
      </article>
      <article>
        <h4>Microsofts panoramatjeneste kan nu importere videostilbilleder</h4>
        <div>
          Microsofts gratis software Image Composite Editor understøtter nu importering af videoer til panoramabilleder. Af Christian LoiborgImage Composite Editor (ICE) understøtter nu import af videoer til kreering af de populære panoramabilleder, som ICE er særligt kendt for. Den gratis software fra Microsoft Research er tilgængelig i dag.Med ICE kan man nemt lave gigapixelbilleder, ved at samle en række billeder. Det betyder, at du kan få imponerende panoramabilleder med helt utrolige detaljer. Panoramabillederne, du skaber, kan bl.a. ses i 3D, når man bruger fototjenesten Photosynth.Når du laver panoramaer fra flere billeder, kan du komme ud for, at noget af baggrunden mangler på grund af forskellige kameravinkler. Ved hjælp af en algoritme udfylder programmet selv den manglende del af billedet, på samme måde som Adobe Photoshops content aware fill fungerer på.Med ICE 2 kan man nu importere videoer og bruge stilbillederne til at lave panoramaer. I videoen kan du vælge, hvilke elementer, der skal bruges i det endelige billede - eksempelvis en person, der er i bevægelse, så de fremkommer flere gange. Du kan se, hvordan det helt præcist foregår i videoen herunder.Du kan hente ICE 2 gratis hos Microsoft Research
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2015-02-09
          &nbsp;·&nbsp; e4cfeb1f
          &nbsp;·&nbsp; #8
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.686</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.808</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.68</kbd>
        </footer>
      </article>
      <article>
        <h4>Blogindlæg: De kære studerende har ætset os i silicium</h4>
        <div>
          Ok. Jeg har arbejdet med elektronstrålelitografi i omkring 27 år, og synes sørme stadig at det er fascinerende at man kan tegne nanostrukturer med opløsning ned til 10 nm ved at skyde på et stykke plastik med elektroner. Jeg underviser sammen med min gamle våbenbror Anders Kristensen i nanolitografi. Og tænk, blandt de mange mønstre som de studerende havde designet under kynding hjælp fra postdoc Lene Gammelgaard dukkede nogle designs op vi ikke helt havde regnet med at se.Mønstret er tegnet med en 4 nm bred elektronstråle på PMMA (polymethyl methacrylat, også kaldet plexiglas), der efter fremkaldelse i et organisk opløsningsmiddel har fine huller ned til silicium skiven, der hvor PMMA'en blev bestrålet. Efter en kort æts af siliciumskiven, træder mønstrene tydeligt frem.En af de studerende, Tobias Willemoes Jensen, havde skrevet en algoritme der konverterede gråtoner til en tilfældigt antal prikker med en tæthed proportional med hver pixels gråtone, og resultatet af dette eksperimentelle &quot;nanoæts&quot; (en traditionel litografisk metode) er portrætter med samme bredde som et hår, nemlig ca. 50 µm - her er det så os tre læreres fjæs man kan beundre. Billedet er taget med et scanning elektron mikroskop (SEM). Vi spekulerede også på om man ville kunne lave et mønster som gav forskellige billeder alt efter om det er secondary eller backscatter detektoren man bruger til at tage billedet med(*). Og selvfølgeligt hvor lille man ville kunne lave portrættet hvis man virkelig prøver!
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2020-01-20
          &nbsp;·&nbsp; e78bd6fa
          &nbsp;·&nbsp; #9
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.976</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.651</kbd>
        </footer>
      </article>
      <article>
        <h4>Digitalt: Ryd op i dine fotos med kunstig intelligens</h4>
        <div>
          Du behøver ikke stresse over alle de billeder, der fylder lageret op på din smartphone eller computer. Ny teknologi kan hjælpe dig med at få dem sorteret og arkiveret.Vi tager billeder som aldrig før. Analysefirmaet InfoTrends vurderer, at der i 2017 blev taget 1.200 milliarder digitale billeder, eller cirka 160 billeder for hver af klodens 7,5 mia. Indbyggere. Tænk lige over det. Denne statistik viser, at vi mennesker, fra den fattigste tigger til den rigeste milliardær, fra det nyfødte spædbarn til den ældste beboer på plejehjemmet, i gennemsnit tager et billede cirka hver anden dag.Sådan er virkeligheden naturligvis ikke. Verdens digitale fotos er langt mere ulige fordelt. Det ved du naturligvis allerede, for når du kigger på din smartphone eller på din harddisk, ligger der så mange billeder, at du har svært ved at overskue, hvordan du skal få dem organiseret og sat i orden.Heldigvis findes der nu smarte værktøjer, der blandt andet via kunstig intelligens kan hjælpe dig med lige præcis den opgave - og på den platform, du foretrækker.Det er naturligvis kameraerne i vores lommer, der har sat ild i den digitale billedeksplosion, og for mange mennesker kommer billederne aldrig videre. Hvis de skal vises til andre, kommer telefonen bare op fra lommen. Hvis du helst vil bruge smartphonen - og kun smartphonen - som fotoplatform, kan du overveje disse gratis apps.Zyl. Appen bruger metadata som tidspunkt og geografisk lokation for fotografiet til at anbefale, hvordan du kan organisere billederne i mapper, der f.eks. kan deles med venner. Men du kan også lade være, og det gør Zyl til et godt bud på en app til at rydde op i dine billeder, hvis du ikke har lyst til at lægge dine billeder op i skyen eller på sociale medier af privatlivshensyn.Ever. Hvis du derimod ikke er helt så bekymret for at lægge dine billeder i skyen, kan du overveje Ever. Denne app organiserer ikke bare smartphone-fotos, men også billeder fra sociale medier som Facebook og Instagram. Det betyder, at du også kan få billeder, andre har taget af dig, ind i samlingen. Ever er gratis at bruge, hvis du kan nøjes med komprimerede billeder, men fuld opløsning kræver betalingsversionen af appen.Slidebox. Måske har du helt styr på dine fotomapper selv og har bare behov for et værktøj, der hjælpe dig med hurtigt at slette eller arkivere billederne på din telefon? Så skal du have fat i Slidebox. Med denne app kan du stryge til venstre eller til højre, afhængig af om du vil gemme eller slette billedet, og du kan lynhurtigt placere de gemte billeder i de mapper, du har lavet.Billeder på computerenDigitale billeder kommer dog ikke altid fra din smartphone. De kan komme fra et rigtigt digitalkamera eller på en e-mail fra et familiemedlem. Derfor kan en computer ofte være et bedre sted at organisere sine billeder. Den større skærm afslører flere fejl, og der er også mere harddiskplads at gemme billederne på.Windows Photos. I efteråret opdaterede Microsoft sin Billeder-app til Windows 10, så du nu kan fritekstsøge efter indhold i fotos. Hvis du for eksempel skriver -øl- eller -Skagen-, dukker der billeder op fra det nordjyske, eller fotos med øl ombord. Den kunstige intelligens hjælper dig også med at lave fotoalbums eller videoer på en nem måde og kan sortere dine billeder efter de personer, der er på dem.Apple Photos. Ligesom på Windows-pc-er er der nu også kunstig intelligens og søgning indbygget i den medfølgende Fotos-app på Mac, der hjælper dig med at sortere billeder i kategorier som -mine minder- og -personer-. Men Fotos har også relativt avanceret billedredigering modsat mange af konkurrenterne.Adobe Photoshop Elements. Denne let skrabede version af det professionelle Photoshop-program har ud over avancerede redigeringsfunktioner også objekt-genkendelse via kunstig intelligens indbygget. Det betyder, at programmet kan lave såkaldte -smart tags-, der er beskrivelser af, hvad der er på billedet, som du så kan søge på og sortere efter senere.I skyenMange sky-lagertjenester såsom Dropbox understøtter nu automatisk upload af billeder, når du har taget dem på smartphonen. Oftest kan du dog bare bruge de sky-tjenester, der følger med, når du køber noget ny teknologi, som f.eks. disse:Google Photos. Googles fototjeneste følger naturligvis med Android-telefoner, men kan også bruges på f.eks. iPhone. Google har en af de meste avancerede fotogenkendelsesteknologier i skyen, der helt automatisk kan forbedre dine billeder, lave albums og animationer, hvis du ikke har lyst til at bruge tid på det og ikke er nervøs over, at Googles servere kigger i dine billeder.iCloud Photo Stream. Hvis du slår iCloud Photo Stream til under indstillinger på din iPhone eller iPad, bliver dine billeder automatisk lagt op på det iCloud-lager i skyen, der fulgte med dit Apple-produkt.Herfra kan du sortere på samme måde som i Fotos-appen på Mac.Microsoft OneDrive. Har du en Windows-pc eller en Surface-tablet, medfølger der også et OneDrive-lager i skyen, som du kan uploade dine billeder til. Også her kan du få hjælp fra en kunstig intelligens til at sortere dine billeder, og du kan søge i dem og få adgang til dem hvor som helst. Hvis du downloader OneDrive-appen til iOS eller Android, kan du også uploade nye smartphone-billeder automatisk.
        </div>
        <footer>
          <em>Politiken.dk</em>
          &nbsp;·&nbsp; 2018-02-18
          &nbsp;·&nbsp; e69fdd5f
          &nbsp;·&nbsp; #10
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.681</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.75</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.624</kbd>
        </footer>
      </article>
      <article>
        <h4>Kunstig fotointelligens holder orden på billederne</h4>
        <div>
          Har du mistet overblikket over dine tusinder af billeder strøet over mobil, computer og ekstern harddisk, så kan Google Photos give dig kontrollen tilbage.Jeg har 35.363 billeder liggende på min eksterne harddisk. Jeg elsker at tage billeder og skyder ukritisk løs bevæbnet med smartphone og spejlreflekskamera, men jeg hamstrer også og er elendig til at luge ud og organisere og har mistet overblikket til en grad, hvor de fleste fotos samler digitalt støv for aldrig at blive åbnet igen.Jeg elsker ellers at bladre gennem gamle minder og synke ned i morfar-agtig nostalgi, men selv om jeg har prøvet alt lige fra iPhoto til Flickr, Dropbox og Picasa, har jeg endnu ikke fundet en løsning, hvor jeg nemt og hurtigt kan bladre gennem minderne. Men for et par måneder siden lancerede Google deres nye fotoprogram, der slet og ret hedder Google Photos, og som er vokset ud af Googles fejlslåede sociale netværk, Google+. Og tjensten har nogle fede tricks oppe i ærmet.En af de største fordele ved at bruge Google Photos er, at man får ubegrænset lagerplads   i hvert fald så længe man uploader billederne i komprimeret kvalitet (højst 16 MB pr. foto og video kun i 1.080p). For langt de fleste er det dog rigeligt, og kvaliteten er god nok til, at jeg kan blæse dem op på en 23-tommers monitor, uden at de bliver grynede, men insisterer man på at uploade billederne i fuld størrelse, må man nøjes med 15 GB lagerplads, hvorefter man kan købe op til 1 TB for 10 dollars om måneden. Herefter lever dine billeder på photos.google.com samt i den tilhørende Google Photos-app på din smartphone og tablet.Rimeligt godt overblikDet er altid en udfordring at manøvrere sig gennem titusinder af billeder, og Photos er ingen undtagelse, men ved at vise billederne i bånd af miniaturer får man lidt af overblikket tilbage. Når man scroller gennem skærmbilledet, vises dato og årstal til højre, så man nemmere kan spore sig ind på det, man leder efter.Man uploader ved at trække billeder til Google Photos, men desværre samler programmet ikke automatisk dine billeder i album, medmindre man bruger deres Desktop Uploader (photos.google.com/apps ). Man kan selvfølgelig redigere sine billeder med Google Photos med helt basale funktioner såsom eksponering, farvemæthed og vignette samt klaske nogle filtre på i bedste Instagram-stil, men det er ærlig talt ikke Google Photos største styrke.Det er derimod Google Photos- kunstige intelligens. Når man har 35.363 billeder, er det største problem at finde den berømte nål i en høstak, og det løser Photos med en smart søgefunktion. Klikker man på søgefeltet, får man vist ansigterne på de personer, der optræder oftest i ens billeder. Jeg havde ikke tagget en eneste person, og straks kunne jeg med et enkelt klik få vist alle billeder af min kone, min bror og mine bedste venner. Det kan selvfølgelig være overvældende, hvis man pludselig får klasket dusinvis af minder om en ekskæreste eller et familiemedlem, der er gået bort, op i ansigtet, og derfor kan man også slå genkendelsesfunktionen fra.Appen samler dog også alle dine billeder fra forskellige steder, så du med et klik kan finde alle de fotos, du har taget i Aarhus, San Francisco eller Koh Pha Ngan gennem årene. Det mest fascinerende er dog kategorien »Things«. Her samler Photos automatisk billeder af de ting, som du oftest fotograferer, hvad enten det er solnedgange, mad, bjerge, skyer, hunde eller bjerge. Det er forbløffende og lidt skræmmende, hvor godt algoritmen virker, og Photos var på en eller anden måde i stand til at identificere billederne fra en familiejulefrokost som -Christmas-. Man kan også skrive et specifikt ord i søgefeltet, såsom -hund-, men bliver man for specifik og skriver -pandekager-, så virker det ikke.Automatiske GIF-erEn anden sjov nyskabelse ved Google Photos er Assistant. Assistenten laver automatisk nye ting for dig, såsom at lægge et kunstnerisk filter over et foto eller sætte en række billeder sammen til et panorama eller HDR. Ofte tager man en række skud af det samme motiv, og i stedet for at have en masse stort set identiske billeder, sammensætter assistenten dem til en lille GIF-video. Fra en nylig tur i sommerhus havde Photos klippet billederne af min salto fra poolens vippe sammen til en lille stop motion-film, der er som skræddersyet til Instagram.Assistant lavede også automatisk en lille fortælling fra vores bryllup med en forside og en collage af fotos fra den store dag, billeder, jeg ikke havde kigget på i årevis. Fra en rundrejse i Costa Rica lavede den en historie med billeder og indsatte et landkort med en stiplet linje, der markerede vores rute i bedste Indiana Jones-stil. Efterfølgende kan man selv ændre, hvilke billeder man vil have med i collagen og indsætte kommentarer, næsten som et godt gammeldags fotoalbum.Du er produktetDer er masser at råbe hurra over ved Google Photos, men tjenesten har også en bagside. For selv om Google lover, at du stadig har ophavsret over dine billeder, så ved man også, at de lever af dine data, og er man typen, der kigger sig over skulderen en ekstra gang, så er det skræmmende at vide, at søgegiganten nu også har adgang til alle dine private fotos.Det rokker dog ikke ved, at Google Photos er et glimrende redskab til at tæmme dit evigt voksende fotobibliotek. Og det bedste er, at jeg har fået pustet liv i mine billeder igen. Hvem er klar på et nostalgitrip fra gyngestolen?Google Photos gør det nemt at organisere sine billeder, og den intelligente assistent laver automatisk fortællinger, videoer og collager for dig. Foto: Google.Google Photos gør det nemt at organisere sine billeder, og den intelligente assistent laver automatisk fortællinger, videoer og collager for dig. Foto: Google.
        </div>
        <footer>
          <em>Jp.dk (Jyllands-Posten) (Abonnementsområde)</em>
          &nbsp;·&nbsp; 2015-08-26
          &nbsp;·&nbsp; e52eac8a
          &nbsp;·&nbsp; #11
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.652</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.564</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.653</kbd>
        </footer>
      </article>
      <article>
        <h4>VICTIM BLAMING FOR TV-LICENSEN</h4>
        <div>
          DR oplyser i et stort opsat journalistisk projekt om en ny form for digitale krænkelser. En række kvinder, der har delt billeder af sig selv på Instagram, er af ukendte gerningsmand blevet ' afklædt' på billederne med et særligt program, som via kunstig intelligens kan imitere, hvordan de ser ud uden tøj på. På nul komma fem genererer programmet en falsk krop, som passer til ansigtet på billedet.Og voila - fabrikeret hævnporno.Det er godt, grundigt og forstemmende journalistisk arbejde. Men man indigneres desværre yderligere af det her 100 procent victim blamende spørgsmål, som journalisterne stiller den 20-årige influencer Anna Briand, der har været udsat for forbrydelsen: »Du har over 200.000 følgere på Instagram og bruger dig selv meget via mange opslag, og du har selv optrådt i bikini og bh på din profil. Er det med til at lægge op til, at de falske billeder bliver lavet?« Buh, DR.
        </div>
        <footer>
          <em>Information</em>
          &nbsp;·&nbsp; 2021-04-16
          &nbsp;·&nbsp; e838b5a2
          &nbsp;·&nbsp; #12
          <br>
          <br>
            <kbd data-tooltip="Tech industry &amp; regulation">L02_BIGTEC&nbsp;0.51</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.601</kbd>
        </footer>
      </article>
      <article>
        <h4>Farvel til pixels? Nyt billed- og videoformat er ren vektorgrafik</h4>
        <div>
          Britiske forskere er på trapperne med et videoformat, som kan omsætte levende billeder til vektorbaserede data. Dermed kan billedet skaleres op uden pixelering.Af Jesper KildebogaardOm fem år er billeder sat sammen af pixels et fortidslevn, på linje med grønne bogstaver på sort baggrund og ASCII-art.Sådan lyder forudsigelsen fra britiske forskere, som i løbet af det næste halve år er klar med en løsning, de selv mener vil gøre pixels helt overflødige.I stedet for at beskrive billeder og video som bitmaps, altså pixel for pixel, vil forskernes nye video-codec kunne omsætte al billedinformation til vektorgrafik, hvor alt beskrives som former og streger og derfor kan opskaleres uden problemer. Det skriver Extremetech.com.Det er Philip Willis og John Patterson fra University of Bath, som efter først at have udviklet et vektorbaseret format til fotos nu er på vej med et codec til videobrug. Navnet på det nye format bliver Vectorized Streaming Video, eller VSV, og hvor der ikke er så meget information tilgængeligt om video-formatet endnu, har forskerne udgivet en artikel om deres algoritme til billedformatet.Et bitmap-billede er til at starte med en 1 til 1-gengivelse af billedinformationen, delt op i mange små pixels. Det fylder dog meget, og der opstod derfor komprimeringsalgoritmer som jpeg, der for eksempel samler nabo-pixels, der har samme farve, til ét element, og dermed kan slanke datamængden drastisk.Det kræver en smule regnekraft, men det er intet imod, hvad det vil kræve at omdanne videobilleder til vektorgrafik, hvor alt skal omregnes til figurer og streger. Da beregningerne egner sig godt til at blive paralleliserede og dermed kan drives af kraftfulde, men billige grafik-processorer, burde regnekraft dog med tiden ikke blive noget problem, lyder vurderingen.Bliver pixels aflivet, vil det betyde en langt nemmere arbejdsdag for eksempelvis web- og apps-udviklere, der lige nu kæmper med alverdens forskellige skærmopløsninger, fra Apples nye Macbook med retina-opløsning til billige Android-telefoner.Vektorbaserede billeder ville dermed altid kunne skaleres til en passende størrelse, uden at billedet pixelerer, om end kvaliteten selvfølgelig vil falde ved store forstørrelser.Om de britiske forskere får ret i, at alle de bitmap-baserede formater er væk om fem år, mener Extremetech dog er tvivlsomt, for det har vist sig svært at trænge igennem med nye billedformater. Det har for eksempel ikke gjort den store forskel på internettet, at Google tilbage i 2011 lancerede WebP og WebM, til henholdsvis billeder og video.Læs også: Google forbedrer billedformatet WebP: Nu med gennemsigtighedVia: ExtremetechDet traditionelle pixelbaserede billede til venstre er til højre omsat til vektorgrafik med den nye algoritme. Billedet ser mere skarpt ud og kan opskaleres mere, men omvendt kan man også se, at motivets iris er blevet lidt deform i processen. Klik for større billede..
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2012-12-18
          &nbsp;·&nbsp; e3923af5
          &nbsp;·&nbsp; #13
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.964</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.784</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.731</kbd>
        </footer>
      </article>
      <article>
        <h4>Techtopia #40: 3D-print af reservedele til mennesker og maskiner</h4>
        <div>
          Podcast: 3D-print har mistet terræn som en af tidens mest omtalte teknologier, men det betyder ikke, at teknologien er væk. Tværtimod arbejdes der hårdt på nye anvendelsesmuligheder.3D-print er ikke så omtalt, som det har været. Men på Hasso Plattner Institute i Tyskland arbejder man på at finde nye anvendelsesmuligherder. Her printes i såkaldte metamaterialer, som f.eks. kan være et håndtag med hele åbne- og lukkemekanikken til en dør printet i plastik med alle funktioner indbygget. Hermed er 3D-print ikke bare form men også funktion.Det hollandske firma Xabian bruger scannere og kunstig intelligens til at bane vejen for 3D printede proteser som arme og ben, der også er behagelige at have på.I 2016 lancerede Rotterdams havnemyndigheder i Holland et 3D laboratorium, RAMLAB, der printer reservedele til maritim brug. RAMLAB har produceret verdens første certificerede slæbebådspropel ved hjælp af en 3D print robot.Medvirkende:Alexandra Ion, ph.d.-studerende, Hasso Plattner InstituteBen Hayward, CEO, XabianVincent Wegener, direktør, RAMLAB
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2018-02-19
          &nbsp;·&nbsp; e6a016e6
          &nbsp;·&nbsp; #14
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.924</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.698</kbd>
        </footer>
      </article>
      <article>
        <h4>Kunstig intelligens lærer selv</h4>
        <div>
          En ny type neuralt netværk har potentialet til at revolutionere arbejdet med at skabe kunstig intelligens, fortæller amerikanske forskere fra University of California i et nyt studie.I stedet for at blive programmeret af mennesker lærer det neurale netværk selv af sine fejl. Det nye netværk er opbygget af såkaldte &quot;memristorer&quot;, der ikke kun bruger ettaller og nuller, men også alle mulige værdier ind imellem.
        </div>
        <footer>
          <em>Jyllands-Posten</em>
          &nbsp;·&nbsp; 2015-05-22
          &nbsp;·&nbsp; e50b0c56
          &nbsp;·&nbsp; #15
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.964</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.823</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.548</kbd>
        </footer>
      </article>
      <article>
        <h4>Verdensfirma på en mark i Stige</h4>
        <div>
          STIGE: STIGE: Ude bag et drivhus, ned ad en grusvej og på en mark med juletræer ligger et stort, hvidt hus.Her holder en masse biler og cykler, og hvis man ikke vidste det, var det ikke til at gætte, at her ligger en international virksomhed.For enden af grusvejen ligger nemlig det firma, som Shinta Darling Aarup og Esben Darling Meng etablerede tilbage i 2006: Colourbox.Colourbox er en kæmpe billeddatabase, hvor du kan finde billeder af stort set alt.Parret har en fortid i reklamebranchen, og deres erfaring var, at det var meget besværligt at købe billeder til netop dette.-Så lavede vi en streamingtjeneste.Her var der 65.000 billeder, forklarer Esben Darling Meng.I dag har Colourbox ti millioner billeder, og der kommer 10.000 nye til hver dag.-I begyndelsen lavede vi selv billederne og agerede selv modeller, så der findes mange billeder af os selv, hunden, katten, børnene og bedsteforældrene, siger Esben Darling Meng og smiler.Lokale ansigterHvis du kender Colourbox og bruger det, kan det være, du har set et ansigt derinde, som du også har set et sted i byen.Der findes nemlig en del folk fra Odense, der har ageret modeller til colourboxbilleder.-Vi tog på et tidspunkt nogle billeder i Billund Lufthavn, der skulle handle om flyforsinkelser.Der var jeg model, og der sad jeg på en bænk og kiggede på mit ur. Næste gang jeg så det billede, var det i en artikel om mænd og depression. Lidt efter var det i en artikel om, at kloge mænd har god sædkvalitet, siger Esben Darling Meng og griner.Når billeder fra Colourbox kan bruges frit til hvad som helst, så kan der ske mærkelige ting og sager.-For halvandet års tid siden blev vi ringet op af en kvinde.Hun havde læst Ugeavisen Odense, og deri var et billede af en mand og en kvinde i en intim situation. Kvinden spurgte, hvem den anden kvinde på billedet var, for manden var hendes kæreste, og han havde bestemt ikke fået lov til at lave den slags billeder. Det viste sig så, at manden sammen med sin ekskæreste havde lavet de billeder uden den nuværende kærestes viden, fortæller Esben Darling Meng.Fra Skibhus til Stige Da Shinta og Esben Darling etablerede firmaet, var det i en lejlighed på Døckerslundsvej i Skibhuskvarteret.Ret hurtigt fik de brug for mere plads, og så fandt de en gammel gård fra 1877 i Stige.-Vi skulle finde noget, der både kunne bruges til privatbolig og havde muligheder for ar udvide til erhverv. Det skulle ikke være noget, der havde nogle kedelige kontorer, og så skulle der være en god skole i nærheden, forklarer Esben Darling Meng.Sådan endte de i Stige.I dag er den gamle gård ikke at se. Bygningerne er topmoderne og vrimler med medarbejdere.Store tal på skærmen Hos Colourbox er der medarbejdere fra mange forskellige lande, blandt andet Pakistan og Rumænien, derfor er sproget engelsk, når alle taler sammen.På en skærm i mødelokalet popper der tal op hele tiden.Handlen af billeder på forskellige kontinenter overvåges tæt, og det er store tal -i euro vel at mærke.Alt i Colourbox måles hele tiden.-Det er algoritmer, der styrer, hvilket billede, der kommer frem, siger Esben Darling.Også faktorer som hvor brugeren kommer fra, hvilke højtider der er i landet og hvad der sidst er blevet søgt på, er med til at bestemme, hvilket foto, der kommer frem.Alt i alt går det meget godt hos Colourbox, og det er nok ogsågået meget hurtigere, end parret havde turde håbe på.-Vores succes er, at vi gode har layouts og gode priser. Både en erfaren IT-bruger og en uerfaren kan finde det, de søger på vores side. Og så var vi med fra start af, siger Esben Darling Meng.»Vi tog på et tidspunkt nogle billeder i Billund Lufthavn, der skulle handle om flyforsinkelser. Der var jeg model, og der sad jeg på en bænk og kiggede på mit ur. Næste gang jeg så det billede, var det i en artikel om mænd og depression. Lidt efter var det i en artikel om, at kloge mænd har god sædkvalitet.ESBEN DARLING MENG, MEDEJER OG -STIFTER AF COLOURBOX.Om ColourboxColourbox har billeder af stort set alt. Her kan reklamebureauer finde billeder, som de kan anvende i reklamer, og aviser kan finde et billede, der passer til en artikel, hvis der ikke findes et billede i forvejen. Det kunne foreksempel være, at der blev afholdt andespil i forsamlingshuset, og at der dertil skulle være et billede af en andesteg. Sådan et billede kan man finde på Colourbox.Colourbox har 50.000 fotografer tilknyttet. Nye fotografer skal sende 14 billeder ind, som bliver kigget igennem af en medarbejder på kontoret i Stige, og bliver de godkendt, kan fotografen levere så mange billeder, det skal være.For sit foto får fotografen 20 % af salgsprisen, dog minimum 20 cent.Alle billeder, der kommer ind fra fotografer, bliver set igennem. Colourbox sikrer sig, at der ikke er racistisk eller pornografisk materiale iblandt.En fotograf skal selv sørge for at sætte så mange søgeord på sine billeder som muligt. Dem, der får sat de bedst rammende søgeord på billedet, vil også få solgt flest billeder, da billederne så vil dukke op på flere søgninger.Når en kunde køber en billede på Colourbox, er billedet frit til brug af hvad som helst. Derfor kan det samme billede blive brugt til to meget forskellige ting.Colourbox har kunder i hele Verden. Ifølge Esben Darling Meng vil der på en måned kun være 25 lande i hele Verden, der ikke har købt et billede hos Colourbox.Colourbox har 200.000 aktive brugere, der køber billeder, og der er 75.000 besøgende hver dag.Colourbox har også en afdeling i Berlin, og alt i alt er der 30 ansatte.
        </div>
        <footer>
          <em>Erhvervsavisen Fyn</em>
          &nbsp;·&nbsp; 2014-11-18
          &nbsp;·&nbsp; e4aa7da5
          &nbsp;·&nbsp; #16
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.874</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.689</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.69</kbd>
        </footer>
      </article>
      <article>
        <h4>Facebook tillader nu alligevel ikonisk Vietnam-billede</h4>
        <div>
          Det sociale medie genindsætter billedet de steder, hvor det er blevet fjernet.Facebook har stoppet deres censur af det ikoniske napalm-fotografi fra Vietnamkrigen efter stærk kritik af, at det blevet slettet fra det sociale netværk.Det skriver avisen The Guardian.Særligt den norske statsminister Erna Solberg har lagt stemme til lagt en skarp kritik og blandt andet delt et billede, hvor pigens nøgne krop er dækket af en sort firkant.LÆS OGSÅ Norges statsminister svarer igen på Facebook-censurOpslaget har fået massiv medvind på de sociale medier, ligesom et åbent brev fra Norges største avis, Aftenposten, hvor chefredaktør Espen Egil Hansen erklærer, at han nægter at efterleve Facebooks krav om at fjerne billedet.Facebook har nu besluttet, at det igen skal være tilladt at dele billedet af den nøgne vietnamesiske pige, der løber væk fra de sydvietnamesiske napalmbomber.»Et billede af et nøgent barn ville normalt bryde med vores grundlæggende regelsæt - i nogle lande ville det endda blive kvalificeret som børnepornografi. Men i denne sag, har vi indset den historiske vigtighed af det her billede som dokumentation på en specielt øjeblik i historien«, siger Facebook i en udtalelse til The Guardien.»På grund af dette billedes historiske værdi, overskygger vigtigheden i at tillade deling af billedet vores ønske om at beskytte samfundet fra at se det. Derfor har vi besluttet at genindsætte billedet de steder, hvor vi ved det er blevet fjernet«.I udtalelsen skriver Facebook, at de vil rette på den algoritme som forhindrer, at man kan lægge fotografiet op, og at det igen vil være muligt at dele og poste fotografiet om nogle dage.Censur. Den svenske statsminister, Erna Solberg, og avisen Aftenposten har ført kampagne mod Facebooks censur af det ikoniske Nick Ut-billede fra Vietnamkrigen. Nu giver Facebook sig. Foto: Nick Ut/AP.Censur. Den svenske statsminister, Erna Solberg, og avisen Aftenposten har ført kampagne mod Facebooks censur af det ikoniske Nick Ut-billede fra Vietnamkrigen. Nu giver Facebook sig. Foto: Nick Ut/AP.
        </div>
        <footer>
          <em>Politiken.dk</em>
          &nbsp;·&nbsp; 2016-09-09
          &nbsp;·&nbsp; e5e063ff
          &nbsp;·&nbsp; #17
          <br>
          <br>
            <kbd data-tooltip="Tech industry &amp; regulation">L02_BIGTEC&nbsp;0.822</kbd>
            <kbd data-tooltip="Facebook, fake news &amp; Trump">L05_FBTRUM&nbsp;0.946</kbd>
            <kbd data-tooltip="Social media &amp; well being">L10_SOMEWB&nbsp;0.699</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.589</kbd>
        </footer>
      </article>
      <article>
        <h4>Hybrid mellem neuralt net og beslutningstræ giver forklarlig deep learning</h4>
        <div>
          Neurale net arrangeret som beslutningstræ giver både forklarlighed og præcision, mener AI-forskere. Beslutningstræer er den gyldne standard, hvis en model skal være både forklarlig og intuitiv. Men på komplekse opgaver som at klassificere billeder fejler træerne med en præcision, der er væsentligt ringere end et neuralt netværk. Men med et nyt koncept, udviklet af forskere fra Berkleys center for AI-forskning, kan man få det bedste af begge verdener. Neural-Backed Decision Trees (NBDT) tager den overordnede, intuitive gennesigtighed fra beslutningstræer, men bruger neurale netværk til at tage beslutninger. Resultatet er ifølge Berkeley-forskerne en model, der kan matche almindelige neurale netværk i præcision, men hvor en almindelig bruger kan aflæse, hvordan modellen kom frem til sin beslutning. NBDT-modellen består af et beslutningstræ, hvor hver node er et neuralt netværk. På billede-datasæts CIFAR10, CIFAR100, og TinyImageNet200 slår den kombination andre forklarlige, træbaserede metoder med en betydelig margin. Og forbliver indenfor omkring 1 procent i nærheden af performance af neurale netværk. Forklaringen giver særligt menig, når modellen skal klassificere billeder med indhold, den ikk har set før. CIFAR10-modellen har f.eks. aldrig set et Zebra, men gennem NBDT-modellen kan vi se, at modellen korrekt identificere at der er tale om et hovdyr, før den gætter på hest. Bedre performance betyder mere forstålig Ideen er simpel, men det er ikke helt simpelt, at omdanne et neuralt netværk til et beslutningstræ. Processen kræver blandt andet, hvad forskerne kalder induced hierarchy, der afgør, hvilke sæt af klasser - f.eks. hund eller kat - noderne modellen skal tage stilling til. Hierarkiet bliver bygget ud fra vægtene i et prætrænet neuralt netværk, og med en clustering-teknik finder man frem til hvilke klassifikationer bør have en fælles 'forældre'-node. De noder kan efterfølgende testes kvantitativt. Hvis man f.eks. antager, at en node afgør om billedet forestiller dyr eller fartøj, kan man teste det ved at løbe en masse billeder af dyr og fartøjer gennem modellen. Og på den måde kan man give hver node - som effektivt er en underdel af et lag i det samlede neurale netværk - en semantisk betydning. I forskernes præpublicerede artikel bemærker de en positiv sammenhæng mellem det neurale netværks præcision og hvor semantisk fornuftig hierakiet i stidste ende virker. »We believe that higher-accuracy models exhibit more semantically-sound weight spaces. Thus, unlike previous work, NBDTs feature better interpretability with higher accuracy, instead of sacrificing one for the other.«  Fugl eller fly Eksisterende metoder til at forklare belsutningerne fra et neuralt netværk, har sin mangler, påpeger Alvin Wan, der er en af forskerne bag projektet og pt. skriver sin ph.d. i AI ved Berkeley, i en blog Saliency maps, som kan bruges til at forstå klassifikationer af billeder, kan f.eks. ikke bruges, når et netværk kommer frem til forkerte beslutninger, men fokuserer på det rigtige - som f.eks. når en fugl klassificeres som et fly. Endnu er NBDT-modellen kun brugt på de klassiske billede-klassifikationsdatabaser. Det er derfor uvist, hvor meget klarhed NBDT-modellen kan bringe til situationer, hvor den logiske vej til en beslutning ikke er så simpel som at skelne dyr fra køretøjer - f.eks. når et neuralt netværk skal spotte brystkræft. Ikke desto mindre er der givet situationer, hvor kombinationer af et effektivt neuralt netværk og et visuelt, intuitivt beslutningstræ er attraktivt. Man kan afprøve prætrænede NBDT-modeller her , hvor man også kan hente koden.
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2020-05-28
          &nbsp;·&nbsp; e7b9f4fe
          &nbsp;·&nbsp; #18
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.969</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.973</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.665</kbd>
        </footer>
      </article>
      <article>
        <h4>Er Face ID overhovedet sikker når 2D-ansigtsbilleder kan omdannes til 3D-masker? Måske</h4>
        <div>
          Selv med 3D-printede ansigtsmasker bliver det nok svært uden videre narre iPhone X.Under heftig og vanlig mediebevågenhed annoncerede Apple flere nye telefoner forleden. Noget af det, som har fået rigtig meget opmærksomhed er, at den kommende iPhone X kan låses op via ansigtsgenkendelse i stedet for fingeraftryk.For at autentifikation via ansigtet kan foregå nogenlunde forsvarligt - så det eksempelvis ikke er muligt bare at holde et billede af et ansigt op foran telefonen - så er flere elementer end bare et almindeligt kamera involveret i processen.Der skydes eksempelvis prikker op på brugerens ansigt, hvor prikkernes position så bliver registreret af apparatet i forhold til, om det nu også er en autoriseret person, der forsøger at låse enheden op. Ifølge Los Angeles Times involverer det 30.000 usynlige infrarøde prikker.Wired bemærker, at 3D-kortlægningen af brugerens ansigt via prikkerne vil gøre det vanskeligere at snyde ansigtsgenkendelsen, end det har været tilfældet med tidligere systemer med ansigtsgenkendelse.Los Angeles Times kan citere senior vice president for worldwide marketing Phil Schiller for at sige, at Apple sågar har samarbejdet med professionelle maskefremstillere og make up-artister i Hollywood for at sikre, at Face ID ikke sådan kan omgås (antageligt med en maske).Kig i kameraetFor at systemet skal fungere, så må brugeren heller ikke have øjnene lukkede eller kigge væk fra kameraet. Så altså i udgangspunktet er der ikke noget med lige at nappe en telefon, og så holde den op foran et sovende ansigt for at låse den op.Ifølge Apple er Face ID langt sikrere end en fingeraftrykslæser. I hvert fald end den fingeraftrykslæser-teknologi, der ellers har været anvendt i iPhones. Under annonceringen fremgik det således, at risikoen for, at Touch ID (Apples fingeraftrykslæser) kunne låses op af en tilfældig persons fingeraftryk er 1 ud af 50.000. Ved Face ID skulle tallet være en ud af en million.Forbes kan dog også tage Schiller til indtægt for at ytre, at en persons dobbeltgænger eller tvilling muligvis kan låse telefonen op med ansigtet. Forbes stiller iøvrigt det interessante spørgsmål, om ansigtsgenkendelse i iPhone kan vise sig at gøre det lettere for politimyndigheder at tilgå indhold på telefonen sammenlignet med fingeraftryk.Fra 2D-billede til 3D-maskeI forhold til ansigtsgenkendelse og folk, der ligner, så kunne det være en nærliggende tanke at forsøge at snyde Face ID med en 3D-printet maske. Og det behøver ikke nødvendigvis at være særlig vanskeligt at få lavet sådan et 3D-maske.Forskere har eksempelvis i 2016 demonstreret en algoritme (PDF),, der ud fra et enkelt 2D-billede er i stand til at lave en 3D-gengivelse af et ansigt. En af forskerne er Hao Li. Han er lektor ved University of Southern California, hvor han underviser indenfor datalogi.Derudover er han CEO Pinscreen, som beskæftiger sig med virtuelle avatarer i 3D. Og så var han med til at lave Faceshift. Det er software til at indfange ansigter. Apple købte Faceshift i 2015. Og det skulle være denne software, som bliver anvendt i iPhone X til at indsætte sjove computer-ansigter, kaldet animojis, i stedet for folks egne ansigter på telefonen.Hao Li fortæller via mail til Version2, at det er være muligt at 3D-printe et ansigt ud fra et 2D-billede via den teknologi, han har været med til at udvikle. Hvorvidt det så vil være muligt at narre Face ID, er et andet spørgsmål.»Der kan være yderligere funktioner (jeg tror ikke, Apple har dem endnu), så som at identificere små bevægelser, så statiske objekter (som en maske, red), ikke vil kunne bruges. Og så kan der også være yderligere genkendelses-egenskaber til at detektere, om nogen bærer en 3D-maske.« Derudover bemærker Hao Li, at brugerens øjne skal være rettet mod kameraet. Han er i den forbindelse inde på, at man jo kunne printe huller i 3D-masken, så angriberens øjne måske ville kunne bruges.»Man kan printe med nogle huller. Men [jeg er] ikke sikker på, hvor god detekteringen ville være,« skriver han.Der er også den mulighed, at Apple anvender det infrarøde kamera på telefonen til at opfange en varmesignatur fra ansigtet, bemærker han. Igen en funktion, der kan vanskeliggøre brugen af en 'død'maske til at låse telefonen op med.Vi må sePræcist hvor svær eller let det bliver at narre Face ID må tiden vise, al den stund, at iPhone X slet ikke er lanceret endnu.»Hvis det viser sig ikke at være en gangbar sikkerheds-feature, så er jeg sikker på, Apple's udviklere vil diske op med yderligere sikkerheds-funktioner og opgraderinger (som dem nævnt ovenover),«  skriver Hao Li og henviser blandt andet til registrering af ansigtsbevægelser, så en stilstående maske ikke bare kan bruges.»Ikke desto mindre, hvis det viser sig let at omgå denne sikkerhedsfunktion (Face ID, red.), så vil vi i bund og grund gå rundt med oplåste iPhones, og digitale betalinger vil let kunne udføres. iPhone-tyverier kunne nå nye højder.« Her henviser Hao Li til, at Face ID på samme måde som Touch ID kan bruges til at autorisere betalinger på mobiltelefonen.»For øjeblikket er jeg mere bekymret for, om det er en belejlig måde at sikre en telefon på, eftersom det kræver, at personen vender mod telefonen for at låse den op. Fingeraftryks-funktionen virker foreløbigt mere praktisk.« Nedenfor kan ses en video, der demonstrerer den teknik, Hao Li har været med til at udvikle, hvor 2D-input, der bliver forvandet til 3D-billeder.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2017-09-15
          &nbsp;·&nbsp; e66ab300
          &nbsp;·&nbsp; #19
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.876</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.844</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.666</kbd>
        </footer>
      </article>
      <article>
        <h4>Machine learning sorterer agurker i Japan</h4>
        <div>
          Raspberry Pi, et kamera, et neuralt netværk og en lille kreds på et kort er de centrale dele i et selvlærende agurkesorteringsanlæg.Vi skriver på Version2 om mange mere eller mindre spektakulære løsninger inden for sundhed, kundeservice og politiarbejde der anvender machine learning.Systemdiagram over agurkesorteringsanlæggetMen teknologien kan såmænd også bruges til noget så banalt som at sortere agurker - agurketid eller ej.Japaneren Makoto Koike, der er tidligere udvikler af indlejrede systemer, har bygget et agurke-sorteringsanlæg, der gør brug af Googles TensorFlow machine learning teknologi for at spare hans forældre, der ejer grøntsagsproduktionen, for en masse arbejde. Det fortæller Engadget.Systemet bruger Raspberry Pi 3 med et kamera til at tage billeder af grøntsagerne og sende optagelserne til et lille TensorFlow neuralt netværk, hvori identificeres som agurker.Herefter sendes billeder til en Linux-server, der klassificerer agurkerne efter farve, form og størrelse. Et kort med en lille kreds, Arduino Micro, styrer herefter selve sorteringen, mens en Windows-pc sikrer at det neurale netværk løbende optrænes ved hjælp af billeder.Det er ikke et perfekt system, i hvert fald lige nu. Til trods for at 7000 billeder er høvlet igennem systemet.Makoto Koike anslår, at det tager omkring 2-3 dage at træne den intelligente software op i sortering, hvilket dog sker billeder meget meget lav opløsning (80 x 80 pixels).Uanset at resultatet ikke er perfekt, antyder eksemplet en fremtid, hvor robotbaseret landbrugsudstyr kan håndterer mange opgaver, der tidligere krævede menneskehånd og -øjne.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2016-09-05
          &nbsp;·&nbsp; e5de815a
          &nbsp;·&nbsp; #20
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.988</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.942</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.642</kbd>
        </footer>
      </article>
      <article>
        <h4>Algoritme skaber skarpe billeder ud fra slørede - og sætter ild under etik-debat</h4>
        <div>
          En metode til at 'upsample' slørede eller pixelerede billeder har fået AI-eksperter hos Google og Facebook til at fare i flint. Muligheden for at depixelere et billede - eller forstørre et billede langt over den oprindelige opløsning - er hyppigt anvendt i alskens detektiv-serier. Vil du have fuld adgang til DataTech? Vi oplever i øjeblikket tekniske udfordringer. Kan du ikke læse indholdet, selvom du er logget ind, bedes du logge ud og ind igen. Ellers er du altid velkommen til at kontakte os på pro@ing.dk DataTech skriver til dig, der arbejder professionelt med data og analytics. Vi giver dig inspirerende cases, nyheder og debat om alt fra Machine Learning-modeller til dataetik. Har du allerede et abonnement? Log ind Er dit prøveabonnement udløbet? Køb
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2020-06-25
          &nbsp;·&nbsp; e7c45af6
          &nbsp;·&nbsp; #21
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.658</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.651</kbd>
        </footer>
      </article>
      <article>
        <h4>Derfor skjuler Instagram de kurvede kroppe</h4>
        <div>
          Den engelske betegnelse for &quot;kurvet&quot; (&quot;curvy&quot;) er ikke længere tilladt på platformen, der dagligt giver os vores foto-fix, når venner, bekendte og fremmede deler billeder af mad, flyvinger, kæledyr og selfies, selfies og atter selfies.Instagrams beslutning kan undre, fordi ordet &quot;curvy&quot; er ret uskyldigt og oftest bruges til at hylde almindelige, fyldige kropsformer - særligt i en tid, hvor mange mener, at sygeligt tynde, kvindelige modeller nok er dygtige modeller... men dårlige rolle-modeller. Eller hvor bagdelene i Hollywood, ofte via kirurgiske indgreb, ligner forstørrede kanonkugler, der banker hul i selve naturens love.Fjernelsen af hashtagget &quot;#curvy&quot; bliver ikke mindre mærkelig af, at mere vovede eller provokerende hashtags er tilladt på Instagram: For eksempel clitoris (klitoris, red.), #dildo, #fat (fed), #chubby (buttet) #fatpig (fede gris), #fatfuck (frit oversat: 'fede svin').Ovennævnte hashtags synes i højere grad at indikere nøgenhed eller at være ladet med negative konnotationer i forhold til kropsformer, der bør være i strid mod Instagrams retningslinjer .Mediet Dazed and Confused har taget kontakt til Instagram for at høre, hvorfor de har afskåret brugerne fra muligheden for at lave &quot;curvy-hashtagget&quot;.Talsmanden forklarede at hashtagget &quot;#curvy&quot; stred simpelthen mod mediets nøgenheds-politikker, fordi folk jævnligt har brugt det til at dele upassende indhold.Så det er ikke ordets egentlige betydning, der er afgørende i denne sag, men det faktum, at brugerne benytter hashtagget til at dele indhold, der strider mod retningslinjerne.Andre variationer af hashtagget er stadig søgbare og bliver foreslået, når man prøver at søge på &quot;curvy&quot;: Fx &quot;#Curvygirl&quot;, &quot;#curvyfashion&quot; og &quot;#curvywoman&quot;.Man må formode, at &quot;curvy-billederne&quot; i strid mod Instagrams retningslinjer blot vil migrere til disse hashtags som følge af beslutningen.Det vides ikke, om Instagrams algoritmer automatisk har stået for at fjerne hashtagget, eller om det er sket med menneskelig indgriben. Eller begge dele.I en kronik for mediet Salon under overskriften &quot;Instagram bringer skam over kroppen: #curvy er forbudt, men #skinny (tynd, red.) er okay&quot; ,skriver Mary Elizabeth Williams, som reaktion på sagen:&quot;Nu har Instagram igen afsløret sin forvirring over at lade kvinder være kvinder ved at blokere et tilsyneladende harmløst hashtag som &quot;Curvy&quot;.Williams opsummerer de seneste sager, hvor Instagram lader til at have et forvirret forhold til kvindekroppen: Tidligere på året blev det australske magasin Sticks and Stones' Instagram-konto midlertidigt lukket, fordi de postede et billede af to kvinder i badedragte , hvor kønsdelene var tildækket, men kønsbehøringen synlig.I foråret startede debatten igen, da kunstneren Rupi Kaur delte et billede af sig selv i jogging-bukser, hvorpå en klat menstrurationsblod på størrelse med en femkrone kunne ses (læs Jyllands-Postens dækning af historier her ).Og så er der naturligvis hele debatten om kvindelige kønsvorter på Instagram, der ikke tillades, omend Instagram har sagt god for at dele billeder af brystfødende kvinder (hvis brystvorten er tildækket).Uartig aubergine er også bandlystDet er ikke første gang, at Instagram fjerner muligheden for at bruge tilsyneladende uskyldige hashtags.Så sent som i år blokerede mediet for muligheden for at bruge aubergine-emojien i hashtags. (Instagram tillader, at man bruger emojis i stedet for tekst i hashtags).Grunden var simpelthen, at for mange brugte aubergine-emojien som hashtag, når de postede penis-billeder.Da avisen The Guardian skrev om sagen, blev det humoristisk tilføjet: &quot;Banan- og fersken-emojis er endnu upåvirkede&quot;.Instagram bekræftede overfor mediet Buzzfeed , at brugen af aubergine-hashtagget strider mod platformens retningslinjerI brugernes anvendelse af forskellige hashtags finder man således nøglen til at forstå, hvorfor en uskyldig aubergine ikke må bruges som hashtag, når pistol-emojien og sprøjte-emojien med blod stadig er søgbare.SØRENSEN THOMAS EMIL.SØRENSEN THOMAS EMIL.
        </div>
        <footer>
          <em>Jp.dk (Jyllands-Posten)</em>
          &nbsp;·&nbsp; 2015-07-20
          &nbsp;·&nbsp; e5217b9a
          &nbsp;·&nbsp; #22
          <br>
          <br>
            <kbd data-tooltip="Tech industry &amp; regulation">L02_BIGTEC&nbsp;0.545</kbd>
            <kbd data-tooltip="Facebook, fake news &amp; Trump">L05_FBTRUM&nbsp;0.587</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.539</kbd>
        </footer>
      </article>
      <article>
        <h4>Startup rejser 70 millioner til at lave AI-vidoer</h4>
        <div>
          Startupvirksomheden Synthesia har gennem kapitalfonden FirstMark capital sikret en investering på 70 millioner kroner til at sætte skub på videoer produceret ved hjælp af kunstig intelligens. Det skriverComputerworld.Ved hjælp af teknologien arbejder Synthesia med at skabe videoindhold uden brug af hverken skuespillere eller kameraer.»Vi har stadig kun ridset overfladen af videoøkonomien. Om 10 år tror vi, at de fleste af vores digitale oplevelser vil blive drevet af video i en eller anden måde eller form. Men for virkelig at realisere video-first internet har vi brug for en mere skalerbar og tilgængelig måde at lave video på,« fortæller Victor Riparbelli, en af grundlæggernde af Synthesia.
        </div>
        <footer>
          <em>Pro.ing.dk/Gridtech</em>
          &nbsp;·&nbsp; 2021-04-21
          &nbsp;·&nbsp; e83b43ef
          &nbsp;·&nbsp; #23
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.664</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.626</kbd>
        </footer>
      </article>
      <article>
        <h4>Ny AI-bot tegner overraskende detaljeret efter tekst</h4>
        <div>
          Microsoft har løftet sløret for deres nye AI-bot der kan tegne billeder alene ud fra tekstbeskrivelser.En fugl med sorte vinger, en gul krop og et lille næb. Det er de eneste informationer som Microsofts research lab har fodret deres nye AI-tegnebot, før den har tegnet en forholdsvis avanceret tegning med mange detaljer.Microsoft kalder deres nye AI-program for Drawing bot, og de har i et løftet sløret for teknologien bag i et paper der er udgivet ved Cornell University i USA.Den nye teknologi, der er drevet af kunstig intelligens og er fortsat under udvikling, ser på individuelle ord, når der skabes billeder fra tekst.Programmet kan generere billeder af alt fra klassiske scener med græssende dyr, til mere absurde situationer med en flyvende dobbeltdækkerbus. Hvert billede indeholder detaljer der ikke indgår i den tekst som tegneprogrammet har fået leveret.»Hvis du går på Bing og søger efter en fugl, så får du et fuglebillede. Men her er billedet skabt af computeren, pixel for pixel helt fra bunden. De her fugle findes ikke i den virkelige verden. De er blot en del af computerens forestilling om fugle,« siger Xiadong He, forskningsleder ved Deep Learning Technology Center hos Microsoft-s research lab i Redmond, Washington i et blogindlæg hos Microsoft.To modeller kæmperTegneprogrammet kommer i forlængelse af et udviklingsarbejde mellem computer vision og sprogprocessering som Microsoft har arbejdet med i en del år.Tidligere har udviklingsholdet lavet CaptionBot, der automatisk skriver billedtekster til billeder, ligesom de har udviklet AI-modeller der besvarer spørgsmål om konkrete billeder, fx lokation, objekter, hvilket kan være brugbart for eksempelvis blinde.Kernen i Microsofts tegne-bot er Generative Adversarial Network(GAN). Det er et netværk der består af to machine learning modeller, en der generer billeder fra tekstbeskrivelser og en anden der kaldes diskriminatoren, der bruger tekstbeskrivelser til at vurderer autenticiteten af de genererede billeder.Den genererings-modellen forsøger at få falske billeder forbi diskrimatoren, som omvendt forsøger at presse genereringsmodellen til at lave så optimale billeder som muligt.Tegne-programmet er trænet med datasæt der indeholder billeder og tekster der er parret, så modellen kan lære at matche ord med den visuelle repræsentation af ordene.GAN-netværket fungerer fint når den skal generere billeder fra simple tekstbeskrivelser, fx blå fugl, eller et grønt træ, men kvaliteten dalen i takt med at kompleksiteten stiger, da det er hele sætningen, der fungerer som input til GAN-netværket.Så når man skriver en fulg med en grøn krone, gule vinger og en rød mave, så bliver kvaliteten ikke så god, da de detaljerede informationer går tabt i beskrivelsen og billedet bliver eksempelvis mere uskarpt.Skal hjælpe filmproducenterTegneprogrammet forsøger at efterligne den menneskelige måde at tegne på ved at dele ordene op i forskellige afsnit af billedet.Det kaldes attentional GAN, eller AttnGAN, som matematisk repræsenterer det menneskelige koncept opmærksomhed.»Opmærksomhed er en menneskelig koncept og vi bruger så matematik til at gøre opmærksomhed til en beregning, « siger Xiandon He.P.t er teknologien endnu ikke funktionel, og når man ser tættere på billederne, vil man stort set hver gang se fejl.Ifølge Microsoft er AttnGAN-billeder dog alligevel tre gange bedre end de forrige GAN-netværk.På sigt håber Microsoft at deres tegne-bot kan bruges til at assistere malere eller hjælpe filmproducenter ved at tegne animerede scener baseret på et manuskript.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2018-01-19
          &nbsp;·&nbsp; e6957c40
          &nbsp;·&nbsp; #24
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.933</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.953</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.663</kbd>
        </footer>
      </article>
      <article>
        <h4>Lær at bruge Instagram</h4>
        <div>
          TULLEBØLLE: Business Network Langeland har inviteret Camilla Stemann Jensen, som er ekspert i Instagram og influencermarketing, til Langeland mandag 13. maj.I løbet af eftermiddagen vil hun arbejde med medlemmernes Instagramprofiler, men om aftenen er der et egentligt kursus i at bruge Instagram, som alle kan tilmelde sig.Der er mange muligheder i Instagram til at brande og markedsføre sig, hvad enten man er et firma eller man arbejder for en sag. På dette kursus vil man blandt andet lære at bruge hashtags og finde ud af dem, der virker i forskellige brancher, forstå Instagram-algoritmen, lære om storytelling, community-opbygning, at skabe effektive call to actions og hvad skal der til for at gå viralt.Camilla Stemann Jensen har tidligere holdt foredrag under Social Media Week samt undervist/ holdt oplæg hos blandt andre Vice, Landbrug &amp; Fødevarer, Bolius og Friday Kommunikation.Kurset i Instagram finder sted i Now-huset, Skolevej 10, Tullebølle. EXP.
        </div>
        <footer>
          <em>Fyns Amts Avis</em>
          &nbsp;·&nbsp; 2019-05-10
          &nbsp;·&nbsp; e73131e9
          &nbsp;·&nbsp; #25
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.501</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.611</kbd>
        </footer>
      </article>
      <article>
        <h4>Video: Forskere animerer statiske portrætter med separat videostump</h4>
        <div>
          Med en kort video kan et Israelsk forskerhold give liv til stilbilleder.Et forskerhold fra Tel Aviv University og Facebook har sammensat en serie af algoritmer, der kan overføre ansigtstræk   fra en person i en video   til ansigtet i et vilkårligt portrætfoto.Arbejdet er netop blevet præsenteret i forskningsartiklen -Bringing Portraits to Life-, skriver Engadget.Tidligere har forskere demonstreret, hvordan man kan overføre ansigtsmimik fra en video til en anden. Den teknik har de israelske forskere arbejdet videre på og udviklet, så softwaren minutiøst overfører ansigtsdetaljer som rynker og skygger fra den såkaldte driving video til portrættet.Dertil har forskerne udviklet en metode til at tilføje elementer til portrættet, som ikke er en del af originalbilledet   hvilket primært gælder den indre del af munden. Når personen i videoen åbner munden overføres billedet af mundens indre til portræt-personen, som så åbner munden og viser den første persons tænder.Resultatet er overbevisende   omend ansigterne til tider stadig ser unaturlige og en smule foruroligende ud.Facebooks andel i forskningsartiklen antyder, at det sociale medie overvejer et form for animeret profilbillede, der kan reagere på, hvad brugeren foretager sig. Det koncept demonstreres sammen med den generelle teknik i videoen herunder.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2017-10-10
          &nbsp;·&nbsp; e673cb7a
          &nbsp;·&nbsp; #26
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.636</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.62</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.676</kbd>
        </footer>
      </article>
      <article>
        <h4>Obama blev 'deepfaked': Strippede i falsk video</h4>
        <div>
          Kunstig intelligens kan narre dig til at tro, du ser videoer af kendte menneskerBerømtheder har i årevis måttet leve med at få deres ansigter digitalt klistret på billeder af nøgne kroppe eller det, der er værre.Men en ny trend kaldet -deepfaking- tager falske billeder til et helt nyt niveau.Med hjælp fra en lynhurtig computer og et program, der bruger kunstig intelligens til at sætte falske ansigter på sine ofre, kan man nu få videoer til at virke ægte.Rent teknisk bruger man en række ægte billeder af den person, man vil overføre til en anden video.Jo flere billeder og jo bedre kvalitet, de har, jo nemmere er det at skabe en video, som ligner virkeligheden.Se også: Falsk kendis-porno er en juridisk gråzoneHar ingen skruplerTidligere præsidentfrue Michelle Obama er en af dem, der har været gennem programmet. Resultatet blev en ganske virkelighedstro strippervideo, hvor man ser Obama tage tøjet af:- Der er reelt ingen grænser for, hvad du kan gøre, hvis du har lidt fantasi, siger den anonyme skaber af programmet FakeApp til New York Times.Ifølge ham er FakeApp downloadet mere end 120.000 gange, siden det blev kendt tidligere i år. Og manden, der angivelig er en softwareudvikler fra Maryland i USA, har ingen skrupler ved teknologien:- Jeg har tænkt meget over det, og jeg mener ikke, at teknologien skal fordømmes. Den kan bruges til mange formål, både gode og dårlige.Teknologi - 3. mar. 2018 - kl. 23:01Tjek kortet: Så hurtigt er internettet i dit sommerhusMere end pornoDet mest skræmmende ved -deepfaking- er dog ikke, at amatører klistrer Obamas ansigt på en stripper.Det er, at kommende videoer bliver så virkelighedstro, at hele befolkninger og måske regeringer tror på dem. Og det kan få fatale konsekvenser:- Det her bliver den næste form for kommunikation. Og jeg er bekymret for, at det bliver brugt til afpresning eller ting, der er værre, siger professor Hao Li fra University of Southern Califonia til avisen.Udvikleren bag FakeApp mener ikke, at det er muligt at stoppe udviklingen:- Algoritmer (til kunstig intelligens, red.) bliver meget vigtige i fremtiden. Og ikke kun i de enkelte programmer, men også som en del af mange gadgets.Her kan du se en demonstration af, hvordan FakeApp virker. Video: YouTubeSe også: Sikkerheden er knækket i iPhone: Sådan sikrer du digKan beskytte TrumpHvis falske videoer, der ligner den ægte vare, spreder sig yderligere, kan en anden konsekvens blive, at det bliver nemmere at afvise ægte videoer som falske nyheder:- Hvis den ægte video af præsident Trump, der angivelig har urinsex, dukker op, kan han hævde, at den er -deepfake-, siger Benjamin Van Den Broeck, der er ekspert i videomanipulation, til The Verge.Se også: Ny retromobil fra Nokia: Kan du huske denne model?
        </div>
        <footer>
          <em>Ekstrabladet.dk</em>
          &nbsp;·&nbsp; 2018-03-07
          &nbsp;·&nbsp; e6a7d354
          &nbsp;·&nbsp; #27
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.616</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.631</kbd>
        </footer>
      </article>
      <article>
        <h4>Ph.d.-forsvar: Kan man se originalen bagved?</h4>
        <div>
          Helene Matilde Svane forsvarer onsdag 30. oktober kl. 14.15 sin ph.d.-afhandling på Aarhus Universitet, 1531-219, auditorium D4, Ny Munkegade 116, Aarhus C. Afhandlingen omhandler forskellige aspekter af rekonstruktion af et objekt fra dets digitale gråskala-billede. Man forestiller sig, at man fremstiller et digitalt billede af et sort objekt på en hvid baggrund ved at placere et gitter oven på objektet og derefter farve hvert gitterfelt i en grå nuance, der svarer til den brøkdel af den firkant, der er dækket af objektet. På denne måde får man et digitalt billede i gråskala af objektet, der består af pixels med forskellige gråtoner. Spørgsmålet er nu, hvor meget man kan udlede om det originale objekt, hvis man kun kender det digitale billede af det, især når det digitale billede har en dårlig opløsning. I afhandlingen foreslås algoritmer til rekonstruktion af en bestemt klasse af objekter ved hjælp af deres digitale billeder. Ph.d.-graden blev afsluttet ved Center for Stokastisk Geometri og Bioimaging (CSGB), Institut for Matematik, Videnskab og Teknologi, Aarhus Universitet.
        </div>
        <footer>
          <em>Stiften.dk (Århus Stiftstidende)</em>
          &nbsp;·&nbsp; 2019-10-29
          &nbsp;·&nbsp; e76a8f2e
          &nbsp;·&nbsp; #28
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.95</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.648</kbd>
        </footer>
      </article>
      <article>
        <h4>Javascript genkender ansigter i browseren</h4>
        <div>
          Nu kan Javascript-udviklere bygge ansigtsgenkendelse i webapps. Face-api.js er et Javascript-api til ansigtsgenkendelse i browseren implementeret oven på Googles Tensorflow.js, som er en Javascript-implementering af firmaets populære machine learning teknologi til browsere og Node.js-miljøet.Til teknologibloggen Infoq forklarer Vincent Mühler, som er skaberen af Face-api.js motivationen bag:»Jeg havde et andet bibliotek, som var i stand til at detektere ansigter og udføre ansigtsgenkendelse med Node.js. På et tidspunkt opdagede jeg Tensorflow.js og blev interesseret i maskinlæring i browseren. Jeg var nysgerrig på, om det var muligt at flytte eksisterende modeller til ansigtsgenkendelse og ansigtsgenkendelse til Tensorflow.js, og det fungerede ganske godt.« Face-api.js kommer med tre modeller: SSD Mobilenet V1, Tiny Face Detector og MTCNN.Tiny Face Detector er trænet på et brugerdefineret datasæt med 14.000 billeder. Apps med begrænsede resurser bør bruge denne model.Til ansigtsgenkendelse benyttes en model baseret på en ResNet-34-lignende arkitektur, til at beregne en ansigtsbeskrivelse ud fra et billede. Denne model er ikke begrænset til det sæt ansigter, der bruges til træning, hvilket betyder, at udviklere kan bruge det til genkendelse af alle personernes ansigter. Det er muligt at bestemme ligheden mellem to vilkårlige ansigter, ved at sammenligne deres ansigtsbeskrivelser.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2018-11-14
          &nbsp;·&nbsp; e6f8ed73
          &nbsp;·&nbsp; #29
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.977</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.912</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.665</kbd>
        </footer>
      </article>
      <article>
        <h4>Reference-tv fra Loewe</h4>
        <div>
          Loewe satser på tv i luksusklassen med sit nye Reference ID.Perfekte billeder, fantastisk lyd og enestående design, påstår Loewe i sin pressemeddelelse. Loewe har med Reference ID skabt en eksklusiv kombination af billede og lyd fremstillet med brug af eksklusive materialer som blankpoleret aluminium og Berliner Glas.LÆS OGSÅ: Tossekassen er blevet afløst af smart t vLoewe Reference ID har en kontrastfilter-skærm med anti-refleksionsglas på begge sider. Det gråtonede glas skal gøre billedet tydeligt mere skarpt og præcist og optimerer kontraster og reducerer reflektioner cirka 10 gange mere end andre glasskærme, siger man fra Loewe. Med 200 fps (frames per second) og en særlig styring af LED backlight teknologien får Loewe Reference ID en 400 Hz billedvisning, som i kombination med tv´ets intelligente algoritmer skal sikre en optimal gengivelse af ekstremt hurtige bevægelser, siger man. Du har desuden også mulighed for at konvertere 2D indhold til 3D-visning.LÆS OGSÅ: Samsung først ude med krumme OLED-tv160 watt forstærkning skal give et lydtryk på 102 dB fra to integrerede fuldtone-højttalere, en 6'' subwoofer og en ekstra passiv membran. Ekstra Loewe Reference ID Speakers kan fås separat til en surroundløsning. Den integrerede harddisk (DR+) er på 1 terrabyte, svarende til ca. 450 filmtimer. Med Dual Channel er det muligt at optage ét program og se et andet samtidigt. Loewe DR+-teknologien gør det endvidere muligt at benytte Follow-me-funktionen, hvor et program kan sættes på pause og efterfølgende fortsættes på et andet Loewe-tv (i samme netværk). Desuden er streaming af programmer og optagelser fra ét Loewe-tv til et andet (i samme netværk) ligeledes muligt med Loewe DR+.LÆS OGSÅ: 77&quot; 4K OLED - og meget mere - fra LGLoewe Reference ID har alle gængse tv-modtagere og formater integreret: DVB-T/-C/-S/-T2/-S2, SD/HD og 3D. Desuden har tv´et to CI+ slots. Det fås i skærmstørrelserne: 40&quot;, 46&quot; og 55&quot; og i flere rammefarver. Standardmodellen er med ramme i Alu Silver og med højttalerfront i Black. Desuden kan du vælge forskellige farver på stoffet til højttalerfronten. Loewe Reference ID 40&quot; koster fra 46.999 kr., Loewe Reference ID 46&quot; fra 51.999 kr. og Loewe Reference ID 55&quot; fra kr. 61.999 kr.www.loewe.dk
        </div>
        <footer>
          <em>Jp.dk (Jyllands-Posten)</em>
          &nbsp;·&nbsp; 2013-10-05
          &nbsp;·&nbsp; e405d07c
          &nbsp;·&nbsp; #30
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.611</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.527</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.571</kbd>
        </footer>
      </article>
      <article>
        <h4>Sci-fi kortfilm fra 3D College er et viralt hit</h4>
        <div>
          20-25 elever fra 3D College i Grenaa har lavet de visuelle effekter til sci-fi kortfilmen »Arene«, hvor det aarhusianske Level Up Pictures også har taget del.GrenaaEt unikt samarbejde mellem 3D College i Grenaa, filminstruktør Henrik Bjerregaard Clausen samt produktionsselskaberne Level Up Pictures, Frøstrup Videolab og Stunt360 - Stunt Service Int. er godt i gang med at brede sig udover hele verden.På nuværende tidspunkt har den fire minutter lange sci-fi kortfilm »Arene«trukket over 170.000 views på Youtube og Vimeo og er omtalt på flere internationale sci-fi-sider, hvor brugerne godt kunne se den blive forvandlet til en spillefilm eller en tv-serie.Læs også:Nyt tiltag: Containerboliger skal huse studerendeDet virale hit er den foreløbige kulmination på et erhvervsrettet forløb på 3D College, hvor udvalgte elever eller klasser får lov til at prøve kræfter med en virkelig produktion.»I et undervisningsmiljø får eleverne mange opgaver, men det er ofte først, når de kommer ud i et rigtigt virksomhedsmiljø, at de oplever formålet med de forventninger og krav, de skal leve op til. Det er også her, at de virkelig kan vise, hvad de selv kan præstere,«forklarer afdelingsleder på 3D College, Alex Townley Porsborg, der sammen med underviser Kasper Appel har været med til at starte forløbet op for små fire år siden.»De første film, vi lavede, var en-to minutter lange, for det tager virkelig lang tid at lave 3D-modellerne. Nu har vi haft en hel produktion med rigtige skuespillere og stuntmænd for andet år i træk, og det er blevet den bedste produktion, vi endnu har lavet,«forklarer afdelingslederen.Stor produktionDet er det aarhusianske produktionsselskab Level Up Pictures, der har sørget for rammerne i den post-apokalyptiske sci-fi film, der omhandler en krig mellem mennesker og maskiner med kunstig intelligens.»Målet var at lave en produktion, hvor eleverne blev guidet gennem hele produktionen, så de fik et indtryk af, hvad det vil sige at lave en film fra bunden,«forklarer den bulgarske producer Stoyan Yankov, der er partner i Level Up Pictures.Læs også:Ung spiludvikler i panik: Hjemmebygget computer med uerstattelige filer stjåletMens eleverne fra 3D College har skabt hele det univers med broer og øde ørkenområder, som kortfilmen udspiller sig i, så skabte Level Up Pictures rumskibets indre på Godsbanen, hvor stuntmænd, der blandt andet har været med i Hollywood-film som Edge of Tomorrow og World War Z, blev fløjet ind fra London.I alt har over 50 mennesker været involveret i filmen.Noget at vise frem»Eleverne fra 3D College har virkelig leveret et flot stykke arbejde, og man kunne godt fornemme, at de havde prøvet noget lignende før. Men de skulle leve op til kravene, og de har alle sammen arbejdet hårdt. Nu har de noget til deres portefølje, som de kan vise frem,«siger Stoyan Yankov, der gerne vil fortsætte samarbejdet med 3D College.Netop muligheden for at få noget til elevernes portefølje er en vigtig del af baggrunden for, at 3D College startede projektet op.Læs også:Kreative unge klar med med spændende projekter»Det giver eleverne noget andet at vise frem end bare en skoleopgave, hvor vi har sat rammerne. Samtidig giver det også 3D College og Viden Djurs muligheden for at bruge projekterne i vores branding af uddannelsen. Og der mener jeg, at vi vil kunne fange nogle nye studerende med sådan en produktion,«siger Alex Townley Porsborg.3D College er så småt i gang med en ny produktion.»Arene«kan ses på Youtube.com eller Vimeo.comDet er første gang, at der bruges rigtige skuespillere og stuntmænd i en produktion fra 3D College, og det har givet traileren et løft fra de tidligere år. Stunmændene har blandt andet lavet flere Hollywood-film. Foto: Simon Falkentorp.Det er første gang, at der bruges rigtige skuespillere og stuntmænd i en produktion fra 3D College, og det har givet traileren et løft fra de tidligere år. Stunmændene har blandt andet lavet flere Hollywood-film. Foto: Simon Falkentorp.
        </div>
        <footer>
          <em>Amtsavisen.dk (Randers Amtsavis) (Abonnementsområde)</em>
          &nbsp;·&nbsp; 2016-05-19
          &nbsp;·&nbsp; e5b743d8
          &nbsp;·&nbsp; #31
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.964</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.687</kbd>
        </footer>
      </article>
      <article>
        <h4>Computer genkender ansigter bedre end mennesker</h4>
        <div>
          To kinesiske forskere har udviklet en ny algoritme til ansigtsgenkendelse. Den matcher ansigter med 98,5 procents sikkerhed, og det er faktisk bedre, end mennesker kan gøre det.Vi mennesker er rigtig gode til at genkende ansigter. Hvis vi bliver præsenteret for to portrætter, kan vi med uhyre stor sikkerhed sige, om det er samme person, der optræder på billederne. Faktisk gætter vi rigtigt i 97,53 procent af tilfældene.Men nu er vi blevet overgået af en computer. To kinesiske forskere fra Det Kinesiske Universitet i Hong Kong har udviklet og testet en ny algoritme til ansigtsgenkendelse, og her er succesraten oppe på 98,52 procent.I en artikel på preprint-serveren ArXiv skriver forskerne, at det er første gang, at en computer klarer opgaven bedre end mennesker. Den nye algoritme kaldes GaussianFace, og den er en smule bedre end Facebooks DeepFace , der byder på en præcision på 97,35 procent.Den form for ansigtsgenkendelse, hvor to billeder af samme person skal matches, er ellers en ret vanskelig opgave for en computer. Det gælder især, hvis lysforholdene på de to fotos er forskellige, hvis personen har drejet hovedet i forhold til kameraet, eller hvis ansigtsudtrykkene er forskellige.Netop derfor benyttes databasen Labeled Faces in the Wild ofte, når udviklere af ansigtsgenkendelsessoftware skal teste algoritmer. Databasen rummer nemlig mere end 13.000 billeder hentet ned fra internettet, og 1.680 af de navngivne personer på billederne optræder to eller flere gange i databasen.Eftersom billederne er høstet fra nettet og ikke er pæne pasfotos, er der stor forskel på, hvordan personerne optræder på dem, så billederne er en god udfordring for algoritmer til ansigtsgenkendelse. For eksempel kan skuespilleren Johnny Depp være sminket som sørøver i Pirates of the Caribbean på det ene billede og posere på den røde løber til en Oscar-uddeling på det andet.GaussianFace finder først øjne, næse og mundvige hos personen på billedet, og ud fra disse fem punkter bliver der konstrueret et 150 x 120 pixels billede af ansigtet set forfra. Billedet deles op i overlappende felter på 25 x 25 pixels, og hvert af disse felter bliver repræsenteret af en vektor. Så bruges samlingen af vektorer i sammenligningen af billeder.Algoritmen blev først trænet ved hjælp af tusindvis af billeder fra andre databaser, før den blev sluppet løs i databasen Labeled Faces in the Wild.
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2014-04-28
          &nbsp;·&nbsp; e460c347
          &nbsp;·&nbsp; #32
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.844</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.714</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.629</kbd>
        </footer>
      </article>
      <article>
        <h4>AI-faldgruber: Deep learning kan udviske tumorer i MRI-scanninger</h4>
        <div>
          Deep learning-modeller til at rekonstruere medicinske billeder kan lede til forkerte diagnoser, advarer forskere. At bruge deep learning til at rekonstruere billeder fra MRI- og CT-scanninger kan i værste fald lede til forkerte diagnoser. De neurale netværk kan nemlig ikke blive meget præcise uden samtidig at blive ustabile, viser forskning. Vil du have fuld adgang til DataTech? DataTech skriver til dig, der arbejder professionelt med data og analytics. Vi giver dig inspirerende cases, nyheder og debat om alt fra Machine Learning-modeller til dataetik. Har du allerede et abonnement? Log ind Er dit prøveabonnement udløbet? Køb
        </div>
        <footer>
          <em>Pro.ing.dk/datatech</em>
          &nbsp;·&nbsp; 2020-08-11
          &nbsp;·&nbsp; e7d4eefc
          &nbsp;·&nbsp; #33
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.837</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.847</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.519</kbd>
        </footer>
      </article>
      <article>
        <h4>Wauw: Forskere skaber verdens mest detaljerede billede af atomer</h4>
        <div>
          Billedet er zoomet 100 millioner gange ind på atomerne I 2018 byggede et forskerhold fra Cornell University i USA en maskine, der hjalp dem med at sætte verdensrekorden i at skabe et billede i høj opløsning af en elektron.Forskerne kunne dog kun lave målinger af tynde atomopbygninger, da målinger af tykkere atomer ville få elektronerne til at dele sig på måder, der ikke kunne analyseres af forskere.Nu har holdet igen på banen med et nyt billede af atomer, der har den højeste opløsning nogensinde målt.I en pressemeddelelse fortæller forskerne, at man har zoomet 100 millioner gange ind på atomerne på billedet, som du kan se herover.Ved hjælp af et særligt mikroskop kaldet EMPAD (Electron Microscope Pixel Array Detector) og en algoritme-drevet proces kendt som 'ptychografi' har forskerne fundet en løsning på de tidligere udfordringer og har kunnet genskabe et billede i ultrahøj opløsning.- Det her sætter ikke bare en ny rekord. Vi har nået et punkt, hvor opløsningen ikke kan blive højere. Vi kan basalt set nemt forudse, hvor atomer bevæger sig hen, udtaler professor David Muller fra Cornell University i en pressemeddelelse ifølge Videnskab.dk.'Ptychografi' fungerer, ved at man skanner atomers bevægelser og registrerer, hvor de overlapper hinanden, og hvor de adskiller sig fra hinanden.- Man kan sige, at vi jagter mønstre og bevægelser, ligesom en kat jagter et laserlys på en væg. Ved at se på, hvordan disse mønstre ændrer sig, kan vi ved hjælp af en computer undersøge, hvad der fører til disse ændringer, siger Muller i pressemeddelelsen ifølge Videnskab.dk.Andre artikler fra Videnskab.dk
        </div>
        <footer>
          <em>EkstraBladet.dk</em>
          &nbsp;·&nbsp; 2021-06-08
          &nbsp;·&nbsp; e84d95ad
          &nbsp;·&nbsp; #34
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.895</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.775</kbd>
            <kbd data-tooltip="Algorithms &amp; apps">L80_ALGOAP&nbsp;0.52</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.639</kbd>
        </footer>
      </article>
      <article>
        <h4>Facebook bandlyser brugen af deepfakes</h4>
        <div>
            Manipulerende og vildledende indhold er ikke længere velkomment på platformen. Videoer og billeder, der manipuleres og redigeres med henblik på at vildlede platformens brugere, vil blive fjernet og blokeret fra Facebook. Det skriver Facebook i et blogindlæg Photoshop, kunstig intelligens og kreativ redigering kan eksempelvis anvendes således, at det i en video af en politiker ser ud, som om personen fremfører den modsatte pointe af, hvad de faktisk gjorde i den originale video og altså i virkeligheden. Ligeledes kan samme software bruges til at lave såkaldte 'deepfakes', der eksempelvis kan være en computergenereret tale fra en statsminister, som den rigtige statsminister aldrig har holdt. Ikke forbud mod Photoshop Der er fra Facebooks side ikke tale om et kategorisk forbud mod software som Photoshop og deslige. Facebook har eksempelvis ikke et problem med, at Photoshop anvendes til at gøre farverne på et model-billede skarpere. Det er først, når denne type software bruges til at kreere såkaldte deepfakes, at det endelige billede eller den endelige video kan blive lukket ned.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2020-01-07
          &nbsp;·&nbsp; e787a974
          &nbsp;·&nbsp; #35
          <br>
          <br>
            <kbd data-tooltip="Tech industry &amp; regulation">L02_BIGTEC&nbsp;0.586</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.518</kbd>
            <kbd data-tooltip="Social media &amp; well being">L10_SOMEWB&nbsp;0.557</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.652</kbd>
        </footer>
      </article>
      <article>
        <h4>FBI køber ansigtsgenkendelse for 5,8 milliarder</h4>
        <div>
          Et nyt projekt skal gøre det nemmere for det amerikanske forbundspoliti FBI at lokalisere og identificere forbrydere.Det amerikanske forbundspoliti, FBI, er i fuld gang med at søsætte et nyt ambitiøst ansigtsgenkendelsessystem, som i 2014 skal finde forbrydere over hele USA. Projektet går under navnet Next Generation Idenfication (NGI) programme og koster ikke mindre end én milliard dollar eller 5,8 milliarder kroner.Med billeder af kriminelle i politiets database er det meningen, at det nye system skal kunne registrere en mistænkt, når han eller hun bevæger sig ind i synsfeltet af et sikkerhedskamera. Omvendt kan det også bruges til at finde en forbryder i databasen, hvis forbrydelsen er fanget på kamera.FBI har endnu ikke frigivet nogen detaljer om den algoritme, NGI bruger, men tidligere tests viser, at moderne algoritmer til ansigtsgenkendelse kan identificere en person med 92 procent sikkerhed i en database med 1,6 millioner billeder. Selv hvis personen er optaget på en skæv vinkel kan algoritmer generere en 3D-version af ansigtet og dreje det op til 70 grader, så det matcher billeder i databasen.Ud over ansigtsgenkendelse vil NGI også indeholde DNA-analyser, stemmegenkendelse og iris-scanner.Pilotprojektet kan kun søge efter tidligere kriminelle, men det er ukendt om FBI også vil tilføje billeder af andre, som ellers ikke har været i politiets søgelys.Moderne algoritmer til ansigtsgenkendelse kan identificere en person med 92 procent sikkerhed i en database med 1,6 millioner billeder..
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2012-09-14
          &nbsp;·&nbsp; e367038c
          &nbsp;·&nbsp; #36
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.614</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.647</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.601</kbd>
        </footer>
      </article>
      <article>
        <h4>Microsoft frigiver API til at måle følelser ud fra ansigter</h4>
        <div>
          Bertel Haarder var 98 procent vred i mislykket DR-interview, vurderer Microsofts nye maskinlæringsbaserede API.Microsoft har frigivet et nyt værktøj i forbindelse med selskabets Project Oxford, som nok hører i den mere pudsige ende, men alligevel demonstrerer mulighederne i billedanalyse ved hjælp af maskinlæring.Det nye Emotion API giver nemlig mulighed for at vurdere, hvilke følelser en person udtrykker på et foto. API'et detekterer ansigter på et givent billede og returnerer en sandsynlighed for forskellige følelser ud fra ansigtsudtrykket.Fodrer man således Emotion API med et billede af Bertel Haarder fra et mislykket DR-interview , vurderer algoritmerne, at Bertel Haarder med 98,4 procents sandsynlighed udtrykker vrede på billedet.Spørger man algoritmen, hvordan Mona Lisas smil på Leonardo Da Vincis maleri skal fortolkes, så er algoritmen splittet med 55 procents sandsynlighed for et neutralt udtryk, og 44 procent for at hun er glad.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2015-11-11
          &nbsp;·&nbsp; e54f2ce4
          &nbsp;·&nbsp; #37
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.728</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.593</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.565</kbd>
        </footer>
      </article>
      <article>
        <h4>Ritzau Plus: Overvågning i Mannheim</h4>
        <div>
          MannheimMannheim Way 2.0:* Der opsættes 71 videokameraer. * Kameraerne opsættes på 28 offentlige steder, hvor der ofte begås kriminalitet.* Krypterede optagelser sendes til en computer på byens politistation.* Et computerprogram udviklet på Fraunhofer Institute i Karlsruhe analyserer bevægelsesmønstre fra optagelserne ved hjælp af en algoritme. * Finder computeren et atypisk mønster, tilkaldes en politibetjent. * Alle billeder slettes efter tre dage.Kilde: Borgmesterkontoret i Mannheim/ritzau/Denne nyhed må publiceres digitalt bag paywall fra d. 17/02/2018 14:00Denne nyhed publiceres ikke på NET-tjenesten
        </div>
        <footer>
          <em>Ritzaus Bureau</em>
          &nbsp;·&nbsp; 2018-02-17
          &nbsp;·&nbsp; e69f9590
          &nbsp;·&nbsp; #38
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.681</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.575</kbd>
        </footer>
      </article>
      <article>
        <h4>MIT fjerner datasæt, der har trænet AI-systemer til at være racistisk og sexistisk</h4>
        <div>
          Universitetet undskylder for datasæt, der er annoteret med nedsættende ord om kvinder og sorte. MIT, et af verdens ledende universiteter inden for AI-forskning, har permanent fjernet et billeddatasæt på grund af racisitisk og sexistiske labels. Det skriver The Register Datasættet blev skabt i 2006, og er siden blevet flittigt brugt til at udvikle modeller, der kan identificerer personer og objekter på billeder. Men da MIT sammensatte datasættet - 80 Million Tiny Images - blev det gjort uden nogen nærmere kuratering af de label, der er tilknyttet hvert billede, og som f.eks. skal lære et neuralt netværk, at billedet forestiller en cykel eller en bil. Tusindvis af billeder er nemlig annoteret med ord som 'luder', 'bitch' og 'pædofil'. Tilsvarende er mange billeder noteret med nedsættende ord rettet mod bestemte etniske grupper. Det viser en større kulegravning , som Vinay Prabhu, chief scientist hos UnifyID, og Abeba Birhane, ph.d.-studerende ved University College Dublin, har lavet. Forskere: Undskyld De problematiske labels er opstået fordi MIT i sin tid hentede navneord fra ord-databasen Wordnet, og brugte dem til automatisk at hente korresponderende billeder på søgemaskiner. I en meddelelse fra Antonio Torralba, Rob Fergus og Bill Freeman, der oprindeligt præsenterede datasættet , fortæller MIT-forskerne, at de ikke var klar over de problematisk labels. »Vi er meget berørte over det, og vi undskylder over for alle, der er blevet påvirket,«  skriver de. At manuelt rydde op i de 80 millioner billeder er ikke muligt, skriver forskerne. Og derfor fjerner de nu datasættet og opfordrer udviklere til at slette lokale kopier. Oprydning i ImageNet 80 Million Tiny Images er ligesom det ikoniske ImageNet-datasæt blevet brugt til at benchmarke AI-modeller. Men i modsætning til ImageNet har ingen altså tidligere lavet et grundig og kritisk gennemgang af indholdet. ImageNet - der er skabt af forskere ved Stanford og Princeton - har været signifikant for udvikling af deep learning-modeller til billedgenkendelse gennem den såkaldte ImageNet Challenge. Men heller ikke her stod etikken ekstremt højt på dagsordenen, da datasættet blev skabt mellem 2007 og 2009. Vinay Prabhu har tidligere demonstreret, at der er flere tvivlsomme billeder at finde i arkivet med over 14.000.000 billeder - foruden problematiske labels fandt Prabhu flere billeder af nøgne børn samt pornografisk materiale. Forskerne bag ImageNet satte i september sidste år gang i en større indsats, der blandt andet skal fjerne kønsmæssige og etniske bias i datasættet.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2020-07-03
          &nbsp;·&nbsp; e7c796cc
          &nbsp;·&nbsp; #39
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.99</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.719</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.61</kbd>
        </footer>
      </article>
      <article>
        <h4>Googles Captcha-afløser hjælper computeren med at lære at fortolke billeder</h4>
        <div>
          Mennesker er stadig bedre end computere til at genkende billeder. Men flere forskerhold arbejder på at gøre kål på menneskets forspring.Af Jesper Stein SandalGoogle har sagt farvel til den klassiske CAPTCHA, som skulle skille mennesker fra automatiske scripts ved at bede dem tyde en sløret tekststreng. Afløseren bruger billeder, og det skal hjælpe Googles billedgenkendelsessoftware, skriver New Scientist .I den nye udgave af Googles CAPTCHA-udfordring vil et menneske som regel kunne genkendes alene ud fra visse kendetegn som eksempelvis musens bevægelser, som kan aflæses af hjemmesiden. Men hvis Googles algoritme kommer i tvivl, kan brugeren blive bedt om eksempelvis at identificere et billede, som skiller sig ud i en gruppe af billeder.CAPTCHA-udfordringer bruges blandt andet til at forhindre automatiske scripts, som kan registrere sig på hjemmesider og spamme debattråde med reklamer.De gamle udgaver er ikke længere så pålidelige, fordi computerne er blevet bedre til at afkode de slørede tekster. Men computere er stadig meget mere upålidelige til eksempelvis at se, om et lille pelset dyr er en kat eller en kanin. Det er mennesker til gengæld ekstremt gode til.Det er det, Google nu udnytter, men ud over at beskytte hjemmesider mod spam, så giver teknologien også Google værdifulde datasæt. Hver gang et menneske har hjulpet med at identificere et billede ud af en mængde, så kan Google bruge det samme datasæt til oplæring af billedanalysealgoritmer.Det vil blandt andet kunne hjælpe Google med at forbedre billedsøgning, hvor Google i dag er afhængig af enten tekst i sammenhæng med et billede eller mønstergenkendelse, som har en vis fejlrate.Google arbejder også ifølge MIT Technology Review på et billedanalyseværktøj, som bruger vektormatematik til at sætte ord på billeder. Det er en videreudvikling af en teknik, som Google i forvejen bruger til tekstoversættelse mellem sprog, men den kan også bruges til billeder.Et forskerhold ved Stanford University arbejder ligeledes på et sæt af maskinlæringsalgoritmer, der kan sættes ord på billeder . Ved hjælp af en database bestående af 14 millioner objekter udtrykt ved hjælp af vektorer, kan algoritmerne genkende objekterne i billeder og sammensætte en beskrivelse. Det gør det eksempelvis muligt at beskrive indholdet af et billede som eksempelvis 'en kat sidder på et tastatur'.Denne type avanceret analyse af indholdet i billeder er især interessant i forhold til at kunne søge i og kategorisere de millioner af billeder og videoer, som distribueres på internettet, som ofte ikke er forsynet med mange oplysninger om, hvad de forestiller.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2014-12-11
          &nbsp;·&nbsp; e4b7abfc
          &nbsp;·&nbsp; #40
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.707</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.654</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.688</kbd>
        </footer>
      </article>
      <article>
        <h4>Se 'intelligente terninger' som kopimaskine</h4>
        <div>
          Professor Daniela Rus fra Massachusetts Institiute of Technology og hendes ph.d.-studerende Kyle Gilpin arbejder med algoritmer, der skal få 'intelligente' sandkorn eller terninger til at kommunikere med hinanden for at lave en kopi af en genstand. På denne video forklarer Kyle Gilpin mere præcist, hvordan algoritmen for 3D-kopiering fungerer i en 2D-version.
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2012-04-05
          &nbsp;·&nbsp; e32d4765
          &nbsp;·&nbsp; #41
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.964</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.843</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.547</kbd>
        </footer>
      </article>
      <article>
        <h4>Googles video-AI kan snydes af skjulte budskaber om spaghetti</h4>
        <div>
          Video er et enormt vildnis af information, hvor søgemaskinerne lige nu kommer til kort og hovedsageligt er afhængige af mennesker, som beskriver, hvad videoen forestiller og handler om. Google arbejder på at bruge kunstig intelligens til at analysere eksempelvis de 300 timers video, som hvert sekund uploades til YouTube.Men den kunstige intelligens er langt fra fejlfri.En gruppe forskere fra University of Washington satte sig ifølge Vice Motherboard for at afprøve, hvordan Googles Cloud Video Intelligence API ville klare sig, hvis afsenderen af videoen havde skjulte intentioner.De fire billeder, som blev indsat i tre videoer og gentaget hvert andet sekund.Svaret, ifølge deres paper, er, at det er forholdsvis nemt at få Googles algoritme til at tro, at en video handler om noget helt andet, end det et menneske ville se.En video om Jane Goodall og gorillaer blev eksempelvis fortolket til at handle om 'pasta'ifølge Google.Algoritmer fokuserer på afvigende enkeltbillederMetoden var enkel. Uden at gå i detaljer om, hvordan subliminale budskaber påvirker mennesker eller ej, så brugte forskerne en klassisk tilgang og erstattede et enkeltbillede i filmsekvensen med et billede af noget andet.Forskerne fandt frem til, at hvis man placerede det samme billede hvert andet sekund, eller for hver 50. billede i filmen, så ville Googles algoritme udelukkende fortolke indholdet af hele filmen på lige netop dette billede.For filmen om gorillaer og et billede af en tallerken med spaghetti var Googles kunstige intelligens 99 procent sikker på, at filmen handlede om pasta. Alle de ord, algoritmen knyttede til filmklippet handlede om billedet af spaghettien.Tilsvarende gjorde det sig gældende for tre andre fotos og i to andre filmsekvenser. Når Googles algoritme analyserede de originale filmklip uden de indsatte billeder, kunne algoritmen fortolke dem korrekt.Ulovligt indhold kan skjulesForskerne påpeger, at det gør et system, der forlader sig på denne automatiske analyse, sårbart, fordi det er muligt at få en videosekvens til at fremtræde over for algoritmen som én ting, men i virkeligheden forestiller den noget andet.Det kunne eksempelvis bruges til at promovere et budskab ved at knytte sig til en aktuel begivenhed eller et populært emne, som mange vil søge efter. Eller det kunne skjule, at en video indeholder ulovligt eller anstødeligt indhold.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2017-04-05
          &nbsp;·&nbsp; e6332938
          &nbsp;·&nbsp; #42
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.774</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.648</kbd>
        </footer>
      </article>
      <article>
        <h4>Flydende skærmbånd gør brillefri 3D mere naturtro</h4>
        <div>
          Forskere over hele verden arbejder benhårdt på at give biografgængere og tv-seere mulighed for 3D-effekt uden de lidet flatterende plasticbriller.For en måned siden kom Nintendo på banen med sin håndholdte konsol 3DS, som giver 3D-effekt til computerspil, hvis man vel at mærke holder hovedet nogenlunde samme sted hele tiden. Den har allerede solgt over en million enheder i USA.Også Microsoft er i gang med at udvikle en teknologi, der gør, at man også kan flytte hovedet, fordi kameraer holder øje med øjenpositionen. [aid:110607]Men nu vil en gruppe MIT-forskere få gjort teknologien endnu mere effektiv og handy  og ikke mindst strømbesparende. Problemet med Nintendo 3DS er nemlig, ifølge forskerne, at den måde, skærmen er bygget op på for at give 3D-effekter, suger ufattelig meget energi ud af batteriet, så det kun holder halvt så længe som på en almindelig Nintendo-konsol, dvs. omkring tre timer.Den nye teknologi kalder de HR3D, og det er meningen, at den skal kunne bruges på store skærme, hvor flere følger med  f.eks. en konference- eller biografskærm  uden at 3D-effekten glipper ude i siderne, skriver ScienceDaily. Ligeledes skal 3D-effekten holdes, hvis skærmen bliver tippet 90 grader, hvilket man f.eks. ofte gør på håndholdte enheder.[aid:107513]Postdoc på MIT, Doug Lanman, siger, at Nintendo har benyttet sig af en århundreder gammel teknologi, som kaldes 'parallax barrier' eller parallakse barrierer. Dette begreb dækker over, at man blokerer for det naturlige samarbejde mellem højre og venstre øje om at vurdere en genstands position.Det gør man ved at lægge en ekstra skærm oven på billedet, som indeholder lodrette bånd, der holder billeder til hhv. højre og venstre øje adskilt, så man kan opnå den velkendte dybdefornemmelse i 3D-billeder. Det sker ved, at øjnene kommer til at fokusere på forskellige pixels i billedet.Ulempen ved denne teknologi er imidlertid, at man helst ikke må rykke hovedet for meget, fordi man så ikke kommer til at se de dedikerede pixels fra den rigtige vinkel med det rigtige øje. Men en anden ulempe er også, at fordi disse 'bånd' blokerer for halvdelen af lyset, skal det skrues dobbelt så meget op, før man kan se noget, og derfor dræner den også batteriet på den halve tid.For at løse første problem med at man ikke må rykke hovedet, foreslår MIT-forskerne, at man må lægge mindst 12 forskellige vinkler ind i 3D-skærmen, så man kan fange de rigtige pixels uanset hvor man står i forhold til skærmen. Og det kan måske nok lade sig gøre, men så bliver andet problem bare endnu større  nemlig at der er endnu mere blokering af lys og endnu mere rovdrift på batteriet. Især hvis det også skal være muligt at vende skærmen om, hvilket så vil kræve et helt gitter af barrierer. Flydende 3D-effekt
For at der kommer nok synsvinkler, mener forskerne, at yderskærmen realistisk set vil ende op med at være en ugennemsigtig plade med små huller til de pixels, som øjnene skal fange.Så nu er de endt op med, at LCD-yderskærmen simpelthen skal skræddersys til det billede, der ligger bagved i stedet for at indeholde store lodrette bånd eller små huller. Det vil sige, at skærmen indeholder små bitte bånd i et mønster svarende til billedet, som så skal kunne flytte sig med konturerne i objekterne på skærmen.Fordi båndene er så små og ligger i forskellige retninger, skulle det derfor ikke betyde noget, hvor man står, og i hvilken vinkel man holder sin skærm. De skulle heller ikke blokere for mere lys, end det er nødvendigt.Professor på Cambridge University, Neil Dodgson, kalder opfindelsen for smart, men tvivler dog på en fuld batterigevinst ved at gøre det på denne måde, da processoren jo også hele tiden skal lure på billedet for at finde ud af, hvor båndene skal ligge.»Hvis man sparer batteri, fordi der kommer mere lys til, men faktisk bruger det hele på at lave beregningerne, så sparer man ikke noget,« pointerer han.Denne barriere regner Doug Lanman fra MIT dog med kan overvindes under forfinelsen af algoritmerne, især hvis der også kommer dedikerede chips i maskinen til formålet.
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2011-05-15
          &nbsp;·&nbsp; e2ae87dc
          &nbsp;·&nbsp; #43
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.994</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.87</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.73</kbd>
        </footer>
      </article>
      <article>
        <h4>Googles computer har psykedeliske drømme</h4>
        <div>
          Elektroniske feberfantasier: Androider drømmer ikke om elektriske får - men om hunde med mange øjne.Hvad drømmer en intelligent computer om? Den amerikanske science fiction forfatter Philip K. Dick skrev i 1968 romanen &quot;Drømmer androider om elektriske får-, som siden blev til kultfilmen &quot;Blade Runner.- Bogen sætter spørgsmålstegn ved, hvad det vil sige at være levende. Hvis en robot kan have drømme og længsler, er den så ikke også i live?Hvad der i 1968 var rent hjernespind, er tæt på at være virkeligt i dag. IGoogles forskningslaboratorium for kunstig intelligens har forskerne ladet et neuralt netværk kigge på billeder. Formålet var at undersøge, hvordan computeren kan genkende objekter i billeder.LÆS OGSÅ:Gør smartphones os mere sociale?Resultatet var mildt sagt forbløffende. Ved at justere på følsomheden i billedanalyseprogrammet kan computeren genkende objekter på billederne. Men lige som vi kan se figurer i skyerne eller ane monstre i mørket under sengen, kan computerøjet også opdage flere detaljer, der ikke var der i virkeligheden.PåGoogles blog kan man se en række af de billeder, som computeren opfattede, når den blev fodret med landskaber og skyer. Ud af den kunstige hjerne kom LSD-fantasier og feberdrømme af pagoder og slotte i technicolorlandskaber. Og af hunde med mange øjne og flere hoveder.LÆS OGSÅ:Björks VR-musikvideo er herLÆS OGSÅ:Spotify for ugeblade og magasinerGoogle afprøver lige nu sin førerløse bil på amerikanske veje. Spørgsmålet er, om computeren er ædru nok til at køre?i Googles forskningslaboratorium for kunstig intelligens har en computer opdaget detaljer i billeder, der ikke var der i virkeligheden. Fotos: photos.google.com.Når computeren kigger godt efter, kan den opdage detaljer, der ikke var der..Googles neurale netværk ser hunde overalt. Hunde med mange øjne..Sådan tolker Googles AI Edvard Munchs &quot;Skriget-. Originalt   men egentlig ret troværdigt!.i Googles forskningslaboratorium for kunstig intelligens har en computer opdaget detaljer i billeder, der ikke var der i virkeligheden. Fotos: photos.google.com.Når computeren kigger godt efter, kan den opdage detaljer, der ikke var der..Googles neurale netværk ser hunde overalt. Hunde med mange øjne..Sådan tolker Googles AI Edvard Munchs &quot;Skriget-. Originalt   men egentlig ret troværdigt!.
        </div>
        <footer>
          <em>Jp.dk (Jyllands-Posten)</em>
          &nbsp;·&nbsp; 2015-06-29
          &nbsp;·&nbsp; e51a1280
          &nbsp;·&nbsp; #44
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.965</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.579</kbd>
        </footer>
      </article>
      <article>
        <h4>Når Anita går i byen følger verden med</h4>
        <div>
          Man skal ikke gå mange meter i en større dansk by for at opdage det. De fleste af os har næsen dybt i vores mobiltelefoner og holder resten af verden ude.Og møder du den 50-årige bibliotekar Anita Tejlgaard på gaden, har hun skam også en mobiltelefon i hånden. Men modsat de fleste, bruger hun den til at åbne for verden og fange de bedste indtryk.- Jeg går hele tiden med telefonen i hånden for at kigge igennem søgeren.- Det gør jeg tit, men jeg kan også godt finde på at stoppe op og kigge rundt for at spørge mig selv: Hvad kan det her sted? Anita har altid godt kunnet lide at tage billeder, men de seneste seks år har interessen for alvor taget fart. I dag er hun nemlig en af de danskere, der har samlet mange følgere på Instagram ved at dele de bedste skud fra hendes liv.DET BETYDER DOG IKKE, at de flere end 100.000 følgere ser meget af Anita selv. Hun deler primært flotte billeder af storbyen og den arkitektur, man kan se der.- Det kom meget af, at jeg arbejdede ude i Ørestad, fortæller hun.- Jeg blev fascineret af arkitekturen. Og så begyndte jeg at tage en masse billeder på min mobiltelefon. Og kun med den.- Hvor finder du din største inspiration? - Min hovedkilde som inspiration er byen.Jeg er vokset op på landet, men er meget interesseret i byen og elsker også London og New York.- Jeg er vild med det, som sker mellem bygningerne.Jeg synes, at der er en dynamik, en energi og et drive.- Føler du dig presset til altid at have indhold til dine følgere? - Jeg føler ikke rigtig et pres for at skulle lægge noget ud, da jeg producerer så meget mere, end jeg lægger ud.- På en god dag når jeg at tage minimum 1000 billeder, så lige der er jeg ret produktiv.Og så har jeg altid en masse billeder til overs i mit billedredigeringsprogram, som jeg altid kan tage fra og lægge ud, hvis jeg mangler noget.- Fortæller dine billeder noget om dig selv - De fortæller noget om mig selv på den måde, at jeg har svært ved at dyrke det grimme.- Men jeg skriver tit meget under mine billeder, og det peger mod mig.- Hvordan fik du så mange følgere? - Min historie er, at jeg meget hurtigt blev stor for tre-fire år siden. Og en af tingene, der har hjulpet min profil rigtig meget er, at jeg er blevet delt på Instagrams egen profil.- Det hjalp rigtig meget. Jeg vokser stadig i dag, men det går ikke lige så stærkt.- Er det stadig bare en hobby? Eller er det gået hen og blevet et arbejde for dig? - Altså, det er jo en hobby, hvor jeg kan fordybe mig og være kreativ, men jeg tjener også lidt på det.- Men jeg plejer også at sige, at jeg er glad for mit dagjob, og det holder jeg fast i indtil videre.- Hvis jeg nogensinde skal gøre billeder til mit fuldtidsjob, skal det ikke være igennem Instagram, men som fotograf.ANITA HAR I DAG FÅET et stort netværk ud af sin profil på Instagram og haft mange gode oplevelser.Men selvom tusindvis bogstaveligt talt følger med, når hun går ud i byen, er det sjældent, at hun bliver genkendt.- Jeg mærker ikke så meget, at jeg har så mange følgere i min hverdag. Der er jeg bare Anita, der går på et arbejde, hun godt kan lide.- Jeg bliver aldrig genkendt på gaden, når jeg sidder bag kameraet. Jeg har jo ikke en livsstils profil, så det er ikke mig, der bliver eksponeret. Jeg er bare usynlig.- Men jeg får selvfølgelig en masse mails og henvendelser, jeg skal svare på.Anitas bedste råd til andre, der vil kaste sig over Instagram, er, at man aldrig skal glemme at have det sjovt med det.- Mit primære mål er, at jeg skal hygge mig med det.- Jeg får udfoldet mine kreative sider, og jeg er blevet virkelig glad for at tage billeder. Så det med billederne og min Instagram giver en helt masse ekstra i min hverdag. Det er et sted, man kan fordybe sig.Algoritmen betyder altDet er ikke nok med god vilje og fantastiske billeder, hvis man skal få succes på Instagram.Den algoritme, der styrer, hvor meget ens opslag bliver spredt, er nemlig både lunefuld og nogle gange helt uigennemskuelig.- Alle snakker om algoritmer, og de fylder, forklarer Anita Tejlgaard.- Når instagrammere mødes, så snakker de allermest om algoritmen. Det er en nørdet snak, og vi kan ikke altid regne ud, hvad som sker.- Jeg prøver på ikke at lade det påvirke mig, men selvfølgelig påvirker det mig.- Bliver du påvirket af kommentarer og likes, som gør at du sletter billeder? - Jeg ville lyve, hvis jeg ikke sagde ja. Men jeg har aftalt med mig selv, at jeg helst ikke sletter billeder.- Jeg gør det en sjælden gang, men så handler det om, at man kan fortryde at have postet et billede. Hvis jeg opdager, jeg har postet et billede, som bare ser helt anderledes ud, end jeg havde forestillet mig, kan jeg selvfølgelig godt finde på at slette det.Jeg er vokset op på landet, men er meget interesseret i byen Mit primære mål er, at jeg skal hygge mig med det.Fakta: BAG OM INSTAGRAMInstagram er en tjeneste til at dele billeder og videoer med. Den blev lanceret 6. oktober 2010. Tjenesten har i dag flere end en milliard brugere. Ifølge Kulturministeriet bruger 42 procent af alle danskere Instagram. Blandt de 12 til 18 årige er det hele 78 procent. Den mest fulgte profil er Instagrams egen med 314 millioner følgere. Herefter kommer fo dboldspilleren Cristiano Ronaldo og sangeren Ariana Grande med henholdsvis187 millioner følgere og 165 millioner følgere.ANITAS 5 FOTORÅD1 Brug lyset til at skabe et bedre billede.Kig altid på lyset - måske er der noget naturligt lys eller noget elektronisk lys, der kan ' samarbejde' med billedet?2 Brug linjerne i dit motiv. Er der nogle linjer, der går igennem billedet? Eller er der en tydelig horisontlinje?3 Tag stilling til hvilken type af billede du gerne vil tage. Er det vigtigt, hvad der sker? Eller går du efter et billede, der er mere opstillet og pænt?4 Beskæring er også vigtigt - både når du optager det og redigerer.Ofte får du mere end det nødvendige med i billedet, når du tager det. Måske findes der en naturlig ramme i motivet, du kan udnytte?5 Det er vigtigt at efter-redigere billederne.Det er meget nemt og kan gøres direkte på telefonen. Det betyder meget, selv når du bare laver en hurtig redigering.Anitas egne billederHer er tre billeder, som Anita selv er rigtig glad for.
        </div>
        <footer>
          <em>Ekstra Bladet</em>
          &nbsp;·&nbsp; 2019-10-26
          &nbsp;·&nbsp; e76993d6
          &nbsp;·&nbsp; #45
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.761</kbd>
            <kbd data-tooltip="Testimonies (says, tells...)">L80_TSTMNS&nbsp;0.507</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.648</kbd>
        </footer>
      </article>
      <article>
        <h4>IBM har udviklet AI-malware, der venter med at angribe til det rette øjeblik</h4>
        <div>
          IBM har udviklet proof-of-concept malware baseret på et 'convolutional neural network', som kan forblive i ro indtil helt specifikke betingelser er opfyldtKonceptet hedder DeepLocker og bliver i dag præsenteret på sikkerhedskonferencen Black Hat USA, som bliver afholdt i Las Vegas.Det skriver The Register.Ved at bruge et krypteret payload og samtidig lade et neuralt netværk afgøre, hvornår det skal aktiveres, kan konceptet gøre det væsentligt sværere for sikkerhedsforskere og anti-virus-værktøjer at stoppe malwaren, skriver The Register.IBM har demonstreret konceptet ved at kryptere og gemme en kopi af Wannacry-ransomwaren i en videokommunikations-app sammen med kode, der bruger et neuralt netværk til at afgøre, hvornår en krypteringsnøgle skal frigives.Det neurale netværk, var blevet trænet til at vente indtil et bestemt ansigt blev opfanget på video-appen. Da den rette person satte sig foran PC'en genkendte koden ansigtet, nøglen blev frigivet, payload kørt og systemets dokumenter taget til gidsel.
        </div>
        <footer>
          <em>Version2.dk</em>
          &nbsp;·&nbsp; 2018-08-09
          &nbsp;·&nbsp; e6da5664
          &nbsp;·&nbsp; #46
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.815</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.639</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.65</kbd>
        </footer>
      </article>
      <article>
        <h4>Blogindlæg: AI lærer at se verden - men ikke som mennesker gør</h4>
        <div>
          Ind og ud på 20 minutter, gennemrodede huset, tog for omkring 100 kr. og ødelagde inventar, vinduer og døre for 15.000 kr. - måske skal man bare have en boks på døren, hvor der står &quot;Tag bare denne 500 kr. seddel, der er mindre værdi i huset&quot;. Hvis bare man kunne sende vagtselskabet afsted før alarmen gik!. Inden indbruddet gik der nemlig 15 minutter med at luske rundt, ringe på og kigge i vores udhus. Alt sammen fanget på kamera, hvis bare de havde opfattet, at det var en indbrudstyv. I dag optager kameraerne nemlig når de mærker bevægelse, men hvis jeg skulle have en alarm på min mobiltelefon, hver gang naboens kat går forbi eller ved kraftig blæst, ville jeg hurtigt slå funktionen fra.Der er dog i dag billedgenkendelsesalgoritmer, som ret sikkert kan sige, om det er en kat på billedet. AI-systemer bliver modelleret efter menneskelig biologi, men deres systemer virker ganske anderledes. AI-computer visions systemer kan identificere objekter i billeder ved hjælp af Neurale Netværk, som er inspireret af vores egen biologi. De ligner i deres arkitektur den biologiske sans, hvor neuronerne byttes ud med matematiske funktioner. Nu viser en undersøgelse fra forskere hos Facebook og Virginia Tech, at på trods af disse ligheder, bør vi være forsigtige med at antage, at begge arbejder på samme måde. (Se Robot eyes and humans fix on different things to decode a scene ). For at undersøge, hvad der sker når både mennesker og AI analyserer et billede, studerede forskerne, hvor de to fokuserer deres opmærksomhed. Begge blev forsynet med slørede billeder og stillet spørgsmål om, hvad der skete på billedet - &quot;hvor er katten?&quot; I forsøget kunne dele af billedet selekteres, en ad gangen, og både menneske og AI gjorde det, indtil de kunne svare på spørgsmålet. Holdet gentog testene ved hjælp af flere forskellige algoritmer. Selvfølgelig kunne de begge give svar, men det interessante resultat er, hvordan de gjorde det. På en skala fra 1 til -1, hvor 1 er helt enig og -1 total uenighed, scorede to mennesker i gennemsnit 0,63 i forhold til, hvor de fokuserede deres opmærksomhed på tværs af billedet. Ved krydset mellem et menneske og et Neuralt Netværk faldt gennemsnittet til 0,26. Med andre ord når AI og mennesker kigger på samme billede og får stillet samme spørgsmål er de lige gode, til at komme til et korrekt svar, men kommer til slutningen ved at kigge på forskellige ting på billedet. Bare fordi computere ikke bruger den samme metode, betyder det ikke nødvendigvis, at de er dårligere. Med nye grafikkorts regnekraft bliver det muligt for et PC-system at analysere mange videostrømme samtidig og uden at blive træt eller skulle have ferie.Er det muligt at lave billeder, der snyder AI, til at se ting som ikke er der? Dette er et fænomen forskere har kigget på de sidste par år. Forskere fra Cornell University har vist, at det er muligt at lave billeder, som snyder ved simpelthen at kreere et billede af stærke visuelle features, som softwaren har lært at associerer med et objekt (Se Smart Software Can Be Tricked into Seeing What Isn't There ) Mennesker trækker på en stor 'common sense' viden, som betyder, at vi ikke let bliver snydt af sådanne tricks. Jeg glæder mig til, at min video overvågning kan detektere indbrudstyve før de smadrer noget, så skal jeg bare have en megafon på taget, så jeg kan råbe &quot;forsvind&quot;. Men vi skal huske på, at kriminelle er nogle af de mest kreative innovatorer i verden. Så måske kommer vi i fremtiden til at se indbrudstyve klædt ud som skraldespande eller kronhjorte for at forvirre AI baserede detektionssystemer.
        </div>
        <footer>
          <em>Ing.dk (Ingeniøren)</em>
          &nbsp;·&nbsp; 2018-09-03
          &nbsp;·&nbsp; e6e1ef36
          &nbsp;·&nbsp; #47
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.921</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.71</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.626</kbd>
        </footer>
      </article>
      <article>
        <h4>Instagram sletter folketingsmedlems regeringskritiske billede</h4>
        <div>
          I mange år har politikere og andre magthavere i Danmark fundet sig i satiretegnernes kreative og ofte bidende streg.Mange ofre har gennem årene udtrykt glæde ved den ligefremme kritik, og Folketinget har i årevis købt satiretegninger og udstillet dem på Christiansborg. Genren er blevet en dansk tradition.Sådan forholder det sig tilsyneladende ikke på Instagram, der har slettet et billede, som folketingsmedlem Kristian Hegaard (R) lagde op som en støtteerklæring.Det amerikanske billedmedie har fjernet opslaget på grund af » hadefuld retorik eller symboler « . Billedet er regeringskritisk og forestiller statsminister Mette Frederiksen (S) og hendes højre hånd, stabschef Martin Rossen, der står i en fold med får, der skal forestille borgerne.De to personers hoveder er redigeret ind på to kroppe, der vogter over fårene, hvortil Rossen siger, » Kæft, de er dumme, hva' Mette? « , mens statsministeren står og smiler.Tirsdag blev billedet delt på profilen » dkpolmemes « , der har knap 33.000 følgere og jævnligt lægger billeder eller memes op af politikere fra forskellige partier med kritik eller satire.Billedet blev slettet, og derfor lagde Kristian Hegaard billedet op som en støtteerklæring.Det blev dog også slettet.-Fuldstændig grotesk.Normalt ville jeg ikke selv lægge dette meme op. Som støtteaktion for » dkpolmemes « lagde jeg det op for at teste grænsen for ytringsfrihed på Instagram for et almindeligt regeringskritisk meme. Nu er det slettet på min konto. MF'er må heller ikke kritisere regeringen, skriver han på Twitter.Et meme er et internetfænomen, hvor et billede, videoklip eller lignende, typisk sammen med et stykke tekst, kopieres og deles.Grundloven giver folketingsmedlemmerne en udvidet form for ytringsfrihed, men det gælder, når de taler i Folketinget.I en kommentar fra Facebook, der ejer Instagram, lyder det, at man er ved at undersøge sagen.-Både Facebook og Instagram er steder, hvor der er vide rammer for både debat og kritik, herunder også af regeringer og deres håndtering af den nuværende krise.-Der kan dog være mange andre årsager til, at et opslag bliver taget ned. Hvis der er sket en fejl, vil den naturligvis blive rettet hurtigst muligt, lyder det i en skriftlig kommentar fra Facebook.På grund travlhed under udbrud af coronavirus har begge tjenester overladt meget af deres arbejde med at vurdere indhold til kunstig intelligens.Ritzau har forsøgt at få en kommentar fra statsministeren, men i stedet vendte Socialdemokratiets politiske ordfører, Jesper Petersen, tilbage. Han kalder det et » harmløst opslag « og siger, at debatten i forvejen kører på Christiansborg.-Der er ikke noget konkret lovforslag, men der er en diskussion i Retsudvalget om det her, som også er noget, vi som parti er optaget af. Så må vi se, hvor debatten ender, og om der er behov for, at Folketinget tager affære, siger han/ ritzau/.Som støtteaktion for » dkpolmemes « lagde jeg det op for at teste grænsen for ytringsfrihed på Instagram for et almindeligt regeringskritisk meme. Nu er det slettet på min konto.Kristian Hegaard (R), folketingsmedlem.
        </div>
        <footer>
          <em>Sjællandske Slagelse</em>
          &nbsp;·&nbsp; 2020-05-01
          &nbsp;·&nbsp; e7b02b87
          &nbsp;·&nbsp; #48
          <br>
          <br>
            <kbd data-tooltip="Tech industry &amp; regulation">L02_BIGTEC&nbsp;0.765</kbd>
            <kbd data-tooltip="Facebook, fake news &amp; Trump">L05_FBTRUM&nbsp;0.674</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.642</kbd>
        </footer>
      </article>
      <article>
        <h4>Ansigter kan gøres mindeværdige</h4>
        <div>
          Et computerprogram, der manipulerer ansigter på billeder mere mindeværdige.Det har forskere ved MIT i USA skabt. De har udregnet en algoritme, som manipulerer billeder, så de bliver mere eller mindre mindeværdige. Da forskerne viste de manipulerede billeder til 80 forsøgspersoner, viste det sig, at computerprogrammet havde formået at gøre ansigterne henholdsvis lettere og vanskeligere at huske i mere end syv ud af ti tilfælde.
        </div>
        <footer>
          <em>Jyllands-Posten</em>
          &nbsp;·&nbsp; 2014-02-23
          &nbsp;·&nbsp; e446994a
          &nbsp;·&nbsp; #49
          <br>
          <br>
            <kbd data-tooltip="AI &amp; new algorithmic solutions">L02_AIALGO&nbsp;0.868</kbd>
            <kbd data-tooltip="AI, progress &amp; cybersecurity concerns">L05_AISECUR&nbsp;0.821</kbd>
            <kbd data-tooltip="hSBM 2_0">H_2_0&nbsp;0.649</kbd>
        </footer>
      </article>
    </main>
  </body>
</html>